{"meta":{"version":1,"warehouse":"4.0.2"},"models":{"Asset":[{"_id":"themes/hexo-theme-claudia/source/favicon.ico","path":"favicon.ico","modified":0,"renderable":1},{"_id":"themes/hexo-theme-claudia/source/js/common.js","path":"js/common.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-claudia/source/js/highlight.pack.js","path":"js/highlight.pack.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-claudia/source/js/post.js","path":"js/post.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-claudia/source/style/about.scss","path":"style/about.scss","modified":0,"renderable":1},{"_id":"themes/hexo-theme-claudia/source/style/archive.scss","path":"style/archive.scss","modified":0,"renderable":1},{"_id":"themes/hexo-theme-claudia/source/style/base.scss","path":"style/base.scss","modified":0,"renderable":1},{"_id":"themes/hexo-theme-claudia/source/style/post.scss","path":"style/post.scss","modified":0,"renderable":1},{"_id":"themes/hexo-theme-claudia/source/style/widget-header.scss","path":"style/widget-header.scss","modified":0,"renderable":1},{"_id":"themes/hexo-theme-claudia/source/style/widget-post-list.scss","path":"style/widget-post-list.scss","modified":0,"renderable":1},{"_id":"themes/hexo-theme-claudia/source/style/common/bulma.css","path":"style/common/bulma.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-claudia/source/style/common/helper.scss","path":"style/common/helper.scss","modified":0,"renderable":1},{"_id":"themes/hexo-theme-claudia/source/style/common/variable.scss","path":"style/common/variable.scss","modified":0,"renderable":1},{"_id":"themes/hexo-theme-claudia/source/style/themes/default-dark.scss","path":"style/themes/default-dark.scss","modified":0,"renderable":1},{"_id":"themes/hexo-theme-claudia/source/style/themes/default-light.scss","path":"style/themes/default-light.scss","modified":0,"renderable":1},{"_id":"themes/hexo-theme-claudia/source/style/themes/highlight-theme-light.css","path":"style/themes/highlight-theme-light.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-claudia/source/style/themes/theme.scss","path":"style/themes/theme.scss","modified":0,"renderable":1},{"_id":"source/images/ASO-PRACTICA1.png","path":"images/ASO-PRACTICA1.png","modified":0,"renderable":0},{"_id":"source/images/Ansible.png","path":"images/Ansible.png","modified":0,"renderable":0},{"_id":"source/images/DeepinScreenshot_Seleccionar área_20230109125013.png","path":"images/DeepinScreenshot_Seleccionar área_20230109125013.png","modified":0,"renderable":0},{"_id":"source/images/LDAP-LOGO.png","path":"images/LDAP-LOGO.png","modified":0,"renderable":0},{"_id":"source/images/LOGO-LDAP.png","path":"images/LOGO-LDAP.png","modified":0,"renderable":0},{"_id":"source/images/Untitled-2023-01-10-0143.png","path":"images/Untitled-2023-01-10-0143.png","modified":0,"renderable":0},{"_id":"source/images/ansibleandvagrant.jpg","path":"images/ansibleandvagrant.jpg","modified":0,"renderable":0},{"_id":"source/images/avatar.jpg","path":"images/avatar.jpg","modified":0,"renderable":0},{"_id":"source/images/debian-11.jpg","path":"images/debian-11.jpg","modified":0,"renderable":0},{"_id":"source/images/interfaces.png","path":"images/interfaces.png","modified":0,"renderable":0},{"_id":"source/images/iscsi-1.png","path":"images/iscsi-1.png","modified":0,"renderable":0},{"_id":"source/images/iscsi-2.png","path":"images/iscsi-2.png","modified":0,"renderable":0},{"_id":"source/images/iscsi-3.png","path":"images/iscsi-3.png","modified":0,"renderable":0},{"_id":"source/images/linux-6.0.jpg","path":"images/linux-6.0.jpg","modified":0,"renderable":0},{"_id":"source/images/logo-wireguard.png","path":"images/logo-wireguard.png","modified":0,"renderable":0},{"_id":"source/images/obelix-2.png","path":"images/obelix-2.png","modified":0,"renderable":0},{"_id":"source/images/obelix-3.png","path":"images/obelix-3.png","modified":0,"renderable":0},{"_id":"source/images/obelix-4.jpg","path":"images/obelix-4.jpg","modified":0,"renderable":0},{"_id":"source/images/obelix.png","path":"images/obelix.png","modified":0,"renderable":0},{"_id":"source/images/openstack-1.png","path":"images/openstack-1.png","modified":0,"renderable":0},{"_id":"source/images/oracle-ejercicio1.png","path":"images/oracle-ejercicio1.png","modified":0,"renderable":0},{"_id":"source/images/oracle-ejercicio10.png","path":"images/oracle-ejercicio10.png","modified":0,"renderable":0},{"_id":"source/images/oracle-ejercicio2.png","path":"images/oracle-ejercicio2.png","modified":0,"renderable":0},{"_id":"source/images/oracle-ejercicio3.png","path":"images/oracle-ejercicio3.png","modified":0,"renderable":0},{"_id":"source/images/oracle-ejercicio4.png","path":"images/oracle-ejercicio4.png","modified":0,"renderable":0},{"_id":"source/images/oracle-ejercicio5.png","path":"images/oracle-ejercicio5.png","modified":0,"renderable":0},{"_id":"source/images/oracle-ejercicio6.png","path":"images/oracle-ejercicio6.png","modified":0,"renderable":0},{"_id":"source/images/oracle-ejercicio7.png","path":"images/oracle-ejercicio7.png","modified":0,"renderable":0},{"_id":"source/images/oracle-ejercicio8.png","path":"images/oracle-ejercicio8.png","modified":0,"renderable":0},{"_id":"source/images/oracle-ejercicio9.png","path":"images/oracle-ejercicio9.png","modified":0,"renderable":0},{"_id":"source/images/oracle-postgres.png","path":"images/oracle-postgres.png","modified":0,"renderable":0},{"_id":"source/images/oraclepostgres.jpg","path":"images/oraclepostgres.jpg","modified":0,"renderable":0},{"_id":"source/images/postgres-ejercicio1.png","path":"images/postgres-ejercicio1.png","modified":0,"renderable":0},{"_id":"source/images/postgres-ejercicio2.png","path":"images/postgres-ejercicio2.png","modified":0,"renderable":0},{"_id":"source/images/postgres-oracle.png","path":"images/postgres-oracle.png","modified":0,"renderable":0},{"_id":"source/images/postgres-postgres.png","path":"images/postgres-postgres.png","modified":0,"renderable":0},{"_id":"source/images/prueba-dns-mysql.png","path":"images/prueba-dns-mysql.png","modified":0,"renderable":0},{"_id":"source/images/prueba-dns-mysql2.png","path":"images/prueba-dns-mysql2.png","modified":0,"renderable":0},{"_id":"source/images/slap-1-1.png","path":"images/slap-1-1.png","modified":0,"renderable":0},{"_id":"source/images/slap-1-10.png","path":"images/slap-1-10.png","modified":0,"renderable":0},{"_id":"source/images/slap-1-11.png","path":"images/slap-1-11.png","modified":0,"renderable":0},{"_id":"source/images/slap-1-2.png","path":"images/slap-1-2.png","modified":0,"renderable":0},{"_id":"source/images/slap-1-3.png","path":"images/slap-1-3.png","modified":0,"renderable":0},{"_id":"source/images/slap-1-4.png","path":"images/slap-1-4.png","modified":0,"renderable":0},{"_id":"source/images/slap-1-5.png","path":"images/slap-1-5.png","modified":0,"renderable":0},{"_id":"source/images/slap-1-6.png","path":"images/slap-1-6.png","modified":0,"renderable":0},{"_id":"source/images/slap-1-7.png","path":"images/slap-1-7.png","modified":0,"renderable":0},{"_id":"source/images/slap-1-8.png","path":"images/slap-1-8.png","modified":0,"renderable":0},{"_id":"source/images/slap-1-9.png","path":"images/slap-1-9.png","modified":0,"renderable":0},{"_id":"source/images/systemd-1.png","path":"images/systemd-1.png","modified":0,"renderable":0},{"_id":"source/images/systemd-2.png","path":"images/systemd-2.png","modified":0,"renderable":0},{"_id":"source/images/systemd-3.png","path":"images/systemd-3.png","modified":0,"renderable":0},{"_id":"source/images/systemd-title.jpg","path":"images/systemd-title.jpg","modified":0,"renderable":0},{"_id":"source/images/traceroute-openvpn.png","path":"images/traceroute-openvpn.png","modified":0,"renderable":0},{"_id":"source/images/vistas-dns-1.png","path":"images/vistas-dns-1.png","modified":0,"renderable":0},{"_id":"source/images/vpn-acceso-remoto-ssh-openvpn.png","path":"images/vpn-acceso-remoto-ssh-openvpn.png","modified":0,"renderable":0},{"_id":"source/images/vpn-cliente-C-lin.png","path":"images/vpn-cliente-C-lin.png","modified":0,"renderable":0},{"_id":"source/images/vpn-cliente-C-win.png","path":"images/vpn-cliente-C-win.png","modified":0,"renderable":0},{"_id":"source/images/vpn-cliente-C-win2.png","path":"images/vpn-cliente-C-win2.png","modified":0,"renderable":0},{"_id":"source/images/vpn-cliente1-traceroute.png","path":"images/vpn-cliente1-traceroute.png","modified":0,"renderable":0},{"_id":"source/images/vpn-cliente1.png","path":"images/vpn-cliente1.png","modified":0,"renderable":0},{"_id":"source/images/vpn-cliente2-traceroute.png","path":"images/vpn-cliente2-traceroute.png","modified":0,"renderable":0},{"_id":"source/images/vpn-cliente2.png","path":"images/vpn-cliente2.png","modified":0,"renderable":0},{"_id":"source/images/vpn-logo.png","path":"images/vpn-logo.png","modified":0,"renderable":0},{"_id":"source/images/vpn-site-esquema.png","path":"images/vpn-site-esquema.png","modified":0,"renderable":0},{"_id":"source/images/web-alfa.png","path":"images/web-alfa.png","modified":0,"renderable":0},{"_id":"source/images/wireguard-site-1.png","path":"images/wireguard-site-1.png","modified":0,"renderable":0},{"_id":"source/images/wireguard-site-2.png","path":"images/wireguard-site-2.png","modified":0,"renderable":0},{"_id":"source/images/wireguard-site-3.png","path":"images/wireguard-site-3.png","modified":0,"renderable":0},{"_id":"source/images/wireguard-site-4.png","path":"images/wireguard-site-4.png","modified":0,"renderable":0},{"_id":"source/images/xconfig.png","path":"images/xconfig.png","modified":0,"renderable":0},{"_id":"source/images/xorriso-1.png","path":"images/xorriso-1.png","modified":0,"renderable":0},{"_id":"source/images/xorriso-2.png","path":"images/xorriso-2.png","modified":0,"renderable":0},{"_id":"source/images/xorriso-3.png","path":"images/xorriso-3.png","modified":0,"renderable":0},{"_id":"source/images/xorriso-4.png","path":"images/xorriso-4.png","modified":0,"renderable":0},{"_id":"source/images/iscsi-logo.png","path":"images/iscsi-logo.png","modified":0,"renderable":0},{"_id":"source/images/iscsi-win-1.png","path":"images/iscsi-win-1.png","modified":0,"renderable":0},{"_id":"source/images/iscsi-win-2.png","path":"images/iscsi-win-2.png","modified":0,"renderable":0},{"_id":"source/images/iscsi-win-3.png","path":"images/iscsi-win-3.png","modified":0,"renderable":0},{"_id":"source/images/iscsi-win-4.png","path":"images/iscsi-win-4.png","modified":0,"renderable":0},{"_id":"source/images/iscsi-win-5.png","path":"images/iscsi-win-5.png","modified":0,"renderable":0},{"_id":"source/images/iscsi-win-6.png","path":"images/iscsi-win-6.png","modified":0,"renderable":0},{"_id":"source/images/iscsi-win-7.png","path":"images/iscsi-win-7.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-1-1.png","path":"images/k8s-taller-1-1.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-1-2.png","path":"images/k8s-taller-1-2.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-1-3.png","path":"images/k8s-taller-1-3.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-1-4.png","path":"images/k8s-taller-1-4.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-1-5.png","path":"images/k8s-taller-1-5.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-1-6.png","path":"images/k8s-taller-1-6.png","modified":0,"renderable":0},{"_id":"source/images/k8s-logo.png","path":"images/k8s-logo.png","modified":0,"renderable":0},{"_id":"source/images/docker-logo.png","path":"images/docker-logo.png","modified":0,"renderable":0},{"_id":"source/images/docker-taller-1-1.png","path":"images/docker-taller-1-1.png","modified":0,"renderable":0},{"_id":"source/images/docker-taller1-2.png","path":"images/docker-taller1-2.png","modified":0,"renderable":0},{"_id":"source/images/docker-taller1-3.png","path":"images/docker-taller1-3.png","modified":0,"renderable":0},{"_id":"source/images/docker-taller1-4.png","path":"images/docker-taller1-4.png","modified":0,"renderable":0},{"_id":"source/images/docker-taller2-1.png","path":"images/docker-taller2-1.png","modified":0,"renderable":0},{"_id":"source/images/docker-taller2-2.png","path":"images/docker-taller2-2.png","modified":0,"renderable":0},{"_id":"source/images/docker-taller2-3.png","path":"images/docker-taller2-3.png","modified":0,"renderable":0},{"_id":"source/images/docker-taller2-4.png","path":"images/docker-taller2-4.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-2-1.png","path":"images/k8s-taller-2-1.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-2-2.png","path":"images/k8s-taller-2-2.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-2-3.png","path":"images/k8s-taller-2-3.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-2-4.png","path":"images/k8s-taller-2-4.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-2-5.png","path":"images/k8s-taller-2-5.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-3-1.png","path":"images/k8s-taller-3-1.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-3-2-1.png","path":"images/k8s-taller-3-2-1.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-3-2-2.png","path":"images/k8s-taller-3-2-2.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-3-2-3.png","path":"images/k8s-taller-3-2-3.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-3-2-4.png","path":"images/k8s-taller-3-2-4.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-3-2-5.png","path":"images/k8s-taller-3-2-5.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-3-2-6.png","path":"images/k8s-taller-3-2-6.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-3-2.png","path":"images/k8s-taller-3-2.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-3-3-1.png","path":"images/k8s-taller-3-3-1.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-3-3-2.png","path":"images/k8s-taller-3-3-2.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-3-3.png","path":"images/k8s-taller-3-3.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-3-4.png","path":"images/k8s-taller-3-4.png","modified":0,"renderable":0},{"_id":"source/images/drbd-1.png","path":"images/drbd-1.png","modified":0,"renderable":0},{"_id":"source/images/drbd-logo.png","path":"images/drbd-logo.png","modified":0,"renderable":0},{"_id":"source/images/peek.gif","path":"images/peek.gif","modified":0,"renderable":0},{"_id":"source/images/docker-taller3-1.png","path":"images/docker-taller3-1.png","modified":0,"renderable":0},{"_id":"source/images/docker-taller3-2.png","path":"images/docker-taller3-2.png","modified":0,"renderable":0},{"_id":"source/images/docker-taller3-3.png","path":"images/docker-taller3-3.png","modified":0,"renderable":0},{"_id":"source/images/docker-taller3-4.png","path":"images/docker-taller3-4.png","modified":0,"renderable":0},{"_id":"source/images/docker-taller3-5.png","path":"images/docker-taller3-5.png","modified":0,"renderable":0},{"_id":"source/images/forense-1.png","path":"images/forense-1.png","modified":0,"renderable":0},{"_id":"source/images/forense-19-1.png","path":"images/forense-19-1.png","modified":0,"renderable":0},{"_id":"source/images/forense-19-2.png","path":"images/forense-19-2.png","modified":0,"renderable":0},{"_id":"source/images/forense-19-3.png","path":"images/forense-19-3.png","modified":0,"renderable":0},{"_id":"source/images/forense-19-4.png","path":"images/forense-19-4.png","modified":0,"renderable":0},{"_id":"source/images/forense-2.png","path":"images/forense-2.png","modified":0,"renderable":0},{"_id":"source/images/forense-20.png","path":"images/forense-20.png","modified":0,"renderable":0},{"_id":"source/images/forense-21.png","path":"images/forense-21.png","modified":0,"renderable":0},{"_id":"source/images/forense-22.png","path":"images/forense-22.png","modified":0,"renderable":0},{"_id":"source/images/forense-23.png","path":"images/forense-23.png","modified":0,"renderable":0},{"_id":"source/images/forense-24.png","path":"images/forense-24.png","modified":0,"renderable":0},{"_id":"source/images/forense-25.jpg","path":"images/forense-25.jpg","modified":0,"renderable":0},{"_id":"source/images/forense-25.png","path":"images/forense-25.png","modified":0,"renderable":0},{"_id":"source/images/forense-3.png","path":"images/forense-3.png","modified":0,"renderable":0},{"_id":"source/images/forense-5.png","path":"images/forense-5.png","modified":0,"renderable":0},{"_id":"source/images/forense-8.png","path":"images/forense-8.png","modified":0,"renderable":0},{"_id":"source/images/forense-hash-win.png","path":"images/forense-hash-win.png","modified":0,"renderable":0},{"_id":"source/images/forense-10.png","path":"images/forense-10.png","modified":0,"renderable":0},{"_id":"source/images/forense-11.png","path":"images/forense-11.png","modified":0,"renderable":0},{"_id":"source/images/forense-13.png","path":"images/forense-13.png","modified":0,"renderable":0},{"_id":"source/images/forense-14.png","path":"images/forense-14.png","modified":0,"renderable":0},{"_id":"source/images/forense-15.png","path":"images/forense-15.png","modified":0,"renderable":0},{"_id":"source/images/forense-16.png","path":"images/forense-16.png","modified":0,"renderable":0},{"_id":"source/images/forense-17-1.png","path":"images/forense-17-1.png","modified":0,"renderable":0},{"_id":"source/images/forense-17.png","path":"images/forense-17.png","modified":0,"renderable":0},{"_id":"source/images/forense-18.png","path":"images/forense-18.png","modified":0,"renderable":0},{"_id":"source/images/forense-9.png","path":"images/forense-9.png","modified":0,"renderable":0},{"_id":"source/images/forense-Android-1.png","path":"images/forense-Android-1.png","modified":0,"renderable":0},{"_id":"source/images/forense-Android-2.png","path":"images/forense-Android-2.png","modified":0,"renderable":0},{"_id":"source/images/forense-Android-3.png","path":"images/forense-Android-3.png","modified":0,"renderable":0},{"_id":"source/images/forense-linux-10.png","path":"images/forense-linux-10.png","modified":0,"renderable":0},{"_id":"source/images/forense-linux-11.png","path":"images/forense-linux-11.png","modified":0,"renderable":0},{"_id":"source/images/forense-linux-12.png","path":"images/forense-linux-12.png","modified":0,"renderable":0},{"_id":"source/images/forense-linux-13.png","path":"images/forense-linux-13.png","modified":0,"renderable":0},{"_id":"source/images/forense-linux-15.png","path":"images/forense-linux-15.png","modified":0,"renderable":0},{"_id":"source/images/forense-linux-16.png","path":"images/forense-linux-16.png","modified":0,"renderable":0},{"_id":"source/images/forense-linux-19-1.png","path":"images/forense-linux-19-1.png","modified":0,"renderable":0},{"_id":"source/images/forense-linux-19-2.png","path":"images/forense-linux-19-2.png","modified":0,"renderable":0},{"_id":"source/images/forense-linux-20.png","path":"images/forense-linux-20.png","modified":0,"renderable":0},{"_id":"source/images/forense-linux-21.png","path":"images/forense-linux-21.png","modified":0,"renderable":0},{"_id":"source/images/forense-linux-22.png","path":"images/forense-linux-22.png","modified":0,"renderable":0},{"_id":"source/images/forense-linux-23.png","path":"images/forense-linux-23.png","modified":0,"renderable":0},{"_id":"source/images/forense-linux-24.png","path":"images/forense-linux-24.png","modified":0,"renderable":0},{"_id":"source/images/forense-linux-25.png","path":"images/forense-linux-25.png","modified":0,"renderable":0},{"_id":"source/images/forense-linux-8.png","path":"images/forense-linux-8.png","modified":0,"renderable":0},{"_id":"source/images/forense-linux-9.png","path":"images/forense-linux-9.png","modified":0,"renderable":0},{"_id":"source/images/forense-logo.png","path":"images/forense-logo.png","modified":0,"renderable":0},{"_id":"source/images/forense-linux-18.png","path":"images/forense-linux-18.png","modified":0,"renderable":0},{"_id":"source/images/journal-1.png","path":"images/journal-1.png","modified":0,"renderable":0},{"_id":"source/images/journal-2.png","path":"images/journal-2.png","modified":0,"renderable":0},{"_id":"source/images/journal-3.png","path":"images/journal-3.png","modified":0,"renderable":0},{"_id":"source/images/journal-4.png","path":"images/journal-4.png","modified":0,"renderable":0},{"_id":"source/images/jurnal-logo.png","path":"images/jurnal-logo.png","modified":0,"renderable":0},{"_id":"source/images/favicon.ico","path":"images/favicon.ico","modified":0,"renderable":0},{"_id":"source/images/favicon.png","path":"images/favicon.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-4-1.png","path":"images/k8s-taller-4-1.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-4-2.png","path":"images/k8s-taller-4-2.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-4-3.png","path":"images/k8s-taller-4-3.png","modified":0,"renderable":0},{"_id":"source/images/firewall1-logo.png","path":"images/firewall1-logo.png","modified":0,"renderable":0},{"_id":"source/images/fw1-1.png","path":"images/fw1-1.png","modified":0,"renderable":0},{"_id":"source/images/fw1-10.png","path":"images/fw1-10.png","modified":0,"renderable":0},{"_id":"source/images/fw1-11.png","path":"images/fw1-11.png","modified":0,"renderable":0},{"_id":"source/images/fw1-12.png","path":"images/fw1-12.png","modified":0,"renderable":0},{"_id":"source/images/fw1-13.png","path":"images/fw1-13.png","modified":0,"renderable":0},{"_id":"source/images/fw1-14.png","path":"images/fw1-14.png","modified":0,"renderable":0},{"_id":"source/images/fw1-15.png","path":"images/fw1-15.png","modified":0,"renderable":0},{"_id":"source/images/fw1-16.png","path":"images/fw1-16.png","modified":0,"renderable":0},{"_id":"source/images/fw1-2.png","path":"images/fw1-2.png","modified":0,"renderable":0},{"_id":"source/images/fw1-3.png","path":"images/fw1-3.png","modified":0,"renderable":0},{"_id":"source/images/fw1-4.png","path":"images/fw1-4.png","modified":0,"renderable":0},{"_id":"source/images/fw1-5.png","path":"images/fw1-5.png","modified":0,"renderable":0},{"_id":"source/images/fw1-6.png","path":"images/fw1-6.png","modified":0,"renderable":0},{"_id":"source/images/fw1-7.png","path":"images/fw1-7.png","modified":0,"renderable":0},{"_id":"source/images/fw1-8.png","path":"images/fw1-8.png","modified":0,"renderable":0},{"_id":"source/images/fw1-9.png","path":"images/fw1-9.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-4-4.png","path":"images/k8s-taller-4-4.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-4-5.png","path":"images/k8s-taller-4-5.png","modified":0,"renderable":0},{"_id":"source/images/letschat-minikube-esquema.png","path":"images/letschat-minikube-esquema.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-5-1.png","path":"images/k8s-taller-5-1.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-5-2.png","path":"images/k8s-taller-5-2.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-5-3.png","path":"images/k8s-taller-5-3.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-5-4.png","path":"images/k8s-taller-5-4.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-5-5.png","path":"images/k8s-taller-5-5.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-5-6.png","path":"images/k8s-taller-5-6.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-5-7.png","path":"images/k8s-taller-5-7.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-6-1.png","path":"images/k8s-taller-6-1.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-6-2.png","path":"images/k8s-taller-6-2.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-6-3.png","path":"images/k8s-taller-6-3.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-6-4.png","path":"images/k8s-taller-6-4.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-6-5.png","path":"images/k8s-taller-6-5.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-6-6.png","path":"images/k8s-taller-6-6.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-6-7.png","path":"images/k8s-taller-6-7.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-6-8.gif","path":"images/k8s-taller-6-8.gif","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-6-8.png","path":"images/k8s-taller-6-8.png","modified":0,"renderable":0},{"_id":"source/images/k8s-taller-6-9.gif","path":"images/k8s-taller-6-9.gif","modified":0,"renderable":0},{"_id":"source/images/ldap-2-1.png","path":"images/ldap-2-1.png","modified":0,"renderable":0},{"_id":"source/images/ldap-2-2.png","path":"images/ldap-2-2.png","modified":0,"renderable":0},{"_id":"source/images/ldap-2-3.png","path":"images/ldap-2-3.png","modified":0,"renderable":0},{"_id":"source/images/ldap-2-4.png","path":"images/ldap-2-4.png","modified":0,"renderable":0},{"_id":"source/images/ldap-2-5.png","path":"images/ldap-2-5.png","modified":0,"renderable":0},{"_id":"source/images/ldap-csv-logo.png","path":"images/ldap-csv-logo.png","modified":0,"renderable":0},{"_id":"source/images/nazareth1.jpeg","path":"images/nazareth1.jpeg","modified":0,"renderable":0},{"_id":"source/images/rober1.jpeg","path":"images/rober1.jpeg","modified":0,"renderable":0},{"_id":"source/images/audit-1.png","path":"images/audit-1.png","modified":0,"renderable":0},{"_id":"source/images/audit-2.png","path":"images/audit-2.png","modified":0,"renderable":0},{"_id":"source/images/audit-3.png","path":"images/audit-3.png","modified":0,"renderable":0},{"_id":"source/images/audit-4.png","path":"images/audit-4.png","modified":0,"renderable":0},{"_id":"source/images/audit-5.png","path":"images/audit-5.png","modified":0,"renderable":0},{"_id":"source/images/audit-6.png","path":"images/audit-6.png","modified":0,"renderable":0},{"_id":"source/images/audit-7.png","path":"images/audit-7.png","modified":0,"renderable":0},{"_id":"source/images/audit-10.png","path":"images/audit-10.png","modified":0,"renderable":0},{"_id":"source/images/audit-11.png","path":"images/audit-11.png","modified":0,"renderable":0},{"_id":"source/images/audit-12.png","path":"images/audit-12.png","modified":0,"renderable":0},{"_id":"source/images/audit-13.png","path":"images/audit-13.png","modified":0,"renderable":0},{"_id":"source/images/audit-14.png","path":"images/audit-14.png","modified":0,"renderable":0},{"_id":"source/images/audit-15.png","path":"images/audit-15.png","modified":0,"renderable":0},{"_id":"source/images/audit-16.png","path":"images/audit-16.png","modified":0,"renderable":0},{"_id":"source/images/audit-17.png","path":"images/audit-17.png","modified":0,"renderable":0},{"_id":"source/images/audit-18.png","path":"images/audit-18.png","modified":0,"renderable":0},{"_id":"source/images/audit-19.png","path":"images/audit-19.png","modified":0,"renderable":0},{"_id":"source/images/audit-20.png","path":"images/audit-20.png","modified":0,"renderable":0},{"_id":"source/images/audit-21.png","path":"images/audit-21.png","modified":0,"renderable":0},{"_id":"source/images/audit-22.png","path":"images/audit-22.png","modified":0,"renderable":0},{"_id":"source/images/audit-8.png","path":"images/audit-8.png","modified":0,"renderable":0},{"_id":"source/images/audit-9.png","path":"images/audit-9.png","modified":0,"renderable":0},{"_id":"source/images/audit-logo.png","path":"images/audit-logo.png","modified":0,"renderable":0},{"_id":"source/images/helm-1.png","path":"images/helm-1.png","modified":0,"renderable":0},{"_id":"source/images/helm-2.png","path":"images/helm-2.png","modified":0,"renderable":0},{"_id":"source/images/helm-3.png","path":"images/helm-3.png","modified":0,"renderable":0},{"_id":"source/images/helm-4.png","path":"images/helm-4.png","modified":0,"renderable":0},{"_id":"source/images/helm-5.png","path":"images/helm-5.png","modified":0,"renderable":0},{"_id":"source/images/helm-6.png","path":"images/helm-6.png","modified":0,"renderable":0},{"_id":"source/images/logo-helm.png","path":"images/logo-helm.png","modified":0,"renderable":0},{"_id":"source/images/helm-7.png","path":"images/helm-7.png","modified":0,"renderable":0},{"_id":"source/images/audit-23.png","path":"images/audit-23.png","modified":0,"renderable":0},{"_id":"source/images/audit-24.png","path":"images/audit-24.png","modified":0,"renderable":0},{"_id":"source/images/audit-25.png","path":"images/audit-25.png","modified":0,"renderable":0},{"_id":"source/images/audit-26.png","path":"images/audit-26.png","modified":0,"renderable":0},{"_id":"source/images/audit-27.png","path":"images/audit-27.png","modified":0,"renderable":0},{"_id":"source/images/audit-28.png","path":"images/audit-28.png","modified":0,"renderable":0},{"_id":"source/images/audit-29.png","path":"images/audit-29.png","modified":0,"renderable":0},{"_id":"source/images/audit-30.png","path":"images/audit-30.png","modified":0,"renderable":0},{"_id":"source/images/audit-31.png","path":"images/audit-31.png","modified":0,"renderable":0},{"_id":"source/images/docker-1.png","path":"images/docker-1.png","modified":0,"renderable":0},{"_id":"source/images/docker-10.png","path":"images/docker-10.png","modified":0,"renderable":0},{"_id":"source/images/docker-11.png","path":"images/docker-11.png","modified":0,"renderable":0},{"_id":"source/images/docker-12.png","path":"images/docker-12.png","modified":0,"renderable":0},{"_id":"source/images/docker-13.png","path":"images/docker-13.png","modified":0,"renderable":0},{"_id":"source/images/docker-2.png","path":"images/docker-2.png","modified":0,"renderable":0},{"_id":"source/images/docker-3.png","path":"images/docker-3.png","modified":0,"renderable":0},{"_id":"source/images/docker-4.png","path":"images/docker-4.png","modified":0,"renderable":0},{"_id":"source/images/docker-5.png","path":"images/docker-5.png","modified":0,"renderable":0},{"_id":"source/images/docker-6.png","path":"images/docker-6.png","modified":0,"renderable":0},{"_id":"source/images/docker-7.png","path":"images/docker-7.png","modified":0,"renderable":0},{"_id":"source/images/docker-8.png","path":"images/docker-8.png","modified":0,"renderable":0},{"_id":"source/images/docker-9.png","path":"images/docker-9.png","modified":0,"renderable":0},{"_id":"source/images/docker-logo-2.png","path":"images/docker-logo-2.png","modified":0,"renderable":0},{"_id":"source/images/ldaps-1.png","path":"images/ldaps-1.png","modified":0,"renderable":0},{"_id":"source/images/ldaps-2.png","path":"images/ldaps-2.png","modified":0,"renderable":0},{"_id":"source/images/ldaps-3.png","path":"images/ldaps-3.png","modified":0,"renderable":0},{"_id":"source/images/ldaps-4.png","path":"images/ldaps-4.png","modified":0,"renderable":0},{"_id":"source/images/ldaps-5.png","path":"images/ldaps-5.png","modified":0,"renderable":0},{"_id":"source/images/ldaps-6.png","path":"images/ldaps-6.png","modified":0,"renderable":0},{"_id":"source/images/ldaps-7.png","path":"images/ldaps-7.png","modified":0,"renderable":0},{"_id":"source/images/ldaps-8.gif","path":"images/ldaps-8.gif","modified":0,"renderable":0},{"_id":"source/images/ldaps-logo.png","path":"images/ldaps-logo.png","modified":0,"renderable":0},{"_id":"source/images/django-1.png","path":"images/django-1.png","modified":0,"renderable":0},{"_id":"source/images/django-2.png","path":"images/django-2.png","modified":0,"renderable":0},{"_id":"source/images/django-3.png","path":"images/django-3.png","modified":0,"renderable":0},{"_id":"source/images/docker-django.png","path":"images/docker-django.png","modified":0,"renderable":0},{"_id":"source/images/bookmedik-1.png","path":"images/bookmedik-1.png","modified":0,"renderable":0},{"_id":"source/images/bookmedik-2.gif","path":"images/bookmedik-2.gif","modified":0,"renderable":0},{"_id":"source/images/bookmedik-2.png","path":"images/bookmedik-2.png","modified":0,"renderable":0},{"_id":"source/images/bookmedik-3.png","path":"images/bookmedik-3.png","modified":0,"renderable":0},{"_id":"source/images/bookmedik-4.png","path":"images/bookmedik-4.png","modified":0,"renderable":0},{"_id":"source/images/bookmedik-5.png","path":"images/bookmedik-5.png","modified":0,"renderable":0},{"_id":"source/images/bookmedik-6.png","path":"images/bookmedik-6.png","modified":0,"renderable":0},{"_id":"source/images/bookmedik-7.png","path":"images/bookmedik-7.png","modified":0,"renderable":0},{"_id":"source/images/bookmedik-8.png","path":"images/bookmedik-8.png","modified":0,"renderable":0},{"_id":"source/images/bookmedik-9.png","path":"images/bookmedik-9.png","modified":0,"renderable":0},{"_id":"source/images/k8s-logo-2.png","path":"images/k8s-logo-2.png","modified":0,"renderable":0},{"_id":"source/images/centos-1.png","path":"images/centos-1.png","modified":0,"renderable":0},{"_id":"source/images/centos-10.png","path":"images/centos-10.png","modified":0,"renderable":0},{"_id":"source/images/centos-11.png","path":"images/centos-11.png","modified":0,"renderable":0},{"_id":"source/images/centos-12.png","path":"images/centos-12.png","modified":0,"renderable":0},{"_id":"source/images/centos-13.png","path":"images/centos-13.png","modified":0,"renderable":0},{"_id":"source/images/centos-14.png","path":"images/centos-14.png","modified":0,"renderable":0},{"_id":"source/images/centos-15.png","path":"images/centos-15.png","modified":0,"renderable":0},{"_id":"source/images/centos-16.png","path":"images/centos-16.png","modified":0,"renderable":0},{"_id":"source/images/centos-17.png","path":"images/centos-17.png","modified":0,"renderable":0},{"_id":"source/images/centos-18.png","path":"images/centos-18.png","modified":0,"renderable":0},{"_id":"source/images/centos-19.png","path":"images/centos-19.png","modified":0,"renderable":0},{"_id":"source/images/centos-2.png","path":"images/centos-2.png","modified":0,"renderable":0},{"_id":"source/images/centos-20.png","path":"images/centos-20.png","modified":0,"renderable":0},{"_id":"source/images/centos-21.png","path":"images/centos-21.png","modified":0,"renderable":0},{"_id":"source/images/centos-22.png","path":"images/centos-22.png","modified":0,"renderable":0},{"_id":"source/images/centos-23.png","path":"images/centos-23.png","modified":0,"renderable":0},{"_id":"source/images/centos-24.png","path":"images/centos-24.png","modified":0,"renderable":0},{"_id":"source/images/centos-25.png","path":"images/centos-25.png","modified":0,"renderable":0},{"_id":"source/images/centos-26.png","path":"images/centos-26.png","modified":0,"renderable":0},{"_id":"source/images/centos-27.png","path":"images/centos-27.png","modified":0,"renderable":0},{"_id":"source/images/centos-3.png","path":"images/centos-3.png","modified":0,"renderable":0},{"_id":"source/images/centos-4.png","path":"images/centos-4.png","modified":0,"renderable":0},{"_id":"source/images/centos-5.png","path":"images/centos-5.png","modified":0,"renderable":0},{"_id":"source/images/centos-6.png","path":"images/centos-6.png","modified":0,"renderable":0},{"_id":"source/images/centos-7.png","path":"images/centos-7.png","modified":0,"renderable":0},{"_id":"source/images/centos-8.png","path":"images/centos-8.png","modified":0,"renderable":0},{"_id":"source/images/centos-9.png","path":"images/centos-9.png","modified":0,"renderable":0},{"_id":"source/images/jenkins-taller-1-2.png","path":"images/jenkins-taller-1-2.png","modified":0,"renderable":0},{"_id":"source/images/jenkins-taller-1-1.png","path":"images/jenkins-taller-1-1.png","modified":0,"renderable":0},{"_id":"source/images/jenkins-taller-1-3.png","path":"images/jenkins-taller-1-3.png","modified":0,"renderable":0},{"_id":"source/images/jenkins-taller-1-4.png","path":"images/jenkins-taller-1-4.png","modified":0,"renderable":0},{"_id":"source/images/jenkins-taller-2-1.png","path":"images/jenkins-taller-2-1.png","modified":0,"renderable":0},{"_id":"source/images/jenkins-taller-2-2.gif","path":"images/jenkins-taller-2-2.gif","modified":0,"renderable":0},{"_id":"source/images/jenkins-taller-3-1.png","path":"images/jenkins-taller-3-1.png","modified":0,"renderable":0},{"_id":"source/images/jenkins-taller-3-2.png","path":"images/jenkins-taller-3-2.png","modified":0,"renderable":0},{"_id":"source/images/jenkins-taller-3-3.png","path":"images/jenkins-taller-3-3.png","modified":0,"renderable":0},{"_id":"source/images/jenkins-taller-3-4.png","path":"images/jenkins-taller-3-4.png","modified":0,"renderable":0},{"_id":"source/images/jenkins-taller-3-5.png","path":"images/jenkins-taller-3-5.png","modified":0,"renderable":0},{"_id":"source/images/practica-jenkins-1-1.png","path":"images/practica-jenkins-1-1.png","modified":0,"renderable":0},{"_id":"source/images/practica-jenkins-1.png","path":"images/practica-jenkins-1.png","modified":0,"renderable":0},{"_id":"source/images/practica-jenkins-2-2.png","path":"images/practica-jenkins-2-2.png","modified":0,"renderable":0},{"_id":"source/images/practica-jenkins-2.png","path":"images/practica-jenkins-2.png","modified":0,"renderable":0},{"_id":"source/images/practica-jenkins-3.png","path":"images/practica-jenkins-3.png","modified":0,"renderable":0},{"_id":"source/images/practica-jenkins-4.png","path":"images/practica-jenkins-4.png","modified":0,"renderable":0},{"_id":"source/images/jenkins-intro.png","path":"images/jenkins-intro.png","modified":0,"renderable":0},{"_id":"source/images/jenkins-logo.png","path":"images/jenkins-logo.png","modified":0,"renderable":0},{"_id":"source/images/practica-jenkins-5.png","path":"images/practica-jenkins-5.png","modified":0,"renderable":0}],"Cache":[{"_id":"source/_posts/integrar-apps-java","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1674094242851},{"_id":"source/_posts/ASO-apt","hash":"58651a3afad1eaf2dc57fbad5ea100fa0203e374","modified":1666079919771},{"_id":"source/_posts/Ansible+Vagrant.md","hash":"f16fe692a015725f692752efe5e6430dcd695ae4","modified":1672839760307},{"_id":"source/_posts/Compilar-en-debian.md","hash":"fa42ea6c4789d8bf4e23a64c1dbf7d6fc2778feb","modified":1666182858078},{"_id":"source/_posts/Compilar-linux-a-medida.md","hash":"e87c177dbbd2247c36fec26bdeb1a9b7e81b3183","modified":1672839773119},{"_id":"source/_posts/Interconexiones.md","hash":"b6e505842945cb1181d5d76d52085c84f21257ee","modified":1672838971339},{"_id":"source/_posts/LXC","hash":"b7e3389db1f6f9654fca496228c1339f2a20fec6","modified":1674719359758},{"_id":"source/_posts/Migrar-Apache-Nginx","hash":"45deaffa752a62f106eebe8f414c017e420ee937","modified":1672838744195},{"_id":"source/_posts/Oracle","hash":"9f470338d2d0c089e71abcd6a13cf79b98d63150","modified":1665053428959},{"_id":"source/_posts/Preseed-pxe.md","hash":"377da3a373b4325a735fe22e2f9fd34265088f13","modified":1672839284707},{"_id":"source/_posts/compilar-kernel-linux","hash":"d11a382baafc4e825524880b2c67ab93eb00e386","modified":1666783344286},{"_id":"source/_posts/dns-vistas.md","hash":"f036b799301c17913ee260fe322a0ae43070aa1a","modified":1673790153828},{"_id":"source/_posts/dns.md","hash":"f1d0e3097a857c33ac318c26cc870dcc5804569a","modified":1673311092677},{"_id":"source/_posts/docker","hash":"9edf035944a3ae6c4c7af8f35152eb42cc19561c","modified":1674739897009},{"_id":"source/_posts/examen-bdd","hash":"2852041b1361ba39ef3ac8472858c649151850c1","modified":1669803039552},{"_id":"source/_posts/iscsi","hash":"b1c8a6a4f752da6c9794685e5acb2acb080214d6","modified":1674725929836},{"_id":"source/_posts/nfs-systemd.md","hash":"d74bf35c0585dc6621b77730035e1ce5344c3b52","modified":1672839266899},{"_id":"source/_posts/openstack","hash":"5f022847f33542c6e74e3d8d3fd78ec91625a29a","modified":1669704201096},{"_id":"source/_posts/plsql_basico.md","hash":"818be56f2a02ddb091948db32e78f866c6f76668","modified":1676599268792},{"_id":"source/_posts/preseed.md","hash":"37a4971423621f4da09879289ffcc57dca512a24","modified":1672839306211},{"_id":"source/_posts/slap-nfs.md","hash":"486795a2c27830b2e913a8c267eb900ac560d2cc","modified":1675236693784},{"_id":"source/_posts/systemd","hash":"559b8a756bad066ef47dc3a6b0f19e7602f8e352","modified":1670920562645},{"_id":"source/_posts/vpn-wireguard.md","hash":"967694db5e4145f8edb7ed0dba1927f132862191","modified":1675172009550},{"_id":"source/archives/index.md","hash":"7d0c0d0627957bdb2cc8295ec97687aea1473cd0","modified":1664448164348},{"_id":"source/_posts/vpn.md","hash":"6aab9fe31e16f7800a0e93cf3db5ee60d60d9845","modified":1674943004525},{"_id":"source/about/index.md","hash":"cd386b326ee9bedd85b97a3150818e01d337450c","modified":1664448166932},{"_id":"source/categories/index.md","hash":"4f4b2d0a3dea2866229a4071a48902cccc436dd7","modified":1664448165208},{"_id":"source/images/DeepinScreenshot_Seleccionar área_20230109125013.png","hash":"c8f5fe4a30991d0d1a1580a8a75b12915aa7c6db","modified":1673265013059},{"_id":"source/images/LDAP-LOGO.png","hash":"4ca32c33412131db35a8211279b273bb2dbd205a","modified":1675228539368},{"_id":"source/images/LOGO-LDAP.png","hash":"8f0e96e3751a0e4132a324130b509037142e1923","modified":1675228667048},{"_id":"source/images/ansibleandvagrant.jpg","hash":"971466418b3ab8273ecadd85ee0e4db1b0dca8aa","modified":1665683165056},{"_id":"source/images/debian-11.jpg","hash":"0ec714f3546f8aa4e1dec561f22200a1a7e834f7","modified":1665957485105},{"_id":"source/images/iscsi-2.png","hash":"8224bed1ef784765bfe1250f699f602934ff5694","modified":1675287354280},{"_id":"source/images/iscsi-3.png","hash":"30612c83110853a0aecf9c74cb01b864a2066394","modified":1674723991383},{"_id":"source/images/logo-wireguard.png","hash":"ba7901e5e8974e849fcd5ee9fc346ab6c38f058a","modified":1674786738124},{"_id":"source/images/obelix-4.jpg","hash":"41deba00d16881be564bc3c2b6c38b6c9edcbbe2","modified":1670973813189},{"_id":"source/images/oracle-ejercicio1.png","hash":"29dd25a06447a8f4fa535a383e0031d72338c00d","modified":1670378458548},{"_id":"source/images/oracle-ejercicio10.png","hash":"e76c08f41feb072224354119f1f301707e9801e3","modified":1670380058755},{"_id":"source/images/oracle-ejercicio2.png","hash":"e8048be041d163e7a1985897b2f139bc3fa8cc37","modified":1670378563000},{"_id":"source/images/oracle-ejercicio3.png","hash":"ea378d9e3203e7277679b0b1cf0fe7005c649864","modified":1670379090152},{"_id":"source/images/oracle-ejercicio4.png","hash":"33cdc878dffce0c026dcf2955486ed7cf924b801","modified":1670379189912},{"_id":"source/images/oracle-ejercicio5.png","hash":"6cec63601b96812d96b3287b95a34f1b1bd8b164","modified":1670379436679},{"_id":"source/images/oracle-ejercicio7.png","hash":"7e2e58dfc9f67bbb26c2b2eff374da3ae8241f07","modified":1670379678807},{"_id":"source/images/oracle-ejercicio8.png","hash":"df6b429fec204dc994166f53f45d9b57f45b5e3b","modified":1670379724671},{"_id":"source/images/oracle-postgres.png","hash":"7e094bc8ebd39321abae95dcb7ba2b791f832ce8","modified":1669294309291},{"_id":"source/images/postgres-ejercicio1.png","hash":"c779d6d4b5d87523b52d110370412caa5a33e406","modified":1670378122360},{"_id":"source/images/oraclepostgres.jpg","hash":"49f24db75b5a65e82eebf7885eb3144e93fece84","modified":1670380544431},{"_id":"source/images/postgres-ejercicio2.png","hash":"04c9e70b5f3190ceda891bb9f955800af866de84","modified":1670378374568},{"_id":"source/images/postgres-postgres.png","hash":"3088be58cdf85b4b7a2bdfad7fee66d2b4361707","modified":1669303696740},{"_id":"source/images/prueba-dns-mysql2.png","hash":"e3771b76bcef65de8246116704b2b1b72116d06c","modified":1673315034461},{"_id":"source/images/slap-1-2.png","hash":"f0095156418e8020d57e46705c923dbe3adb2cc2","modified":1675210551744},{"_id":"source/images/slap-1-4.png","hash":"33cd347b0bc84ef8055c883d03b8908dcc023bc9","modified":1675212175016},{"_id":"source/images/slap-1-5.png","hash":"07e3c259878958b9e172bd578f978ec0997fe2d0","modified":1675212820148},{"_id":"source/images/slap-1-7.png","hash":"b50e3a83c85685c034a8701d49ef3c2cd496b3ad","modified":1675215049140},{"_id":"source/images/slap-1-6.png","hash":"8f5455d42738ec8b3fa94559d431a07f57e029b0","modified":1675212995596},{"_id":"source/images/slap-1-8.png","hash":"911ce0b78c9d5656525d2e5b390ee418b6bd63a1","modified":1675218253732},{"_id":"source/images/slap-1-9.png","hash":"ea5552dcbd876cbf921fe633ed7d40d52c21a6e6","modified":1675220818296},{"_id":"source/images/traceroute-openvpn.png","hash":"df547bcd8779208925a87598dba72a929255f148","modified":1674685997933},{"_id":"source/images/vpn-cliente-C-lin.png","hash":"41207c845de1a19270fdf2c30c84473c494541f4","modified":1674931269609},{"_id":"source/images/vpn-cliente1-traceroute.png","hash":"f7f6b6f4b5343a04dec8fe9f3955d70ceaea9618","modified":1674699944617},{"_id":"source/images/vpn-cliente2-traceroute.png","hash":"6df66844ef593a700cfcbde2f12beaab9a62fcd8","modified":1674699995721},{"_id":"source/images/vpn-logo.png","hash":"6ff76f203702e5484a9a31ac88bb57beab17e1fc","modified":1674701026469},{"_id":"source/images/wireguard-site-2.png","hash":"df98cec5dafd87ce85a1e0006e20260278537fbd","modified":1674785920272},{"_id":"source/tags/index.md","hash":"d1e1645001288189b944c03ddac11c48b3964413","modified":1664968155316},{"_id":"source/images/ASO-PRACTICA1.png","hash":"7835d5258c3db2e4ff89d9a3b68d878de321a2d7","modified":1664474618526},{"_id":"source/images/Ansible.png","hash":"bb2219f79f255fd314a7a30ff5c1ea836e59e45c","modified":1665684412756},{"_id":"source/images/obelix-3.png","hash":"df792e4fbc26d4e49cf0d96a29cc7fdb5fe22df2","modified":1670973080209},{"_id":"source/images/obelix-2.png","hash":"095139626f99764efecc71aa7ec3c9dd277bcfe8","modified":1670970878781},{"_id":"source/images/obelix.png","hash":"0685e54f4641567c507545d0a5f62849a53c30f6","modified":1670969485265},{"_id":"source/images/oracle-ejercicio9.png","hash":"65cf3e3f684daab8b4d4350955d2d5549ae58635","modified":1670379782275},{"_id":"source/images/postgres-oracle.png","hash":"2108b5c5062f5ac874786078e55637dadd245c4a","modified":1669301117092},{"_id":"source/images/prueba-dns-mysql.png","hash":"24be237fd026bae7bf47101b51597d5488de393d","modified":1673314889313},{"_id":"source/images/slap-1-1.png","hash":"26cc09b1e5b77a9b1fac8c5ada98fcd7f94c32f6","modified":1675209625676},{"_id":"source/images/slap-1-10.png","hash":"c39b04a4fd8e580f1b801f097484b6a712a6a4c0","modified":1675221664808},{"_id":"source/images/slap-1-11.png","hash":"88d064d8b4ce0f77ac41c958e6cdf4c51f918c1b","modified":1675228261924},{"_id":"source/images/systemd-1.png","hash":"f5a54a913b85f7e815e3fe1eed43eee11e5abc28","modified":1672754513717},{"_id":"source/images/systemd-2.png","hash":"bb80e91aeffeb304d5d5800148da30a2ee1d0e4b","modified":1672777624132},{"_id":"source/images/systemd-3.png","hash":"2bfcf433b7417607980bc503982e0a7f906d5e05","modified":1672777820092},{"_id":"source/images/systemd-title.jpg","hash":"6552098416a1ccecd84c86102e815b231d426d4a","modified":1672778567432},{"_id":"source/images/vpn-acceso-remoto-ssh-openvpn.png","hash":"2feeb9b251549130bda54d5a0416816e778f770a","modified":1674685019653},{"_id":"source/images/vpn-cliente1.png","hash":"ce417062cef920c7cf46b9d860bc50900571f00d","modified":1674699642877},{"_id":"source/images/vpn-cliente2.png","hash":"26f92ef87cb189c9bc86cd010ea2639bc79f696d","modified":1674699678533},{"_id":"source/images/xorriso-2.png","hash":"c14d072f96c297e98913ea1492395b3069b0568e","modified":1665958312449},{"_id":"source/images/xorriso-3.png","hash":"73ec7f50ca43b000120a460d765b1305ad064cf1","modified":1665958689513},{"_id":"source/images/xorriso-4.png","hash":"a6bbd021a01b5873eee676f8dc395a1b6c4020fc","modified":1665963675157},{"_id":"source/images/interfaces.png","hash":"09b65917ff81f7ab32727becb66e124b50f1c3a8","modified":1665684992696},{"_id":"source/images/iscsi-1.png","hash":"074def37d31e717f64aeeeb9b661d58d44e84d51","modified":1674720336582},{"_id":"source/images/openstack-1.png","hash":"bef024c334c2c76de1b1e424da669f59fa30a2ba","modified":1669547985501},{"_id":"source/images/oracle-ejercicio6.png","hash":"991b7d4599d67b9be602b678359993197118e535","modified":1670379503791},{"_id":"source/images/slap-1-3.png","hash":"578d1bc0e5451eb1128f7f290122759a17e3a4a8","modified":1675210720108},{"_id":"source/images/vpn-cliente-C-win2.png","hash":"9181fc162112c31a8cced20c9df3cacfa5274d44","modified":1674931443137},{"_id":"source/images/web-alfa.png","hash":"5e12750488680d46f2b3898f53ea433fd529a30f","modified":1673317144944},{"_id":"source/images/xorriso-1.png","hash":"22495b789d51bab231b0ebd499e931751cd926af","modified":1665958115337},{"_id":"source/images/Untitled-2023-01-10-0143.png","hash":"595586ea75d531b1bc561d405d2fa330d46a1338","modified":1673312269233},{"_id":"source/images/linux-6.0.jpg","hash":"e89d19a4881437b2fafd6449282aa8167c29f555","modified":1668647690461},{"_id":"source/images/vpn-cliente-C-win.png","hash":"ca4c33a76a761fe8bc7af32e8172d2b0af02d78e","modified":1674931028117},{"_id":"source/images/vpn-site-esquema.png","hash":"a9e5d42add7c2c3737a08247cf3a0b5c669566a7","modified":1674698416261},{"_id":"source/images/wireguard-site-3.png","hash":"602695aee2eccb46a58d08c52135cdeb7bb58b0b","modified":1674786232292},{"_id":"source/images/wireguard-site-4.png","hash":"f049ed5685dc7a251f59a43d9061cc1d8d339fc8","modified":1674786315832},{"_id":"source/images/vistas-dns-1.png","hash":"296a712b836268cd0c5652317898f20dcc6807fa","modified":1673317770068},{"_id":"source/images/xconfig.png","hash":"51356565c80c184def49c0519c7d69b5f645ba49","modified":1668647275249},{"_id":"themes/hexo-theme-claudia/.gitignore","hash":"bd20d54c57507594cd16a21021c3600f9311a1f5","modified":1664451874440},{"_id":"themes/hexo-theme-claudia/CONTRIBUTING.md","hash":"618215987cc9a774c37cc70efa1cb8545457a49c","modified":1664451874440},{"_id":"themes/hexo-theme-claudia/CHANGELOG.md","hash":"6a2a5c3e4399d19fa06c175bc7e78c9b18413251","modified":1664451874440},{"_id":"themes/hexo-theme-claudia/CODE_OF_CONDUCT.md","hash":"787b987cd6079f93c7846b69c3b4dfa41cb3ac03","modified":1664451874440},{"_id":"themes/hexo-theme-claudia/LICENSE","hash":"9812afb9d0aa8596067b6fd30cf6089345b7b678","modified":1664451874440},{"_id":"themes/hexo-theme-claudia/package.json","hash":"c59cb2089c51ed56deb2df69171d7adc63c1148f","modified":1664451874444},{"_id":"themes/hexo-theme-claudia/README.md","hash":"17911c948337830658d8322b6b9e37e8431b7b64","modified":1664451874440},{"_id":"themes/hexo-theme-claudia/_config.yml","hash":"68f14c8f5f276e7d306d23c5b9fd6b61c6ecc9ee","modified":1664969298756},{"_id":"themes/hexo-theme-claudia/README-CN.md","hash":"2dddb18f2761b5e495d6f71ab9880797af839926","modified":1664451874440},{"_id":"themes/hexo-theme-claudia/.github/FUNDING.yml","hash":"dd672081ec4678929f6c1ac3ebbef4d990291ecd","modified":1664451874440},{"_id":"themes/hexo-theme-claudia/languages/en.yml","hash":"52f0fa56a60333dccc19c3be1e4bcc8085668d5a","modified":1664969412168},{"_id":"themes/hexo-theme-claudia/.github/PULL_REQUEST_TEMPLATE.md","hash":"35751990a36fffe5a5f6fd682452fe5594cadde9","modified":1664451874440},{"_id":"themes/hexo-theme-claudia/languages/zh-CN.yml","hash":"9d8b1f0a337f56907aadddf406c5977435d34fc1","modified":1664451874440},{"_id":"themes/hexo-theme-claudia/layout/about.pug","hash":"98dea176f76053d5deaf35ed25518d218d70be7d","modified":1664451874440},{"_id":"themes/hexo-theme-claudia/layout/archive.pug","hash":"68c709495bc39a659d9c4b19216714a5ac2b5579","modified":1664451874440},{"_id":"themes/hexo-theme-claudia/layout/category.pug","hash":"2147f3d66640bc6604c9b15325a480d196a4df3d","modified":1664451874440},{"_id":"themes/hexo-theme-claudia/layout/page.pug","hash":"6c5db904a03adb4794b7ada222389da12d395bc7","modified":1664451874440},{"_id":"themes/hexo-theme-claudia/layout/index.pug","hash":"b84b3b89b3ecd0f3c604c2517ccd694d6a8489f4","modified":1664451874440},{"_id":"themes/hexo-theme-claudia/layout/post.pug","hash":"c76194840b5d6b7b881651cb492ab4b6963d1725","modified":1664451874440},{"_id":"themes/hexo-theme-claudia/.github/ISSUE_TEMPLATE/bug_report.md","hash":"b38365fec9b6cac6bbb75441082f041c4efd35bf","modified":1664451874440},{"_id":"themes/hexo-theme-claudia/source/favicon.ico","hash":"96b9a549337c2bec483c2879eeafa4d1f8748fed","modified":1664451874460},{"_id":"themes/hexo-theme-claudia/layout/tag.pug","hash":"16dac6e0a6ef939ceb6adb21dfbe0276538ff269","modified":1664451874440},{"_id":"themes/hexo-theme-claudia/.github/ISSUE_TEMPLATE/feature_request.md","hash":"9d8447814c3ac93d7fbd336015e7ef80c4a32831","modified":1664451874440},{"_id":"themes/hexo-theme-claudia/layout/widget/base.pug","hash":"b75bac1f7c8b76c555c53fb062b85a2c15822326","modified":1664970310036},{"_id":"themes/hexo-theme-claudia/layout/widget/methods.pug","hash":"fa62f6ad95d1a4cda5038595d19d4d11b4b39e17","modified":1664451874440},{"_id":"themes/hexo-theme-claudia/layout/widget/widget-archives.pug","hash":"e6bcf8b09a5e06119baf3f97f7798ef7600ab65c","modified":1664451874440},{"_id":"themes/hexo-theme-claudia/layout/widget/widget-header.pug","hash":"d7cf01cbe962a02dc03788eafcfb9a32780032a0","modified":1664969029568},{"_id":"themes/hexo-theme-claudia/layout/widget/widget-categories.pug","hash":"ea3bcd5f5fb06e26d8b67f30f224e7c129672980","modified":1664451874444},{"_id":"themes/hexo-theme-claudia/layout/widget/widget-post-list.pug","hash":"f034a4b8231f7933d06e364671b11847c74b9a5c","modified":1664451874444},{"_id":"themes/hexo-theme-claudia/layout/widget/widget-profile.pug","hash":"fbe18f3dd5e8d2850f8e6510da4fbd499d5096f0","modified":1664451874444},{"_id":"themes/hexo-theme-claudia/layout/widget/widget-recent.pug","hash":"7512dceae690ea219d562a6e450d633e29916072","modified":1664451874444},{"_id":"themes/hexo-theme-claudia/layout/widget/widget-search.pug","hash":"c17612dd4ae2d439d757818ec0e4215d71dd9ad5","modified":1664451874444},{"_id":"themes/hexo-theme-claudia/source/js/common.js","hash":"7f62c8c148ee0b528a2bea47b248b2a7f5501142","modified":1664451874460},{"_id":"themes/hexo-theme-claudia/layout/widget/widget-sns.pug","hash":"8ec154d321b36a5f3bf5974c75668b45ec660c1d","modified":1664451874444},{"_id":"themes/hexo-theme-claudia/layout/widget/widget-tag.pug","hash":"714a05148758e1e3cc12635c875cb6ef1753c6ab","modified":1664451874444},{"_id":"themes/hexo-theme-claudia/source/js/post.js","hash":"04edd583f103ba444d8174d55e7f45e27b8f2549","modified":1664451874460},{"_id":"themes/hexo-theme-claudia/source/style/about.scss","hash":"4a1beebb317c598b11fc4815e70b07bbb6d2aed7","modified":1664451874460},{"_id":"themes/hexo-theme-claudia/source/style/post.scss","hash":"8a3520a0ceb22a2fde35b09485e2df6dd5a23b6f","modified":1664451874464},{"_id":"themes/hexo-theme-claudia/source/style/archive.scss","hash":"cd1dc16dfa7c482cc88ddabaf8c9a459299a98cf","modified":1664451874460},{"_id":"themes/hexo-theme-claudia/source/style/widget-header.scss","hash":"18782c2ab206abbeb0ee59632864251acfd20d85","modified":1664451874464},{"_id":"themes/hexo-theme-claudia/source/style/base.scss","hash":"da7457c952b6b433f273d7ecc562d24dcd4aa431","modified":1664451874460},{"_id":"themes/hexo-theme-claudia/source/style/widget-post-list.scss","hash":"db24becef1636806767dfaa33b3f90c40450de8d","modified":1664451874464},{"_id":"themes/hexo-theme-claudia/source/style/common/helper.scss","hash":"7cd0982fe839e760523f8f85ea6f06f2b5d2111a","modified":1664451874464},{"_id":"themes/hexo-theme-claudia/source/style/common/variable.scss","hash":"fffe6eacfa4d814626a1e1d84dc651233eded060","modified":1664451874464},{"_id":"themes/hexo-theme-claudia/source/style/themes/default-dark.scss","hash":"0cbdc5738503f55e5b84e1bd00e445c98c7d56d2","modified":1664451874464},{"_id":"themes/hexo-theme-claudia/source/style/themes/default-light.scss","hash":"23e7c1f87e252db80d34d36a2129e98dde7b1b55","modified":1664451874464},{"_id":"themes/hexo-theme-claudia/source/style/themes/highlight-theme-light.css","hash":"f7b19080f00e10723bc86e6819fc25143a0137c5","modified":1664451874464},{"_id":"themes/hexo-theme-claudia/source/style/themes/theme.scss","hash":"caf7517c9200bbf7152a7f5edba4298fbf9ae629","modified":1664451874464},{"_id":"themes/hexo-theme-claudia/source/js/highlight.pack.js","hash":"2ef9bbbc688ce413686ce0eb64d0b25af4ea34e2","modified":1664451874460},{"_id":"source/images/wireguard-site-1.png","hash":"b72c57eec7956096a4f21e0ebecf7199a616e231","modified":1674785744944},{"_id":"themes/hexo-theme-claudia/images/avatar.jpg","hash":"51120c892d8c6d78ab7a76540be50f8cd40afc73","modified":1664454009184},{"_id":"themes/hexo-theme-claudia/source/style/common/bulma.css","hash":"7ede761951c6f274850a1038416559a8f648c493","modified":1664451874460},{"_id":"themes/hexo-theme-claudia/screenshot/claudia-cover.png","hash":"757680cd3648e3569d6a18abaf33180dc427d620","modified":1664451874460},{"_id":"themes/hexo-theme-claudia/screenshot/claudia-cover-v2.png","hash":"f477d90d327a638a46b3caa172332e931955a532","modified":1664451874452},{"_id":"source/images/avatar.jpg","hash":"88cc5b48d09f7f81bad425206dc76a47084aaf99","modified":1664647815576},{"_id":"public/rss.xml","hash":"b4509b8a40bd2c325d7a7e6e9c253040d492f024","modified":1678325531391},{"_id":"public/tag/servicios de red e internet/rss.xml","hash":"56934184c03286b65083a7a75e8fcf98a4388609","modified":1675231937166},{"_id":"public/tag/sistemas operativos/rss.xml","hash":"883d24b04b26bfe50b3ca8b1ed27986786e9cde8","modified":1675231937166},{"_id":"public/tag/seguridad/rss.xml","hash":"2a2f73e8f32f45772549b15dc1692597b40801d9","modified":1675231937166},{"_id":"public/category/servicios de red e internet/rss.xml","hash":"1652930ccaa036da54f216403d087cb71ac28f90","modified":1675231937166},{"_id":"public/category/sistemas operativos/rss.xml","hash":"cd8ae28bfbddbcc5671e313144d2f86ad8c0d18e","modified":1675231937166},{"_id":"public/category/bases de datos/rss.xml","hash":"f127b27f87bec50296f0652680c2ba773fcc539a","modified":1676724271556},{"_id":"public/category/administración de sistemas/rss.xml","hash":"9539937a237032da8c3e39f00aff87903b210fc7","modified":1675236717227},{"_id":"public/category/seguridad/rss.xml","hash":"91d5c4953e2683ac4f1f94338745ab2a1a48cabf","modified":1675231937166},{"_id":"public/atom.xml","hash":"43b92acb348facf57068a2279001f4ea48c6c868","modified":1678325531391},{"_id":"public/feed.json","hash":"092c8ac0fd02b63f7862ab2ef495b13f38994a10","modified":1678325531391},{"_id":"public/tag/servicios de red e internet/feed.json","hash":"ac5c17879a2893b1903de4a2790f350f0adbfeb1","modified":1675231937166},{"_id":"public/tag/sistemas operativos/feed.json","hash":"a45bda71f2ef2745fbccd4ada0fdf772b1df0971","modified":1675231937166},{"_id":"public/tag/seguridad/feed.json","hash":"589ec8883908b3fb4973d43377146bd0638961f2","modified":1675231937166},{"_id":"public/category/servicios de red e internet/feed.json","hash":"fd2fc445d079c8f71af934a18460d05c040a7237","modified":1675231937166},{"_id":"public/category/sistemas operativos/feed.json","hash":"6078354d0d6909684ef80805d7ebf0f21c6e4b34","modified":1675231937166},{"_id":"public/category/bases de datos/feed.json","hash":"c502d8e8480da31501be9be52f351cfe8d166a18","modified":1676724271556},{"_id":"public/category/administración de sistemas/feed.json","hash":"f62b8aedcb35056945d4e0c37ecbb7d639e7325e","modified":1675236717227},{"_id":"public/category/seguridad/feed.json","hash":"86cbea25d303169e34328a207f5a8156ca84d6d0","modified":1675231937166},{"_id":"public/search.xml","hash":"5cb1bc0fda5b953c948d2ae21e36e3f5f9a4f82c","modified":1678325531391},{"_id":"public/categories/index.html","hash":"514d1fb526cdb45a93c7dd132309144ca92fda02","modified":1675231937166},{"_id":"public/tags/index.html","hash":"326ae74800092ce15f375c1139b1b44dfa7ceeae","modified":1675231937166},{"_id":"public/about/index.html","hash":"e0d9b2c843a2c75eef5ea0251e420be306f3200c","modified":1675231937166},{"_id":"public/2023/01/26/vpn-wireguard/index.html","hash":"cfbd3e33e541b84e4cbc3542e73ca7a0ff26b665","modified":1675284157355},{"_id":"public/2023/01/24/vpn/index.html","hash":"98601223c400553ba070b069c57a22b42ca14c2b","modified":1675284157355},{"_id":"public/2023/01/10/dns-vistas/index.html","hash":"53272411f06a01c45e984421e876f49c4ddd655d","modified":1675231937166},{"_id":"public/2023/01/03/nfs-systemd/index.html","hash":"85fd1aea0888df4b0b0eedd0f366d72c2a643c7a","modified":1675231937166},{"_id":"public/2022/11/16/Compilar-linux-a-medida/index.html","hash":"e99af0d446627ea1656bd2ae90b1dd81d5786ebc","modified":1675231937166},{"_id":"public/2022/10/13/Ansible+Vagrant/index.html","hash":"a2b4e8b6e7f77ea3f050f04859d15fe0cf623a06","modified":1675231937166},{"_id":"public/2022/10/04/Preseed-pxe/index.html","hash":"545137f702a34781b7aa8230d083bf02d7a08fb2","modified":1675231937166},{"_id":"public/2022/09/30/preseed/index.html","hash":"4d9c3e3a134bab08907b674c2ac9146449622d97","modified":1675231937166},{"_id":"public/2022/09/30/Compilar-en-debian/index.html","hash":"e1b60cc68d81b7e8de4ffd5e99b11345c00f66b1","modified":1675231937166},{"_id":"public/archives/page/2/index.html","hash":"a113fa906714a07dfdbd15de744851d755ad75a7","modified":1678312853388},{"_id":"public/archives/2022/index.html","hash":"373b13a8b48ba9aa847feb6e0a11ea22f26ea531","modified":1678312853388},{"_id":"public/archives/2022/09/index.html","hash":"6dffb9371a9c88f9f62f5f2e2ee850672ae0e4b8","modified":1678312853388},{"_id":"public/archives/2022/10/index.html","hash":"b0f2a329b3c5d21a38e3703aa19efb68e9f2a1e4","modified":1678312853388},{"_id":"public/archives/2022/11/index.html","hash":"d50c772c3d4f6591169dfb13031539efd1420065","modified":1678312853388},{"_id":"public/archives/2022/12/index.html","hash":"90e1b6ed1e5b6ae784574c9176c09f5c0ef41272","modified":1678312853388},{"_id":"public/archives/2023/index.html","hash":"745f497c76abc01e180f5ffa3276e8c889d90800","modified":1678325465633},{"_id":"public/archives/2023/01/index.html","hash":"561706414d328badf43d3ae2b314d7f448535510","modified":1678312853388},{"_id":"public/archives/2023/02/index.html","hash":"bc32d6d072076567e2a6178c70f7142369ff649c","modified":1678312853388},{"_id":"public/categories/Servicios-de-Red-e-Internet/index.html","hash":"5dc289712205969eed3b62cf463d431cd5f19509","modified":1675621918299},{"_id":"public/categories/Sistemas-Operativos/index.html","hash":"acda73a5c4cb5324c6f646b903b9db1c6ad81245","modified":1675621918299},{"_id":"public/categories/Bases-de-Datos/index.html","hash":"2c121b8c877ff058c3ef2055cda71849204448b7","modified":1676724271556},{"_id":"public/categories/Administracion-de-Sistemas/index.html","hash":"db63ba5e02f30911c5698bcc80b7c5a73c1979b6","modified":1675621918299},{"_id":"public/categories/Seguridad/index.html","hash":"427014952f4e98d4a805f1801ed5d91fa46891ec","modified":1675621918299},{"_id":"public/tags/Servicios-de-Red-e-Internet/index.html","hash":"f73d45cf9363a7434ddd1ba38ac9e66b5d391b8d","modified":1675231937166},{"_id":"public/tags/Sistemas-Operativos/index.html","hash":"c1722e24141140b2810225f1683ed8fead7069d8","modified":1675231937166},{"_id":"public/tags/Seguridad/index.html","hash":"bb67f2dc51ca89320a2399ab9002e3da881ffa5b","modified":1675231937166},{"_id":"public/archives/index.html","hash":"94bff36cb9d1431f76fa5047ed2a913f90a9d964","modified":1678325465633},{"_id":"public/2023/02/01/slap-nfs/index.html","hash":"14db242691eab9121523583a4042a364872d5b41","modified":1675329286129},{"_id":"public/2022/12/13/dns/index.html","hash":"02078079ac410b7f7ecf738eea1bb8561c24341d","modified":1675231937166},{"_id":"public/2022/12/07/plsql_basico/index.html","hash":"ca46f05a409ff8ba0f758d31a81043d9a1e02711","modified":1676724271556},{"_id":"public/2022/11/09/Interconexiones/index.html","hash":"b771e0a21e906927b4cceba31132eadff2b4b232","modified":1675231937166},{"_id":"public/index.html","hash":"3b2292166e4a19913afc4268f715a13d9c195b7f","modified":1678325465633},{"_id":"public/page/2/index.html","hash":"3c52074c483fa12d39c9f696c4d72620e5c49591","modified":1678312853388},{"_id":"public/favicon.ico","hash":"96b9a549337c2bec483c2879eeafa4d1f8748fed","modified":1675231937166},{"_id":"public/images/DeepinScreenshot_Seleccionar área_20230109125013.png","hash":"c8f5fe4a30991d0d1a1580a8a75b12915aa7c6db","modified":1675231937166},{"_id":"public/images/LDAP-LOGO.png","hash":"4ca32c33412131db35a8211279b273bb2dbd205a","modified":1675231937166},{"_id":"public/images/LOGO-LDAP.png","hash":"8f0e96e3751a0e4132a324130b509037142e1923","modified":1675231937166},{"_id":"public/images/ansibleandvagrant.jpg","hash":"971466418b3ab8273ecadd85ee0e4db1b0dca8aa","modified":1675231937166},{"_id":"public/images/debian-11.jpg","hash":"0ec714f3546f8aa4e1dec561f22200a1a7e834f7","modified":1675231937166},{"_id":"public/images/iscsi-2.png","hash":"8224bed1ef784765bfe1250f699f602934ff5694","modified":1675287378062},{"_id":"public/images/iscsi-3.png","hash":"30612c83110853a0aecf9c74cb01b864a2066394","modified":1675231937166},{"_id":"public/images/logo-wireguard.png","hash":"ba7901e5e8974e849fcd5ee9fc346ab6c38f058a","modified":1675231937166},{"_id":"public/images/obelix-4.jpg","hash":"41deba00d16881be564bc3c2b6c38b6c9edcbbe2","modified":1675231937166},{"_id":"public/images/oracle-ejercicio1.png","hash":"29dd25a06447a8f4fa535a383e0031d72338c00d","modified":1675231937166},{"_id":"public/images/oracle-ejercicio10.png","hash":"e76c08f41feb072224354119f1f301707e9801e3","modified":1675231937166},{"_id":"public/images/oracle-ejercicio2.png","hash":"e8048be041d163e7a1985897b2f139bc3fa8cc37","modified":1675231937166},{"_id":"public/images/oracle-ejercicio3.png","hash":"ea378d9e3203e7277679b0b1cf0fe7005c649864","modified":1675231937166},{"_id":"public/images/oracle-ejercicio4.png","hash":"33cdc878dffce0c026dcf2955486ed7cf924b801","modified":1675231937166},{"_id":"public/images/oracle-ejercicio5.png","hash":"6cec63601b96812d96b3287b95a34f1b1bd8b164","modified":1675231937166},{"_id":"public/images/oracle-ejercicio7.png","hash":"7e2e58dfc9f67bbb26c2b2eff374da3ae8241f07","modified":1675231937166},{"_id":"public/images/oracle-ejercicio8.png","hash":"df6b429fec204dc994166f53f45d9b57f45b5e3b","modified":1675231937166},{"_id":"public/images/oracle-postgres.png","hash":"7e094bc8ebd39321abae95dcb7ba2b791f832ce8","modified":1675231937166},{"_id":"public/images/oraclepostgres.jpg","hash":"49f24db75b5a65e82eebf7885eb3144e93fece84","modified":1675231937166},{"_id":"public/images/postgres-ejercicio2.png","hash":"04c9e70b5f3190ceda891bb9f955800af866de84","modified":1675231937166},{"_id":"public/images/postgres-ejercicio1.png","hash":"c779d6d4b5d87523b52d110370412caa5a33e406","modified":1675231937166},{"_id":"public/images/postgres-postgres.png","hash":"3088be58cdf85b4b7a2bdfad7fee66d2b4361707","modified":1675231937166},{"_id":"public/images/prueba-dns-mysql2.png","hash":"e3771b76bcef65de8246116704b2b1b72116d06c","modified":1675231937166},{"_id":"public/images/slap-1-2.png","hash":"f0095156418e8020d57e46705c923dbe3adb2cc2","modified":1675231937166},{"_id":"public/images/slap-1-4.png","hash":"33cd347b0bc84ef8055c883d03b8908dcc023bc9","modified":1675231937166},{"_id":"public/images/slap-1-5.png","hash":"07e3c259878958b9e172bd578f978ec0997fe2d0","modified":1675231937166},{"_id":"public/images/slap-1-6.png","hash":"8f5455d42738ec8b3fa94559d431a07f57e029b0","modified":1675231937166},{"_id":"public/images/slap-1-7.png","hash":"b50e3a83c85685c034a8701d49ef3c2cd496b3ad","modified":1675231937166},{"_id":"public/images/slap-1-8.png","hash":"911ce0b78c9d5656525d2e5b390ee418b6bd63a1","modified":1675231937166},{"_id":"public/images/slap-1-9.png","hash":"ea5552dcbd876cbf921fe633ed7d40d52c21a6e6","modified":1675231937166},{"_id":"public/images/traceroute-openvpn.png","hash":"df547bcd8779208925a87598dba72a929255f148","modified":1675231937166},{"_id":"public/images/vpn-cliente-C-lin.png","hash":"41207c845de1a19270fdf2c30c84473c494541f4","modified":1675231937166},{"_id":"public/images/vpn-cliente1-traceroute.png","hash":"f7f6b6f4b5343a04dec8fe9f3955d70ceaea9618","modified":1675231937166},{"_id":"public/images/vpn-cliente2-traceroute.png","hash":"6df66844ef593a700cfcbde2f12beaab9a62fcd8","modified":1675231937166},{"_id":"public/images/vpn-logo.png","hash":"6ff76f203702e5484a9a31ac88bb57beab17e1fc","modified":1675231937166},{"_id":"public/images/wireguard-site-2.png","hash":"df98cec5dafd87ce85a1e0006e20260278537fbd","modified":1675231937166},{"_id":"public/images/ASO-PRACTICA1.png","hash":"7835d5258c3db2e4ff89d9a3b68d878de321a2d7","modified":1675231937166},{"_id":"public/images/Ansible.png","hash":"bb2219f79f255fd314a7a30ff5c1ea836e59e45c","modified":1675231937166},{"_id":"public/images/obelix-2.png","hash":"095139626f99764efecc71aa7ec3c9dd277bcfe8","modified":1675231937166},{"_id":"public/images/obelix-3.png","hash":"df792e4fbc26d4e49cf0d96a29cc7fdb5fe22df2","modified":1675231937166},{"_id":"public/images/obelix.png","hash":"0685e54f4641567c507545d0a5f62849a53c30f6","modified":1675231937166},{"_id":"public/images/oracle-ejercicio9.png","hash":"65cf3e3f684daab8b4d4350955d2d5549ae58635","modified":1675231937166},{"_id":"public/images/postgres-oracle.png","hash":"2108b5c5062f5ac874786078e55637dadd245c4a","modified":1675231937166},{"_id":"public/images/slap-1-10.png","hash":"c39b04a4fd8e580f1b801f097484b6a712a6a4c0","modified":1675231937166},{"_id":"public/images/prueba-dns-mysql.png","hash":"24be237fd026bae7bf47101b51597d5488de393d","modified":1675231937166},{"_id":"public/images/slap-1-1.png","hash":"26cc09b1e5b77a9b1fac8c5ada98fcd7f94c32f6","modified":1675231937166},{"_id":"public/images/slap-1-11.png","hash":"88d064d8b4ce0f77ac41c958e6cdf4c51f918c1b","modified":1675231937166},{"_id":"public/images/systemd-1.png","hash":"f5a54a913b85f7e815e3fe1eed43eee11e5abc28","modified":1675231937166},{"_id":"public/images/systemd-2.png","hash":"bb80e91aeffeb304d5d5800148da30a2ee1d0e4b","modified":1675231937166},{"_id":"public/images/systemd-3.png","hash":"2bfcf433b7417607980bc503982e0a7f906d5e05","modified":1675231937166},{"_id":"public/images/systemd-title.jpg","hash":"6552098416a1ccecd84c86102e815b231d426d4a","modified":1675231937166},{"_id":"public/images/vpn-acceso-remoto-ssh-openvpn.png","hash":"2feeb9b251549130bda54d5a0416816e778f770a","modified":1675231937166},{"_id":"public/images/vpn-cliente1.png","hash":"ce417062cef920c7cf46b9d860bc50900571f00d","modified":1675231937166},{"_id":"public/images/vpn-cliente2.png","hash":"26f92ef87cb189c9bc86cd010ea2639bc79f696d","modified":1675231937166},{"_id":"public/images/xorriso-2.png","hash":"c14d072f96c297e98913ea1492395b3069b0568e","modified":1675231937166},{"_id":"public/images/xorriso-3.png","hash":"73ec7f50ca43b000120a460d765b1305ad064cf1","modified":1675231937166},{"_id":"public/images/xorriso-4.png","hash":"a6bbd021a01b5873eee676f8dc395a1b6c4020fc","modified":1675231937166},{"_id":"public/js/common.js","hash":"7f62c8c148ee0b528a2bea47b248b2a7f5501142","modified":1675231937166},{"_id":"public/js/post.js","hash":"04edd583f103ba444d8174d55e7f45e27b8f2549","modified":1675231937166},{"_id":"public/style/themes/highlight-theme-light.css","hash":"f7b19080f00e10723bc86e6819fc25143a0137c5","modified":1675231937166},{"_id":"public/js/highlight.pack.js","hash":"2ef9bbbc688ce413686ce0eb64d0b25af4ea34e2","modified":1675231937166},{"_id":"public/style/common/bulma.css","hash":"337aa6363e207135f5ea4ca3f25e18f820220f52","modified":1675231937166},{"_id":"public/images/interfaces.png","hash":"09b65917ff81f7ab32727becb66e124b50f1c3a8","modified":1675231937166},{"_id":"public/images/iscsi-1.png","hash":"074def37d31e717f64aeeeb9b661d58d44e84d51","modified":1675231937166},{"_id":"public/images/openstack-1.png","hash":"bef024c334c2c76de1b1e424da669f59fa30a2ba","modified":1675231937166},{"_id":"public/images/oracle-ejercicio6.png","hash":"991b7d4599d67b9be602b678359993197118e535","modified":1675231937166},{"_id":"public/images/slap-1-3.png","hash":"578d1bc0e5451eb1128f7f290122759a17e3a4a8","modified":1675231937166},{"_id":"public/images/vpn-cliente-C-win2.png","hash":"9181fc162112c31a8cced20c9df3cacfa5274d44","modified":1675231937166},{"_id":"public/images/web-alfa.png","hash":"5e12750488680d46f2b3898f53ea433fd529a30f","modified":1675231937166},{"_id":"public/images/xorriso-1.png","hash":"22495b789d51bab231b0ebd499e931751cd926af","modified":1675231937166},{"_id":"public/style/themes/default-light.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1675231937166},{"_id":"public/style/themes/default-dark.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1675231937166},{"_id":"public/style/common/variable.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1675231937166},{"_id":"public/style/archive.css","hash":"fc79cddde5b0ee019889337bb3098d73bb6824cb","modified":1675231937166},{"_id":"public/style/about.css","hash":"9a244b903c425bb5d8c7f0859c620574e834a38e","modified":1675231937166},{"_id":"public/style/widget-header.css","hash":"80113d3a162a87b0574b478700242e8bb8cc9cf0","modified":1675231937166},{"_id":"public/style/common/helper.css","hash":"a3e09c0e185f4e960f4a83124306e7589f0a01c1","modified":1675231937166},{"_id":"public/style/themes/theme.css","hash":"a334f9eaa157eda2bce485b22237a5d24cdf7d70","modified":1675231937166},{"_id":"public/style/post.css","hash":"9e42bd627735bf438d97c1709f76b853f2989a25","modified":1675231937166},{"_id":"public/style/base.css","hash":"e83bb81e864a736a80abe2901485cf43a1d86a87","modified":1675231937166},{"_id":"public/style/widget-post-list.css","hash":"456f9bee783a92b40774d48d250be118e2602f36","modified":1675231937166},{"_id":"public/images/Untitled-2023-01-10-0143.png","hash":"595586ea75d531b1bc561d405d2fa330d46a1338","modified":1675231937166},{"_id":"public/images/linux-6.0.jpg","hash":"e89d19a4881437b2fafd6449282aa8167c29f555","modified":1675231937166},{"_id":"public/images/vpn-cliente-C-win.png","hash":"ca4c33a76a761fe8bc7af32e8172d2b0af02d78e","modified":1675231937166},{"_id":"public/images/vpn-site-esquema.png","hash":"a9e5d42add7c2c3737a08247cf3a0b5c669566a7","modified":1675231937166},{"_id":"public/images/wireguard-site-3.png","hash":"602695aee2eccb46a58d08c52135cdeb7bb58b0b","modified":1675231937166},{"_id":"public/images/wireguard-site-4.png","hash":"f049ed5685dc7a251f59a43d9061cc1d8d339fc8","modified":1675231937166},{"_id":"public/images/vistas-dns-1.png","hash":"296a712b836268cd0c5652317898f20dcc6807fa","modified":1675231937166},{"_id":"public/images/xconfig.png","hash":"51356565c80c184def49c0519c7d69b5f645ba49","modified":1675231937166},{"_id":"public/images/wireguard-site-1.png","hash":"b72c57eec7956096a4f21e0ebecf7199a616e231","modified":1675231937166},{"_id":"public/images/avatar.jpg","hash":"88cc5b48d09f7f81bad425206dc76a47084aaf99","modified":1675231937166},{"_id":"source/_posts/iscsi.md","hash":"dbf1c87bd826026b332fa574ccfc47e670aad6a0","modified":1675289575592},{"_id":"source/images/iscsi-logo.png","hash":"4dbf16f003639c60e0b5c5dcce889afc411a105a","modified":1675283890056},{"_id":"public/category/almacenamiento/rss.xml","hash":"8a26a330bd70f9636d34a4959b708a6fb020df25","modified":1676014049845},{"_id":"public/category/almacenamiento/feed.json","hash":"b55d71063bc9c484ecbade004357d39ecaa85744","modified":1676014049845},{"_id":"public/2023/01/26/iscsi/index.html","hash":"bd25d5836510689019e8e82a8508b0aaa5d230c5","modified":1675289579047},{"_id":"public/categories/Almacenamiento/index.html","hash":"759ffd7c72ae953d3bf62bf278f65ef008ef68ad","modified":1675621918299},{"_id":"public/images/iscsi-logo.png","hash":"4dbf16f003639c60e0b5c5dcce889afc411a105a","modified":1675284157355},{"_id":"source/images/iscsi-win-6.png","hash":"42f03fffa33b25855440a6f7ad7d3d415e458961","modified":1675286693600},{"_id":"source/images/iscsi-win-7.png","hash":"35d106976fcd43953947a2bf6e71faca8e12af53","modified":1675286822816},{"_id":"source/images/iscsi-win-4.png","hash":"dc10b7fe615a638400f99acd45aa8d7b934c2666","modified":1675286450128},{"_id":"source/images/iscsi-win-1.png","hash":"08fd764701f5594c9c955911550528c31212ae3d","modified":1675285941396},{"_id":"source/images/iscsi-win-3.png","hash":"4f93358376b8952f22730e9a4253098a618907c6","modified":1675286348828},{"_id":"source/images/iscsi-win-5.png","hash":"7b7f554ec95598f65452835484ca4f72199095c4","modified":1675286550276},{"_id":"source/images/iscsi-win-2.png","hash":"6f00c70b4bf583fb4256623a87e403d846ff09fe","modified":1675286106964},{"_id":"public/images/iscsi-win-6.png","hash":"42f03fffa33b25855440a6f7ad7d3d415e458961","modified":1675287227909},{"_id":"public/images/iscsi-win-7.png","hash":"35d106976fcd43953947a2bf6e71faca8e12af53","modified":1675287227909},{"_id":"public/images/iscsi-win-4.png","hash":"dc10b7fe615a638400f99acd45aa8d7b934c2666","modified":1675287227909},{"_id":"public/images/iscsi-win-1.png","hash":"08fd764701f5594c9c955911550528c31212ae3d","modified":1675287227909},{"_id":"public/images/iscsi-win-3.png","hash":"4f93358376b8952f22730e9a4253098a618907c6","modified":1675287227909},{"_id":"public/images/iscsi-win-5.png","hash":"7b7f554ec95598f65452835484ca4f72199095c4","modified":1675287227909},{"_id":"public/images/iscsi-win-2.png","hash":"6f00c70b4bf583fb4256623a87e403d846ff09fe","modified":1675287227909},{"_id":"source/_posts/kubernetes.md","hash":"3886d81e104f09f4e0ebd907208a68ca310aac19","modified":1677140374078},{"_id":"source/images/k8s-taller-1-1.png","hash":"cd59d4a92be0b1ea60f1002f637ac796c36a6a08","modified":1675326220551},{"_id":"source/images/k8s-taller-1-2.png","hash":"f8a0c12100c2888370f918a7a1a996eb303fb09a","modified":1675326330775},{"_id":"source/images/k8s-taller-1-5.png","hash":"0ff958b7a51d8a2108834bcc5ff049d126ff8e69","modified":1675328722539},{"_id":"source/images/k8s-taller-1-6.png","hash":"ca9a561b55b4755caaaad5a0a37696b222246e14","modified":1675329044479},{"_id":"source/images/k8s-taller-1-4.png","hash":"0f5f23b57f91f077975221215458bda423726956","modified":1675328334763},{"_id":"source/images/k8s-taller-1-3.png","hash":"1150335803e7b84e6f8f5d7b12cea83656700133","modified":1675326474027},{"_id":"public/category/contenedores/rss.xml","hash":"961c1ef1778b4a94b9a39609a29d764dd46bc90a","modified":1677196844344},{"_id":"public/category/contenedores/feed.json","hash":"4cf6e7af71e170fa8a44196f285f4a3a83a9fbec","modified":1677196844344},{"_id":"public/2023/02/02/kubernetes/index.html","hash":"e3f9db81546359553ddaec4e1c6d7d74e3a33165","modified":1677196844344},{"_id":"public/categories/Contenedores/index.html","hash":"f41bbdec5fc50220223cc525581f0c6fafd33f50","modified":1677196844344},{"_id":"public/images/k8s-taller-1-1.png","hash":"cd59d4a92be0b1ea60f1002f637ac796c36a6a08","modified":1675329286129},{"_id":"public/images/k8s-taller-1-2.png","hash":"f8a0c12100c2888370f918a7a1a996eb303fb09a","modified":1675329286129},{"_id":"public/images/k8s-taller-1-5.png","hash":"0ff958b7a51d8a2108834bcc5ff049d126ff8e69","modified":1675329286129},{"_id":"public/images/k8s-taller-1-6.png","hash":"ca9a561b55b4755caaaad5a0a37696b222246e14","modified":1675329286129},{"_id":"public/images/k8s-taller-1-4.png","hash":"0f5f23b57f91f077975221215458bda423726956","modified":1675329286129},{"_id":"public/images/k8s-taller-1-3.png","hash":"1150335803e7b84e6f8f5d7b12cea83656700133","modified":1675329286129},{"_id":"source/images/k8s-logo.png","hash":"a610bcc71de25dcc539c4ccfdccb09db2d471ad8","modified":1675330465203},{"_id":"public/images/k8s-logo.png","hash":"a610bcc71de25dcc539c4ccfdccb09db2d471ad8","modified":1675330483483},{"_id":"source/_posts/docker-introduccion.md","hash":"773a13604567663c31df34113972bb66c3978177","modified":1676014222704},{"_id":"source/images/docker-logo.png","hash":"66b23d82ac04873ece4faeb64b9db559aeee2f4b","modified":1675338367835},{"_id":"source/images/docker-taller-1-1.png","hash":"9786880779dcb641bceb368a776a858a050db515","modified":1675337252923},{"_id":"source/images/docker-taller1-2.png","hash":"9786880779dcb641bceb368a776a858a050db515","modified":1675337330147},{"_id":"source/images/docker-taller1-3.png","hash":"0a667ce1b65b489434deab531cf1659a0b655dbc","modified":1675337342275},{"_id":"source/images/docker-taller1-4.png","hash":"5864d1b7584fa45b47583837574d05a391c36f47","modified":1675337575435},{"_id":"public/2023/02/02/docker-introduccion/index.html","hash":"a848303d6a87b5ef010ceb7572771aff39816858","modified":1676014226936},{"_id":"public/categories/contenedores/index.html","hash":"f5880c4657fbc0d86e9ee11c39331d8ab130fcea","modified":1675338419303},{"_id":"public/images/docker-logo.png","hash":"66b23d82ac04873ece4faeb64b9db559aeee2f4b","modified":1675338419303},{"_id":"public/images/docker-taller-1-1.png","hash":"9786880779dcb641bceb368a776a858a050db515","modified":1675338419303},{"_id":"public/images/docker-taller1-2.png","hash":"9786880779dcb641bceb368a776a858a050db515","modified":1675338419303},{"_id":"public/images/docker-taller1-3.png","hash":"0a667ce1b65b489434deab531cf1659a0b655dbc","modified":1675338419303},{"_id":"public/images/docker-taller1-4.png","hash":"5864d1b7584fa45b47583837574d05a391c36f47","modified":1675338419303},{"_id":"source/images/docker-taller2-3.png","hash":"61552919c4287e5c64c7c29eaa0bd8f85b86e6e7","modified":1675342957879},{"_id":"source/images/docker-taller2-4.png","hash":"c564f26317839802b7547a734434ddaee52a69e7","modified":1675343867263},{"_id":"source/images/docker-taller2-2.png","hash":"584b8909100eba7423a9c6cc8a3619d35c61d167","modified":1675342861707},{"_id":"source/images/docker-taller2-1.png","hash":"fb5a2a0cbad6e200be095241e296219725416f8c","modified":1675342353499},{"_id":"public/images/docker-taller2-2.png","hash":"584b8909100eba7423a9c6cc8a3619d35c61d167","modified":1675344714693},{"_id":"public/images/docker-taller2-3.png","hash":"61552919c4287e5c64c7c29eaa0bd8f85b86e6e7","modified":1675344714693},{"_id":"public/images/docker-taller2-4.png","hash":"c564f26317839802b7547a734434ddaee52a69e7","modified":1675344714693},{"_id":"public/images/docker-taller2-1.png","hash":"fb5a2a0cbad6e200be095241e296219725416f8c","modified":1675344714693},{"_id":"source/images/k8s-taller-2-1.png","hash":"634c35df4c8a44727da0b49035018c4cd690c966","modified":1675413220927},{"_id":"source/images/k8s-taller-2-2.png","hash":"e71d06c7eee4ad48bf4a6e71a1ce50b17be369eb","modified":1675413333471},{"_id":"source/images/k8s-taller-2-4.png","hash":"9e3fa2ae4771e90b2a2b695616557d133ee29935","modified":1675413543279},{"_id":"source/images/k8s-taller-2-3.png","hash":"a2cd3ef11e138bd6cc2303d1a9b25a9821af6955","modified":1675413418075},{"_id":"source/images/k8s-taller-2-5.png","hash":"b1db88a248f23e4c4d97b705fc6d8381f7f7a18e","modified":1675413718419},{"_id":"public/images/k8s-taller-2-4.png","hash":"9e3fa2ae4771e90b2a2b695616557d133ee29935","modified":1675413857724},{"_id":"public/images/k8s-taller-2-1.png","hash":"634c35df4c8a44727da0b49035018c4cd690c966","modified":1675413857724},{"_id":"public/images/k8s-taller-2-2.png","hash":"e71d06c7eee4ad48bf4a6e71a1ce50b17be369eb","modified":1675413857724},{"_id":"public/images/k8s-taller-2-3.png","hash":"a2cd3ef11e138bd6cc2303d1a9b25a9821af6955","modified":1675413857724},{"_id":"public/images/k8s-taller-2-5.png","hash":"b1db88a248f23e4c4d97b705fc6d8381f7f7a18e","modified":1675413857724},{"_id":"source/images/k8s-taller-3-2-3.png","hash":"ce25342dc4a7ad18609b324234dcc59996056daf","modified":1675423965539},{"_id":"source/images/k8s-taller-3-2-5.png","hash":"70b156a2fa93c3741f19ed930be65ba0a8ef12fc","modified":1675424395259},{"_id":"source/images/k8s-taller-3-2.png","hash":"1cba62cdebca2f0d2c9ee5d9457b2a7be768c4b1","modified":1675415619039},{"_id":"source/images/k8s-taller-3-1.png","hash":"0054bad319c0272805d1d4111a90b29b27d03c04","modified":1675415546583},{"_id":"source/images/k8s-taller-3-2-4.png","hash":"16b7a862dd6abdfb83f02ae8d12ddd065e1b5e6a","modified":1675424204471},{"_id":"source/images/k8s-taller-3-3-1.png","hash":"b66d106ee3c3f5c36235465eb2366ab4a88b4ca9","modified":1675438018295},{"_id":"source/images/k8s-taller-3-3-2.png","hash":"4026daf00843ac115d1317d47de2edce7dc9f719","modified":1675438147423},{"_id":"source/images/k8s-taller-3-4.png","hash":"062fb80a2d6e0acbc6e9e698f391b9b28084c5d7","modified":1675415841827},{"_id":"source/images/k8s-taller-3-2-1.png","hash":"243f34efb3775cf458d60c7a74e2bfb117696c43","modified":1675417892299},{"_id":"source/images/k8s-taller-3-2-2.png","hash":"6f512dadfb88d91ecdb2bed580684c43980f7c0c","modified":1675421439851},{"_id":"source/images/k8s-taller-3-2-6.png","hash":"a9f511f02dfb99efe99855c124f3b7b8236a7dab","modified":1675424448535},{"_id":"source/images/k8s-taller-3-3.png","hash":"a4bfcace3a3104f253a46831c6a27ca3d5752221","modified":1675415727935},{"_id":"public/images/k8s-taller-3-2-5.png","hash":"70b156a2fa93c3741f19ed930be65ba0a8ef12fc","modified":1675438286038},{"_id":"public/images/k8s-taller-3-2-3.png","hash":"ce25342dc4a7ad18609b324234dcc59996056daf","modified":1675438286038},{"_id":"public/images/k8s-taller-3-2.png","hash":"1cba62cdebca2f0d2c9ee5d9457b2a7be768c4b1","modified":1675438286038},{"_id":"public/images/k8s-taller-3-2-4.png","hash":"16b7a862dd6abdfb83f02ae8d12ddd065e1b5e6a","modified":1675438286038},{"_id":"public/images/k8s-taller-3-3-2.png","hash":"4026daf00843ac115d1317d47de2edce7dc9f719","modified":1675438286038},{"_id":"public/images/k8s-taller-3-3-1.png","hash":"b66d106ee3c3f5c36235465eb2366ab4a88b4ca9","modified":1675438286038},{"_id":"public/images/k8s-taller-3-1.png","hash":"0054bad319c0272805d1d4111a90b29b27d03c04","modified":1675438286038},{"_id":"public/images/k8s-taller-3-4.png","hash":"062fb80a2d6e0acbc6e9e698f391b9b28084c5d7","modified":1675438286038},{"_id":"public/images/k8s-taller-3-2-1.png","hash":"243f34efb3775cf458d60c7a74e2bfb117696c43","modified":1675438286038},{"_id":"public/images/k8s-taller-3-2-6.png","hash":"a9f511f02dfb99efe99855c124f3b7b8236a7dab","modified":1675438286038},{"_id":"public/images/k8s-taller-3-2-2.png","hash":"6f512dadfb88d91ecdb2bed580684c43980f7c0c","modified":1675438286038},{"_id":"public/images/k8s-taller-3-3.png","hash":"a4bfcace3a3104f253a46831c6a27ca3d5752221","modified":1675438286038},{"_id":"source/_posts/drbd.md","hash":"3a12c8571cb9f93aab57635e5c618cbd2b514ffa","modified":1675671696840},{"_id":"source/images/drbd-logo.png","hash":"9ac85a44377d6f088b9bee7ef2956b048ef2a0f6","modified":1675621753560},{"_id":"source/images/peek.gif","hash":"e5b0c61233136f1aa6b7e271abc813b2f2864ed3","modified":1675621384736},{"_id":"source/images/drbd-1.png","hash":"896de95ef1491d11d65bbcbad1d7847c4ca3b6e1","modified":1675617880464},{"_id":"public/2023/02/05/drbd/index.html","hash":"595abc7f840ca78e37fd093cce68387e3966e874","modified":1676014049845},{"_id":"public/categories/almacenamiento/index.html","hash":"0f81f9ef77aa2e06ab87bbd22d7d61262194dc2a","modified":1676014049845},{"_id":"public/images/drbd-1.png","hash":"896de95ef1491d11d65bbcbad1d7847c4ca3b6e1","modified":1675621918299},{"_id":"public/images/drbd-logo.png","hash":"9ac85a44377d6f088b9bee7ef2956b048ef2a0f6","modified":1675621918299},{"_id":"public/images/peek.gif","hash":"e5b0c61233136f1aa6b7e271abc813b2f2864ed3","modified":1675621918299},{"_id":"source/_posts/forense.md","hash":"8be08567827a1564128b1834d19676ed601da9bb","modified":1676217842172},{"_id":"source/images/docker-taller3-1.png","hash":"ec8a925369e423a097fccd19ee625af277ea3e66","modified":1675689440512},{"_id":"source/images/docker-taller3-2.png","hash":"ec5dfc7e0030327b54e0d2dfae29ae0e2ff662d0","modified":1675689488224},{"_id":"source/images/docker-taller3-4.png","hash":"8796251dd46569566245e51073c207772c3b86c5","modified":1675689770920},{"_id":"source/images/forense-23.png","hash":"672e8153b856bdb5d478507f9efbb0e063ed290e","modified":1675944773584},{"_id":"source/images/forense-hash-win.png","hash":"364dcd28ba4503f15178917b936e42789e528b82","modified":1675878608737},{"_id":"source/images/docker-taller3-3.png","hash":"ee41fe03b16cdeb97d916990bde330ec2ab9741f","modified":1675689545040},{"_id":"source/images/docker-taller3-5.png","hash":"7782bf6ece0d8e0f2155c268b7e6033a0e796b53","modified":1675689940848},{"_id":"source/images/forense-2.png","hash":"4bccbf59dad9131c8560ab819655e78f5a5bcc6f","modified":1675974070037},{"_id":"source/images/forense-20.png","hash":"ef60aff3c38c45c7ed12008ae4feb190a7d08d63","modified":1675945268000},{"_id":"source/images/forense-24.png","hash":"07fe834ab4d9076667cb63cc50a940cfd1bdf76d","modified":1675932010934},{"_id":"source/images/forense-8.png","hash":"f3c1e0879fc8131e022bf5179c82a9491c356e0d","modified":1675976489325},{"_id":"source/images/forense-3.png","hash":"01a2ef2bd79877fb47aa1cae7d11c8a95fe23113","modified":1675975414161},{"_id":"source/images/forense-5.png","hash":"0b785bc85ee35d2b549c84f48028b089e62870dd","modified":1675975878029},{"_id":"source/images/forense-1.png","hash":"068848f949b566f2e36d0a1f6dbf6f6e71b40753","modified":1675973849033},{"_id":"source/images/forense-19-1.png","hash":"fbe3153229ec867ae38b8784feac09e092a35d33","modified":1675945030540},{"_id":"source/images/forense-19-3.png","hash":"c2eb9b6af7c592f9f4a24e2e85fabe20e5771d9d","modified":1675945104308},{"_id":"source/images/forense-22.png","hash":"37743c8b05f1e3fef589f8ee4ff8831967698e71","modified":1675945434044},{"_id":"source/images/forense-19-2.png","hash":"d2e8c57c62f6fe4799946918f410fa27d5a4ada1","modified":1675945056808},{"_id":"source/images/forense-21.png","hash":"83391f733bd1a63695991001a482677b03d311c1","modified":1675944625196},{"_id":"source/images/forense-19-4.png","hash":"338c52e8ce9c7b849bb074b7ba5adf2978346a04","modified":1675945142096},{"_id":"source/images/forense-25.jpg","hash":"214e4a903218d14258a0717415979c65824a4805","modified":1675931390194},{"_id":"source/images/forense-25.png","hash":"972e20089a413d380688954b058c6ec70dc8de98","modified":1675930537474},{"_id":"public/2023/02/08/forense/index.html","hash":"20dea86b7084bd060e47f9bcf735d12feaff0ce2","modified":1676251071556},{"_id":"public/images/docker-taller3-1.png","hash":"ec8a925369e423a097fccd19ee625af277ea3e66","modified":1676014049845},{"_id":"public/images/docker-taller3-4.png","hash":"8796251dd46569566245e51073c207772c3b86c5","modified":1676014049845},{"_id":"public/images/forense-23.png","hash":"672e8153b856bdb5d478507f9efbb0e063ed290e","modified":1676014049845},{"_id":"public/images/docker-taller3-2.png","hash":"ec5dfc7e0030327b54e0d2dfae29ae0e2ff662d0","modified":1676014049845},{"_id":"public/images/forense-hash-win.png","hash":"364dcd28ba4503f15178917b936e42789e528b82","modified":1676014049845},{"_id":"public/images/docker-taller3-3.png","hash":"ee41fe03b16cdeb97d916990bde330ec2ab9741f","modified":1676014049845},{"_id":"public/images/docker-taller3-5.png","hash":"7782bf6ece0d8e0f2155c268b7e6033a0e796b53","modified":1676014049845},{"_id":"public/images/forense-2.png","hash":"4bccbf59dad9131c8560ab819655e78f5a5bcc6f","modified":1676014049845},{"_id":"public/images/forense-20.png","hash":"ef60aff3c38c45c7ed12008ae4feb190a7d08d63","modified":1676014049845},{"_id":"public/images/forense-24.png","hash":"07fe834ab4d9076667cb63cc50a940cfd1bdf76d","modified":1676014049845},{"_id":"public/images/forense-8.png","hash":"f3c1e0879fc8131e022bf5179c82a9491c356e0d","modified":1676014049845},{"_id":"public/images/forense-3.png","hash":"01a2ef2bd79877fb47aa1cae7d11c8a95fe23113","modified":1676014049845},{"_id":"public/images/forense-5.png","hash":"0b785bc85ee35d2b549c84f48028b089e62870dd","modified":1676014049845},{"_id":"public/images/forense-1.png","hash":"068848f949b566f2e36d0a1f6dbf6f6e71b40753","modified":1676014049845},{"_id":"public/images/forense-19-1.png","hash":"fbe3153229ec867ae38b8784feac09e092a35d33","modified":1676014049845},{"_id":"public/images/forense-19-3.png","hash":"c2eb9b6af7c592f9f4a24e2e85fabe20e5771d9d","modified":1676014049845},{"_id":"public/images/forense-22.png","hash":"37743c8b05f1e3fef589f8ee4ff8831967698e71","modified":1676014049845},{"_id":"public/images/forense-19-2.png","hash":"d2e8c57c62f6fe4799946918f410fa27d5a4ada1","modified":1676014049845},{"_id":"public/images/forense-21.png","hash":"83391f733bd1a63695991001a482677b03d311c1","modified":1676014049845},{"_id":"public/images/forense-19-4.png","hash":"338c52e8ce9c7b849bb074b7ba5adf2978346a04","modified":1676014049845},{"_id":"public/images/forense-25.jpg","hash":"214e4a903218d14258a0717415979c65824a4805","modified":1676014049845},{"_id":"public/images/forense-25.png","hash":"972e20089a413d380688954b058c6ec70dc8de98","modified":1676014049845},{"_id":"source/images/forense-Android-1.png","hash":"707b9a72f740eb72bd6c368903d67e7d6550e430","modified":1676209434112},{"_id":"source/images/forense-Android-2.png","hash":"179c63a863d365e784fee5f9bb2247e542765397","modified":1676209434116},{"_id":"source/images/forense-Android-3.png","hash":"76a1a52530353c5435811fd3b8632cb7741bdfd6","modified":1676209434116},{"_id":"source/images/forense-linux-13.png","hash":"2b0358c9464150e288dee198760f81c5153e9cb5","modified":1676209434120},{"_id":"source/images/forense-linux-10.png","hash":"8bd4cea00c497a4f21ec657ce55ebc8001c6ee41","modified":1676211490456},{"_id":"source/images/forense-logo.png","hash":"c3cf9c87bad4accf3c1b22eb0ea9c5e2710ec51e","modified":1676214246696},{"_id":"source/images/forense-13.png","hash":"c685de9955fba81d60b98a04043137c8cf1659db","modified":1676216257312},{"_id":"source/images/forense-17.png","hash":"a82b89d603848209064a03391cebeadfc16c5404","modified":1676212380700},{"_id":"source/images/forense-9.png","hash":"6dff1afac8d04501579fc1490978d06672f95dca","modified":1676215043160},{"_id":"source/images/forense-linux-15.png","hash":"319c2a7b9bd3f880fc365d68358f47b3e3dc5e72","modified":1676212217248},{"_id":"source/images/forense-linux-19-2.png","hash":"551a7f259e3eb145f7fd1a50dcb2bf415755301c","modified":1676209434128},{"_id":"source/images/forense-linux-19-1.png","hash":"7dd30d035203713f47d021d357ec392cdf2bfee1","modified":1676209434124},{"_id":"source/images/forense-linux-20.png","hash":"a13b4fd8de7641dd021edb8ddaa3b146a5d46e97","modified":1676209434128},{"_id":"source/images/forense-linux-22.png","hash":"7a91fd4a30e48fa456742f1ae452acc5675a804c","modified":1676209434140},{"_id":"source/images/forense-linux-23.png","hash":"855e0fdfb862b7cc4a1effd404191d0f56311c44","modified":1676209434140},{"_id":"source/images/forense-linux-9.png","hash":"f3c22a97999956545aafc69709e86df45062acac","modified":1676211037412},{"_id":"source/images/forense-17-1.png","hash":"29c08251c6680744f448dfe48df1f5bf0a80715e","modified":1676215221232},{"_id":"source/images/forense-linux-11.png","hash":"18e4c48cc5104c9baa9b7be8f9896ea8453b0a1d","modified":1676211604352},{"_id":"source/images/forense-linux-12.png","hash":"fc84db0b028ea9e7c30347c2be5a9985b5284727","modified":1676211741836},{"_id":"source/images/forense-linux-8.png","hash":"b3a5640641dd9f8a9343a796c6d12cfdf167efa5","modified":1676211076752},{"_id":"source/images/forense-11.png","hash":"a14cabdf4e38324c75c2e42edd89e4e82a41d809","modified":1676215616052},{"_id":"source/images/forense-14.png","hash":"4f63ab7edf95d5578f50a329624c337c79fa58eb","modified":1676216702888},{"_id":"source/images/forense-linux-16.png","hash":"fad57623a437a9e882aac1f81849ba99037a008d","modified":1676212330360},{"_id":"source/images/forense-linux-21.png","hash":"8d7516600f2c529d88dd3b283fa6fd79fc865dbf","modified":1676209434136},{"_id":"source/images/forense-linux-24.png","hash":"a4d290ec352170e97710d32c8d1c0fbd7857134a","modified":1676209434148},{"_id":"source/images/forense-linux-25.png","hash":"b1aeab812e63f5c506ff90abd22158c495efba77","modified":1676209434156},{"_id":"source/images/forense-10.png","hash":"491f1aaba9d54f389337f609cddf74af6b02d2b6","modified":1676214822188},{"_id":"source/images/forense-16.png","hash":"753f8cb509989704846b46336c05b625bdb14ddd","modified":1676216922692},{"_id":"source/images/forense-18.png","hash":"16d609663027de09bf07c1193dbcc41e13149da9","modified":1676217028704},{"_id":"source/images/forense-15.png","hash":"03215e0bb6041f7df2035cd9b240d321db56c448","modified":1676216860792},{"_id":"public/images/forense-Android-2.png","hash":"179c63a863d365e784fee5f9bb2247e542765397","modified":1676217064475},{"_id":"public/images/forense-Android-1.png","hash":"707b9a72f740eb72bd6c368903d67e7d6550e430","modified":1676217064475},{"_id":"public/images/forense-Android-3.png","hash":"76a1a52530353c5435811fd3b8632cb7741bdfd6","modified":1676217064475},{"_id":"public/images/forense-linux-10.png","hash":"8bd4cea00c497a4f21ec657ce55ebc8001c6ee41","modified":1676217064475},{"_id":"public/images/forense-linux-13.png","hash":"2b0358c9464150e288dee198760f81c5153e9cb5","modified":1676217064475},{"_id":"public/images/forense-logo.png","hash":"c3cf9c87bad4accf3c1b22eb0ea9c5e2710ec51e","modified":1676217064475},{"_id":"public/images/forense-13.png","hash":"c685de9955fba81d60b98a04043137c8cf1659db","modified":1676217064475},{"_id":"public/images/forense-17.png","hash":"a82b89d603848209064a03391cebeadfc16c5404","modified":1676217064475},{"_id":"public/images/forense-9.png","hash":"6dff1afac8d04501579fc1490978d06672f95dca","modified":1676217064475},{"_id":"public/images/forense-linux-15.png","hash":"319c2a7b9bd3f880fc365d68358f47b3e3dc5e72","modified":1676217064475},{"_id":"public/images/forense-linux-19-2.png","hash":"551a7f259e3eb145f7fd1a50dcb2bf415755301c","modified":1676217064475},{"_id":"public/images/forense-linux-19-1.png","hash":"7dd30d035203713f47d021d357ec392cdf2bfee1","modified":1676217064475},{"_id":"public/images/forense-linux-20.png","hash":"a13b4fd8de7641dd021edb8ddaa3b146a5d46e97","modified":1676217064475},{"_id":"public/images/forense-linux-22.png","hash":"7a91fd4a30e48fa456742f1ae452acc5675a804c","modified":1676217064475},{"_id":"public/images/forense-linux-23.png","hash":"855e0fdfb862b7cc4a1effd404191d0f56311c44","modified":1676217064475},{"_id":"public/images/forense-linux-9.png","hash":"f3c22a97999956545aafc69709e86df45062acac","modified":1676217064475},{"_id":"public/images/forense-17-1.png","hash":"29c08251c6680744f448dfe48df1f5bf0a80715e","modified":1676217064475},{"_id":"public/images/forense-linux-11.png","hash":"18e4c48cc5104c9baa9b7be8f9896ea8453b0a1d","modified":1676217064475},{"_id":"public/images/forense-linux-12.png","hash":"fc84db0b028ea9e7c30347c2be5a9985b5284727","modified":1676217064475},{"_id":"public/images/forense-linux-8.png","hash":"b3a5640641dd9f8a9343a796c6d12cfdf167efa5","modified":1676217064475},{"_id":"public/images/forense-11.png","hash":"a14cabdf4e38324c75c2e42edd89e4e82a41d809","modified":1676217064475},{"_id":"public/images/forense-14.png","hash":"4f63ab7edf95d5578f50a329624c337c79fa58eb","modified":1676217064475},{"_id":"public/images/forense-linux-16.png","hash":"fad57623a437a9e882aac1f81849ba99037a008d","modified":1676217064475},{"_id":"public/images/forense-linux-21.png","hash":"8d7516600f2c529d88dd3b283fa6fd79fc865dbf","modified":1676217064475},{"_id":"public/images/forense-linux-24.png","hash":"a4d290ec352170e97710d32c8d1c0fbd7857134a","modified":1676217064475},{"_id":"public/images/forense-linux-25.png","hash":"b1aeab812e63f5c506ff90abd22158c495efba77","modified":1676217064475},{"_id":"public/images/forense-10.png","hash":"491f1aaba9d54f389337f609cddf74af6b02d2b6","modified":1676217064475},{"_id":"public/images/forense-16.png","hash":"753f8cb509989704846b46336c05b625bdb14ddd","modified":1676217064475},{"_id":"public/images/forense-18.png","hash":"16d609663027de09bf07c1193dbcc41e13149da9","modified":1676217064475},{"_id":"public/images/forense-15.png","hash":"03215e0bb6041f7df2035cd9b240d321db56c448","modified":1676217064475},{"_id":"source/images/forense-linux-18.png","hash":"2222ed93e0c0624b7dcecdb1b1c108a078aea59f","modified":1676217747104},{"_id":"public/images/forense-linux-18.png","hash":"2222ed93e0c0624b7dcecdb1b1c108a078aea59f","modified":1676217756908},{"_id":"source/_posts/journal.md","hash":"65d75b262d92b7d3185641a79c0eafca1b9bfa6a","modified":1676251042884},{"_id":"source/images/journal-1.png","hash":"0ad1ce120cfdc436e19564fb2db30313d18de774","modified":1676250181736},{"_id":"source/images/jurnal-logo.png","hash":"aa52a337f437bfe33943021c403ff7e07b482376","modified":1676251013668},{"_id":"source/images/journal-2.png","hash":"0674f210387f23fde1c408ab729dbcf168783d6e","modified":1676250447056},{"_id":"source/images/journal-3.png","hash":"23999a9588319fbca67ad20cb8220acd250c9177","modified":1676250512364},{"_id":"source/images/journal-4.png","hash":"8368bd15f23a2eb4b196439eaa9701b7c4f33c45","modified":1676250555296},{"_id":"public/2023/02/13/journal/index.html","hash":"f2b53d4931e42664b68080c99045d50625d4ca35","modified":1676517833860},{"_id":"public/archives/2023/page/2/index.html","hash":"75d6af52c1e8d33f3e87d380229871791fc98dc7","modified":1678312853388},{"_id":"public/images/journal-1.png","hash":"0ad1ce120cfdc436e19564fb2db30313d18de774","modified":1676251071556},{"_id":"public/images/jurnal-logo.png","hash":"aa52a337f437bfe33943021c403ff7e07b482376","modified":1676251071556},{"_id":"public/images/journal-3.png","hash":"23999a9588319fbca67ad20cb8220acd250c9177","modified":1676251071556},{"_id":"public/images/journal-2.png","hash":"0674f210387f23fde1c408ab729dbcf168783d6e","modified":1676251071556},{"_id":"public/images/journal-4.png","hash":"8368bd15f23a2eb4b196439eaa9701b7c4f33c45","modified":1676251071556},{"_id":"source/images/favicon.png","hash":"124510b2edfb3158dc57712ac77d98ce1be48b31","modified":1676361436627},{"_id":"source/images/k8s-taller-4-1.png","hash":"e071e17db7603b2b23494360b95abb7a7ff606bf","modified":1676285731323},{"_id":"source/images/k8s-taller-4-3.png","hash":"b378a43fd60508d539ca6ee33bf402085f4bc95a","modified":1676286588243},{"_id":"source/images/k8s-taller-4-2.png","hash":"636f0c2eb5ca5bc655e1c88f718f21c103590839","modified":1676286099659},{"_id":"source/images/favicon.ico","hash":"83c084ae8dd401924efb2a4bb1bf7eeb7e0ef9ee","modified":1676361524371},{"_id":"public/images/favicon.png","hash":"124510b2edfb3158dc57712ac77d98ce1be48b31","modified":1676361653637},{"_id":"public/images/k8s-taller-4-3.png","hash":"b378a43fd60508d539ca6ee33bf402085f4bc95a","modified":1676361653637},{"_id":"public/images/k8s-taller-4-1.png","hash":"e071e17db7603b2b23494360b95abb7a7ff606bf","modified":1676361653637},{"_id":"public/images/k8s-taller-4-2.png","hash":"636f0c2eb5ca5bc655e1c88f718f21c103590839","modified":1676361653637},{"_id":"public/images/favicon.ico","hash":"83c084ae8dd401924efb2a4bb1bf7eeb7e0ef9ee","modified":1676361653637},{"_id":"source/_posts/prueba-usuarios-almacenamiento","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1676445728678},{"_id":"source/_posts/fw1.md","hash":"65bd57c89d406689b2b44b065ba0a989ca4892b2","modified":1676926914628},{"_id":"source/images/firewall1-logo.png","hash":"17996e00b72c6180c52bbded84fa27446b140d16","modified":1676517735124},{"_id":"source/images/fw1-13.png","hash":"c4129f47c6a658ec3ccdb5335ed031a5337e88a7","modified":1676514403280},{"_id":"source/images/fw1-14.png","hash":"08c14bdba44b8a79f4544531a7fa74e1fe022eb8","modified":1676515120180},{"_id":"source/images/fw1-2.png","hash":"982f289f506e8703f58ea44d0852c5fcca0a237c","modified":1676507885752},{"_id":"source/images/fw1-4.png","hash":"a530247cb3cc90d6db7aa9967086266ca4531e2f","modified":1676508345568},{"_id":"source/images/fw1-6.png","hash":"e686e00f29e6a2a87106c2eb105b323dd5969456","modified":1676509391324},{"_id":"source/images/fw1-7.png","hash":"7a3f6dd36cd52c593274df68bb5b36929f8fd96e","modified":1676509603108},{"_id":"source/images/fw1-10.png","hash":"7d711b2d353be7b4f8a8569917e7948e468b7ecc","modified":1676512607880},{"_id":"source/images/fw1-11.png","hash":"d31d4b71caddc671aab7469499c8fbdad4323198","modified":1676514071156},{"_id":"source/images/fw1-16.png","hash":"3c1280c3ac91e1ecf9a4f10799a1c20c90993cc0","modified":1676517609944},{"_id":"source/images/fw1-3.png","hash":"c42e5de207d5fecbce12bc76a8fe05c4a4c9e96a","modified":1676508087728},{"_id":"source/images/fw1-1.png","hash":"cd58ea4e297fc8812cd2891743d55c1b2997718f","modified":1676467694126},{"_id":"source/images/fw1-9.png","hash":"24e95df5fcf500b5c67d03847eaa7753aa9077ad","modified":1676510602484},{"_id":"source/images/fw1-8.png","hash":"7a8cb1c708ba35a75a3401889d8fcbffa5ee29ae","modified":1676510481320},{"_id":"source/images/fw1-12.png","hash":"687ef8d0168b3d6be5778713a8230a976deafb68","modified":1676514237508},{"_id":"source/images/fw1-15.png","hash":"7bc5379486d0e7a63d0f5b40ed6f7dec86bb17d4","modified":1676516762080},{"_id":"source/images/fw1-5.png","hash":"83544d41a83ea080019e0ea208226c4c8a37db94","modified":1676509047232},{"_id":"public/2023/02/15/fw1/index.html","hash":"3047de86adf5f297cc12525a0a7a3c20e6b2bc90","modified":1676926921066},{"_id":"public/images/fw1-13.png","hash":"c4129f47c6a658ec3ccdb5335ed031a5337e88a7","modified":1676517833860},{"_id":"public/images/fw1-14.png","hash":"08c14bdba44b8a79f4544531a7fa74e1fe022eb8","modified":1676517833860},{"_id":"public/images/fw1-2.png","hash":"982f289f506e8703f58ea44d0852c5fcca0a237c","modified":1676517833860},{"_id":"public/images/fw1-4.png","hash":"a530247cb3cc90d6db7aa9967086266ca4531e2f","modified":1676517833860},{"_id":"public/images/fw1-6.png","hash":"e686e00f29e6a2a87106c2eb105b323dd5969456","modified":1676517833860},{"_id":"public/images/fw1-7.png","hash":"7a3f6dd36cd52c593274df68bb5b36929f8fd96e","modified":1676517833860},{"_id":"public/images/firewall1-logo.png","hash":"17996e00b72c6180c52bbded84fa27446b140d16","modified":1676517833860},{"_id":"public/images/fw1-10.png","hash":"7d711b2d353be7b4f8a8569917e7948e468b7ecc","modified":1676517833860},{"_id":"public/images/fw1-1.png","hash":"cd58ea4e297fc8812cd2891743d55c1b2997718f","modified":1676517833860},{"_id":"public/images/fw1-16.png","hash":"3c1280c3ac91e1ecf9a4f10799a1c20c90993cc0","modified":1676517833860},{"_id":"public/images/fw1-3.png","hash":"c42e5de207d5fecbce12bc76a8fe05c4a4c9e96a","modified":1676517833860},{"_id":"public/images/fw1-8.png","hash":"7a8cb1c708ba35a75a3401889d8fcbffa5ee29ae","modified":1676517833860},{"_id":"public/images/fw1-9.png","hash":"24e95df5fcf500b5c67d03847eaa7753aa9077ad","modified":1676517833860},{"_id":"public/images/fw1-11.png","hash":"d31d4b71caddc671aab7469499c8fbdad4323198","modified":1676517833860},{"_id":"public/images/fw1-12.png","hash":"687ef8d0168b3d6be5778713a8230a976deafb68","modified":1676517833860},{"_id":"public/images/fw1-15.png","hash":"7bc5379486d0e7a63d0f5b40ed6f7dec86bb17d4","modified":1676517833860},{"_id":"public/images/fw1-5.png","hash":"83544d41a83ea080019e0ea208226c4c8a37db94","modified":1676517833860},{"_id":"source/images/letschat-minikube-esquema.png","hash":"c4f812fcf8a3d478a791a5c2b6ae7bf7c7af6846","modified":1676541412059},{"_id":"source/images/k8s-taller-4-4.png","hash":"11958d5acfb3db175335919e3421164f285dcf07","modified":1676541515359},{"_id":"source/images/k8s-taller-4-5.png","hash":"24ee05d93e6f693b73cbd289310bd268ee5b9b51","modified":1676541675215},{"_id":"public/images/letschat-minikube-esquema.png","hash":"c4f812fcf8a3d478a791a5c2b6ae7bf7c7af6846","modified":1676541736692},{"_id":"public/images/k8s-taller-4-4.png","hash":"11958d5acfb3db175335919e3421164f285dcf07","modified":1676541736692},{"_id":"public/images/k8s-taller-4-5.png","hash":"24ee05d93e6f693b73cbd289310bd268ee5b9b51","modified":1676541736692},{"_id":"public/tag/servicios de red e internet/atom.xml","hash":"5bba496b06a1bed4b30c0923f2c3b9bc85a9dee7","modified":1677047157228},{"_id":"public/tag/sistemas operativos/atom.xml","hash":"1c6991c3788b2fe5553ce81f49fd3bd719766b04","modified":1677047157228},{"_id":"public/tag/seguridad/atom.xml","hash":"53d6d31365df8c8eb39f80e3be98d9ba8f2d0d2e","modified":1677047157228},{"_id":"public/category/servicios de red e internet/atom.xml","hash":"9130bddc23a20267bd438e095422a7deee40e973","modified":1677047157228},{"_id":"public/category/sistemas operativos/atom.xml","hash":"5b5e463d8250c3d3f4b1be4c1a067d0e0d790307","modified":1677047157228},{"_id":"public/category/bases de datos/atom.xml","hash":"ccbbac848cdefd9d385931bffad28927ad007d5d","modified":1677047157228},{"_id":"public/category/administración de sistemas/atom.xml","hash":"46b94d06f895987766847c55a5554400a0c60389","modified":1677047157228},{"_id":"public/category/seguridad/atom.xml","hash":"4436adae5bcf9c00a3315d1595332dfd4fcc16a6","modified":1677047157228},{"_id":"public/category/almacenamiento/atom.xml","hash":"d95794de129ddf66a9966053e8ca895d25a5054a","modified":1677047157228},{"_id":"public/category/contenedores/atom.xml","hash":"01b9859f05dcb53d5094ce9b27ca5a1085c6e358","modified":1677047157228},{"_id":"source/_posts/ldap-csv.md","hash":"640bfdb86a7f74bcb271716ebf27a7cec1a7549f","modified":1676968148967},{"_id":"source/images/k8s-taller-5-1.png","hash":"353b990f82d9e810e8c23f15291e9b1878fc3a7c","modified":1676622719984},{"_id":"source/images/k8s-taller-5-3.png","hash":"fc078d0f8e563a3553e0e48aca13e69430261552","modified":1676622840340},{"_id":"source/images/k8s-taller-5-2.png","hash":"db562afa8ed6860b5a99965d738caeb70a7c0cfb","modified":1676622800692},{"_id":"source/images/k8s-taller-5-6.png","hash":"d881009c31e362a3f2ab152094874cdd327016eb","modified":1676724102168},{"_id":"source/images/k8s-taller-5-5.png","hash":"7efb44ef6de1efb13d9cac1c1f0c73fc71df19d9","modified":1676724062296},{"_id":"source/images/k8s-taller-5-7.png","hash":"0c7f73de80a8542dbc0d25e8480f4b8b94d7de5c","modified":1676724135496},{"_id":"source/images/k8s-taller-5-4.png","hash":"f937522d394e5c667c7883115b21890ab336c0c1","modified":1676622967604},{"_id":"public/2023/02/17/ldap-csv/index.html","hash":"5901cc296d394ac939a576ea180ea2222c78ed76","modified":1677047157228},{"_id":"public/archives/page/3/index.html","hash":"83d380524065f46404c27b54cac763161507f676","modified":1678312853388},{"_id":"public/page/3/index.html","hash":"b7a6864b49deac557587fc9ec2a922c0c633ede8","modified":1678312853388},{"_id":"public/images/k8s-taller-5-3.png","hash":"fc078d0f8e563a3553e0e48aca13e69430261552","modified":1676724271556},{"_id":"public/images/k8s-taller-5-1.png","hash":"353b990f82d9e810e8c23f15291e9b1878fc3a7c","modified":1676724271556},{"_id":"public/images/k8s-taller-5-2.png","hash":"db562afa8ed6860b5a99965d738caeb70a7c0cfb","modified":1676724271556},{"_id":"public/images/k8s-taller-5-6.png","hash":"d881009c31e362a3f2ab152094874cdd327016eb","modified":1676724271556},{"_id":"public/images/k8s-taller-5-5.png","hash":"7efb44ef6de1efb13d9cac1c1f0c73fc71df19d9","modified":1676724271556},{"_id":"public/images/k8s-taller-5-7.png","hash":"0c7f73de80a8542dbc0d25e8480f4b8b94d7de5c","modified":1676724271556},{"_id":"public/images/k8s-taller-5-4.png","hash":"f937522d394e5c667c7883115b21890ab336c0c1","modified":1676724271556},{"_id":"source/images/k8s-taller-6-1.png","hash":"f6a006164e61be95230358c2d7eda3b3cd0d9da4","modified":1676887132602},{"_id":"source/images/k8s-taller-6-2.png","hash":"ded8911e53bec0d5f28f70f29278b6f38ea6c909","modified":1676887236202},{"_id":"source/images/k8s-taller-6-6.png","hash":"f4e36dc0b742d6d8a781f7f8e96349d9091f8922","modified":1676892017862},{"_id":"source/images/k8s-taller-6-3.png","hash":"b7435febbc5c3710285e3fca15543f9ac62c285a","modified":1676887307094},{"_id":"source/images/k8s-taller-6-7.png","hash":"7208a34d083a805b983a4de988c4b1c69d7079f2","modified":1676892085830},{"_id":"source/images/k8s-taller-6-5.png","hash":"1dfded15e56e214419f0896f1b2dc117734fb242","modified":1676887595830},{"_id":"source/images/k8s-taller-6-8.gif","hash":"080b4214d8172e146de4c8a87681ecae49b27693","modified":1676892246834},{"_id":"source/images/k8s-taller-6-4.png","hash":"4187382bb80745cbb18a4d3b59596840f43b7995","modified":1676887344162},{"_id":"public/images/k8s-taller-6-1.png","hash":"f6a006164e61be95230358c2d7eda3b3cd0d9da4","modified":1676892336603},{"_id":"public/images/k8s-taller-6-2.png","hash":"ded8911e53bec0d5f28f70f29278b6f38ea6c909","modified":1676892336603},{"_id":"public/images/k8s-taller-6-6.png","hash":"f4e36dc0b742d6d8a781f7f8e96349d9091f8922","modified":1676892336603},{"_id":"public/images/k8s-taller-6-3.png","hash":"b7435febbc5c3710285e3fca15543f9ac62c285a","modified":1676892336603},{"_id":"public/images/k8s-taller-6-7.png","hash":"7208a34d083a805b983a4de988c4b1c69d7079f2","modified":1676892336603},{"_id":"public/images/k8s-taller-6-5.png","hash":"1dfded15e56e214419f0896f1b2dc117734fb242","modified":1676892336603},{"_id":"public/images/k8s-taller-6-8.gif","hash":"080b4214d8172e146de4c8a87681ecae49b27693","modified":1676892336603},{"_id":"public/images/k8s-taller-6-4.png","hash":"4187382bb80745cbb18a4d3b59596840f43b7995","modified":1676892336603},{"_id":"source/images/ldap-2-1.png","hash":"dc1e048e63193316cf3213961d16835aa453a35f","modified":1676923746740},{"_id":"source/images/ldap-2-2.png","hash":"1b150b75983f9eb6a41053ca9d5b87ce8595b464","modified":1676925309948},{"_id":"source/images/ldap-csv-logo.png","hash":"c8475f2215b484e2e2097c754acbfd77a439f387","modified":1676926618156},{"_id":"source/images/k8s-taller-6-8.png","hash":"a3fa026691e81af79134bfe32d579c5ed3fed7c0","modified":1676919721361},{"_id":"source/images/ldap-2-3.png","hash":"83d18869c954203cd8505e13e3c1a801b4607980","modified":1676925370192},{"_id":"source/images/ldap-2-5.png","hash":"68d6b184f24b39496763cc2bbc6f2428859b57bf","modified":1676925909864},{"_id":"source/images/ldap-2-4.png","hash":"2ac82abdac5185461a49ab24c504d878d8ffe606","modified":1676925406368},{"_id":"source/images/k8s-taller-6-9.gif","hash":"f9dced1f6c77cbc2fc500b2ef24313f2b4dea29f","modified":1676919660189},{"_id":"public/images/ldap-2-2.png","hash":"1b150b75983f9eb6a41053ca9d5b87ce8595b464","modified":1676926666143},{"_id":"public/images/ldap-2-1.png","hash":"dc1e048e63193316cf3213961d16835aa453a35f","modified":1676926666143},{"_id":"public/images/ldap-csv-logo.png","hash":"c8475f2215b484e2e2097c754acbfd77a439f387","modified":1676926666143},{"_id":"public/images/k8s-taller-6-8.png","hash":"a3fa026691e81af79134bfe32d579c5ed3fed7c0","modified":1676926666143},{"_id":"public/images/ldap-2-3.png","hash":"83d18869c954203cd8505e13e3c1a801b4607980","modified":1676926666143},{"_id":"public/images/ldap-2-5.png","hash":"68d6b184f24b39496763cc2bbc6f2428859b57bf","modified":1676926666143},{"_id":"public/images/ldap-2-4.png","hash":"2ac82abdac5185461a49ab24c504d878d8ffe606","modified":1676926666143},{"_id":"public/images/k8s-taller-6-9.gif","hash":"f9dced1f6c77cbc2fc500b2ef24313f2b4dea29f","modified":1676926666143},{"_id":"source/images/rober1.jpeg","hash":"67bc328bfa77da78a86656b0931df6809c617a41","modified":1676968120699},{"_id":"source/images/nazareth1.jpeg","hash":"ceded217da92b89e7080eadcabe4b399f9d870db","modified":1676966592791},{"_id":"public/images/rober1.jpeg","hash":"67bc328bfa77da78a86656b0931df6809c617a41","modified":1676968162672},{"_id":"public/images/nazareth1.jpeg","hash":"ceded217da92b89e7080eadcabe4b399f9d870db","modified":1676968162672},{"_id":"source/_posts/auditoria.md","hash":"1b9fec1e8ee3a6d83ce9d7e7574a4d75802d276d","modified":1677212159063},{"_id":"source/images/audit-4.png","hash":"4ca175d67ecd4df1aa244795f7f8ce1abc1ecd2a","modified":1677026951512},{"_id":"source/images/audit-5.png","hash":"000a5ccfc9e6fabfcea002df7d607d5bf7f4d8a4","modified":1677027961900},{"_id":"source/images/audit-7.png","hash":"ff1d1abe4dd521b982a964b562fd451b0dd50bb5","modified":1677030297132},{"_id":"source/images/audit-2.png","hash":"d69bf07566a0c087c514d8a88e4aff28e7362ac0","modified":1676976734099},{"_id":"source/images/audit-3.png","hash":"902c88f159b1f9254ea65f44558dee133b767bde","modified":1676973854351},{"_id":"source/images/audit-6.png","hash":"69ff968e5fef22051a468fdf822f816f9e7edf3f","modified":1677028692604},{"_id":"source/images/audit-1.png","hash":"4cabe41398d45de3af13c0a362793e1c34250dc4","modified":1677031362560},{"_id":"public/2023/02/21/auditoria/index.html","hash":"2c27096432e8260db0b86c027bdee53b2a66cded","modified":1677212164505},{"_id":"public/images/audit-5.png","hash":"000a5ccfc9e6fabfcea002df7d607d5bf7f4d8a4","modified":1677029338244},{"_id":"public/images/audit-2.png","hash":"d69bf07566a0c087c514d8a88e4aff28e7362ac0","modified":1677029338244},{"_id":"public/images/audit-3.png","hash":"902c88f159b1f9254ea65f44558dee133b767bde","modified":1677029338244},{"_id":"public/images/audit-4.png","hash":"4ca175d67ecd4df1aa244795f7f8ce1abc1ecd2a","modified":1677029338244},{"_id":"public/images/audit-7.png","hash":"ff1d1abe4dd521b982a964b562fd451b0dd50bb5","modified":1677046801490},{"_id":"public/images/audit-1.png","hash":"4cabe41398d45de3af13c0a362793e1c34250dc4","modified":1677046801490},{"_id":"public/images/audit-6.png","hash":"69ff968e5fef22051a468fdf822f816f9e7edf3f","modified":1677029338244},{"_id":"source/images/audit-10.png","hash":"8d5874ed57a50e74556388a9abd52eb643dbbca3","modified":1677033234424},{"_id":"source/images/audit-11.png","hash":"34dec38ef363743da1a5e68f8b2e30306219c78b","modified":1677033604268},{"_id":"source/images/audit-15.png","hash":"88d82d7fc15757ab1d3bd5ff49a7668ac79f7dbc","modified":1677036493989},{"_id":"source/images/audit-14.png","hash":"9bb46510720af896d747a30242a475e3ab75bc1e","modified":1677035943909},{"_id":"source/images/audit-17.png","hash":"3638c82c9f74c0edcf7c763142c359db46d9ab4b","modified":1677037468149},{"_id":"source/images/audit-16.png","hash":"345896f169363b457811be40db0f8316d1ffe207","modified":1677037362913},{"_id":"source/images/audit-19.png","hash":"fa541a1c994dc18e6d3c48762840f55d6233561e","modified":1677038249977},{"_id":"source/images/audit-21.png","hash":"60ae63965b285805ca382b5c1ccfd8927f9eb23d","modified":1677042695561},{"_id":"source/images/audit-8.png","hash":"84e6d7ec459493c7b20aa3c837b93b769898361f","modified":1677030510568},{"_id":"source/images/audit-22.png","hash":"137a054bdf10a6db118284f47f5fb9b4fc727816","modified":1677044551373},{"_id":"source/images/audit-9.png","hash":"6474130aa3c882278f330da191ff59fea09728e7","modified":1677030631172},{"_id":"source/images/audit-12.png","hash":"131c74714c9285c44fd50f0dadabde6ae333cfb8","modified":1677035106165},{"_id":"source/images/audit-18.png","hash":"963c2e12779753c6ec088193e5b34e6efd636723","modified":1677037667221},{"_id":"source/images/audit-20.png","hash":"61a21803f714a42790da86f14efd5441fcedd008","modified":1677038796213},{"_id":"source/images/audit-13.png","hash":"967adef6fe4033a7681cef5c5c4656b8f19e3b93","modified":1677035567353},{"_id":"public/images/audit-10.png","hash":"8d5874ed57a50e74556388a9abd52eb643dbbca3","modified":1677046801490},{"_id":"public/images/audit-14.png","hash":"9bb46510720af896d747a30242a475e3ab75bc1e","modified":1677046801490},{"_id":"public/images/audit-16.png","hash":"345896f169363b457811be40db0f8316d1ffe207","modified":1677046801490},{"_id":"public/images/audit-11.png","hash":"34dec38ef363743da1a5e68f8b2e30306219c78b","modified":1677046801490},{"_id":"public/images/audit-17.png","hash":"3638c82c9f74c0edcf7c763142c359db46d9ab4b","modified":1677046801490},{"_id":"public/images/audit-15.png","hash":"88d82d7fc15757ab1d3bd5ff49a7668ac79f7dbc","modified":1677046801490},{"_id":"public/images/audit-19.png","hash":"fa541a1c994dc18e6d3c48762840f55d6233561e","modified":1677046801490},{"_id":"public/images/audit-22.png","hash":"137a054bdf10a6db118284f47f5fb9b4fc727816","modified":1677046801490},{"_id":"public/images/audit-21.png","hash":"60ae63965b285805ca382b5c1ccfd8927f9eb23d","modified":1677046801490},{"_id":"public/images/audit-8.png","hash":"84e6d7ec459493c7b20aa3c837b93b769898361f","modified":1677046801490},{"_id":"public/images/audit-9.png","hash":"6474130aa3c882278f330da191ff59fea09728e7","modified":1677046801490},{"_id":"public/images/audit-12.png","hash":"131c74714c9285c44fd50f0dadabde6ae333cfb8","modified":1677046801490},{"_id":"public/images/audit-18.png","hash":"963c2e12779753c6ec088193e5b34e6efd636723","modified":1677046801490},{"_id":"public/images/audit-20.png","hash":"61a21803f714a42790da86f14efd5441fcedd008","modified":1677046801490},{"_id":"public/images/audit-13.png","hash":"967adef6fe4033a7681cef5c5c4656b8f19e3b93","modified":1677046801490},{"_id":"source/images/audit-logo.png","hash":"7e160757e2a063b43466a47bef4ac9b59e516859","modified":1677046977869},{"_id":"public/images/audit-logo.png","hash":"7e160757e2a063b43466a47bef4ac9b59e516859","modified":1677047157228},{"_id":"source/_posts/helm.md","hash":"f051b77b65a7c841b36d108904948f689c623216","modified":1677197197211},{"_id":"source/images/helm-1.png","hash":"da3c9c9f28b9a765093d2a934c4d59ff8a628c56","modified":1677141398610},{"_id":"source/images/helm-2.png","hash":"4db312eca6fa7a09854f0e39eabc4ef88c7b61f2","modified":1677141753330},{"_id":"source/images/logo-helm.png","hash":"d27401ea9bfa5439c1c4af80652f434c71841d79","modified":1677140322214},{"_id":"source/images/helm-5.png","hash":"81a637c45473e45d133101042a83727fec166ec6","modified":1677155803196},{"_id":"source/images/helm-4.png","hash":"fec916c46ae447f2fb1b9352d1225b9917ad75c3","modified":1677155706196},{"_id":"source/images/helm-6.png","hash":"d8a1d778979f9bd4137e035cfc9b8d9af2aecf86","modified":1677156299880},{"_id":"source/images/helm-3.png","hash":"3f4d2db8c0bac3ef6e771c901bd82c2242f26651","modified":1677155614924},{"_id":"public/2023/02/23/helm/index.html","hash":"215716e898ef667bf4ecc1393f71751d59f9b6ac","modified":1677714137390},{"_id":"public/images/helm-2.png","hash":"4db312eca6fa7a09854f0e39eabc4ef88c7b61f2","modified":1677196844344},{"_id":"public/images/helm-1.png","hash":"da3c9c9f28b9a765093d2a934c4d59ff8a628c56","modified":1677196844344},{"_id":"public/images/helm-5.png","hash":"81a637c45473e45d133101042a83727fec166ec6","modified":1677196844344},{"_id":"public/images/logo-helm.png","hash":"d27401ea9bfa5439c1c4af80652f434c71841d79","modified":1677196844344},{"_id":"public/images/helm-6.png","hash":"d8a1d778979f9bd4137e035cfc9b8d9af2aecf86","modified":1677196844344},{"_id":"public/images/helm-4.png","hash":"fec916c46ae447f2fb1b9352d1225b9917ad75c3","modified":1677196844344},{"_id":"public/images/helm-3.png","hash":"3f4d2db8c0bac3ef6e771c901bd82c2242f26651","modified":1677196844344},{"_id":"source/images/helm-7.png","hash":"e6d6b85831c298b2e8684e436925a0b429c922a3","modified":1677197145603},{"_id":"public/images/helm-7.png","hash":"e6d6b85831c298b2e8684e436925a0b429c922a3","modified":1677197239661},{"_id":"source/images/audit-24.png","hash":"fda11ff5ab78b6f10a1236c3ca83e188c981a4ae","modified":1677205174275},{"_id":"source/images/audit-25.png","hash":"bc5cc925c9de0b5bcc738a0e33a10e7bbff135c4","modified":1677202247927},{"_id":"source/images/audit-27.png","hash":"785ce5179a92c2ccbcba9b8af4695e82fdce6115","modified":1677206193595},{"_id":"source/images/audit-29.png","hash":"2ece574b4a911342ff8556799b8d59775d110805","modified":1677207055271},{"_id":"source/images/audit-30.png","hash":"1a0d96de8e6ac2d76a9e4acf6a0830ea8db9fc81","modified":1677207787955},{"_id":"source/images/audit-23.png","hash":"437359d92ff50ce1a3c03bd0eb788f0a73bf67b8","modified":1677199534979},{"_id":"source/images/audit-26.png","hash":"83e933cf838595356946205142864caa677e89f3","modified":1677205372375},{"_id":"source/images/audit-28.png","hash":"587960fabe694ce89b6ff7aa859e68d472d32a82","modified":1677206559627},{"_id":"public/images/audit-24.png","hash":"fda11ff5ab78b6f10a1236c3ca83e188c981a4ae","modified":1677210228609},{"_id":"public/images/audit-25.png","hash":"bc5cc925c9de0b5bcc738a0e33a10e7bbff135c4","modified":1677210228609},{"_id":"public/images/audit-30.png","hash":"1a0d96de8e6ac2d76a9e4acf6a0830ea8db9fc81","modified":1677210228609},{"_id":"public/images/audit-27.png","hash":"785ce5179a92c2ccbcba9b8af4695e82fdce6115","modified":1677210228609},{"_id":"public/images/audit-29.png","hash":"2ece574b4a911342ff8556799b8d59775d110805","modified":1677210228609},{"_id":"public/images/audit-23.png","hash":"437359d92ff50ce1a3c03bd0eb788f0a73bf67b8","modified":1677210228609},{"_id":"public/images/audit-26.png","hash":"83e933cf838595356946205142864caa677e89f3","modified":1677210228609},{"_id":"public/images/audit-28.png","hash":"587960fabe694ce89b6ff7aa859e68d472d32a82","modified":1677210228609},{"_id":"source/images/audit-31.png","hash":"96066da2e9c1a99aef02e37586620fd958e9eaca","modified":1677211923595},{"_id":"public/images/audit-31.png","hash":"96066da2e9c1a99aef02e37586620fd958e9eaca","modified":1677211975348},{"_id":"source/_posts/LDAPs.md","hash":"031a6c143b79b2a51726f8955fe67f2d2832a65e","modified":1677763589047},{"_id":"source/_posts/docker-practica.md","hash":"99984195d0da1c584a1c75d555463369e84a2b0b","modified":1677714246704},{"_id":"source/images/docker-2.png","hash":"5783a39823bb73adc9046e903bf6d5b6501942e7","modified":1677627457520},{"_id":"source/images/docker-5.png","hash":"3a750c126f484c72824ec8fb798ff03ef44edea8","modified":1677699344043},{"_id":"source/images/docker-8.png","hash":"84a57e32b8503d7399090c730a362a7b678db408","modified":1677708562420},{"_id":"source/images/docker-logo-2.png","hash":"9f6f88337cd83d73de5d44343dda38c124002831","modified":1677714073204},{"_id":"source/images/docker-4.png","hash":"324fc95ce1afad2a50edff5f6b6ced6b23cab18f","modified":1677670360476},{"_id":"source/images/docker-10.png","hash":"23990976e4eee8e08fae057b5f052e93830ccb75","modified":1677711608152},{"_id":"source/images/docker-12.png","hash":"23d599343d440137ede0006dfa08526c82715182","modified":1677712624192},{"_id":"source/images/docker-13.png","hash":"c957b80627536e4454f293880515d6778ea3eaec","modified":1677712731968},{"_id":"source/images/docker-1.png","hash":"63ef7b855c7ffef032676af30c7b5434d302888c","modified":1677600030867},{"_id":"source/images/docker-11.png","hash":"f807b3c8ae7ae42251253ff3375f150ae99919ac","modified":1677711761104},{"_id":"source/images/docker-6.png","hash":"ec225b0f5b054c412b1983ff3d32a415be4cab07","modified":1677699385859},{"_id":"source/images/docker-7.png","hash":"b60a6270f76ac0989d96825e76bf7c21e757fa53","modified":1677708442236},{"_id":"source/images/docker-9.png","hash":"562adab44980a1116e53f800159a79d2a5f06e97","modified":1677708619524},{"_id":"source/images/docker-3.png","hash":"1c2a4aab746cae169265f2f2d12590ce86f4cba4","modified":1677627772412},{"_id":"public/2023/03/01/LDAPs/index.html","hash":"5845467fba08eab25cb5f222ffcfb9ddd8d54bbe","modified":1678023483553},{"_id":"public/archives/2023/02/page/2/index.html","hash":"fb111983be653273ff88c4f9f73fc2106589747e","modified":1678312853388},{"_id":"public/archives/2023/03/index.html","hash":"59363a06a0d4f603cdeba02d9ea9407b4cdc2a88","modified":1678325465633},{"_id":"public/2023/02/24/docker-practica/index.html","hash":"e23bf120a0aa3fc3e93040908c6a0ea3427c3ed4","modified":1677761656626},{"_id":"public/images/docker-2.png","hash":"5783a39823bb73adc9046e903bf6d5b6501942e7","modified":1677714137390},{"_id":"public/images/docker-4.png","hash":"324fc95ce1afad2a50edff5f6b6ced6b23cab18f","modified":1677714137390},{"_id":"public/images/docker-5.png","hash":"3a750c126f484c72824ec8fb798ff03ef44edea8","modified":1677714137390},{"_id":"public/images/docker-8.png","hash":"84a57e32b8503d7399090c730a362a7b678db408","modified":1677714137390},{"_id":"public/images/docker-logo-2.png","hash":"9f6f88337cd83d73de5d44343dda38c124002831","modified":1677714137390},{"_id":"public/images/docker-10.png","hash":"23990976e4eee8e08fae057b5f052e93830ccb75","modified":1677714137390},{"_id":"public/images/docker-1.png","hash":"63ef7b855c7ffef032676af30c7b5434d302888c","modified":1677714137390},{"_id":"public/images/docker-13.png","hash":"c957b80627536e4454f293880515d6778ea3eaec","modified":1677714137390},{"_id":"public/images/docker-12.png","hash":"23d599343d440137ede0006dfa08526c82715182","modified":1677714137390},{"_id":"public/images/docker-3.png","hash":"1c2a4aab746cae169265f2f2d12590ce86f4cba4","modified":1677714137390},{"_id":"public/images/docker-6.png","hash":"ec225b0f5b054c412b1983ff3d32a415be4cab07","modified":1677714137390},{"_id":"public/images/docker-7.png","hash":"b60a6270f76ac0989d96825e76bf7c21e757fa53","modified":1677714137390},{"_id":"public/images/docker-9.png","hash":"562adab44980a1116e53f800159a79d2a5f06e97","modified":1677714137390},{"_id":"public/images/docker-11.png","hash":"f807b3c8ae7ae42251253ff3375f150ae99919ac","modified":1677714137390},{"_id":"source/images/ldaps-2.png","hash":"fa104e3911ecb6f853048c93112d36f5be8aaeab","modified":1677751262168},{"_id":"source/images/ldaps-3.png","hash":"c6ee46820ee97ff6d403475ae776b086a5239da0","modified":1677755199248},{"_id":"source/images/ldaps-6.png","hash":"cd783d9e23406e1aeaacdadda86cfc1f67b85639","modified":1677756271476},{"_id":"source/images/ldaps-1.png","hash":"ccd4c4807d515f5b1c1b8132c22f771ce415037f","modified":1677751161828},{"_id":"source/images/ldaps-8.gif","hash":"59be10149a0b5d7c32e9657ad0817f0300424c02","modified":1677761414343},{"_id":"source/images/ldaps-4.png","hash":"7ba0ef48e6ac79023b69f6bfe1e720be231d911c","modified":1677755230512},{"_id":"source/images/ldaps-5.png","hash":"29eec18adb64a3623bfa6a0b3d359ceb8ad917f1","modified":1677755425544},{"_id":"source/images/ldaps-7.png","hash":"6fc7ea403801443fb48e867471a3e65a81ce9227","modified":1677756855176},{"_id":"public/images/ldaps-2.png","hash":"fa104e3911ecb6f853048c93112d36f5be8aaeab","modified":1677761509031},{"_id":"public/images/ldaps-3.png","hash":"c6ee46820ee97ff6d403475ae776b086a5239da0","modified":1677761509031},{"_id":"public/images/ldaps-6.png","hash":"cd783d9e23406e1aeaacdadda86cfc1f67b85639","modified":1677761509031},{"_id":"public/images/ldaps-1.png","hash":"ccd4c4807d515f5b1c1b8132c22f771ce415037f","modified":1677761509031},{"_id":"public/images/ldaps-8.gif","hash":"59be10149a0b5d7c32e9657ad0817f0300424c02","modified":1677761509031},{"_id":"public/images/ldaps-5.png","hash":"29eec18adb64a3623bfa6a0b3d359ceb8ad917f1","modified":1677761509031},{"_id":"public/images/ldaps-4.png","hash":"7ba0ef48e6ac79023b69f6bfe1e720be231d911c","modified":1677761509031},{"_id":"public/images/ldaps-7.png","hash":"6fc7ea403801443fb48e867471a3e65a81ce9227","modified":1677761509031},{"_id":"source/images/ldaps-logo.png","hash":"41afe99103dc6c53f58d233e37c4254f058c804f","modified":1677761599711},{"_id":"public/images/ldaps-logo.png","hash":"41afe99103dc6c53f58d233e37c4254f058c804f","modified":1677761656626},{"_id":"source/_posts/docker-django.md","hash":"16821c79df531ca1a506b13f771b86f9b6ce96d7","modified":1678029082456},{"_id":"source/_posts/firewall-3.md","hash":"a5495e3a694d2ec158705bae682e7279f5cec04e","modified":1677811471403},{"_id":"source/images/docker-django.png","hash":"9c95ebed18a7f4f47db95d6eccf37fd72cb18acb","modified":1678023095316},{"_id":"source/images/django-1.png","hash":"a4c0e9ec69a6e89e0c43a1df3720d14bd313a6ec","modified":1678016822416},{"_id":"source/images/django-3.png","hash":"96abda77713474a6b0c559984c9b10e7d7544474","modified":1678019341616},{"_id":"source/images/django-2.png","hash":"8e15fbe42530d66b419794d9736fb0718c55ee70","modified":1678017268900},{"_id":"public/2023/03/03/docker-django/index.html","hash":"3fa5b6931a7431473a72ab68cfc24794277ad4f4","modified":1678060790707},{"_id":"public/2023/03/03/firewall-3/index.html","hash":"bf4afdf250426fb12ef7f3f22c9644d3b2e8b759","modified":1678023483553},{"_id":"public/images/docker-django.png","hash":"9c95ebed18a7f4f47db95d6eccf37fd72cb18acb","modified":1678023483553},{"_id":"public/images/django-1.png","hash":"a4c0e9ec69a6e89e0c43a1df3720d14bd313a6ec","modified":1678023483553},{"_id":"public/images/django-3.png","hash":"96abda77713474a6b0c559984c9b10e7d7544474","modified":1678023483553},{"_id":"public/images/django-2.png","hash":"8e15fbe42530d66b419794d9736fb0718c55ee70","modified":1678023483553},{"_id":"source/_posts/vagrantfile","hash":"a30fa0b0b7369ef1c9521c72254413881bf0910e","modified":1678105429207},{"_id":"source/_posts/k8s.md","hash":"86620df56cb2743da9991748fa6a50fa7ac489dd","modified":1678060787559},{"_id":"source/images/bookmedik-3.png","hash":"d23d6853835b5c77a46ae3ea7a977b0e760b6c0c","modified":1678045775320},{"_id":"source/images/bookmedik-4.png","hash":"285cafabd958875572b5e49777e0ca4abfa5eae7","modified":1678046340408},{"_id":"source/images/bookmedik-8.png","hash":"981582cc3fe95daf4214afb761bf9346c01e33bd","modified":1678060312251},{"_id":"source/images/bookmedik-6.png","hash":"e0ddab3bb9813f87cd096ca3a41fd3fd2fdaae21","modified":1678046864216},{"_id":"source/images/bookmedik-5.png","hash":"38b4709b0e3cc25205b657277282c218e886bbe5","modified":1678046805316},{"_id":"source/images/bookmedik-7.png","hash":"b48174e8ecff158a716f162cd3f19cb888975b8d","modified":1678047081480},{"_id":"source/images/k8s-logo-2.png","hash":"4b5f5c5f3fae7219699da275529b0362c203793b","modified":1678059950871},{"_id":"source/images/bookmedik-1.png","hash":"f11f00f4c3c63633867794ae0665b91a7a367d08","modified":1678044588224},{"_id":"source/images/bookmedik-2.png","hash":"556299068f117530ff43c5640f810a5df4758920","modified":1678045100532},{"_id":"source/images/bookmedik-9.png","hash":"fa70fbb8c72972176e2dd2e8eabdd3acd8944c13","modified":1678060612259},{"_id":"source/images/bookmedik-2.gif","hash":"63fed7cc050b080b9e0f131ca0936a8d285c4f78","modified":1678044804320},{"_id":"public/2023/03/05/k8s/index.html","hash":"b6fe8ec0a83068f48aecde73eef28513c5c30a72","modified":1678163991994},{"_id":"public/images/bookmedik-4.png","hash":"285cafabd958875572b5e49777e0ca4abfa5eae7","modified":1678060654884},{"_id":"public/images/bookmedik-3.png","hash":"d23d6853835b5c77a46ae3ea7a977b0e760b6c0c","modified":1678060654884},{"_id":"public/images/bookmedik-5.png","hash":"38b4709b0e3cc25205b657277282c218e886bbe5","modified":1678060654884},{"_id":"public/images/bookmedik-6.png","hash":"e0ddab3bb9813f87cd096ca3a41fd3fd2fdaae21","modified":1678060654884},{"_id":"public/images/bookmedik-7.png","hash":"b48174e8ecff158a716f162cd3f19cb888975b8d","modified":1678060654884},{"_id":"public/images/bookmedik-8.png","hash":"981582cc3fe95daf4214afb761bf9346c01e33bd","modified":1678060654884},{"_id":"public/images/k8s-logo-2.png","hash":"4b5f5c5f3fae7219699da275529b0362c203793b","modified":1678060654884},{"_id":"public/images/bookmedik-1.png","hash":"f11f00f4c3c63633867794ae0665b91a7a367d08","modified":1678060654884},{"_id":"public/images/bookmedik-2.png","hash":"556299068f117530ff43c5640f810a5df4758920","modified":1678060654884},{"_id":"public/images/bookmedik-9.png","hash":"fa70fbb8c72972176e2dd2e8eabdd3acd8944c13","modified":1678060654884},{"_id":"public/images/bookmedik-2.gif","hash":"63fed7cc050b080b9e0f131ca0936a8d285c4f78","modified":1678060654884},{"_id":"source/_posts/centos8.md","hash":"a20ad43786684c9f3f8a31f6bb11fc0861071c08","modified":1678274990828},{"_id":"source/images/centos-1.png","hash":"4af39eb17a1aa9c21ed1dd694d88ce2d7bfec388","modified":1678107623111},{"_id":"source/images/centos-13.png","hash":"455c9bcddc87b03c834dcf8bb587a89645ccbfec","modified":1678149480328},{"_id":"source/images/centos-26.png","hash":"080f2046309c48e9e8f63ec5726c8c3d2c603e56","modified":1678163663279},{"_id":"source/images/centos-4.png","hash":"30d2da4e61379a0bfb88162351213ebbb87c180b","modified":1678108577183},{"_id":"source/images/centos-9.png","hash":"f6f2c71780dd3097bae617b1bda67c0d9aef4b83","modified":1678148521556},{"_id":"source/images/centos-10.png","hash":"835cbcf7b048ca6f10d8cbbe2a2c02f56dcb9386","modified":1678148548256},{"_id":"source/images/centos-12.png","hash":"b8c632a3636e7375d528495872c8fe3b9ed529da","modified":1678149371948},{"_id":"source/images/centos-14.png","hash":"1f8b6eb8f6f9aeabd5385050608db2f437569987","modified":1678152623768},{"_id":"source/images/centos-15.png","hash":"557b308c247bd4e2d305256734009dfd67beee1d","modified":1678152698568},{"_id":"source/images/centos-23.png","hash":"a99a7a018f754f03d3bf28eee8671ddd8639367c","modified":1678163310875},{"_id":"source/images/centos-27.png","hash":"8ac8195b8688f087da160709cef7e0a9d98aa1b7","modified":1678163808047},{"_id":"source/images/centos-3.png","hash":"435a7306ca072c2e1504a7bb7fe60f747a03cf42","modified":1678108468475},{"_id":"source/images/centos-5.png","hash":"31c29b292a84eb69568d3f6cb4f7f48aa25f7126","modified":1678108975883},{"_id":"source/images/centos-6.png","hash":"30a4ed0c994af6ec545177e9390b86474d961a67","modified":1678109072655},{"_id":"source/images/centos-7.png","hash":"f5f82ec8caaa0f1b5b93dbbf0bcc2ab6a36e81b9","modified":1678130686456},{"_id":"source/images/centos-2.png","hash":"7f2a8233d433442f0d5b72e0f5373db012aa1ad8","modified":1678108388275},{"_id":"source/images/centos-25.png","hash":"f7a082ab1097a2cb6b8789f45f2cfc2bb910f639","modified":1678163451727},{"_id":"source/images/centos-20.png","hash":"959a4fca322f2955bbfe1280876ddc4acb86e898","modified":1678159262348},{"_id":"source/images/centos-16.png","hash":"741738c6302e7f4862ac93f52b0fa20339e6c914","modified":1678154142052},{"_id":"source/images/centos-17.png","hash":"0f1b44447be3ac2b184700117233841c34ebfef2","modified":1678154620112},{"_id":"source/images/centos-11.png","hash":"efb78b70f33975d80df4432cba6c058c2c42e019","modified":1678149203928},{"_id":"source/images/centos-24.png","hash":"7e9f34fb42ec5c8f8c921a66399fb2a88b9ff592","modified":1678163384475},{"_id":"source/images/centos-8.png","hash":"6ab7aa19fdf9a84632553a1023337c2fe6a763c4","modified":1678132707292},{"_id":"source/images/centos-19.png","hash":"c9b10612061110e0137d99a29883bbc29ed6fdca","modified":1678159171284},{"_id":"source/images/centos-22.png","hash":"be6a673829e08c3a2792d56acc9afa4aad2c4f10","modified":1678163186219},{"_id":"source/images/centos-21.png","hash":"5bad3179566690ad2a3205d5ac22e46c60d8db9e","modified":1678162768067},{"_id":"source/images/centos-18.png","hash":"0f68f70108a1d25a9159199f52f1146046fc6ccd","modified":1678155405356},{"_id":"public/2023/03/06/centos8/index.html","hash":"c029bad44ed28725f8005e62b92299fcb53aefa8","modified":1678303765168},{"_id":"public/archives/2023/page/3/index.html","hash":"c4adf0a8f6a334ae0d9ad8e7e4ec4119d967a632","modified":1678312853388},{"_id":"public/images/centos-1.png","hash":"4af39eb17a1aa9c21ed1dd694d88ce2d7bfec388","modified":1678163991994},{"_id":"public/images/centos-13.png","hash":"455c9bcddc87b03c834dcf8bb587a89645ccbfec","modified":1678163991994},{"_id":"public/images/centos-26.png","hash":"080f2046309c48e9e8f63ec5726c8c3d2c603e56","modified":1678163991994},{"_id":"public/images/centos-4.png","hash":"30d2da4e61379a0bfb88162351213ebbb87c180b","modified":1678163991994},{"_id":"public/images/centos-9.png","hash":"f6f2c71780dd3097bae617b1bda67c0d9aef4b83","modified":1678163991994},{"_id":"public/images/centos-10.png","hash":"835cbcf7b048ca6f10d8cbbe2a2c02f56dcb9386","modified":1678163991994},{"_id":"public/images/centos-12.png","hash":"b8c632a3636e7375d528495872c8fe3b9ed529da","modified":1678163991994},{"_id":"public/images/centos-14.png","hash":"1f8b6eb8f6f9aeabd5385050608db2f437569987","modified":1678163991994},{"_id":"public/images/centos-15.png","hash":"557b308c247bd4e2d305256734009dfd67beee1d","modified":1678163991994},{"_id":"public/images/centos-23.png","hash":"a99a7a018f754f03d3bf28eee8671ddd8639367c","modified":1678163991994},{"_id":"public/images/centos-27.png","hash":"8ac8195b8688f087da160709cef7e0a9d98aa1b7","modified":1678163991994},{"_id":"public/images/centos-3.png","hash":"435a7306ca072c2e1504a7bb7fe60f747a03cf42","modified":1678163991994},{"_id":"public/images/centos-5.png","hash":"31c29b292a84eb69568d3f6cb4f7f48aa25f7126","modified":1678163991994},{"_id":"public/images/centos-6.png","hash":"30a4ed0c994af6ec545177e9390b86474d961a67","modified":1678163991994},{"_id":"public/images/centos-7.png","hash":"f5f82ec8caaa0f1b5b93dbbf0bcc2ab6a36e81b9","modified":1678163991994},{"_id":"public/images/centos-2.png","hash":"7f2a8233d433442f0d5b72e0f5373db012aa1ad8","modified":1678163991994},{"_id":"public/images/centos-25.png","hash":"f7a082ab1097a2cb6b8789f45f2cfc2bb910f639","modified":1678163991994},{"_id":"public/images/centos-20.png","hash":"959a4fca322f2955bbfe1280876ddc4acb86e898","modified":1678163991994},{"_id":"public/images/centos-16.png","hash":"741738c6302e7f4862ac93f52b0fa20339e6c914","modified":1678163991994},{"_id":"public/images/centos-17.png","hash":"0f1b44447be3ac2b184700117233841c34ebfef2","modified":1678163991994},{"_id":"public/images/centos-11.png","hash":"efb78b70f33975d80df4432cba6c058c2c42e019","modified":1678163991994},{"_id":"public/images/centos-24.png","hash":"7e9f34fb42ec5c8f8c921a66399fb2a88b9ff592","modified":1678163991994},{"_id":"public/images/centos-8.png","hash":"6ab7aa19fdf9a84632553a1023337c2fe6a763c4","modified":1678163991994},{"_id":"public/images/centos-19.png","hash":"c9b10612061110e0137d99a29883bbc29ed6fdca","modified":1678163991994},{"_id":"public/images/centos-22.png","hash":"be6a673829e08c3a2792d56acc9afa4aad2c4f10","modified":1678163991994},{"_id":"public/images/centos-21.png","hash":"5bad3179566690ad2a3205d5ac22e46c60d8db9e","modified":1678163991994},{"_id":"public/images/centos-18.png","hash":"0f68f70108a1d25a9159199f52f1146046fc6ccd","modified":1678163991994},{"_id":"source/images/jenkins-taller-1-2.png","hash":"1328b9ec75820a93a6e66e4a21d215bb619e3552","modified":1678243138467},{"_id":"public/images/jenkins-taller-1-2.png","hash":"1328b9ec75820a93a6e66e4a21d215bb619e3552","modified":1678274300718},{"_id":"source/_posts/jenkins-intro.md","hash":"84be8e867612f6862a9aadea34d78148f8080312","modified":1678325449445},{"_id":"source/images/jenkins-taller-1-1.png","hash":"278a88927374d4f0f90d47e4cafcacae3ea4600c","modified":1678279825204},{"_id":"source/images/jenkins-taller-3-1.png","hash":"3f06e0b25c1a47b48e9bca656ce63485e1686c3b","modified":1678300394810},{"_id":"source/images/jenkins-taller-2-1.png","hash":"f0666fe951d69a134aef1311fa391614c68fb8a6","modified":1678298327190},{"_id":"source/images/jenkins-taller-3-4.png","hash":"fff56b6d949423ee0804176874cca31a0cda3518","modified":1678303467326},{"_id":"source/images/jenkins-taller-1-4.png","hash":"92e212cb028eab76dff12191f3717d7214e88b7b","modified":1678279737372},{"_id":"source/images/jenkins-taller-3-2.png","hash":"c05770688894fc4f762298214ef417989d45527c","modified":1678300565210},{"_id":"source/images/jenkins-taller-3-3.png","hash":"cd74afd37e93fbf752e3f27e9c0b79e15ae53d64","modified":1678302726706},{"_id":"source/images/jenkins-taller-3-5.png","hash":"fac12af6bac55074734617df50b64a2a0738cdf9","modified":1678303552490},{"_id":"source/images/jenkins-taller-1-3.png","hash":"bfc4ad4677adb34c95f4b00d80766f66ae5184a0","modified":1678279646772},{"_id":"source/images/jenkins-taller-2-2.gif","hash":"b6a57086f9b25b15046ddb85a9615e179cc86761","modified":1678298717622},{"_id":"public/2023/03/08/jenkins-intro/index.html","hash":"0296fab0a2e37f5c12d83e8f0b788e4b2bfddd3f","modified":1678325465633},{"_id":"public/images/jenkins-taller-1-1.png","hash":"278a88927374d4f0f90d47e4cafcacae3ea4600c","modified":1678303765168},{"_id":"public/images/jenkins-taller-3-1.png","hash":"3f06e0b25c1a47b48e9bca656ce63485e1686c3b","modified":1678303765168},{"_id":"public/images/jenkins-taller-1-4.png","hash":"92e212cb028eab76dff12191f3717d7214e88b7b","modified":1678303765168},{"_id":"public/images/jenkins-taller-2-1.png","hash":"f0666fe951d69a134aef1311fa391614c68fb8a6","modified":1678303765168},{"_id":"public/images/jenkins-taller-3-4.png","hash":"fff56b6d949423ee0804176874cca31a0cda3518","modified":1678303765168},{"_id":"public/images/jenkins-taller-1-3.png","hash":"bfc4ad4677adb34c95f4b00d80766f66ae5184a0","modified":1678303765168},{"_id":"public/images/jenkins-taller-3-2.png","hash":"c05770688894fc4f762298214ef417989d45527c","modified":1678303765168},{"_id":"public/images/jenkins-taller-3-3.png","hash":"cd74afd37e93fbf752e3f27e9c0b79e15ae53d64","modified":1678303765168},{"_id":"public/images/jenkins-taller-3-5.png","hash":"fac12af6bac55074734617df50b64a2a0738cdf9","modified":1678303765168},{"_id":"public/images/jenkins-taller-2-2.gif","hash":"b6a57086f9b25b15046ddb85a9615e179cc86761","modified":1678303765168},{"_id":"source/_posts/jenkins-practica.md","hash":"7353ef1729547c951729278371789b7b6bffdde5","modified":1678325521289},{"_id":"source/images/practica-jenkins-2-2.png","hash":"f19404c170297dffb050bbcf03622185395cf79c","modified":1678307979782},{"_id":"source/images/practica-jenkins-1.png","hash":"e058bbaf67e0f188776813a1525730a1c81e6602","modified":1678307137178},{"_id":"source/images/practica-jenkins-3.png","hash":"28e540ff14089dbd59c130a161398b2c18c12431","modified":1678307751942},{"_id":"source/images/practica-jenkins-1-1.png","hash":"d4bc69081b034b3f63b965f2dd91a534dfaf6f5b","modified":1678307612306},{"_id":"source/images/practica-jenkins-2.png","hash":"20f896071240da3c45aae35ba34974d5aa30f9b0","modified":1678307335994},{"_id":"source/images/practica-jenkins-4.png","hash":"232f5b665b69340b32b92cce4e63546523183231","modified":1678308661686},{"_id":"public/2023/03/08/jenkins-practica/index.html","hash":"e3a30ba36e61ba4212a6c3599972615b1072b0bd","modified":1678325531391},{"_id":"public/archives/page/4/index.html","hash":"33be2d18055d5737a2c6afe344d1e4fd9f6436fb","modified":1678312853388},{"_id":"public/page/4/index.html","hash":"272ecbd73d038b3e70eb3370567cd07121000229","modified":1678312853388},{"_id":"public/images/practica-jenkins-2-2.png","hash":"f19404c170297dffb050bbcf03622185395cf79c","modified":1678312853388},{"_id":"public/images/practica-jenkins-1.png","hash":"e058bbaf67e0f188776813a1525730a1c81e6602","modified":1678312853388},{"_id":"public/images/practica-jenkins-3.png","hash":"28e540ff14089dbd59c130a161398b2c18c12431","modified":1678312853388},{"_id":"public/images/practica-jenkins-1-1.png","hash":"d4bc69081b034b3f63b965f2dd91a534dfaf6f5b","modified":1678312853388},{"_id":"public/images/practica-jenkins-2.png","hash":"20f896071240da3c45aae35ba34974d5aa30f9b0","modified":1678312853388},{"_id":"public/images/practica-jenkins-4.png","hash":"232f5b665b69340b32b92cce4e63546523183231","modified":1678312853388},{"_id":"source/images/jenkins-intro.png","hash":"7a117670bbdeb48383e820af093a8db7cfa209fd","modified":1678325414357},{"_id":"source/images/jenkins-logo.png","hash":"a19ce805aa144a397c93a9be4e847dd732ec533d","modified":1678325348213},{"_id":"source/images/practica-jenkins-5.png","hash":"f11f699cd46e35841b12811eef61ed09a74e311e","modified":1678322127646},{"_id":"public/images/jenkins-intro.png","hash":"7a117670bbdeb48383e820af093a8db7cfa209fd","modified":1678325465633},{"_id":"public/images/jenkins-logo.png","hash":"a19ce805aa144a397c93a9be4e847dd732ec533d","modified":1678325465633},{"_id":"public/images/practica-jenkins-5.png","hash":"f11f699cd46e35841b12811eef61ed09a74e311e","modified":1678325465633}],"Category":[{"name":"Servicios de Red e Internet","_id":"cldl9ucgh00040yi5edldd0zy"},{"name":"Sistemas Operativos","_id":"cldl9ucgl000b0yi54x783cwm"},{"name":"Bases de Datos","_id":"cldl9ucgn000h0yi5dzea5q6a"},{"name":"Administración de Sistemas","_id":"cldl9ucgu000t0yi559vsbdg5"},{"name":"Seguridad","_id":"cldl9ucgw00120yi58s9r89pz"},{"name":"Almacenamiento","_id":"cldm4xm9f0001qni538qo5xbj"},{"name":"Contenedores","_id":"cldmvsvqn0001m3i53fhe1t18"},{"name":"contenedores","_id":"cldn18mbj00014qi56kyn0mvh"},{"name":"almacenamiento","_id":"cldrq0zqq0001v4i565i6dei6"}],"Data":[],"Page":[{"title":"archives","date":"2022-09-29T10:42:44.000Z","_content":"","source":"archives/index.md","raw":"---\ntitle: archives\ndate: 2022-09-29 12:42:44\n---\n","updated":"2022-09-29T10:42:44.348Z","path":"archives/index.html","comments":1,"layout":"page","_id":"cldl9ucga00000yi5duwkc1k5","content":"","site":{"data":{}},"length":0,"excerpt":"","more":""},{"title":"categories","date":"2022-09-29T10:42:45.000Z","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2022-09-29 12:42:45\n---\n","updated":"2022-09-29T10:42:45.208Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cldl9ucgf00020yi5amn8fble","content":"","site":{"data":{}},"length":0,"excerpt":"","more":""},{"title":"tags","date":"2022-09-29T10:42:46.000Z","_content":"\n","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2022-09-29 12:42:46\n---\n\n","updated":"2022-10-05T11:09:15.316Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cldl9ucgi00060yi563kwg82r","content":"","site":{"data":{}},"length":0,"excerpt":"","more":""},{"title":"about","date":"2022-09-29T10:42:46.000Z","_content":"","source":"about/index.md","raw":"---\ntitle: about\ndate: 2022-09-29 12:42:46\n---\n","updated":"2022-09-29T10:42:46.932Z","path":"about/index.html","comments":1,"layout":"page","_id":"cldl9ucgk00080yi516bch8g1","content":"","site":{"data":{}},"length":0,"excerpt":"","more":""}],"Post":[{"title":"Ansible + Vagrant, configurar y enrutar servidor web.","_content":"\n\n![Descripción de la imagen](/images/ansibleandvagrant.jpg)\n\n\nComenzaremos este post viendo como adjuntamos una box https://app.vagrantup.com/boxes/search\nbuscamos por ejemplo la de debian/ullseye, vamos a nuestra terminal y escribimos lo siguiente:\n`vagrant box add debian/bullseye64`\n\nEn ese momento se guardará en `~/.vagrant.d/boxes`\nBueno, dicho esto procedemos a crear la carpeta donde vamos a trabajar y hacemos un `vagrant init`, esto hará que se cree un archivo llamado vagrantfile, el cual debe quedar de la siguiente manera:\n\n```\nVagrant.configure(\"2\") do |config|\n    config.vm.define :nodo1 do |nodo1|\n      nodo1.vm.box = \"debian/bullseye64\"\n      nodo1.vm.hostname= \"nodo1\"\n      nodo1.vm.synced_folder \".\", \"/vagrant\", disabled: true\n      nodo1.vm.network :public_network,\n        :dev => \"br0\",\n        :mode => \"bridge\",\n        :type => \"bridge\",\n        use_dhcp_assigned_default_route: true\n      nodo1.vm.network :private_network,\n        :libvirt__network_name => \"red1\",\n        :libvirt__dhcp_enabled => false,\n        :ip => \"10.0.0.10\",\n        :libvirt__forward_mode => \"veryisolated\"\n    end\n    config.vm.define :nodo2 do |nodo2|\n      nodo2.vm.box = \"debian/bullseye64\"\n      nodo2.vm.hostname = \"nodo2\"\n      nodo2.vm.synced_folder \".\", \"/vagrant\", disabled: true\n      nodo2.vm.network :private_network,\n        :libvirt__network_name => \"red1\",\n        :libvirt__dhcp_enabled => false,\n        :ip => \"10.0.0.11\",\n        :libvirt__forward_mode => \"veryisolated\",\n        use_dhcp_assigned_default_route: true\n    end\nend\n\n```\n\nVamos a explicar paso por paso qué vemos en el código:\n- El vagrantfile debe estar perfectamente alineado, los end con sus respectivos config.\n- Al ser dos máquinas las vamos a llamar nodo1 y nodo2, que una será el router y la segunda el servidor que aloje apache\n- Si nos fijamos con atención podemos ver que **nodo1** tiene dos redes, una será pública, la cual tiene un bridge por donde saldrá a internet, y una red privada muy aislada, la cual no contendrá nada más que una ip estática, pondremos que la ruta por defecto va a ser el bridge que nos llevará a internet.\n- En **nodo2** tendremos una red privada, más tarde procederemos a ejecutar unas reglas que nos permitan salir por el exterior a través de la red muy aislada con **nat**\n  \nUna vez hecho esto procedemos a ver de cerca lo que contiene Ansible, el cual ejecutaremos tras iniciar las máquinas de Vagrant junto con sus redes.\n\n![Descripción de la imagen](/images/Ansible.png)\n\nComo podemos ver, hay una serie de carpetas llamadas roles, cada rol va a ejecutar una o varias tareas dependiendo de lo que se trate, por lo tanto así quedaría por ejemplo el activado del bit de forwarding del router:\n\n```\n- ansible.posix.sysctl:\n    name: net.ipv4.ip_forward\n    value: '1'\n    sysctl_set: yes\n```\n\nEstas tareas tienen un orden, y se realiza dentro de site.yml:\n```\n- hosts: nodo1\n  become: true\n  roles:\n   - role: copy\n\n- hosts: all\n  become: true\n  roles:\n   - role: commons\n\n- hosts: nodo2\n  become: true\n  roles:\n   - role: copy2\n   - role: apache2\n\n- hosts: nodo1\n  become: true\n  roles:\n   - role: ipv4\n\n```\n\nCon un poco de conocimientos en sistemas podemos ver claramente qué realiza cada rol.\n\nAhora vamos a poner la lupa en `roles/commons/handlers/main.yaml`, una parte muy importante de la ejecución de Ansible:\n```\n- name: reiniciando maquina\n  ansible.builtin.reboot:\n    msg: \"reboot by Ansible\"\n    pre_reboot_delay: 5\n    post_reboot_delay: 10\n    test_command: \"whoami\"\n```\n\nEste handler se ejecuta en el momento en el que se hace un llamamiento, en nuestro caso es cuando copiamos al router un fichero configurado para etc/network/interfaces, con sus interfaces, ruta por defecto e iptables:\n\n![Descripción de la imagen](/images/interfaces.png)\n\npodemos ver como en `roles/copy/tasks/main.yaml` hace el llamamiento al **handler** en el notify:\n\n```\n- name: Copiando al etc/network/interfaces\n  ansible.builtin.copy:\n    src: interfaz_nodo1/interfaces\n    dest: /etc/network/\n    owner: root\n    group: root\n    mode: u-rw,g-wx,o-rwx\n  notify:\n    - reiniciando maquina\n\n```\n\nA continuación podemos copiar nuestra clave pública a través de la tarea **commons** que será lo que nos permita atravesar por ssh sin utilizar la clave vagrant, es decir, la nuestra.\n\n```\n- name: Ensure system is updated\n  apt: update_cache=yes upgrade=yes\n\n- name: Set authorized key took from file\n  authorized_key:\n    user: vagrant\n    state: present\n    key: \"{{ lookup('file', '/home/antonio/.ssh/id_rsa.pub') }}\"\n\n```\n\nLuego pasamos a la instalación de Apache,a través del módulo apt para instalar apache2, ports.conf es la configuración de los puertos por los que escucha, también alberga el fichero index.html y una plantilla jinja2.\n\nPor último pero no menos importante está el fichero hosts, el cual será el inventario por el cual el sistema sabrá cuál será nodo1 y cuál nodo2, a través de las correspondientes ips que asignaremos,el usuario más la clave privada que asignará vagrant:\n\n```\nall:\n  children:\n    servidores_web:\n      hosts:\n        nodo1:\n          ansible_ssh_host: 192.168.121.212\n          ansible_ssh_user: vagrant\n          ansible_ssh_private_key_file: ../.vagrant/machines/nodo1/libvirt/private_key\n        nodo2:\n          ansible_ssh_host: 192.168.121.111\n          ansible_ssh_user: vagrant\n          ansible_ssh_private_key_file: ../.vagrant/machines/nodo2/libvirt/private_key\n\n```\n\ncon esto solo necesitaremos ejecutar el `ansible-playbook site.yaml` y tendremos enrutado y configurado nuestro servidor web.","source":"_posts/Ansible+Vagrant.md","raw":"---\ntitle: Ansible + Vagrant, configurar y enrutar servidor web.\ncategories: Servicios de Red e Internet\ntags: Servicios de Red e Internet\n---\n\n\n![Descripción de la imagen](/images/ansibleandvagrant.jpg)\n\n\nComenzaremos este post viendo como adjuntamos una box https://app.vagrantup.com/boxes/search\nbuscamos por ejemplo la de debian/ullseye, vamos a nuestra terminal y escribimos lo siguiente:\n`vagrant box add debian/bullseye64`\n\nEn ese momento se guardará en `~/.vagrant.d/boxes`\nBueno, dicho esto procedemos a crear la carpeta donde vamos a trabajar y hacemos un `vagrant init`, esto hará que se cree un archivo llamado vagrantfile, el cual debe quedar de la siguiente manera:\n\n```\nVagrant.configure(\"2\") do |config|\n    config.vm.define :nodo1 do |nodo1|\n      nodo1.vm.box = \"debian/bullseye64\"\n      nodo1.vm.hostname= \"nodo1\"\n      nodo1.vm.synced_folder \".\", \"/vagrant\", disabled: true\n      nodo1.vm.network :public_network,\n        :dev => \"br0\",\n        :mode => \"bridge\",\n        :type => \"bridge\",\n        use_dhcp_assigned_default_route: true\n      nodo1.vm.network :private_network,\n        :libvirt__network_name => \"red1\",\n        :libvirt__dhcp_enabled => false,\n        :ip => \"10.0.0.10\",\n        :libvirt__forward_mode => \"veryisolated\"\n    end\n    config.vm.define :nodo2 do |nodo2|\n      nodo2.vm.box = \"debian/bullseye64\"\n      nodo2.vm.hostname = \"nodo2\"\n      nodo2.vm.synced_folder \".\", \"/vagrant\", disabled: true\n      nodo2.vm.network :private_network,\n        :libvirt__network_name => \"red1\",\n        :libvirt__dhcp_enabled => false,\n        :ip => \"10.0.0.11\",\n        :libvirt__forward_mode => \"veryisolated\",\n        use_dhcp_assigned_default_route: true\n    end\nend\n\n```\n\nVamos a explicar paso por paso qué vemos en el código:\n- El vagrantfile debe estar perfectamente alineado, los end con sus respectivos config.\n- Al ser dos máquinas las vamos a llamar nodo1 y nodo2, que una será el router y la segunda el servidor que aloje apache\n- Si nos fijamos con atención podemos ver que **nodo1** tiene dos redes, una será pública, la cual tiene un bridge por donde saldrá a internet, y una red privada muy aislada, la cual no contendrá nada más que una ip estática, pondremos que la ruta por defecto va a ser el bridge que nos llevará a internet.\n- En **nodo2** tendremos una red privada, más tarde procederemos a ejecutar unas reglas que nos permitan salir por el exterior a través de la red muy aislada con **nat**\n  \nUna vez hecho esto procedemos a ver de cerca lo que contiene Ansible, el cual ejecutaremos tras iniciar las máquinas de Vagrant junto con sus redes.\n\n![Descripción de la imagen](/images/Ansible.png)\n\nComo podemos ver, hay una serie de carpetas llamadas roles, cada rol va a ejecutar una o varias tareas dependiendo de lo que se trate, por lo tanto así quedaría por ejemplo el activado del bit de forwarding del router:\n\n```\n- ansible.posix.sysctl:\n    name: net.ipv4.ip_forward\n    value: '1'\n    sysctl_set: yes\n```\n\nEstas tareas tienen un orden, y se realiza dentro de site.yml:\n```\n- hosts: nodo1\n  become: true\n  roles:\n   - role: copy\n\n- hosts: all\n  become: true\n  roles:\n   - role: commons\n\n- hosts: nodo2\n  become: true\n  roles:\n   - role: copy2\n   - role: apache2\n\n- hosts: nodo1\n  become: true\n  roles:\n   - role: ipv4\n\n```\n\nCon un poco de conocimientos en sistemas podemos ver claramente qué realiza cada rol.\n\nAhora vamos a poner la lupa en `roles/commons/handlers/main.yaml`, una parte muy importante de la ejecución de Ansible:\n```\n- name: reiniciando maquina\n  ansible.builtin.reboot:\n    msg: \"reboot by Ansible\"\n    pre_reboot_delay: 5\n    post_reboot_delay: 10\n    test_command: \"whoami\"\n```\n\nEste handler se ejecuta en el momento en el que se hace un llamamiento, en nuestro caso es cuando copiamos al router un fichero configurado para etc/network/interfaces, con sus interfaces, ruta por defecto e iptables:\n\n![Descripción de la imagen](/images/interfaces.png)\n\npodemos ver como en `roles/copy/tasks/main.yaml` hace el llamamiento al **handler** en el notify:\n\n```\n- name: Copiando al etc/network/interfaces\n  ansible.builtin.copy:\n    src: interfaz_nodo1/interfaces\n    dest: /etc/network/\n    owner: root\n    group: root\n    mode: u-rw,g-wx,o-rwx\n  notify:\n    - reiniciando maquina\n\n```\n\nA continuación podemos copiar nuestra clave pública a través de la tarea **commons** que será lo que nos permita atravesar por ssh sin utilizar la clave vagrant, es decir, la nuestra.\n\n```\n- name: Ensure system is updated\n  apt: update_cache=yes upgrade=yes\n\n- name: Set authorized key took from file\n  authorized_key:\n    user: vagrant\n    state: present\n    key: \"{{ lookup('file', '/home/antonio/.ssh/id_rsa.pub') }}\"\n\n```\n\nLuego pasamos a la instalación de Apache,a través del módulo apt para instalar apache2, ports.conf es la configuración de los puertos por los que escucha, también alberga el fichero index.html y una plantilla jinja2.\n\nPor último pero no menos importante está el fichero hosts, el cual será el inventario por el cual el sistema sabrá cuál será nodo1 y cuál nodo2, a través de las correspondientes ips que asignaremos,el usuario más la clave privada que asignará vagrant:\n\n```\nall:\n  children:\n    servidores_web:\n      hosts:\n        nodo1:\n          ansible_ssh_host: 192.168.121.212\n          ansible_ssh_user: vagrant\n          ansible_ssh_private_key_file: ../.vagrant/machines/nodo1/libvirt/private_key\n        nodo2:\n          ansible_ssh_host: 192.168.121.111\n          ansible_ssh_user: vagrant\n          ansible_ssh_private_key_file: ../.vagrant/machines/nodo2/libvirt/private_key\n\n```\n\ncon esto solo necesitaremos ejecutar el `ansible-playbook site.yaml` y tendremos enrutado y configurado nuestro servidor web.","slug":"Ansible+Vagrant","published":1,"date":"2022-10-13T17:45:40.684Z","updated":"2023-01-04T13:42:40.307Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cldl9ucgc00010yi54vf709rr","content":"<p><img src=\"/images/ansibleandvagrant.jpg\" alt=\"Descripción de la imagen\"></p>\n<p>Comenzaremos este post viendo como adjuntamos una box <a href=\"https://app.vagrantup.com/boxes/search\">https://app.vagrantup.com/boxes/search</a><br>\nbuscamos por ejemplo la de debian/ullseye, vamos a nuestra terminal y escribimos lo siguiente:<br>\n <code>vagrant box add debian/bullseye64</code></p>\n<p>En ese momento se guardará en  <code>~/.vagrant.d/boxes</code> <br>\nBueno, dicho esto procedemos a crear la carpeta donde vamos a trabajar y hacemos un  <code>vagrant init</code> , esto hará que se cree un archivo llamado vagrantfile, el cual debe quedar de la siguiente manera:</p>\n<pre><code>Vagrant.configure(&quot;2&quot;) do |config|\n    config.vm.define :nodo1 do |nodo1|\n      nodo1.vm.box = &quot;debian/bullseye64&quot;\n      nodo1.vm.hostname= &quot;nodo1&quot;\n      nodo1.vm.synced_folder &quot;.&quot;, &quot;/vagrant&quot;, disabled: true\n      nodo1.vm.network :public_network,\n        :dev =&gt; &quot;br0&quot;,\n        :mode =&gt; &quot;bridge&quot;,\n        :type =&gt; &quot;bridge&quot;,\n        use_dhcp_assigned_default_route: true\n      nodo1.vm.network :private_network,\n        :libvirt__network_name =&gt; &quot;red1&quot;,\n        :libvirt__dhcp_enabled =&gt; false,\n        :ip =&gt; &quot;10.0.0.10&quot;,\n        :libvirt__forward_mode =&gt; &quot;veryisolated&quot;\n    end\n    config.vm.define :nodo2 do |nodo2|\n      nodo2.vm.box = &quot;debian/bullseye64&quot;\n      nodo2.vm.hostname = &quot;nodo2&quot;\n      nodo2.vm.synced_folder &quot;.&quot;, &quot;/vagrant&quot;, disabled: true\n      nodo2.vm.network :private_network,\n        :libvirt__network_name =&gt; &quot;red1&quot;,\n        :libvirt__dhcp_enabled =&gt; false,\n        :ip =&gt; &quot;10.0.0.11&quot;,\n        :libvirt__forward_mode =&gt; &quot;veryisolated&quot;,\n        use_dhcp_assigned_default_route: true\n    end\nend\n\n</code></pre>\n<p>Vamos a explicar paso por paso qué vemos en el código:</p>\n<ul>\n<li>El vagrantfile debe estar perfectamente alineado, los end con sus respectivos config.</li>\n<li>Al ser dos máquinas las vamos a llamar nodo1 y nodo2, que una será el router y la segunda el servidor que aloje apache</li>\n<li>Si nos fijamos con atención podemos ver que <strong>nodo1</strong> tiene dos redes, una será pública, la cual tiene un bridge por donde saldrá a internet, y una red privada muy aislada, la cual no contendrá nada más que una ip estática, pondremos que la ruta por defecto va a ser el bridge que nos llevará a internet.</li>\n<li>En <strong>nodo2</strong> tendremos una red privada, más tarde procederemos a ejecutar unas reglas que nos permitan salir por el exterior a través de la red muy aislada con <strong>nat</strong></li>\n</ul>\n<p>Una vez hecho esto procedemos a ver de cerca lo que contiene Ansible, el cual ejecutaremos tras iniciar las máquinas de Vagrant junto con sus redes.</p>\n<p><img src=\"/images/Ansible.png\" alt=\"Descripción de la imagen\"></p>\n<p>Como podemos ver, hay una serie de carpetas llamadas roles, cada rol va a ejecutar una o varias tareas dependiendo de lo que se trate, por lo tanto así quedaría por ejemplo el activado del bit de forwarding del router:</p>\n<pre><code>- ansible.posix.sysctl:\n    name: net.ipv4.ip_forward\n    value: '1'\n    sysctl_set: yes\n</code></pre>\n<p>Estas tareas tienen un orden, y se realiza dentro de site.yml:</p>\n<pre><code>- hosts: nodo1\n  become: true\n  roles:\n   - role: copy\n\n- hosts: all\n  become: true\n  roles:\n   - role: commons\n\n- hosts: nodo2\n  become: true\n  roles:\n   - role: copy2\n   - role: apache2\n\n- hosts: nodo1\n  become: true\n  roles:\n   - role: ipv4\n\n</code></pre>\n<p>Con un poco de conocimientos en sistemas podemos ver claramente qué realiza cada rol.</p>\n<p>Ahora vamos a poner la lupa en  <code>roles/commons/handlers/main.yaml</code> , una parte muy importante de la ejecución de Ansible:</p>\n<pre><code>- name: reiniciando maquina\n  ansible.builtin.reboot:\n    msg: &quot;reboot by Ansible&quot;\n    pre_reboot_delay: 5\n    post_reboot_delay: 10\n    test_command: &quot;whoami&quot;\n</code></pre>\n<p>Este handler se ejecuta en el momento en el que se hace un llamamiento, en nuestro caso es cuando copiamos al router un fichero configurado para etc/network/interfaces, con sus interfaces, ruta por defecto e iptables:</p>\n<p><img src=\"/images/interfaces.png\" alt=\"Descripción de la imagen\"></p>\n<p>podemos ver como en  <code>roles/copy/tasks/main.yaml</code>  hace el llamamiento al <strong>handler</strong> en el notify:</p>\n<pre><code>- name: Copiando al etc/network/interfaces\n  ansible.builtin.copy:\n    src: interfaz_nodo1/interfaces\n    dest: /etc/network/\n    owner: root\n    group: root\n    mode: u-rw,g-wx,o-rwx\n  notify:\n    - reiniciando maquina\n\n</code></pre>\n<p>A continuación podemos copiar nuestra clave pública a través de la tarea <strong>commons</strong> que será lo que nos permita atravesar por ssh sin utilizar la clave vagrant, es decir, la nuestra.</p>\n<pre><code>- name: Ensure system is updated\n  apt: update_cache=yes upgrade=yes\n\n- name: Set authorized key took from file\n  authorized_key:\n    user: vagrant\n    state: present\n    key: &quot;&#123;&#123; lookup('file', '/home/antonio/.ssh/id_rsa.pub') &#125;&#125;&quot;\n\n</code></pre>\n<p>Luego pasamos a la instalación de Apache,a través del módulo apt para instalar apache2, ports.conf es la configuración de los puertos por los que escucha, también alberga el fichero index.html y una plantilla jinja2.</p>\n<p>Por último pero no menos importante está el fichero hosts, el cual será el inventario por el cual el sistema sabrá cuál será nodo1 y cuál nodo2, a través de las correspondientes ips que asignaremos,el usuario más la clave privada que asignará vagrant:</p>\n<pre><code>all:\n  children:\n    servidores_web:\n      hosts:\n        nodo1:\n          ansible_ssh_host: 192.168.121.212\n          ansible_ssh_user: vagrant\n          ansible_ssh_private_key_file: ../.vagrant/machines/nodo1/libvirt/private_key\n        nodo2:\n          ansible_ssh_host: 192.168.121.111\n          ansible_ssh_user: vagrant\n          ansible_ssh_private_key_file: ../.vagrant/machines/nodo2/libvirt/private_key\n\n</code></pre>\n<p>con esto solo necesitaremos ejecutar el  <code>ansible-playbook site.yaml</code>  y tendremos enrutado y configurado nuestro servidor web.</p>\n","site":{"data":{}},"length":4487,"excerpt":"","more":"<p><img src=\"/images/ansibleandvagrant.jpg\" alt=\"Descripción de la imagen\"></p>\n<p>Comenzaremos este post viendo como adjuntamos una box <a href=\"https://app.vagrantup.com/boxes/search\">https://app.vagrantup.com/boxes/search</a><br>\nbuscamos por ejemplo la de debian/ullseye, vamos a nuestra terminal y escribimos lo siguiente:<br>\n <code>vagrant box add debian/bullseye64</code></p>\n<p>En ese momento se guardará en  <code>~/.vagrant.d/boxes</code> <br>\nBueno, dicho esto procedemos a crear la carpeta donde vamos a trabajar y hacemos un  <code>vagrant init</code> , esto hará que se cree un archivo llamado vagrantfile, el cual debe quedar de la siguiente manera:</p>\n<pre><code>Vagrant.configure(&quot;2&quot;) do |config|\n    config.vm.define :nodo1 do |nodo1|\n      nodo1.vm.box = &quot;debian/bullseye64&quot;\n      nodo1.vm.hostname= &quot;nodo1&quot;\n      nodo1.vm.synced_folder &quot;.&quot;, &quot;/vagrant&quot;, disabled: true\n      nodo1.vm.network :public_network,\n        :dev =&gt; &quot;br0&quot;,\n        :mode =&gt; &quot;bridge&quot;,\n        :type =&gt; &quot;bridge&quot;,\n        use_dhcp_assigned_default_route: true\n      nodo1.vm.network :private_network,\n        :libvirt__network_name =&gt; &quot;red1&quot;,\n        :libvirt__dhcp_enabled =&gt; false,\n        :ip =&gt; &quot;10.0.0.10&quot;,\n        :libvirt__forward_mode =&gt; &quot;veryisolated&quot;\n    end\n    config.vm.define :nodo2 do |nodo2|\n      nodo2.vm.box = &quot;debian/bullseye64&quot;\n      nodo2.vm.hostname = &quot;nodo2&quot;\n      nodo2.vm.synced_folder &quot;.&quot;, &quot;/vagrant&quot;, disabled: true\n      nodo2.vm.network :private_network,\n        :libvirt__network_name =&gt; &quot;red1&quot;,\n        :libvirt__dhcp_enabled =&gt; false,\n        :ip =&gt; &quot;10.0.0.11&quot;,\n        :libvirt__forward_mode =&gt; &quot;veryisolated&quot;,\n        use_dhcp_assigned_default_route: true\n    end\nend\n\n</code></pre>\n<p>Vamos a explicar paso por paso qué vemos en el código:</p>\n<ul>\n<li>El vagrantfile debe estar perfectamente alineado, los end con sus respectivos config.</li>\n<li>Al ser dos máquinas las vamos a llamar nodo1 y nodo2, que una será el router y la segunda el servidor que aloje apache</li>\n<li>Si nos fijamos con atención podemos ver que <strong>nodo1</strong> tiene dos redes, una será pública, la cual tiene un bridge por donde saldrá a internet, y una red privada muy aislada, la cual no contendrá nada más que una ip estática, pondremos que la ruta por defecto va a ser el bridge que nos llevará a internet.</li>\n<li>En <strong>nodo2</strong> tendremos una red privada, más tarde procederemos a ejecutar unas reglas que nos permitan salir por el exterior a través de la red muy aislada con <strong>nat</strong></li>\n</ul>\n<p>Una vez hecho esto procedemos a ver de cerca lo que contiene Ansible, el cual ejecutaremos tras iniciar las máquinas de Vagrant junto con sus redes.</p>\n<p><img src=\"/images/Ansible.png\" alt=\"Descripción de la imagen\"></p>\n<p>Como podemos ver, hay una serie de carpetas llamadas roles, cada rol va a ejecutar una o varias tareas dependiendo de lo que se trate, por lo tanto así quedaría por ejemplo el activado del bit de forwarding del router:</p>\n<pre><code>- ansible.posix.sysctl:\n    name: net.ipv4.ip_forward\n    value: '1'\n    sysctl_set: yes\n</code></pre>\n<p>Estas tareas tienen un orden, y se realiza dentro de site.yml:</p>\n<pre><code>- hosts: nodo1\n  become: true\n  roles:\n   - role: copy\n\n- hosts: all\n  become: true\n  roles:\n   - role: commons\n\n- hosts: nodo2\n  become: true\n  roles:\n   - role: copy2\n   - role: apache2\n\n- hosts: nodo1\n  become: true\n  roles:\n   - role: ipv4\n\n</code></pre>\n<p>Con un poco de conocimientos en sistemas podemos ver claramente qué realiza cada rol.</p>\n<p>Ahora vamos a poner la lupa en  <code>roles/commons/handlers/main.yaml</code> , una parte muy importante de la ejecución de Ansible:</p>\n<pre><code>- name: reiniciando maquina\n  ansible.builtin.reboot:\n    msg: &quot;reboot by Ansible&quot;\n    pre_reboot_delay: 5\n    post_reboot_delay: 10\n    test_command: &quot;whoami&quot;\n</code></pre>\n<p>Este handler se ejecuta en el momento en el que se hace un llamamiento, en nuestro caso es cuando copiamos al router un fichero configurado para etc/network/interfaces, con sus interfaces, ruta por defecto e iptables:</p>\n<p><img src=\"/images/interfaces.png\" alt=\"Descripción de la imagen\"></p>\n<p>podemos ver como en  <code>roles/copy/tasks/main.yaml</code>  hace el llamamiento al <strong>handler</strong> en el notify:</p>\n<pre><code>- name: Copiando al etc/network/interfaces\n  ansible.builtin.copy:\n    src: interfaz_nodo1/interfaces\n    dest: /etc/network/\n    owner: root\n    group: root\n    mode: u-rw,g-wx,o-rwx\n  notify:\n    - reiniciando maquina\n\n</code></pre>\n<p>A continuación podemos copiar nuestra clave pública a través de la tarea <strong>commons</strong> que será lo que nos permita atravesar por ssh sin utilizar la clave vagrant, es decir, la nuestra.</p>\n<pre><code>- name: Ensure system is updated\n  apt: update_cache=yes upgrade=yes\n\n- name: Set authorized key took from file\n  authorized_key:\n    user: vagrant\n    state: present\n    key: &quot;&#123;&#123; lookup('file', '/home/antonio/.ssh/id_rsa.pub') &#125;&#125;&quot;\n\n</code></pre>\n<p>Luego pasamos a la instalación de Apache,a través del módulo apt para instalar apache2, ports.conf es la configuración de los puertos por los que escucha, también alberga el fichero index.html y una plantilla jinja2.</p>\n<p>Por último pero no menos importante está el fichero hosts, el cual será el inventario por el cual el sistema sabrá cuál será nodo1 y cuál nodo2, a través de las correspondientes ips que asignaremos,el usuario más la clave privada que asignará vagrant:</p>\n<pre><code>all:\n  children:\n    servidores_web:\n      hosts:\n        nodo1:\n          ansible_ssh_host: 192.168.121.212\n          ansible_ssh_user: vagrant\n          ansible_ssh_private_key_file: ../.vagrant/machines/nodo1/libvirt/private_key\n        nodo2:\n          ansible_ssh_host: 192.168.121.111\n          ansible_ssh_user: vagrant\n          ansible_ssh_private_key_file: ../.vagrant/machines/nodo2/libvirt/private_key\n\n</code></pre>\n<p>con esto solo necesitaremos ejecutar el  <code>ansible-playbook site.yaml</code>  y tendremos enrutado y configurado nuestro servidor web.</p>\n"},{"title":"Configurar kernel a medida","_content":"\n![Descripción de la imagen](/images/linux-6.0.jpg)\n\nComenzaremos creando una carpeta que nos sirva de entorno de trabajo\n\n`mkdir kernel && cd kernel`\n\n\nInstalamos las dependencias que nos ayudarán a compilar el kernel, el cual nos ahorrará errores en la compilación:\n\n\n`sudo apt install build-essential flex nbison openssl libssl-dev dkms libncurses-dev ncurses-dev qtbase5-dev libelf-dev`\n\nNos vamos ahora a kernel.org a descargarnos la última versión del kernel de linux.\n\nUna vez descargado el kernel lo descomprimimos con el comando tar -xvf linux-6.0.7.tar.gz, ingresamos dentro y vemos que entre muchos archivos, encontramos un makefile, entramos dentro y encontraremos el archivo EXTRAVERSION, el cual pondremos una versión para poder llevar un control de versiones.\n\nEntramos dentro del directorio descomprimido y procedemos a generar el `make oldconfig` que creará el archivo .config con los módulos que deberemos compilar, intentamos contestar a las preguntas de forma negativa para que no genere módulos opcionales.\n\nUna vez hecho esto debemos de adaptar los módulos que está utilizando nuestra máquina para compilar el kernel a medida, entonces utilizaremos un `make localyesconfig`\n\n```\n╭─antonio@debian ~/Programas/kernel/linux-6.0.7  \n╰─➤  egrep '=y' .config | wc -l                                                                                                 130 ↵\n1934\n╭─antonio@debian ~/Programas/kernel/linux-6.0.7  \n╰─➤  egrep '=m' .config | wc -l\n3\n```\n\nUna vez hecho esto procederemos a probar nuestro kernel a medida `make -j8 bindeb-pkg` pudiendo así compilar el kernel, le otorgaremos 8 jobs y si agregamos un time `time make -j8 bindeb-pkg` podemos ver la duración que ha tardado el sistema en compilarlo.\n\nReiniciamos nuestra máquina y entramos en el nuevo kernel, utilizamos `uname -r`\n\nLuego volvemos a nuestro kernel, y en concreto a nuestro espacio de trabajo, ejecutamos un `make clean` para eliminar los 'residuos' generados tras al compilación, y hacemos un control de versiones del .config, como nos funcionó la primera versión realizamos un `cp .config ../v1.config`\n\n![Descripción de la imagen](/images/xconfig.png)","source":"_posts/Compilar-linux-a-medida.md","raw":"\n---\ntitle: Configurar kernel a medida\ncategories: Sistemas Operativos\ntags: Sistemas Operativos\n---\n\n![Descripción de la imagen](/images/linux-6.0.jpg)\n\nComenzaremos creando una carpeta que nos sirva de entorno de trabajo\n\n`mkdir kernel && cd kernel`\n\n\nInstalamos las dependencias que nos ayudarán a compilar el kernel, el cual nos ahorrará errores en la compilación:\n\n\n`sudo apt install build-essential flex nbison openssl libssl-dev dkms libncurses-dev ncurses-dev qtbase5-dev libelf-dev`\n\nNos vamos ahora a kernel.org a descargarnos la última versión del kernel de linux.\n\nUna vez descargado el kernel lo descomprimimos con el comando tar -xvf linux-6.0.7.tar.gz, ingresamos dentro y vemos que entre muchos archivos, encontramos un makefile, entramos dentro y encontraremos el archivo EXTRAVERSION, el cual pondremos una versión para poder llevar un control de versiones.\n\nEntramos dentro del directorio descomprimido y procedemos a generar el `make oldconfig` que creará el archivo .config con los módulos que deberemos compilar, intentamos contestar a las preguntas de forma negativa para que no genere módulos opcionales.\n\nUna vez hecho esto debemos de adaptar los módulos que está utilizando nuestra máquina para compilar el kernel a medida, entonces utilizaremos un `make localyesconfig`\n\n```\n╭─antonio@debian ~/Programas/kernel/linux-6.0.7  \n╰─➤  egrep '=y' .config | wc -l                                                                                                 130 ↵\n1934\n╭─antonio@debian ~/Programas/kernel/linux-6.0.7  \n╰─➤  egrep '=m' .config | wc -l\n3\n```\n\nUna vez hecho esto procederemos a probar nuestro kernel a medida `make -j8 bindeb-pkg` pudiendo así compilar el kernel, le otorgaremos 8 jobs y si agregamos un time `time make -j8 bindeb-pkg` podemos ver la duración que ha tardado el sistema en compilarlo.\n\nReiniciamos nuestra máquina y entramos en el nuevo kernel, utilizamos `uname -r`\n\nLuego volvemos a nuestro kernel, y en concreto a nuestro espacio de trabajo, ejecutamos un `make clean` para eliminar los 'residuos' generados tras al compilación, y hacemos un control de versiones del .config, como nos funcionó la primera versión realizamos un `cp .config ../v1.config`\n\n![Descripción de la imagen](/images/xconfig.png)","slug":"Compilar-linux-a-medida","published":1,"date":"2022-11-16T21:49:54.792Z","updated":"2023-01-04T13:42:53.119Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cldl9ucgg00030yi54f2j8x4u","content":"<p><img src=\"/images/linux-6.0.jpg\" alt=\"Descripción de la imagen\"></p>\n<p>Comenzaremos creando una carpeta que nos sirva de entorno de trabajo</p>\n<p><code>mkdir kernel &amp;&amp; cd kernel</code></p>\n<p>Instalamos las dependencias que nos ayudarán a compilar el kernel, el cual nos ahorrará errores en la compilación:</p>\n<p><code>sudo apt install build-essential flex nbison openssl libssl-dev dkms libncurses-dev ncurses-dev qtbase5-dev libelf-dev</code></p>\n<p>Nos vamos ahora a <a href=\"http://kernel.org\">kernel.org</a> a descargarnos la última versión del kernel de linux.</p>\n<p>Una vez descargado el kernel lo descomprimimos con el comando tar -xvf linux-6.0.7.tar.gz, ingresamos dentro y vemos que entre muchos archivos, encontramos un makefile, entramos dentro y encontraremos el archivo EXTRAVERSION, el cual pondremos una versión para poder llevar un control de versiones.</p>\n<p>Entramos dentro del directorio descomprimido y procedemos a generar el  <code>make oldconfig</code>  que creará el archivo .config con los módulos que deberemos compilar, intentamos contestar a las preguntas de forma negativa para que no genere módulos opcionales.</p>\n<p>Una vez hecho esto debemos de adaptar los módulos que está utilizando nuestra máquina para compilar el kernel a medida, entonces utilizaremos un  <code>make localyesconfig</code></p>\n<pre><code>╭─antonio@debian ~/Programas/kernel/linux-6.0.7  \n╰─➤  egrep '=y' .config | wc -l                                                                                                 130 ↵\n1934\n╭─antonio@debian ~/Programas/kernel/linux-6.0.7  \n╰─➤  egrep '=m' .config | wc -l\n3\n</code></pre>\n<p>Una vez hecho esto procederemos a probar nuestro kernel a medida  <code>make -j8 bindeb-pkg</code>  pudiendo así compilar el kernel, le otorgaremos 8 jobs y si agregamos un time  <code>time make -j8 bindeb-pkg</code>  podemos ver la duración que ha tardado el sistema en compilarlo.</p>\n<p>Reiniciamos nuestra máquina y entramos en el nuevo kernel, utilizamos  <code>uname -r</code></p>\n<p>Luego volvemos a nuestro kernel, y en concreto a nuestro espacio de trabajo, ejecutamos un  <code>make clean</code>  para eliminar los ‘residuos’ generados tras al compilación, y hacemos un control de versiones del .config, como nos funcionó la primera versión realizamos un  <code>cp .config ../v1.config</code></p>\n<p><img src=\"/images/xconfig.png\" alt=\"Descripción de la imagen\"></p>\n","site":{"data":{}},"length":1634,"excerpt":"","more":"<p><img src=\"/images/linux-6.0.jpg\" alt=\"Descripción de la imagen\"></p>\n<p>Comenzaremos creando una carpeta que nos sirva de entorno de trabajo</p>\n<p><code>mkdir kernel &amp;&amp; cd kernel</code></p>\n<p>Instalamos las dependencias que nos ayudarán a compilar el kernel, el cual nos ahorrará errores en la compilación:</p>\n<p><code>sudo apt install build-essential flex nbison openssl libssl-dev dkms libncurses-dev ncurses-dev qtbase5-dev libelf-dev</code></p>\n<p>Nos vamos ahora a <a href=\"http://kernel.org\">kernel.org</a> a descargarnos la última versión del kernel de linux.</p>\n<p>Una vez descargado el kernel lo descomprimimos con el comando tar -xvf linux-6.0.7.tar.gz, ingresamos dentro y vemos que entre muchos archivos, encontramos un makefile, entramos dentro y encontraremos el archivo EXTRAVERSION, el cual pondremos una versión para poder llevar un control de versiones.</p>\n<p>Entramos dentro del directorio descomprimido y procedemos a generar el  <code>make oldconfig</code>  que creará el archivo .config con los módulos que deberemos compilar, intentamos contestar a las preguntas de forma negativa para que no genere módulos opcionales.</p>\n<p>Una vez hecho esto debemos de adaptar los módulos que está utilizando nuestra máquina para compilar el kernel a medida, entonces utilizaremos un  <code>make localyesconfig</code></p>\n<pre><code>╭─antonio@debian ~/Programas/kernel/linux-6.0.7  \n╰─➤  egrep '=y' .config | wc -l                                                                                                 130 ↵\n1934\n╭─antonio@debian ~/Programas/kernel/linux-6.0.7  \n╰─➤  egrep '=m' .config | wc -l\n3\n</code></pre>\n<p>Una vez hecho esto procederemos a probar nuestro kernel a medida  <code>make -j8 bindeb-pkg</code>  pudiendo así compilar el kernel, le otorgaremos 8 jobs y si agregamos un time  <code>time make -j8 bindeb-pkg</code>  podemos ver la duración que ha tardado el sistema en compilarlo.</p>\n<p>Reiniciamos nuestra máquina y entramos en el nuevo kernel, utilizamos  <code>uname -r</code></p>\n<p>Luego volvemos a nuestro kernel, y en concreto a nuestro espacio de trabajo, ejecutamos un  <code>make clean</code>  para eliminar los ‘residuos’ generados tras al compilación, y hacemos un control de versiones del .config, como nos funcionó la primera versión realizamos un  <code>cp .config ../v1.config</code></p>\n<p><img src=\"/images/xconfig.png\" alt=\"Descripción de la imagen\"></p>\n"},{"title":"Compilar en debian","_content":"\n![Descripción de la imagen](/images/debian-11.jpg)\n\n\nNecesitamos descargar el código fuente de xorriso:\n`apt source xorriso`\nNos pide que instalemos dpkg-dev debido a que necesita el paquete dpkg-source\n`apt install dpkg-dev`\nCon esto al descargar el código fuente de un paquete este se descomprimirá, también podemos hacerlo a través de tar:\n\n`tar -xvf libisoburn_1.5.2.orig.tar.gz`\n\n![Descripción de la imagen](/images/xorriso-1.png)\n\nnos metemos en la carpeta de xorriso y leemos el archivo.dsc\n\nComo podemos ver en la imagen dentro del paquete libisoburn está las diferentes dependencias para el binario que queremos compilar.\n\n\n![Descripción de la imagen](/images/xorriso-2.png)\n\nComo podemos observar hay dos makefile, pero estos no son más que unas plantillas que no lograremos compilar ya que solo sirven de guía.\n\n\nnecesitaremos las dependencias así que procuraremos hacer un `apt build-dep xorriso`.\n\n\nUna vez instaladas las dependencias ejecutamos `./configure --prefix /usr/local/xorriso/`, con esto se habrá generado el makefile, y el binario generado se guardará en /usr/local/xorriso\n\n\n![Descripción de la imagen](/images/xorriso-3.png)\n\n\n\nAhora una vez tengamos el archivo del makefile, ejecutamos un `make` en el directorio del makefile, una vez compilado realizamos un `make install`\n\n\n![Descripción de la imagen](/images/xorriso-4.png)\n\nComo podemos ver existe el binario que ejecutaremos y viene incluído el archivo de ayuda.\n\nOtra forma después de proceder con el make a través de dpkg sería `dpkg-buildpackage -b`, se creará elarchivo .deb con el que emplearemos `dpkg -i archivo.deb`","source":"_posts/Compilar-en-debian.md","raw":"---\ntitle: Compilar en debian\n---\n\n![Descripción de la imagen](/images/debian-11.jpg)\n\n\nNecesitamos descargar el código fuente de xorriso:\n`apt source xorriso`\nNos pide que instalemos dpkg-dev debido a que necesita el paquete dpkg-source\n`apt install dpkg-dev`\nCon esto al descargar el código fuente de un paquete este se descomprimirá, también podemos hacerlo a través de tar:\n\n`tar -xvf libisoburn_1.5.2.orig.tar.gz`\n\n![Descripción de la imagen](/images/xorriso-1.png)\n\nnos metemos en la carpeta de xorriso y leemos el archivo.dsc\n\nComo podemos ver en la imagen dentro del paquete libisoburn está las diferentes dependencias para el binario que queremos compilar.\n\n\n![Descripción de la imagen](/images/xorriso-2.png)\n\nComo podemos observar hay dos makefile, pero estos no son más que unas plantillas que no lograremos compilar ya que solo sirven de guía.\n\n\nnecesitaremos las dependencias así que procuraremos hacer un `apt build-dep xorriso`.\n\n\nUna vez instaladas las dependencias ejecutamos `./configure --prefix /usr/local/xorriso/`, con esto se habrá generado el makefile, y el binario generado se guardará en /usr/local/xorriso\n\n\n![Descripción de la imagen](/images/xorriso-3.png)\n\n\n\nAhora una vez tengamos el archivo del makefile, ejecutamos un `make` en el directorio del makefile, una vez compilado realizamos un `make install`\n\n\n![Descripción de la imagen](/images/xorriso-4.png)\n\nComo podemos ver existe el binario que ejecutaremos y viene incluído el archivo de ayuda.\n\nOtra forma después de proceder con el make a través de dpkg sería `dpkg-buildpackage -b`, se creará elarchivo .deb con el que emplearemos `dpkg -i archivo.deb`","slug":"Compilar-en-debian","published":1,"date":"2022-09-30T06:41:07.316Z","updated":"2022-10-19T12:34:18.078Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cldl9ucgj00070yi5e5pidznp","content":"<p><img src=\"/images/debian-11.jpg\" alt=\"Descripción de la imagen\"></p>\n<p>Necesitamos descargar el código fuente de xorriso:<br>\n <code>apt source xorriso</code> <br>\nNos pide que instalemos dpkg-dev debido a que necesita el paquete dpkg-source<br>\n <code>apt install dpkg-dev</code> <br>\nCon esto al descargar el código fuente de un paquete este se descomprimirá, también podemos hacerlo a través de tar:</p>\n<p><code>tar -xvf libisoburn_1.5.2.orig.tar.gz</code></p>\n<p><img src=\"/images/xorriso-1.png\" alt=\"Descripción de la imagen\"></p>\n<p>nos metemos en la carpeta de xorriso y leemos el archivo.dsc</p>\n<p>Como podemos ver en la imagen dentro del paquete libisoburn está las diferentes dependencias para el binario que queremos compilar.</p>\n<p><img src=\"/images/xorriso-2.png\" alt=\"Descripción de la imagen\"></p>\n<p>Como podemos observar hay dos makefile, pero estos no son más que unas plantillas que no lograremos compilar ya que solo sirven de guía.</p>\n<p>necesitaremos las dependencias así que procuraremos hacer un  <code>apt build-dep xorriso</code> .</p>\n<p>Una vez instaladas las dependencias ejecutamos  <code>./configure --prefix /usr/local/xorriso/</code> , con esto se habrá generado el makefile, y el binario generado se guardará en /usr/local/xorriso</p>\n<p><img src=\"/images/xorriso-3.png\" alt=\"Descripción de la imagen\"></p>\n<p>Ahora una vez tengamos el archivo del makefile, ejecutamos un  <code>make</code>  en el directorio del makefile, una vez compilado realizamos un  <code>make install</code></p>\n<p><img src=\"/images/xorriso-4.png\" alt=\"Descripción de la imagen\"></p>\n<p>Como podemos ver existe el binario que ejecutaremos y viene incluído el archivo de ayuda.</p>\n<p>Otra forma después de proceder con el make a través de dpkg sería  <code>dpkg-buildpackage -b</code> , se creará elarchivo .deb con el que emplearemos  <code>dpkg -i archivo.deb</code></p>\n","site":{"data":{}},"length":1110,"excerpt":"","more":"<p><img src=\"/images/debian-11.jpg\" alt=\"Descripción de la imagen\"></p>\n<p>Necesitamos descargar el código fuente de xorriso:<br>\n <code>apt source xorriso</code> <br>\nNos pide que instalemos dpkg-dev debido a que necesita el paquete dpkg-source<br>\n <code>apt install dpkg-dev</code> <br>\nCon esto al descargar el código fuente de un paquete este se descomprimirá, también podemos hacerlo a través de tar:</p>\n<p><code>tar -xvf libisoburn_1.5.2.orig.tar.gz</code></p>\n<p><img src=\"/images/xorriso-1.png\" alt=\"Descripción de la imagen\"></p>\n<p>nos metemos en la carpeta de xorriso y leemos el archivo.dsc</p>\n<p>Como podemos ver en la imagen dentro del paquete libisoburn está las diferentes dependencias para el binario que queremos compilar.</p>\n<p><img src=\"/images/xorriso-2.png\" alt=\"Descripción de la imagen\"></p>\n<p>Como podemos observar hay dos makefile, pero estos no son más que unas plantillas que no lograremos compilar ya que solo sirven de guía.</p>\n<p>necesitaremos las dependencias así que procuraremos hacer un  <code>apt build-dep xorriso</code> .</p>\n<p>Una vez instaladas las dependencias ejecutamos  <code>./configure --prefix /usr/local/xorriso/</code> , con esto se habrá generado el makefile, y el binario generado se guardará en /usr/local/xorriso</p>\n<p><img src=\"/images/xorriso-3.png\" alt=\"Descripción de la imagen\"></p>\n<p>Ahora una vez tengamos el archivo del makefile, ejecutamos un  <code>make</code>  en el directorio del makefile, una vez compilado realizamos un  <code>make install</code></p>\n<p><img src=\"/images/xorriso-4.png\" alt=\"Descripción de la imagen\"></p>\n<p>Como podemos ver existe el binario que ejecutaremos y viene incluído el archivo de ayuda.</p>\n<p>Otra forma después de proceder con el make a través de dpkg sería  <code>dpkg-buildpackage -b</code> , se creará elarchivo .deb con el que emplearemos  <code>dpkg -i archivo.deb</code></p>\n"},{"title":"Interconexiones entre Bases de Datos","_content":"![remoto](/images/oracle-19c-logo.png)\n\n\n## Interconexión entre dos bases de datos Oracle.\n\nAntes que nada debemos saber que para conectarnos a una base de datos, debemos tener activados los listener y seguidamente tener en el tsnames.ora la base de datos a la que queremos conectarnos, de esta manera:\nsudo nano /opt/oracle/product/19c/dbhome_1/network/admin/tnsnames.ora\n\n```\nORCLCDB =\n  (DESCRIPTION =\n    (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.122.20)(PORT = 1521))\n    (CONNECT_DATA =\n      (SERVER = DEDICATED)\n      (SERVICE_NAME = ORCLCDB)\n    )\n  )\n\nLISTENER_ORCLCDB =\n  (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.122.20)(PORT = 1521))\n\nORACLESERV =\n  (DESCRIPTION =\n    (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.122.168)(PORT = 1521))\n    (CONNECT_DATA =\n      (SERVER = DEDICATED)\n      (SERVICE_NAME = ORCLCDB)\n    )\n  )\n```\nHemos creado una nueva conexión llamada ORACLESERV en el cual procederemos a ingresar la ip del servidor del que queremos recibir los datos, tras esto debemos crear en la otra máquina la tabla de ejemplo que queremos extraer:\n\n```\nCREATE TABLE armas (\ncodarma varchar2 (3),\nnombre varchar2 (20),\nfuerza number (2),\ndestreza number (2),\ninteligencia number (2),\nrareza varchar2 (10),\nnivel number (2),\nCONSTRAINT pk_armas PRIMARY KEY (codarma)\n);\n\ninsert into armas values ('001','Espada Corta',8,10,0,'D',5);\ninsert into armas values ('002','Espada Larga',10,10,0,'C',8);\ninsert into armas values ('003','Espada Artorias',24,18,20,'S',30);\ninsert into armas values ('004','Hacha de Mano',8,8,0,'D',6);\ninsert into armas values ('005','Hacha de Gárgola',14,14,0,'A',15);\ninsert into armas values ('006','Hacha de Demonio',46,0,0,'S',40);\n```\n\nUna vez hecho esto, **nos vamos a la máquina en la que vamos a trabajar con la consulta**, debemos crear un enlace a la base de datos, el cual hemos predefinido como ORACLESERV:\n\n`create database link ORACLESERVIDOR connect to antonio identified by antonio using 'ORACLESERV';`\n\nTras esto, viene una parte un poco compleja, ya que la tabla que vamos a consultar en el otro servidor viene relacionada, y a la hora de crear relaciones entre tablas no se puede especificar una base de datos remota en el DDL, entonces, cómo podemos hacer que esto funcione? bueno pues mi idea ha sido crear una vista materializada:\n\n`create materialized view mv_armas as select codarma from armas@ORACLESERVIDOR;`\n\nUna vez hecho esto, procedemos a crear las tablas personaje y equipar, siendo una relación N,M.\n\n```\nCREATE TABLE personaje (\ncodpersonaje varchar2 (3),\nnombre varchar2 (15),\naltura number (3,2),\npeso number (3),\nraza varchar2 (10),\nCONSTRAINT pk_codpersonaje PRIMARY KEY (codpersonaje),\nCONSTRAINT ck_codpersonaje CHECK (REGEXP_LIKE(codpersonaje,'^1.*$'))\n);\n\ninsert into personaje values ('101','Solaire',1.70,80,'humano');\ninsert into personaje values ('102','Artorias',1.90,90,'hueco');\ninsert into personaje values ('103','Gargola',3.10,680,'Gárgola');\n\nCREATE TABLE equipar (\ncodpersonaje varchar2 (3),\ncodarma varchar2 (3),\nfecha date,\nCONSTRAINT pk_equipar PRIMARY KEY (codpersonaje,codarma,fecha),\nCONSTRAINT fk_codpersonaje FOREIGN KEY (codpersonaje) REFERENCES personaje (codpersonaje),\nCONSTRAINT fk_codarma FOREIGN KEY (codarma) REFERENCES mv_armas(codarma);\n);\n\ninsert into equipar values ('102','003',to_date('2011/02/11','YYYY/MM/DD'));\ninsert into equipar values ('103','005',to_date('2011/05/04','YYYY/MM/DD'));\ninsert into equipar values ('101','002',to_date('2011/06/03','YYYY/MM/DD'));\ninsert into equipar values ('103','002',to_date('2011/09/02','YYYY/MM/DD'));\ninsert into equipar values ('101','006',to_date('2011/08/03','YYYY/MM/DD'));\ninsert into equipar values ('102','004',to_date('2011/07/01','YYYY/MM/DD'));\n\n```\n\n¡¡Mucho ojo!! la restricción que he establecido en equipar, que es la foreign key que relaciona el código de armas con nuestra base de datos, llamará a la view que hemos creado y contendrá los datos de la consulta al servidor externo.\n\n\n\n\n\n![remoto](/images/sql-remoto.png)\n\n\n![remoto](/images/sql-remoto2.png)\n\n\n## Interconexión entre dos bases de datos Postgres.\n\nPrimero vamos a modificar el fichero /etc/postgresql/13/main/postgresql.conf para abrir la escucha a la ip que quiera conectarse:\n`listen_addresses = '*'`\n\nModificamos el fichero /etc/postgresql/13/main/pg_hba.conf, y aladimos la siguiente línea:\n`host    all             all             192.168.122.0/24        md5`\n\nProcedemos a reiniciar Postgres para efectuar los cambios:\n`sudo systemctl restart postgresql`\n\nLuego vamos a crear la base de datos souls, luego vamos a darle permiso al usuario antonio2 para poder manejar la base de datos:\n\n```\npostgres=# create database souls\npostgres-# ;\nCREATE DATABASE\nGRANT ALL PRIVILEGES ON DATABASE souls TO antonio2;\npostgres=# grant connect on database souls to antonio2;\nGRANT\npostgres=# grant usage on schema public to antonio2;\nGRANT\n```\n\nEn el otro servidor establecemos la configuración de antonio1:\n\n```\npostgres=# create user antonio1 with password 'antonio1';\nCREATE ROLE\npostgres=# create database souls;\nCREATE DATABASE\nGRANT ALL PRIVILEGES ON DATABASE souls TO antonio1;\npostgres=# grant connect on database souls to antonio1;\nGRANT\npostgres=# grant usage on schema public to antonio1;\nGRANT\npostgres=# \\c souls;\n```\n\nAhora vamos a instalar el paquete que nos permitirá realizar el dblink:\n`sudo apt install postgresql-contrib`\n\n\n\nDe modo que si hacemos una consulta con dblink especificando el host, usuario y base de datos del que se habla, podremos sacar la información de las bases de datos respectivamente.\n\n\n`select * from dblink('dbname=souls host=192.168.122.168 user=antonio2 password=antonio2', 'select nombre from armas') as armas (Nombre VARCHAR);`\n\n![Descripción de la imagen](/images/postgres-postgres.png)\n\n\n\n## Interconexión entre bases de datos Oracle y Postgres.\n\nEn nuestro caso la paquetería que necesitamos para conectar Oracle a Postgres es la de Debian Bullseye, por tanto el comando sería el siguiente:\n`sudo apt install odbc-postgresql unixodbc -y`\n\nAhora vamos a entrar en /etc/odbc.ini y vamos a ingresar los siguientes parámetros adaptándolos a nuestro usuario, host y base de datos:\n\n```\n[PSQLA]\nDebug = 0\nCommLog = 0\nReadOnly = 1\nDriver = PostgreSQL ANSI\nServername = 192.168.122.168\nUsername = antonio2\nPassword = antonio2\nPort = 5432\nDatabase = souls\nTrace = 0\nTraceFile = /tmp/sql.log\n\n[PSQLU]\nDebug = 0\nCommLog = 0\nReadOnly = 0\nDriver = PostgreSQL Unicode\nServername = 192.168.122.168\nUsername = antonio2\nPassword = antonio2\nPort = 5432\nDatabase = souls\nTrace = 0\nTraceFile = /tmp/sql.log\n\n[Default]\nDriver = /usr/lib/x86_64-linux-gnu/odbc/liboplodbcS.so\n```\nAhora vamos a comprobar el fichero /etc/ocdbinst.ini y debe venir configurado como se muestra abajo.\n\n```\n[PostgreSQL ANSI]\nDescription=PostgreSQL ODBC driver (ANSI version)\nDriver=psqlodbca.so\nSetup=libodbcpsqlS.so\nDebug=0\nCommLog=1\nUsageCount=1\n\n[PostgreSQL Unicode]\nDescription=PostgreSQL ODBC driver (Unicode version)\nDriver=psqlodbcw.so\nSetup=libodbcpsqlS.so\nDebug=0\nCommLog=1\nUsageCount=1\n```\n\n\nPodemos comprobar la configuración ingresando los siguientes comandos:\n\n```\nodbcinst -q -d\n    [PostgreSQL ANSI]\n    [PostgreSQL Unicode]\n\n\nodbcinst -q -s\n    [PSQLA]\n    [PSQLU]\n    [Default]\n```\n\nejecutamos `isql -v PSQLU` y si todo ha ido bien nos devolverá esto:\n```\n+---------------------------------------+\n| Connected!                            |\n|                                       |\n| sql-statement                         |\n| help [tablename]                      |\n| quit                                  |\n|                                       |\n+---------------------------------------+\n```\n\nA continuación vamos a `/opt/oracle/product/19c/dbhome_1/hs/admin/initPSQLU.ora` e ingresamos los siguientes datos:\n\n```\nHS_FDS_CONNECT_INFO = PSQLU\nHS_FDS_TRACE_LEVEL = Debug\nHS_FDS_SHAREABLE_NAME = /usr/lib/x86_64-linux-gnu/odbc/psqlodbcw.so\nHS_LANGUAGE = AMERICAN_AMERICA.WE8ISO8859P1\nset ODBCINI=/etc/odbc.ini\n```\n\nVamos al listener.ora e ingresamos los siguentes parámetros:\n\n\n```\nSID_LIST_LISTENER =\n (SID_LIST =\n  (SID_DESC =\n   (GLOBAL_DBNAME = ORCLCDB)\n   (ORACLE_HOME = /opt/oracle/product/19c/dbhome_1)\n   (SID_NAME = ORCLCDB)\n  )\n  (SID_DESC =\n    (SID_NAME = PSQLU)\n    (PROGRAM = dg4odbc)\n    (ORACLE_HOME = /opt/oracle/product/19c/dbhome_1)\n  )\n )\n```\n\nAhora realizaremos un lsnrctl stop y lisnrctl start, y nos debe salir un mensaje como el siguiente:\n\n```\nService \"PSQLU\" has 1 instance(s).\n  Instance \"PSQLU\", status UNKNOWN, has 1 handler(s) for this service...\nService \"orcl\" has 1 instance(s).\n  Instance \"orcl\", status UNKNOWN, has 1 handler(s) for this service...\nThe command completed successfully\n\n```\nAhora nos vamos al tnsnames.ora y añadimos lo siguiente:\n```\nPSQLU =\n (DESCRIPTION =\n (ADDRESS = (PROTOCOL = TCP)(HOST = localhost)(PORT = 1521))\n   (CONNECT_DATA = (SID = PSQLU))\n   (HS = OK)\n  )\n```\n\nEn localhost estamos especificando que la ip de la máquina sería la misma en la que está alojado el servicio postgre, esto es debido a que se redirecciona a través de la configuración en odbc.ini entonces ya tan solo quedaría conceder permisos de conexión publica de la base de datos a antonio:\n\n```\nGRANT CREATE PUBLIC DATABASE LINK to antonio;\n\nConcesion terminada correctamente.\n```\n\nAhora solo nos queda realizar la conexión:\n```\nCREATE PUBLIC DATABASE LINK CONEXIONPOSTGRES2\nCONNECT TO \"antonio2\"\nIDENTIFIED BY \"antonio2\"\nUSING 'PSQLU';\n\nEnlace con la base de datos creado.\n```\n\nComprobamos que se pueda consultar el nombre de las armas en **CONEXIONPOSTGRES2**\n\n![Descripción de la imagen](/images/oracle-postgres.png)\n\n\n\n## Interconexión entre bases de datos Postgres y Oracle.\n\n\nPrimero vamos a instalar unos paquetes que nos servirán tanto para establecer la conexión con Oracle como a la hora de compilar el Makefile que necesitaremos más adelante:\n\n`apt install git build-essential libaio1 postgresql-server-dev-all -y`\n\nPara realizar la interconexión entre Postgres y Oracle necesitaremos software de terceros, en mi caso vamos a descargar los paquetes que se encuentran en el siguiente enlace:\n\nhttps://drive.google.com/file/d/1UmBNjVLffaj-hXDXdi6hPGpz6CIZr8eN/view?usp=share_link\n\nEn él se encuentran los paquetes en formato.deb, del cual me ocupé de transformar con alien.\n\nAhora procedemos a instalar los paquetes que adaptarán el formato sqlplus:\n```\nsudo dpkg -i oracle-instantclient19.5-devel_19.5.0.0.0-2_amd64.deb\nsudo dpkg -i oracle-instantclient19.5-basic_19.5.0.0.0-2_amd64.deb\nsudo dpkg -i oracle-instantclient19.5-tools_19.5.0.0.0-2_amd64.deb\nsudo dpkg -i oracle-instantclient19.5-sqlplus_19.5.0.0.0-2_amd64.deb\n```\n\nAhora vamos a clonar el repositorio con el que trabajaremos para establecer la conexión de Postgres a Oracle:\n\ngit clone https://github.com/laurenz/oracle_fdw.git\n\nAhora en nuestra máquina postgres necesitaremos crear las variables de entorno de Oracle, para ello ingresaremos lo siguiente al final de nuestro .bashrc\n\n```\nsudo nano ~/.bashrc\n\nexport ORACLE_HOME=\"/usr/lib/oracle/19.5/client64\"\nexport LD_LIBRARY_PATH=\"/usr/lib/oracle/19.5/client64/lib\"\nexport PATH=$ORACLE_HOME:$PATH\nexport USE_PGXS=1\n```\n\nAhora vamos a generar el makefile ejecutando un `make` dentro del directorio que hemos clonado.\n\nUNa vez hecho esto, ante de proceder a instalar el binario, debamo incluir las siguientes líneas a nuestro makefile.\n```\nPG_CPPFLAGS = -I\"$(ORACLE_HOME)/sdk/include\" -I\"$(ORACLE_HOME)/oci/include\" -I\"$(ORACLE_HOME)/rdbms/public\" -I\"$(ORACLE_HOME)/\" $(FIN>\n\nSHLIB_LINK = -L\"$(ORACLE_HOME)/\" -L\"$(ORACLE_HOME)/bin\" -L\"$(ORACLE_HOME)/lib\" -L\"$(ORACLE_HOME)/lib/amd64\" $(FIND_LDFLAGS) -l$(ORACL>\n```\n\nAhora podemos ejecutar un `make install` sin errores ya que las dependencias necesarias para la instalación fueron descargadas con anterioridad.\n\nLuego entramos en nuestra base de datos con el usuario postgres para crear nuestro enlace a Oracle, debemos especificar la ip que tendrá el sevidor y el nombre de la base de datos que en nuestro caso será el por defecto 'ORCLCDB'.\n\n```\nCREATE SERVER oracleantonio FOREIGN DATA WRAPPER oracle_fdw OPTIONS(dbserver '//192.168.122.168:1521/ORCLCDB');\n```\n\nUna vez hecho esto vamos a enlazar la conexión de nuestro oracleantonio con el usuario que tenga acceso a los registros de la tabla armas, de forma que quedaría de la siguiente manera:\n\n```\ncreate user mapping for postgres server oracleantonio options(user 'antonio',password 'antonio');\nDROP user mapping for postgres server oracleantonio; (En caso de que haya algún tipo de error).\n```\n\nCrearemos el esqueleto de la tabla que necesitamos en la base de datos pero sin restricciones ni unique, ya que colisionan con la ejecución de la conexión remota, solo necesitaremos los campos que vayan a ser rellenados:\n\n\n```\nCREATE FOREIGN TABLE personaje (\ncodpersonaje varchar (3),\nnombre varchar (15),\naltura numeric (3,2),\npeso numeric (3),\nraza varchar (10) DEFAULT ('Humano'))\nSERVER oracleantonio OPTIONS(schema 'ANTONIO', table 'PERSONAJE'\n);\n```\n\nAhora solo nos queda realizar la consulta y podemos comprobar como esta se resuelve con éxito.\n\n\n![Descripción de la imagen](/images/postgres-oracle.png)\n","source":"_posts/Interconexiones.md","raw":"---\ntitle: Interconexiones entre Bases de Datos\ncategories: Bases de Datos\n---\n![remoto](/images/oracle-19c-logo.png)\n\n\n## Interconexión entre dos bases de datos Oracle.\n\nAntes que nada debemos saber que para conectarnos a una base de datos, debemos tener activados los listener y seguidamente tener en el tsnames.ora la base de datos a la que queremos conectarnos, de esta manera:\nsudo nano /opt/oracle/product/19c/dbhome_1/network/admin/tnsnames.ora\n\n```\nORCLCDB =\n  (DESCRIPTION =\n    (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.122.20)(PORT = 1521))\n    (CONNECT_DATA =\n      (SERVER = DEDICATED)\n      (SERVICE_NAME = ORCLCDB)\n    )\n  )\n\nLISTENER_ORCLCDB =\n  (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.122.20)(PORT = 1521))\n\nORACLESERV =\n  (DESCRIPTION =\n    (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.122.168)(PORT = 1521))\n    (CONNECT_DATA =\n      (SERVER = DEDICATED)\n      (SERVICE_NAME = ORCLCDB)\n    )\n  )\n```\nHemos creado una nueva conexión llamada ORACLESERV en el cual procederemos a ingresar la ip del servidor del que queremos recibir los datos, tras esto debemos crear en la otra máquina la tabla de ejemplo que queremos extraer:\n\n```\nCREATE TABLE armas (\ncodarma varchar2 (3),\nnombre varchar2 (20),\nfuerza number (2),\ndestreza number (2),\ninteligencia number (2),\nrareza varchar2 (10),\nnivel number (2),\nCONSTRAINT pk_armas PRIMARY KEY (codarma)\n);\n\ninsert into armas values ('001','Espada Corta',8,10,0,'D',5);\ninsert into armas values ('002','Espada Larga',10,10,0,'C',8);\ninsert into armas values ('003','Espada Artorias',24,18,20,'S',30);\ninsert into armas values ('004','Hacha de Mano',8,8,0,'D',6);\ninsert into armas values ('005','Hacha de Gárgola',14,14,0,'A',15);\ninsert into armas values ('006','Hacha de Demonio',46,0,0,'S',40);\n```\n\nUna vez hecho esto, **nos vamos a la máquina en la que vamos a trabajar con la consulta**, debemos crear un enlace a la base de datos, el cual hemos predefinido como ORACLESERV:\n\n`create database link ORACLESERVIDOR connect to antonio identified by antonio using 'ORACLESERV';`\n\nTras esto, viene una parte un poco compleja, ya que la tabla que vamos a consultar en el otro servidor viene relacionada, y a la hora de crear relaciones entre tablas no se puede especificar una base de datos remota en el DDL, entonces, cómo podemos hacer que esto funcione? bueno pues mi idea ha sido crear una vista materializada:\n\n`create materialized view mv_armas as select codarma from armas@ORACLESERVIDOR;`\n\nUna vez hecho esto, procedemos a crear las tablas personaje y equipar, siendo una relación N,M.\n\n```\nCREATE TABLE personaje (\ncodpersonaje varchar2 (3),\nnombre varchar2 (15),\naltura number (3,2),\npeso number (3),\nraza varchar2 (10),\nCONSTRAINT pk_codpersonaje PRIMARY KEY (codpersonaje),\nCONSTRAINT ck_codpersonaje CHECK (REGEXP_LIKE(codpersonaje,'^1.*$'))\n);\n\ninsert into personaje values ('101','Solaire',1.70,80,'humano');\ninsert into personaje values ('102','Artorias',1.90,90,'hueco');\ninsert into personaje values ('103','Gargola',3.10,680,'Gárgola');\n\nCREATE TABLE equipar (\ncodpersonaje varchar2 (3),\ncodarma varchar2 (3),\nfecha date,\nCONSTRAINT pk_equipar PRIMARY KEY (codpersonaje,codarma,fecha),\nCONSTRAINT fk_codpersonaje FOREIGN KEY (codpersonaje) REFERENCES personaje (codpersonaje),\nCONSTRAINT fk_codarma FOREIGN KEY (codarma) REFERENCES mv_armas(codarma);\n);\n\ninsert into equipar values ('102','003',to_date('2011/02/11','YYYY/MM/DD'));\ninsert into equipar values ('103','005',to_date('2011/05/04','YYYY/MM/DD'));\ninsert into equipar values ('101','002',to_date('2011/06/03','YYYY/MM/DD'));\ninsert into equipar values ('103','002',to_date('2011/09/02','YYYY/MM/DD'));\ninsert into equipar values ('101','006',to_date('2011/08/03','YYYY/MM/DD'));\ninsert into equipar values ('102','004',to_date('2011/07/01','YYYY/MM/DD'));\n\n```\n\n¡¡Mucho ojo!! la restricción que he establecido en equipar, que es la foreign key que relaciona el código de armas con nuestra base de datos, llamará a la view que hemos creado y contendrá los datos de la consulta al servidor externo.\n\n\n\n\n\n![remoto](/images/sql-remoto.png)\n\n\n![remoto](/images/sql-remoto2.png)\n\n\n## Interconexión entre dos bases de datos Postgres.\n\nPrimero vamos a modificar el fichero /etc/postgresql/13/main/postgresql.conf para abrir la escucha a la ip que quiera conectarse:\n`listen_addresses = '*'`\n\nModificamos el fichero /etc/postgresql/13/main/pg_hba.conf, y aladimos la siguiente línea:\n`host    all             all             192.168.122.0/24        md5`\n\nProcedemos a reiniciar Postgres para efectuar los cambios:\n`sudo systemctl restart postgresql`\n\nLuego vamos a crear la base de datos souls, luego vamos a darle permiso al usuario antonio2 para poder manejar la base de datos:\n\n```\npostgres=# create database souls\npostgres-# ;\nCREATE DATABASE\nGRANT ALL PRIVILEGES ON DATABASE souls TO antonio2;\npostgres=# grant connect on database souls to antonio2;\nGRANT\npostgres=# grant usage on schema public to antonio2;\nGRANT\n```\n\nEn el otro servidor establecemos la configuración de antonio1:\n\n```\npostgres=# create user antonio1 with password 'antonio1';\nCREATE ROLE\npostgres=# create database souls;\nCREATE DATABASE\nGRANT ALL PRIVILEGES ON DATABASE souls TO antonio1;\npostgres=# grant connect on database souls to antonio1;\nGRANT\npostgres=# grant usage on schema public to antonio1;\nGRANT\npostgres=# \\c souls;\n```\n\nAhora vamos a instalar el paquete que nos permitirá realizar el dblink:\n`sudo apt install postgresql-contrib`\n\n\n\nDe modo que si hacemos una consulta con dblink especificando el host, usuario y base de datos del que se habla, podremos sacar la información de las bases de datos respectivamente.\n\n\n`select * from dblink('dbname=souls host=192.168.122.168 user=antonio2 password=antonio2', 'select nombre from armas') as armas (Nombre VARCHAR);`\n\n![Descripción de la imagen](/images/postgres-postgres.png)\n\n\n\n## Interconexión entre bases de datos Oracle y Postgres.\n\nEn nuestro caso la paquetería que necesitamos para conectar Oracle a Postgres es la de Debian Bullseye, por tanto el comando sería el siguiente:\n`sudo apt install odbc-postgresql unixodbc -y`\n\nAhora vamos a entrar en /etc/odbc.ini y vamos a ingresar los siguientes parámetros adaptándolos a nuestro usuario, host y base de datos:\n\n```\n[PSQLA]\nDebug = 0\nCommLog = 0\nReadOnly = 1\nDriver = PostgreSQL ANSI\nServername = 192.168.122.168\nUsername = antonio2\nPassword = antonio2\nPort = 5432\nDatabase = souls\nTrace = 0\nTraceFile = /tmp/sql.log\n\n[PSQLU]\nDebug = 0\nCommLog = 0\nReadOnly = 0\nDriver = PostgreSQL Unicode\nServername = 192.168.122.168\nUsername = antonio2\nPassword = antonio2\nPort = 5432\nDatabase = souls\nTrace = 0\nTraceFile = /tmp/sql.log\n\n[Default]\nDriver = /usr/lib/x86_64-linux-gnu/odbc/liboplodbcS.so\n```\nAhora vamos a comprobar el fichero /etc/ocdbinst.ini y debe venir configurado como se muestra abajo.\n\n```\n[PostgreSQL ANSI]\nDescription=PostgreSQL ODBC driver (ANSI version)\nDriver=psqlodbca.so\nSetup=libodbcpsqlS.so\nDebug=0\nCommLog=1\nUsageCount=1\n\n[PostgreSQL Unicode]\nDescription=PostgreSQL ODBC driver (Unicode version)\nDriver=psqlodbcw.so\nSetup=libodbcpsqlS.so\nDebug=0\nCommLog=1\nUsageCount=1\n```\n\n\nPodemos comprobar la configuración ingresando los siguientes comandos:\n\n```\nodbcinst -q -d\n    [PostgreSQL ANSI]\n    [PostgreSQL Unicode]\n\n\nodbcinst -q -s\n    [PSQLA]\n    [PSQLU]\n    [Default]\n```\n\nejecutamos `isql -v PSQLU` y si todo ha ido bien nos devolverá esto:\n```\n+---------------------------------------+\n| Connected!                            |\n|                                       |\n| sql-statement                         |\n| help [tablename]                      |\n| quit                                  |\n|                                       |\n+---------------------------------------+\n```\n\nA continuación vamos a `/opt/oracle/product/19c/dbhome_1/hs/admin/initPSQLU.ora` e ingresamos los siguientes datos:\n\n```\nHS_FDS_CONNECT_INFO = PSQLU\nHS_FDS_TRACE_LEVEL = Debug\nHS_FDS_SHAREABLE_NAME = /usr/lib/x86_64-linux-gnu/odbc/psqlodbcw.so\nHS_LANGUAGE = AMERICAN_AMERICA.WE8ISO8859P1\nset ODBCINI=/etc/odbc.ini\n```\n\nVamos al listener.ora e ingresamos los siguentes parámetros:\n\n\n```\nSID_LIST_LISTENER =\n (SID_LIST =\n  (SID_DESC =\n   (GLOBAL_DBNAME = ORCLCDB)\n   (ORACLE_HOME = /opt/oracle/product/19c/dbhome_1)\n   (SID_NAME = ORCLCDB)\n  )\n  (SID_DESC =\n    (SID_NAME = PSQLU)\n    (PROGRAM = dg4odbc)\n    (ORACLE_HOME = /opt/oracle/product/19c/dbhome_1)\n  )\n )\n```\n\nAhora realizaremos un lsnrctl stop y lisnrctl start, y nos debe salir un mensaje como el siguiente:\n\n```\nService \"PSQLU\" has 1 instance(s).\n  Instance \"PSQLU\", status UNKNOWN, has 1 handler(s) for this service...\nService \"orcl\" has 1 instance(s).\n  Instance \"orcl\", status UNKNOWN, has 1 handler(s) for this service...\nThe command completed successfully\n\n```\nAhora nos vamos al tnsnames.ora y añadimos lo siguiente:\n```\nPSQLU =\n (DESCRIPTION =\n (ADDRESS = (PROTOCOL = TCP)(HOST = localhost)(PORT = 1521))\n   (CONNECT_DATA = (SID = PSQLU))\n   (HS = OK)\n  )\n```\n\nEn localhost estamos especificando que la ip de la máquina sería la misma en la que está alojado el servicio postgre, esto es debido a que se redirecciona a través de la configuración en odbc.ini entonces ya tan solo quedaría conceder permisos de conexión publica de la base de datos a antonio:\n\n```\nGRANT CREATE PUBLIC DATABASE LINK to antonio;\n\nConcesion terminada correctamente.\n```\n\nAhora solo nos queda realizar la conexión:\n```\nCREATE PUBLIC DATABASE LINK CONEXIONPOSTGRES2\nCONNECT TO \"antonio2\"\nIDENTIFIED BY \"antonio2\"\nUSING 'PSQLU';\n\nEnlace con la base de datos creado.\n```\n\nComprobamos que se pueda consultar el nombre de las armas en **CONEXIONPOSTGRES2**\n\n![Descripción de la imagen](/images/oracle-postgres.png)\n\n\n\n## Interconexión entre bases de datos Postgres y Oracle.\n\n\nPrimero vamos a instalar unos paquetes que nos servirán tanto para establecer la conexión con Oracle como a la hora de compilar el Makefile que necesitaremos más adelante:\n\n`apt install git build-essential libaio1 postgresql-server-dev-all -y`\n\nPara realizar la interconexión entre Postgres y Oracle necesitaremos software de terceros, en mi caso vamos a descargar los paquetes que se encuentran en el siguiente enlace:\n\nhttps://drive.google.com/file/d/1UmBNjVLffaj-hXDXdi6hPGpz6CIZr8eN/view?usp=share_link\n\nEn él se encuentran los paquetes en formato.deb, del cual me ocupé de transformar con alien.\n\nAhora procedemos a instalar los paquetes que adaptarán el formato sqlplus:\n```\nsudo dpkg -i oracle-instantclient19.5-devel_19.5.0.0.0-2_amd64.deb\nsudo dpkg -i oracle-instantclient19.5-basic_19.5.0.0.0-2_amd64.deb\nsudo dpkg -i oracle-instantclient19.5-tools_19.5.0.0.0-2_amd64.deb\nsudo dpkg -i oracle-instantclient19.5-sqlplus_19.5.0.0.0-2_amd64.deb\n```\n\nAhora vamos a clonar el repositorio con el que trabajaremos para establecer la conexión de Postgres a Oracle:\n\ngit clone https://github.com/laurenz/oracle_fdw.git\n\nAhora en nuestra máquina postgres necesitaremos crear las variables de entorno de Oracle, para ello ingresaremos lo siguiente al final de nuestro .bashrc\n\n```\nsudo nano ~/.bashrc\n\nexport ORACLE_HOME=\"/usr/lib/oracle/19.5/client64\"\nexport LD_LIBRARY_PATH=\"/usr/lib/oracle/19.5/client64/lib\"\nexport PATH=$ORACLE_HOME:$PATH\nexport USE_PGXS=1\n```\n\nAhora vamos a generar el makefile ejecutando un `make` dentro del directorio que hemos clonado.\n\nUNa vez hecho esto, ante de proceder a instalar el binario, debamo incluir las siguientes líneas a nuestro makefile.\n```\nPG_CPPFLAGS = -I\"$(ORACLE_HOME)/sdk/include\" -I\"$(ORACLE_HOME)/oci/include\" -I\"$(ORACLE_HOME)/rdbms/public\" -I\"$(ORACLE_HOME)/\" $(FIN>\n\nSHLIB_LINK = -L\"$(ORACLE_HOME)/\" -L\"$(ORACLE_HOME)/bin\" -L\"$(ORACLE_HOME)/lib\" -L\"$(ORACLE_HOME)/lib/amd64\" $(FIND_LDFLAGS) -l$(ORACL>\n```\n\nAhora podemos ejecutar un `make install` sin errores ya que las dependencias necesarias para la instalación fueron descargadas con anterioridad.\n\nLuego entramos en nuestra base de datos con el usuario postgres para crear nuestro enlace a Oracle, debemos especificar la ip que tendrá el sevidor y el nombre de la base de datos que en nuestro caso será el por defecto 'ORCLCDB'.\n\n```\nCREATE SERVER oracleantonio FOREIGN DATA WRAPPER oracle_fdw OPTIONS(dbserver '//192.168.122.168:1521/ORCLCDB');\n```\n\nUna vez hecho esto vamos a enlazar la conexión de nuestro oracleantonio con el usuario que tenga acceso a los registros de la tabla armas, de forma que quedaría de la siguiente manera:\n\n```\ncreate user mapping for postgres server oracleantonio options(user 'antonio',password 'antonio');\nDROP user mapping for postgres server oracleantonio; (En caso de que haya algún tipo de error).\n```\n\nCrearemos el esqueleto de la tabla que necesitamos en la base de datos pero sin restricciones ni unique, ya que colisionan con la ejecución de la conexión remota, solo necesitaremos los campos que vayan a ser rellenados:\n\n\n```\nCREATE FOREIGN TABLE personaje (\ncodpersonaje varchar (3),\nnombre varchar (15),\naltura numeric (3,2),\npeso numeric (3),\nraza varchar (10) DEFAULT ('Humano'))\nSERVER oracleantonio OPTIONS(schema 'ANTONIO', table 'PERSONAJE'\n);\n```\n\nAhora solo nos queda realizar la consulta y podemos comprobar como esta se resuelve con éxito.\n\n\n![Descripción de la imagen](/images/postgres-oracle.png)\n","slug":"Interconexiones","published":1,"date":"2022-11-09T19:27:01.893Z","updated":"2023-01-04T13:29:31.339Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cldl9ucgk00090yi5dce34dzi","content":"<p><img src=\"/images/oracle-19c-logo.png\" alt=\"remoto\"></p>\n<h2 id=\"interconexión-entre-dos-bases-de-datos-oracle\"><a class=\"markdownIt-Anchor\" href=\"#interconexión-entre-dos-bases-de-datos-oracle\">#</a> Interconexión entre dos bases de datos Oracle.</h2>\n<p>Antes que nada debemos saber que para conectarnos a una base de datos, debemos tener activados los listener y seguidamente tener en el tsnames.ora la base de datos a la que queremos conectarnos, de esta manera:<br>\nsudo nano /opt/oracle/product/19c/dbhome_1/network/admin/tnsnames.ora</p>\n<pre><code>ORCLCDB =\n  (DESCRIPTION =\n    (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.122.20)(PORT = 1521))\n    (CONNECT_DATA =\n      (SERVER = DEDICATED)\n      (SERVICE_NAME = ORCLCDB)\n    )\n  )\n\nLISTENER_ORCLCDB =\n  (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.122.20)(PORT = 1521))\n\nORACLESERV =\n  (DESCRIPTION =\n    (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.122.168)(PORT = 1521))\n    (CONNECT_DATA =\n      (SERVER = DEDICATED)\n      (SERVICE_NAME = ORCLCDB)\n    )\n  )\n</code></pre>\n<p>Hemos creado una nueva conexión llamada ORACLESERV en el cual procederemos a ingresar la ip del servidor del que queremos recibir los datos, tras esto debemos crear en la otra máquina la tabla de ejemplo que queremos extraer:</p>\n<pre><code>CREATE TABLE armas (\ncodarma varchar2 (3),\nnombre varchar2 (20),\nfuerza number (2),\ndestreza number (2),\ninteligencia number (2),\nrareza varchar2 (10),\nnivel number (2),\nCONSTRAINT pk_armas PRIMARY KEY (codarma)\n);\n\ninsert into armas values ('001','Espada Corta',8,10,0,'D',5);\ninsert into armas values ('002','Espada Larga',10,10,0,'C',8);\ninsert into armas values ('003','Espada Artorias',24,18,20,'S',30);\ninsert into armas values ('004','Hacha de Mano',8,8,0,'D',6);\ninsert into armas values ('005','Hacha de Gárgola',14,14,0,'A',15);\ninsert into armas values ('006','Hacha de Demonio',46,0,0,'S',40);\n</code></pre>\n<p>Una vez hecho esto, <strong>nos vamos a la máquina en la que vamos a trabajar con la consulta</strong>, debemos crear un enlace a la base de datos, el cual hemos predefinido como ORACLESERV:</p>\n<p><code>create database link ORACLESERVIDOR connect to antonio identified by antonio using 'ORACLESERV';</code></p>\n<p>Tras esto, viene una parte un poco compleja, ya que la tabla que vamos a consultar en el otro servidor viene relacionada, y a la hora de crear relaciones entre tablas no se puede especificar una base de datos remota en el DDL, entonces, cómo podemos hacer que esto funcione? bueno pues mi idea ha sido crear una vista materializada:</p>\n<p><code>create materialized view mv_armas as select codarma from armas@ORACLESERVIDOR;</code></p>\n<p>Una vez hecho esto, procedemos a crear las tablas personaje y equipar, siendo una relación N,M.</p>\n<pre><code>CREATE TABLE personaje (\ncodpersonaje varchar2 (3),\nnombre varchar2 (15),\naltura number (3,2),\npeso number (3),\nraza varchar2 (10),\nCONSTRAINT pk_codpersonaje PRIMARY KEY (codpersonaje),\nCONSTRAINT ck_codpersonaje CHECK (REGEXP_LIKE(codpersonaje,'^1.*$'))\n);\n\ninsert into personaje values ('101','Solaire',1.70,80,'humano');\ninsert into personaje values ('102','Artorias',1.90,90,'hueco');\ninsert into personaje values ('103','Gargola',3.10,680,'Gárgola');\n\nCREATE TABLE equipar (\ncodpersonaje varchar2 (3),\ncodarma varchar2 (3),\nfecha date,\nCONSTRAINT pk_equipar PRIMARY KEY (codpersonaje,codarma,fecha),\nCONSTRAINT fk_codpersonaje FOREIGN KEY (codpersonaje) REFERENCES personaje (codpersonaje),\nCONSTRAINT fk_codarma FOREIGN KEY (codarma) REFERENCES mv_armas(codarma);\n);\n\ninsert into equipar values ('102','003',to_date('2011/02/11','YYYY/MM/DD'));\ninsert into equipar values ('103','005',to_date('2011/05/04','YYYY/MM/DD'));\ninsert into equipar values ('101','002',to_date('2011/06/03','YYYY/MM/DD'));\ninsert into equipar values ('103','002',to_date('2011/09/02','YYYY/MM/DD'));\ninsert into equipar values ('101','006',to_date('2011/08/03','YYYY/MM/DD'));\ninsert into equipar values ('102','004',to_date('2011/07/01','YYYY/MM/DD'));\n\n</code></pre>\n<p>¡¡Mucho ojo!! la restricción que he establecido en equipar, que es la foreign key que relaciona el código de armas con nuestra base de datos, llamará a la view que hemos creado y contendrá los datos de la consulta al servidor externo.</p>\n<p><img src=\"/images/sql-remoto.png\" alt=\"remoto\"></p>\n<p><img src=\"/images/sql-remoto2.png\" alt=\"remoto\"></p>\n<h2 id=\"interconexión-entre-dos-bases-de-datos-postgres\"><a class=\"markdownIt-Anchor\" href=\"#interconexión-entre-dos-bases-de-datos-postgres\">#</a> Interconexión entre dos bases de datos Postgres.</h2>\n<p>Primero vamos a modificar el fichero /etc/postgresql/13/main/postgresql.conf para abrir la escucha a la ip que quiera conectarse:<br>\n <code>listen_addresses = '*'</code></p>\n<p>Modificamos el fichero /etc/postgresql/13/main/pg_hba.conf, y aladimos la siguiente línea:<br>\n <code>host    all             all             192.168.122.0/24        md5</code></p>\n<p>Procedemos a reiniciar Postgres para efectuar los cambios:<br>\n <code>sudo systemctl restart postgresql</code></p>\n<p>Luego vamos a crear la base de datos souls, luego vamos a darle permiso al usuario antonio2 para poder manejar la base de datos:</p>\n<pre><code>postgres=# create database souls\npostgres-# ;\nCREATE DATABASE\nGRANT ALL PRIVILEGES ON DATABASE souls TO antonio2;\npostgres=# grant connect on database souls to antonio2;\nGRANT\npostgres=# grant usage on schema public to antonio2;\nGRANT\n</code></pre>\n<p>En el otro servidor establecemos la configuración de antonio1:</p>\n<pre><code>postgres=# create user antonio1 with password 'antonio1';\nCREATE ROLE\npostgres=# create database souls;\nCREATE DATABASE\nGRANT ALL PRIVILEGES ON DATABASE souls TO antonio1;\npostgres=# grant connect on database souls to antonio1;\nGRANT\npostgres=# grant usage on schema public to antonio1;\nGRANT\npostgres=# \\c souls;\n</code></pre>\n<p>Ahora vamos a instalar el paquete que nos permitirá realizar el dblink:<br>\n <code>sudo apt install postgresql-contrib</code></p>\n<p>De modo que si hacemos una consulta con dblink especificando el host, usuario y base de datos del que se habla, podremos sacar la información de las bases de datos respectivamente.</p>\n<p><code>select * from dblink('dbname=souls host=192.168.122.168 user=antonio2 password=antonio2', 'select nombre from armas') as armas (Nombre VARCHAR);</code></p>\n<p><img src=\"/images/postgres-postgres.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"interconexión-entre-bases-de-datos-oracle-y-postgres\"><a class=\"markdownIt-Anchor\" href=\"#interconexión-entre-bases-de-datos-oracle-y-postgres\">#</a> Interconexión entre bases de datos Oracle y Postgres.</h2>\n<p>En nuestro caso la paquetería que necesitamos para conectar Oracle a Postgres es la de Debian Bullseye, por tanto el comando sería el siguiente:<br>\n <code>sudo apt install odbc-postgresql unixodbc -y</code></p>\n<p>Ahora vamos a entrar en /etc/odbc.ini y vamos a ingresar los siguientes parámetros adaptándolos a nuestro usuario, host y base de datos:</p>\n<pre><code>[PSQLA]\nDebug = 0\nCommLog = 0\nReadOnly = 1\nDriver = PostgreSQL ANSI\nServername = 192.168.122.168\nUsername = antonio2\nPassword = antonio2\nPort = 5432\nDatabase = souls\nTrace = 0\nTraceFile = /tmp/sql.log\n\n[PSQLU]\nDebug = 0\nCommLog = 0\nReadOnly = 0\nDriver = PostgreSQL Unicode\nServername = 192.168.122.168\nUsername = antonio2\nPassword = antonio2\nPort = 5432\nDatabase = souls\nTrace = 0\nTraceFile = /tmp/sql.log\n\n[Default]\nDriver = /usr/lib/x86_64-linux-gnu/odbc/liboplodbcS.so\n</code></pre>\n<p>Ahora vamos a comprobar el fichero /etc/ocdbinst.ini y debe venir configurado como se muestra abajo.</p>\n<pre><code>[PostgreSQL ANSI]\nDescription=PostgreSQL ODBC driver (ANSI version)\nDriver=psqlodbca.so\nSetup=libodbcpsqlS.so\nDebug=0\nCommLog=1\nUsageCount=1\n\n[PostgreSQL Unicode]\nDescription=PostgreSQL ODBC driver (Unicode version)\nDriver=psqlodbcw.so\nSetup=libodbcpsqlS.so\nDebug=0\nCommLog=1\nUsageCount=1\n</code></pre>\n<p>Podemos comprobar la configuración ingresando los siguientes comandos:</p>\n<pre><code>odbcinst -q -d\n    [PostgreSQL ANSI]\n    [PostgreSQL Unicode]\n\n\nodbcinst -q -s\n    [PSQLA]\n    [PSQLU]\n    [Default]\n</code></pre>\n<p>ejecutamos  <code>isql -v PSQLU</code>  y si todo ha ido bien nos devolverá esto:</p>\n<pre><code>+---------------------------------------+\n| Connected!                            |\n|                                       |\n| sql-statement                         |\n| help [tablename]                      |\n| quit                                  |\n|                                       |\n+---------------------------------------+\n</code></pre>\n<p>A continuación vamos a  <code>/opt/oracle/product/19c/dbhome_1/hs/admin/initPSQLU.ora</code>  e ingresamos los siguientes datos:</p>\n<pre><code>HS_FDS_CONNECT_INFO = PSQLU\nHS_FDS_TRACE_LEVEL = Debug\nHS_FDS_SHAREABLE_NAME = /usr/lib/x86_64-linux-gnu/odbc/psqlodbcw.so\nHS_LANGUAGE = AMERICAN_AMERICA.WE8ISO8859P1\nset ODBCINI=/etc/odbc.ini\n</code></pre>\n<p>Vamos al listener.ora e ingresamos los siguentes parámetros:</p>\n<pre><code>SID_LIST_LISTENER =\n (SID_LIST =\n  (SID_DESC =\n   (GLOBAL_DBNAME = ORCLCDB)\n   (ORACLE_HOME = /opt/oracle/product/19c/dbhome_1)\n   (SID_NAME = ORCLCDB)\n  )\n  (SID_DESC =\n    (SID_NAME = PSQLU)\n    (PROGRAM = dg4odbc)\n    (ORACLE_HOME = /opt/oracle/product/19c/dbhome_1)\n  )\n )\n</code></pre>\n<p>Ahora realizaremos un lsnrctl stop y lisnrctl start, y nos debe salir un mensaje como el siguiente:</p>\n<pre><code>Service &quot;PSQLU&quot; has 1 instance(s).\n  Instance &quot;PSQLU&quot;, status UNKNOWN, has 1 handler(s) for this service...\nService &quot;orcl&quot; has 1 instance(s).\n  Instance &quot;orcl&quot;, status UNKNOWN, has 1 handler(s) for this service...\nThe command completed successfully\n\n</code></pre>\n<p>Ahora nos vamos al tnsnames.ora y añadimos lo siguiente:</p>\n<pre><code>PSQLU =\n (DESCRIPTION =\n (ADDRESS = (PROTOCOL = TCP)(HOST = localhost)(PORT = 1521))\n   (CONNECT_DATA = (SID = PSQLU))\n   (HS = OK)\n  )\n</code></pre>\n<p>En localhost estamos especificando que la ip de la máquina sería la misma en la que está alojado el servicio postgre, esto es debido a que se redirecciona a través de la configuración en odbc.ini entonces ya tan solo quedaría conceder permisos de conexión publica de la base de datos a antonio:</p>\n<pre><code>GRANT CREATE PUBLIC DATABASE LINK to antonio;\n\nConcesion terminada correctamente.\n</code></pre>\n<p>Ahora solo nos queda realizar la conexión:</p>\n<pre><code>CREATE PUBLIC DATABASE LINK CONEXIONPOSTGRES2\nCONNECT TO &quot;antonio2&quot;\nIDENTIFIED BY &quot;antonio2&quot;\nUSING 'PSQLU';\n\nEnlace con la base de datos creado.\n</code></pre>\n<p>Comprobamos que se pueda consultar el nombre de las armas en <strong>CONEXIONPOSTGRES2</strong></p>\n<p><img src=\"/images/oracle-postgres.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"interconexión-entre-bases-de-datos-postgres-y-oracle\"><a class=\"markdownIt-Anchor\" href=\"#interconexión-entre-bases-de-datos-postgres-y-oracle\">#</a> Interconexión entre bases de datos Postgres y Oracle.</h2>\n<p>Primero vamos a instalar unos paquetes que nos servirán tanto para establecer la conexión con Oracle como a la hora de compilar el Makefile que necesitaremos más adelante:</p>\n<p><code>apt install git build-essential libaio1 postgresql-server-dev-all -y</code></p>\n<p>Para realizar la interconexión entre Postgres y Oracle necesitaremos software de terceros, en mi caso vamos a descargar los paquetes que se encuentran en el siguiente enlace:</p>\n<p><a href=\"https://drive.google.com/file/d/1UmBNjVLffaj-hXDXdi6hPGpz6CIZr8eN/view?usp=share_link\">https://drive.google.com/file/d/1UmBNjVLffaj-hXDXdi6hPGpz6CIZr8eN/view?usp=share_link</a></p>\n<p>En él se encuentran los paquetes en formato.deb, del cual me ocupé de transformar con alien.</p>\n<p>Ahora procedemos a instalar los paquetes que adaptarán el formato sqlplus:</p>\n<pre><code>sudo dpkg -i oracle-instantclient19.5-devel_19.5.0.0.0-2_amd64.deb\nsudo dpkg -i oracle-instantclient19.5-basic_19.5.0.0.0-2_amd64.deb\nsudo dpkg -i oracle-instantclient19.5-tools_19.5.0.0.0-2_amd64.deb\nsudo dpkg -i oracle-instantclient19.5-sqlplus_19.5.0.0.0-2_amd64.deb\n</code></pre>\n<p>Ahora vamos a clonar el repositorio con el que trabajaremos para establecer la conexión de Postgres a Oracle:</p>\n<p>git clone <a href=\"https://github.com/laurenz/oracle_fdw.git\">https://github.com/laurenz/oracle_fdw.git</a></p>\n<p>Ahora en nuestra máquina postgres necesitaremos crear las variables de entorno de Oracle, para ello ingresaremos lo siguiente al final de nuestro .bashrc</p>\n<pre><code>sudo nano ~/.bashrc\n\nexport ORACLE_HOME=&quot;/usr/lib/oracle/19.5/client64&quot;\nexport LD_LIBRARY_PATH=&quot;/usr/lib/oracle/19.5/client64/lib&quot;\nexport PATH=$ORACLE_HOME:$PATH\nexport USE_PGXS=1\n</code></pre>\n<p>Ahora vamos a generar el makefile ejecutando un  <code>make</code>  dentro del directorio que hemos clonado.</p>\n<p>UNa vez hecho esto, ante de proceder a instalar el binario, debamo incluir las siguientes líneas a nuestro makefile.</p>\n<pre><code>PG_CPPFLAGS = -I&quot;$(ORACLE_HOME)/sdk/include&quot; -I&quot;$(ORACLE_HOME)/oci/include&quot; -I&quot;$(ORACLE_HOME)/rdbms/public&quot; -I&quot;$(ORACLE_HOME)/&quot; $(FIN&gt;\n\nSHLIB_LINK = -L&quot;$(ORACLE_HOME)/&quot; -L&quot;$(ORACLE_HOME)/bin&quot; -L&quot;$(ORACLE_HOME)/lib&quot; -L&quot;$(ORACLE_HOME)/lib/amd64&quot; $(FIND_LDFLAGS) -l$(ORACL&gt;\n</code></pre>\n<p>Ahora podemos ejecutar un  <code>make install</code>  sin errores ya que las dependencias necesarias para la instalación fueron descargadas con anterioridad.</p>\n<p>Luego entramos en nuestra base de datos con el usuario postgres para crear nuestro enlace a Oracle, debemos especificar la ip que tendrá el sevidor y el nombre de la base de datos que en nuestro caso será el por defecto ‘ORCLCDB’.</p>\n<pre><code>CREATE SERVER oracleantonio FOREIGN DATA WRAPPER oracle_fdw OPTIONS(dbserver '//192.168.122.168:1521/ORCLCDB');\n</code></pre>\n<p>Una vez hecho esto vamos a enlazar la conexión de nuestro oracleantonio con el usuario que tenga acceso a los registros de la tabla armas, de forma que quedaría de la siguiente manera:</p>\n<pre><code>create user mapping for postgres server oracleantonio options(user 'antonio',password 'antonio');\nDROP user mapping for postgres server oracleantonio; (En caso de que haya algún tipo de error).\n</code></pre>\n<p>Crearemos el esqueleto de la tabla que necesitamos en la base de datos pero sin restricciones ni unique, ya que colisionan con la ejecución de la conexión remota, solo necesitaremos los campos que vayan a ser rellenados:</p>\n<pre><code>CREATE FOREIGN TABLE personaje (\ncodpersonaje varchar (3),\nnombre varchar (15),\naltura numeric (3,2),\npeso numeric (3),\nraza varchar (10) DEFAULT ('Humano'))\nSERVER oracleantonio OPTIONS(schema 'ANTONIO', table 'PERSONAJE'\n);\n</code></pre>\n<p>Ahora solo nos queda realizar la consulta y podemos comprobar como esta se resuelve con éxito.</p>\n<p><img src=\"/images/postgres-oracle.png\" alt=\"Descripción de la imagen\"></p>\n","site":{"data":{}},"length":10745,"excerpt":"","more":"<p><img src=\"/images/oracle-19c-logo.png\" alt=\"remoto\"></p>\n<h2 id=\"interconexión-entre-dos-bases-de-datos-oracle\"><a class=\"markdownIt-Anchor\" href=\"#interconexión-entre-dos-bases-de-datos-oracle\">#</a> Interconexión entre dos bases de datos Oracle.</h2>\n<p>Antes que nada debemos saber que para conectarnos a una base de datos, debemos tener activados los listener y seguidamente tener en el tsnames.ora la base de datos a la que queremos conectarnos, de esta manera:<br>\nsudo nano /opt/oracle/product/19c/dbhome_1/network/admin/tnsnames.ora</p>\n<pre><code>ORCLCDB =\n  (DESCRIPTION =\n    (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.122.20)(PORT = 1521))\n    (CONNECT_DATA =\n      (SERVER = DEDICATED)\n      (SERVICE_NAME = ORCLCDB)\n    )\n  )\n\nLISTENER_ORCLCDB =\n  (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.122.20)(PORT = 1521))\n\nORACLESERV =\n  (DESCRIPTION =\n    (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.122.168)(PORT = 1521))\n    (CONNECT_DATA =\n      (SERVER = DEDICATED)\n      (SERVICE_NAME = ORCLCDB)\n    )\n  )\n</code></pre>\n<p>Hemos creado una nueva conexión llamada ORACLESERV en el cual procederemos a ingresar la ip del servidor del que queremos recibir los datos, tras esto debemos crear en la otra máquina la tabla de ejemplo que queremos extraer:</p>\n<pre><code>CREATE TABLE armas (\ncodarma varchar2 (3),\nnombre varchar2 (20),\nfuerza number (2),\ndestreza number (2),\ninteligencia number (2),\nrareza varchar2 (10),\nnivel number (2),\nCONSTRAINT pk_armas PRIMARY KEY (codarma)\n);\n\ninsert into armas values ('001','Espada Corta',8,10,0,'D',5);\ninsert into armas values ('002','Espada Larga',10,10,0,'C',8);\ninsert into armas values ('003','Espada Artorias',24,18,20,'S',30);\ninsert into armas values ('004','Hacha de Mano',8,8,0,'D',6);\ninsert into armas values ('005','Hacha de Gárgola',14,14,0,'A',15);\ninsert into armas values ('006','Hacha de Demonio',46,0,0,'S',40);\n</code></pre>\n<p>Una vez hecho esto, <strong>nos vamos a la máquina en la que vamos a trabajar con la consulta</strong>, debemos crear un enlace a la base de datos, el cual hemos predefinido como ORACLESERV:</p>\n<p><code>create database link ORACLESERVIDOR connect to antonio identified by antonio using 'ORACLESERV';</code></p>\n<p>Tras esto, viene una parte un poco compleja, ya que la tabla que vamos a consultar en el otro servidor viene relacionada, y a la hora de crear relaciones entre tablas no se puede especificar una base de datos remota en el DDL, entonces, cómo podemos hacer que esto funcione? bueno pues mi idea ha sido crear una vista materializada:</p>\n<p><code>create materialized view mv_armas as select codarma from armas@ORACLESERVIDOR;</code></p>\n<p>Una vez hecho esto, procedemos a crear las tablas personaje y equipar, siendo una relación N,M.</p>\n<pre><code>CREATE TABLE personaje (\ncodpersonaje varchar2 (3),\nnombre varchar2 (15),\naltura number (3,2),\npeso number (3),\nraza varchar2 (10),\nCONSTRAINT pk_codpersonaje PRIMARY KEY (codpersonaje),\nCONSTRAINT ck_codpersonaje CHECK (REGEXP_LIKE(codpersonaje,'^1.*$'))\n);\n\ninsert into personaje values ('101','Solaire',1.70,80,'humano');\ninsert into personaje values ('102','Artorias',1.90,90,'hueco');\ninsert into personaje values ('103','Gargola',3.10,680,'Gárgola');\n\nCREATE TABLE equipar (\ncodpersonaje varchar2 (3),\ncodarma varchar2 (3),\nfecha date,\nCONSTRAINT pk_equipar PRIMARY KEY (codpersonaje,codarma,fecha),\nCONSTRAINT fk_codpersonaje FOREIGN KEY (codpersonaje) REFERENCES personaje (codpersonaje),\nCONSTRAINT fk_codarma FOREIGN KEY (codarma) REFERENCES mv_armas(codarma);\n);\n\ninsert into equipar values ('102','003',to_date('2011/02/11','YYYY/MM/DD'));\ninsert into equipar values ('103','005',to_date('2011/05/04','YYYY/MM/DD'));\ninsert into equipar values ('101','002',to_date('2011/06/03','YYYY/MM/DD'));\ninsert into equipar values ('103','002',to_date('2011/09/02','YYYY/MM/DD'));\ninsert into equipar values ('101','006',to_date('2011/08/03','YYYY/MM/DD'));\ninsert into equipar values ('102','004',to_date('2011/07/01','YYYY/MM/DD'));\n\n</code></pre>\n<p>¡¡Mucho ojo!! la restricción que he establecido en equipar, que es la foreign key que relaciona el código de armas con nuestra base de datos, llamará a la view que hemos creado y contendrá los datos de la consulta al servidor externo.</p>\n<p><img src=\"/images/sql-remoto.png\" alt=\"remoto\"></p>\n<p><img src=\"/images/sql-remoto2.png\" alt=\"remoto\"></p>\n<h2 id=\"interconexión-entre-dos-bases-de-datos-postgres\"><a class=\"markdownIt-Anchor\" href=\"#interconexión-entre-dos-bases-de-datos-postgres\">#</a> Interconexión entre dos bases de datos Postgres.</h2>\n<p>Primero vamos a modificar el fichero /etc/postgresql/13/main/postgresql.conf para abrir la escucha a la ip que quiera conectarse:<br>\n <code>listen_addresses = '*'</code></p>\n<p>Modificamos el fichero /etc/postgresql/13/main/pg_hba.conf, y aladimos la siguiente línea:<br>\n <code>host    all             all             192.168.122.0/24        md5</code></p>\n<p>Procedemos a reiniciar Postgres para efectuar los cambios:<br>\n <code>sudo systemctl restart postgresql</code></p>\n<p>Luego vamos a crear la base de datos souls, luego vamos a darle permiso al usuario antonio2 para poder manejar la base de datos:</p>\n<pre><code>postgres=# create database souls\npostgres-# ;\nCREATE DATABASE\nGRANT ALL PRIVILEGES ON DATABASE souls TO antonio2;\npostgres=# grant connect on database souls to antonio2;\nGRANT\npostgres=# grant usage on schema public to antonio2;\nGRANT\n</code></pre>\n<p>En el otro servidor establecemos la configuración de antonio1:</p>\n<pre><code>postgres=# create user antonio1 with password 'antonio1';\nCREATE ROLE\npostgres=# create database souls;\nCREATE DATABASE\nGRANT ALL PRIVILEGES ON DATABASE souls TO antonio1;\npostgres=# grant connect on database souls to antonio1;\nGRANT\npostgres=# grant usage on schema public to antonio1;\nGRANT\npostgres=# \\c souls;\n</code></pre>\n<p>Ahora vamos a instalar el paquete que nos permitirá realizar el dblink:<br>\n <code>sudo apt install postgresql-contrib</code></p>\n<p>De modo que si hacemos una consulta con dblink especificando el host, usuario y base de datos del que se habla, podremos sacar la información de las bases de datos respectivamente.</p>\n<p><code>select * from dblink('dbname=souls host=192.168.122.168 user=antonio2 password=antonio2', 'select nombre from armas') as armas (Nombre VARCHAR);</code></p>\n<p><img src=\"/images/postgres-postgres.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"interconexión-entre-bases-de-datos-oracle-y-postgres\"><a class=\"markdownIt-Anchor\" href=\"#interconexión-entre-bases-de-datos-oracle-y-postgres\">#</a> Interconexión entre bases de datos Oracle y Postgres.</h2>\n<p>En nuestro caso la paquetería que necesitamos para conectar Oracle a Postgres es la de Debian Bullseye, por tanto el comando sería el siguiente:<br>\n <code>sudo apt install odbc-postgresql unixodbc -y</code></p>\n<p>Ahora vamos a entrar en /etc/odbc.ini y vamos a ingresar los siguientes parámetros adaptándolos a nuestro usuario, host y base de datos:</p>\n<pre><code>[PSQLA]\nDebug = 0\nCommLog = 0\nReadOnly = 1\nDriver = PostgreSQL ANSI\nServername = 192.168.122.168\nUsername = antonio2\nPassword = antonio2\nPort = 5432\nDatabase = souls\nTrace = 0\nTraceFile = /tmp/sql.log\n\n[PSQLU]\nDebug = 0\nCommLog = 0\nReadOnly = 0\nDriver = PostgreSQL Unicode\nServername = 192.168.122.168\nUsername = antonio2\nPassword = antonio2\nPort = 5432\nDatabase = souls\nTrace = 0\nTraceFile = /tmp/sql.log\n\n[Default]\nDriver = /usr/lib/x86_64-linux-gnu/odbc/liboplodbcS.so\n</code></pre>\n<p>Ahora vamos a comprobar el fichero /etc/ocdbinst.ini y debe venir configurado como se muestra abajo.</p>\n<pre><code>[PostgreSQL ANSI]\nDescription=PostgreSQL ODBC driver (ANSI version)\nDriver=psqlodbca.so\nSetup=libodbcpsqlS.so\nDebug=0\nCommLog=1\nUsageCount=1\n\n[PostgreSQL Unicode]\nDescription=PostgreSQL ODBC driver (Unicode version)\nDriver=psqlodbcw.so\nSetup=libodbcpsqlS.so\nDebug=0\nCommLog=1\nUsageCount=1\n</code></pre>\n<p>Podemos comprobar la configuración ingresando los siguientes comandos:</p>\n<pre><code>odbcinst -q -d\n    [PostgreSQL ANSI]\n    [PostgreSQL Unicode]\n\n\nodbcinst -q -s\n    [PSQLA]\n    [PSQLU]\n    [Default]\n</code></pre>\n<p>ejecutamos  <code>isql -v PSQLU</code>  y si todo ha ido bien nos devolverá esto:</p>\n<pre><code>+---------------------------------------+\n| Connected!                            |\n|                                       |\n| sql-statement                         |\n| help [tablename]                      |\n| quit                                  |\n|                                       |\n+---------------------------------------+\n</code></pre>\n<p>A continuación vamos a  <code>/opt/oracle/product/19c/dbhome_1/hs/admin/initPSQLU.ora</code>  e ingresamos los siguientes datos:</p>\n<pre><code>HS_FDS_CONNECT_INFO = PSQLU\nHS_FDS_TRACE_LEVEL = Debug\nHS_FDS_SHAREABLE_NAME = /usr/lib/x86_64-linux-gnu/odbc/psqlodbcw.so\nHS_LANGUAGE = AMERICAN_AMERICA.WE8ISO8859P1\nset ODBCINI=/etc/odbc.ini\n</code></pre>\n<p>Vamos al listener.ora e ingresamos los siguentes parámetros:</p>\n<pre><code>SID_LIST_LISTENER =\n (SID_LIST =\n  (SID_DESC =\n   (GLOBAL_DBNAME = ORCLCDB)\n   (ORACLE_HOME = /opt/oracle/product/19c/dbhome_1)\n   (SID_NAME = ORCLCDB)\n  )\n  (SID_DESC =\n    (SID_NAME = PSQLU)\n    (PROGRAM = dg4odbc)\n    (ORACLE_HOME = /opt/oracle/product/19c/dbhome_1)\n  )\n )\n</code></pre>\n<p>Ahora realizaremos un lsnrctl stop y lisnrctl start, y nos debe salir un mensaje como el siguiente:</p>\n<pre><code>Service &quot;PSQLU&quot; has 1 instance(s).\n  Instance &quot;PSQLU&quot;, status UNKNOWN, has 1 handler(s) for this service...\nService &quot;orcl&quot; has 1 instance(s).\n  Instance &quot;orcl&quot;, status UNKNOWN, has 1 handler(s) for this service...\nThe command completed successfully\n\n</code></pre>\n<p>Ahora nos vamos al tnsnames.ora y añadimos lo siguiente:</p>\n<pre><code>PSQLU =\n (DESCRIPTION =\n (ADDRESS = (PROTOCOL = TCP)(HOST = localhost)(PORT = 1521))\n   (CONNECT_DATA = (SID = PSQLU))\n   (HS = OK)\n  )\n</code></pre>\n<p>En localhost estamos especificando que la ip de la máquina sería la misma en la que está alojado el servicio postgre, esto es debido a que se redirecciona a través de la configuración en odbc.ini entonces ya tan solo quedaría conceder permisos de conexión publica de la base de datos a antonio:</p>\n<pre><code>GRANT CREATE PUBLIC DATABASE LINK to antonio;\n\nConcesion terminada correctamente.\n</code></pre>\n<p>Ahora solo nos queda realizar la conexión:</p>\n<pre><code>CREATE PUBLIC DATABASE LINK CONEXIONPOSTGRES2\nCONNECT TO &quot;antonio2&quot;\nIDENTIFIED BY &quot;antonio2&quot;\nUSING 'PSQLU';\n\nEnlace con la base de datos creado.\n</code></pre>\n<p>Comprobamos que se pueda consultar el nombre de las armas en <strong>CONEXIONPOSTGRES2</strong></p>\n<p><img src=\"/images/oracle-postgres.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"interconexión-entre-bases-de-datos-postgres-y-oracle\"><a class=\"markdownIt-Anchor\" href=\"#interconexión-entre-bases-de-datos-postgres-y-oracle\">#</a> Interconexión entre bases de datos Postgres y Oracle.</h2>\n<p>Primero vamos a instalar unos paquetes que nos servirán tanto para establecer la conexión con Oracle como a la hora de compilar el Makefile que necesitaremos más adelante:</p>\n<p><code>apt install git build-essential libaio1 postgresql-server-dev-all -y</code></p>\n<p>Para realizar la interconexión entre Postgres y Oracle necesitaremos software de terceros, en mi caso vamos a descargar los paquetes que se encuentran en el siguiente enlace:</p>\n<p><a href=\"https://drive.google.com/file/d/1UmBNjVLffaj-hXDXdi6hPGpz6CIZr8eN/view?usp=share_link\">https://drive.google.com/file/d/1UmBNjVLffaj-hXDXdi6hPGpz6CIZr8eN/view?usp=share_link</a></p>\n<p>En él se encuentran los paquetes en formato.deb, del cual me ocupé de transformar con alien.</p>\n<p>Ahora procedemos a instalar los paquetes que adaptarán el formato sqlplus:</p>\n<pre><code>sudo dpkg -i oracle-instantclient19.5-devel_19.5.0.0.0-2_amd64.deb\nsudo dpkg -i oracle-instantclient19.5-basic_19.5.0.0.0-2_amd64.deb\nsudo dpkg -i oracle-instantclient19.5-tools_19.5.0.0.0-2_amd64.deb\nsudo dpkg -i oracle-instantclient19.5-sqlplus_19.5.0.0.0-2_amd64.deb\n</code></pre>\n<p>Ahora vamos a clonar el repositorio con el que trabajaremos para establecer la conexión de Postgres a Oracle:</p>\n<p>git clone <a href=\"https://github.com/laurenz/oracle_fdw.git\">https://github.com/laurenz/oracle_fdw.git</a></p>\n<p>Ahora en nuestra máquina postgres necesitaremos crear las variables de entorno de Oracle, para ello ingresaremos lo siguiente al final de nuestro .bashrc</p>\n<pre><code>sudo nano ~/.bashrc\n\nexport ORACLE_HOME=&quot;/usr/lib/oracle/19.5/client64&quot;\nexport LD_LIBRARY_PATH=&quot;/usr/lib/oracle/19.5/client64/lib&quot;\nexport PATH=$ORACLE_HOME:$PATH\nexport USE_PGXS=1\n</code></pre>\n<p>Ahora vamos a generar el makefile ejecutando un  <code>make</code>  dentro del directorio que hemos clonado.</p>\n<p>UNa vez hecho esto, ante de proceder a instalar el binario, debamo incluir las siguientes líneas a nuestro makefile.</p>\n<pre><code>PG_CPPFLAGS = -I&quot;$(ORACLE_HOME)/sdk/include&quot; -I&quot;$(ORACLE_HOME)/oci/include&quot; -I&quot;$(ORACLE_HOME)/rdbms/public&quot; -I&quot;$(ORACLE_HOME)/&quot; $(FIN&gt;\n\nSHLIB_LINK = -L&quot;$(ORACLE_HOME)/&quot; -L&quot;$(ORACLE_HOME)/bin&quot; -L&quot;$(ORACLE_HOME)/lib&quot; -L&quot;$(ORACLE_HOME)/lib/amd64&quot; $(FIND_LDFLAGS) -l$(ORACL&gt;\n</code></pre>\n<p>Ahora podemos ejecutar un  <code>make install</code>  sin errores ya que las dependencias necesarias para la instalación fueron descargadas con anterioridad.</p>\n<p>Luego entramos en nuestra base de datos con el usuario postgres para crear nuestro enlace a Oracle, debemos especificar la ip que tendrá el sevidor y el nombre de la base de datos que en nuestro caso será el por defecto ‘ORCLCDB’.</p>\n<pre><code>CREATE SERVER oracleantonio FOREIGN DATA WRAPPER oracle_fdw OPTIONS(dbserver '//192.168.122.168:1521/ORCLCDB');\n</code></pre>\n<p>Una vez hecho esto vamos a enlazar la conexión de nuestro oracleantonio con el usuario que tenga acceso a los registros de la tabla armas, de forma que quedaría de la siguiente manera:</p>\n<pre><code>create user mapping for postgres server oracleantonio options(user 'antonio',password 'antonio');\nDROP user mapping for postgres server oracleantonio; (En caso de que haya algún tipo de error).\n</code></pre>\n<p>Crearemos el esqueleto de la tabla que necesitamos en la base de datos pero sin restricciones ni unique, ya que colisionan con la ejecución de la conexión remota, solo necesitaremos los campos que vayan a ser rellenados:</p>\n<pre><code>CREATE FOREIGN TABLE personaje (\ncodpersonaje varchar (3),\nnombre varchar (15),\naltura numeric (3,2),\npeso numeric (3),\nraza varchar (10) DEFAULT ('Humano'))\nSERVER oracleantonio OPTIONS(schema 'ANTONIO', table 'PERSONAJE'\n);\n</code></pre>\n<p>Ahora solo nos queda realizar la consulta y podemos comprobar como esta se resuelve con éxito.</p>\n<p><img src=\"/images/postgres-oracle.png\" alt=\"Descripción de la imagen\"></p>\n"},{"title":"Instalación preseed PXE+APACHE","_content":"\nVamos a crear la máquina virtual como hicimos anteriormente en [Instalación automatizada basada en medio de almacenamiento extraíble.](https://entrebytes.neocities.org/2022/09/30/preseed/)\n\nEn vagrant creamos una máquina que tenga una ip estática 192.168.100.3 que va a ser la tarjeta de red por la que funcionará pxe, en mi caso no creó esa ip y la tuve que escribir a mano en el /etc/network/interfaces, la otra tarjeta de red es la de vagrant-libvirt que será la que nos conecte al exterior.\n\nPara proceder a configurar el protocolo **TFTP** Y **DHCP** para que sea el host el que conceda ip a la máquina y establezca la conexión al preseed, utilizando dnsmasq\n\napt install dnsmasq\n\n\nEstablecemos en el fichero /etc/dnsmaq.conf con los siguientes parámetros:\n\n`dhcp-range=192.168.100.100,192.168.100.200,255.255.255.0`\n\nEstablecemos el fichero con  el que va a bootear el dhcp:\n\n`dhcp-boot=pxelinux.0`\n\nHabilitamos el tftp:\n`enable-tftp`\n\nEstablecemos una ruta donde va a albergar nuestro Debian:\n`tftp-root=/srv/tftp`\n\n\nCreamos la carpeta en /srv\n`sudo mkdir /srv/tftp`\n\na continuación instalamos el wget y lo usamos en /srv/tftp\n\n\n`wget http://ftp.debian.org/debian/dists/bullseye/main/installer-amd64/current/images/netboot/netboot.tar.gz\n`\n\n`tar -zxf netboot.tar.gz` (para descomprimir los archivos)\n`rm netboot.tar.gz`\n\n\n\n`srv/tftp/debian-installer/amd64/boot-screens/txt.cfg`\n\nEn este fichero de configuración utilizamos los siguientes parámetros:\n```\nlabel install\n        menu label ^Install\n        kernel debian-installer/amd64/linux\n        append vga=788 initrd=debian-installer/amd64/initrd.gz --- quiet\nlabel unattended-gnome\n        menu label ^Instalacion Debian Desatendida Preseed\n        kernel debian-installer/amd64/linux\n        append vga=788 initrd=debian-installer/amd64/initrd.gz hostname=preseed domain=preseed preseed/url=192.168.100.5/preseed.cfg locale=en_US.UTF-8 console-setup/charmap=UTF-8 console-setup/ask_detect=false keyboard-configuration/xkb-keymap=us --\n```\n\nEn este label he puesto la url del servidor apache que vamos a utilizar, para que descargue el preseed y lo inyecte en la instalación.\n\nInstalamos apache2:\n`sudo apt install apache2`\n\nluego copiamos el preseed, lo ponemos en `/var/www/html/` junto al index.html, hacemos la página HTML que albergue el preseed y la ruta ya está establecida en el txt.cfg\n\n\nUna vez hecho esto, para que nuestra máquina que se conecta a la tarjeta de red estática que hemos creado, necesitamos establecer unas reglas de nftables que nos ayudará a conseguir que la máquina que conecte con el servidor pxe salga al exterior para descargar las dependencias.\n\nPara ello, debemos activar el bit de forwarding que se halla en `/etc/sysctl.conf` y descomentamos `#net.ipv4.ip_forward=1`\n\nInstalamos y habilitamos nftables(Todo esto siendo root):\n\n`apt install nftables`\n`systemctl start nftables.service`\n`systemctl enable nftables.service`\n`nft add table nat`\n`nft list tables`\n\nahora realizamos las reglas de nftables para conseguir que esas máquinas tengan internet:\n`nft add chain nat postrouting { type nat hook postrouting priority 100 \\; }`\n`nft add rule ip nat postrouting oifname \"eth0\" ip saddr 192.168.100.0/24 counter masquerade`\n\nAhora guardamos los cambios: `nft list ruleset > /etc/nftables.conf`\n\nAhora en virt-manager procedemos a crear y enlazar una máquina a una red aislada:\n```\n<network connections=\"2\">\n  <name>red_muy_aislada</name>\n  <uuid>b0083374-5cb6-4a8d-bd3c-32cf0d870b54</uuid>\n  <bridge name=\"virbr3\" stp=\"on\" delay=\"0\"/>\n  <mac address=\"52:54:00:e9:be:50\"/>\n</network>\n```\n\n debemos arrancarla por red como prioridad, luego de esto funcionará perfectamente nuestra instalación desatendida.\n","source":"_posts/Preseed-pxe.md","raw":"---\ntitle: Instalación preseed PXE+APACHE\ncategories: Sistemas Operativos\n---\n\nVamos a crear la máquina virtual como hicimos anteriormente en [Instalación automatizada basada en medio de almacenamiento extraíble.](https://entrebytes.neocities.org/2022/09/30/preseed/)\n\nEn vagrant creamos una máquina que tenga una ip estática 192.168.100.3 que va a ser la tarjeta de red por la que funcionará pxe, en mi caso no creó esa ip y la tuve que escribir a mano en el /etc/network/interfaces, la otra tarjeta de red es la de vagrant-libvirt que será la que nos conecte al exterior.\n\nPara proceder a configurar el protocolo **TFTP** Y **DHCP** para que sea el host el que conceda ip a la máquina y establezca la conexión al preseed, utilizando dnsmasq\n\napt install dnsmasq\n\n\nEstablecemos en el fichero /etc/dnsmaq.conf con los siguientes parámetros:\n\n`dhcp-range=192.168.100.100,192.168.100.200,255.255.255.0`\n\nEstablecemos el fichero con  el que va a bootear el dhcp:\n\n`dhcp-boot=pxelinux.0`\n\nHabilitamos el tftp:\n`enable-tftp`\n\nEstablecemos una ruta donde va a albergar nuestro Debian:\n`tftp-root=/srv/tftp`\n\n\nCreamos la carpeta en /srv\n`sudo mkdir /srv/tftp`\n\na continuación instalamos el wget y lo usamos en /srv/tftp\n\n\n`wget http://ftp.debian.org/debian/dists/bullseye/main/installer-amd64/current/images/netboot/netboot.tar.gz\n`\n\n`tar -zxf netboot.tar.gz` (para descomprimir los archivos)\n`rm netboot.tar.gz`\n\n\n\n`srv/tftp/debian-installer/amd64/boot-screens/txt.cfg`\n\nEn este fichero de configuración utilizamos los siguientes parámetros:\n```\nlabel install\n        menu label ^Install\n        kernel debian-installer/amd64/linux\n        append vga=788 initrd=debian-installer/amd64/initrd.gz --- quiet\nlabel unattended-gnome\n        menu label ^Instalacion Debian Desatendida Preseed\n        kernel debian-installer/amd64/linux\n        append vga=788 initrd=debian-installer/amd64/initrd.gz hostname=preseed domain=preseed preseed/url=192.168.100.5/preseed.cfg locale=en_US.UTF-8 console-setup/charmap=UTF-8 console-setup/ask_detect=false keyboard-configuration/xkb-keymap=us --\n```\n\nEn este label he puesto la url del servidor apache que vamos a utilizar, para que descargue el preseed y lo inyecte en la instalación.\n\nInstalamos apache2:\n`sudo apt install apache2`\n\nluego copiamos el preseed, lo ponemos en `/var/www/html/` junto al index.html, hacemos la página HTML que albergue el preseed y la ruta ya está establecida en el txt.cfg\n\n\nUna vez hecho esto, para que nuestra máquina que se conecta a la tarjeta de red estática que hemos creado, necesitamos establecer unas reglas de nftables que nos ayudará a conseguir que la máquina que conecte con el servidor pxe salga al exterior para descargar las dependencias.\n\nPara ello, debemos activar el bit de forwarding que se halla en `/etc/sysctl.conf` y descomentamos `#net.ipv4.ip_forward=1`\n\nInstalamos y habilitamos nftables(Todo esto siendo root):\n\n`apt install nftables`\n`systemctl start nftables.service`\n`systemctl enable nftables.service`\n`nft add table nat`\n`nft list tables`\n\nahora realizamos las reglas de nftables para conseguir que esas máquinas tengan internet:\n`nft add chain nat postrouting { type nat hook postrouting priority 100 \\; }`\n`nft add rule ip nat postrouting oifname \"eth0\" ip saddr 192.168.100.0/24 counter masquerade`\n\nAhora guardamos los cambios: `nft list ruleset > /etc/nftables.conf`\n\nAhora en virt-manager procedemos a crear y enlazar una máquina a una red aislada:\n```\n<network connections=\"2\">\n  <name>red_muy_aislada</name>\n  <uuid>b0083374-5cb6-4a8d-bd3c-32cf0d870b54</uuid>\n  <bridge name=\"virbr3\" stp=\"on\" delay=\"0\"/>\n  <mac address=\"52:54:00:e9:be:50\"/>\n</network>\n```\n\n debemos arrancarla por red como prioridad, luego de esto funcionará perfectamente nuestra instalación desatendida.\n","slug":"Preseed-pxe","published":1,"date":"2022-10-04T19:21:24.436Z","updated":"2023-01-04T13:34:44.707Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cldl9ucgl000a0yi59nosa7ld","content":"<p>Vamos a crear la máquina virtual como hicimos anteriormente en <a href=\"https://entrebytes.neocities.org/2022/09/30/preseed/\">Instalación automatizada basada en medio de almacenamiento extraíble.</a></p>\n<p>En vagrant creamos una máquina que tenga una ip estática 192.168.100.3 que va a ser la tarjeta de red por la que funcionará pxe, en mi caso no creó esa ip y la tuve que escribir a mano en el /etc/network/interfaces, la otra tarjeta de red es la de vagrant-libvirt que será la que nos conecte al exterior.</p>\n<p>Para proceder a configurar el protocolo <strong>TFTP</strong> Y <strong>DHCP</strong> para que sea el host el que conceda ip a la máquina y establezca la conexión al preseed, utilizando dnsmasq</p>\n<p>apt install dnsmasq</p>\n<p>Establecemos en el fichero /etc/dnsmaq.conf con los siguientes parámetros:</p>\n<p><code>dhcp-range=192.168.100.100,192.168.100.200,255.255.255.0</code></p>\n<p>Establecemos el fichero con  el que va a bootear el dhcp:</p>\n<p><code>dhcp-boot=pxelinux.0</code></p>\n<p>Habilitamos el tftp:<br>\n <code>enable-tftp</code></p>\n<p>Establecemos una ruta donde va a albergar nuestro Debian:<br>\n <code>tftp-root=/srv/tftp</code></p>\n<p>Creamos la carpeta en /srv<br>\n <code>sudo mkdir /srv/tftp</code></p>\n<p>a continuación instalamos el wget y lo usamos en /srv/tftp</p>\n<p><code>wget http://ftp.debian.org/debian/dists/bullseye/main/installer-amd64/current/images/netboot/netboot.tar.gz </code></p>\n<p><code>tar -zxf netboot.tar.gz</code>  (para descomprimir los archivos)<br>\n <code>rm netboot.tar.gz</code></p>\n<p><code>srv/tftp/debian-installer/amd64/boot-screens/txt.cfg</code></p>\n<p>En este fichero de configuración utilizamos los siguientes parámetros:</p>\n<pre><code>label install\n        menu label ^Install\n        kernel debian-installer/amd64/linux\n        append vga=788 initrd=debian-installer/amd64/initrd.gz --- quiet\nlabel unattended-gnome\n        menu label ^Instalacion Debian Desatendida Preseed\n        kernel debian-installer/amd64/linux\n        append vga=788 initrd=debian-installer/amd64/initrd.gz hostname=preseed domain=preseed preseed/url=192.168.100.5/preseed.cfg locale=en_US.UTF-8 console-setup/charmap=UTF-8 console-setup/ask_detect=false keyboard-configuration/xkb-keymap=us --\n</code></pre>\n<p>En este label he puesto la url del servidor apache que vamos a utilizar, para que descargue el preseed y lo inyecte en la instalación.</p>\n<p>Instalamos apache2:<br>\n <code>sudo apt install apache2</code></p>\n<p>luego copiamos el preseed, lo ponemos en  <code>/var/www/html/</code>  junto al index.html, hacemos la página HTML que albergue el preseed y la ruta ya está establecida en el txt.cfg</p>\n<p>Una vez hecho esto, para que nuestra máquina que se conecta a la tarjeta de red estática que hemos creado, necesitamos establecer unas reglas de nftables que nos ayudará a conseguir que la máquina que conecte con el servidor pxe salga al exterior para descargar las dependencias.</p>\n<p>Para ello, debemos activar el bit de forwarding que se halla en  <code>/etc/sysctl.conf</code>  y descomentamos  <code>#net.ipv4.ip_forward=1</code></p>\n<p>Instalamos y habilitamos nftables(Todo esto siendo root):</p>\n<p><code>apt install nftables</code> <br>\n <code>systemctl start nftables.service</code> <br>\n <code>systemctl enable nftables.service</code> <br>\n <code>nft add table nat</code> <br>\n <code>nft list tables</code></p>\n<p>ahora realizamos las reglas de nftables para conseguir que esas máquinas tengan internet:<br>\n <code>nft add chain nat postrouting &#123; type nat hook postrouting priority 100 \\; &#125;</code> <br>\n <code>nft add rule ip nat postrouting oifname &quot;eth0&quot; ip saddr 192.168.100.0/24 counter masquerade</code></p>\n<p>Ahora guardamos los cambios:  <code>nft list ruleset &gt; /etc/nftables.conf</code></p>\n<p>Ahora en virt-manager procedemos a crear y enlazar una máquina a una red aislada:</p>\n<pre><code>&lt;network connections=&quot;2&quot;&gt;\n  &lt;name&gt;red_muy_aislada&lt;/name&gt;\n  &lt;uuid&gt;b0083374-5cb6-4a8d-bd3c-32cf0d870b54&lt;/uuid&gt;\n  &lt;bridge name=&quot;virbr3&quot; stp=&quot;on&quot; delay=&quot;0&quot;/&gt;\n  &lt;mac address=&quot;52:54:00:e9:be:50&quot;/&gt;\n&lt;/network&gt;\n</code></pre>\n<p>debemos arrancarla por red como prioridad, luego de esto funcionará perfectamente nuestra instalación desatendida.</p>\n","site":{"data":{}},"length":3157,"excerpt":"","more":"<p>Vamos a crear la máquina virtual como hicimos anteriormente en <a href=\"https://entrebytes.neocities.org/2022/09/30/preseed/\">Instalación automatizada basada en medio de almacenamiento extraíble.</a></p>\n<p>En vagrant creamos una máquina que tenga una ip estática 192.168.100.3 que va a ser la tarjeta de red por la que funcionará pxe, en mi caso no creó esa ip y la tuve que escribir a mano en el /etc/network/interfaces, la otra tarjeta de red es la de vagrant-libvirt que será la que nos conecte al exterior.</p>\n<p>Para proceder a configurar el protocolo <strong>TFTP</strong> Y <strong>DHCP</strong> para que sea el host el que conceda ip a la máquina y establezca la conexión al preseed, utilizando dnsmasq</p>\n<p>apt install dnsmasq</p>\n<p>Establecemos en el fichero /etc/dnsmaq.conf con los siguientes parámetros:</p>\n<p><code>dhcp-range=192.168.100.100,192.168.100.200,255.255.255.0</code></p>\n<p>Establecemos el fichero con  el que va a bootear el dhcp:</p>\n<p><code>dhcp-boot=pxelinux.0</code></p>\n<p>Habilitamos el tftp:<br>\n <code>enable-tftp</code></p>\n<p>Establecemos una ruta donde va a albergar nuestro Debian:<br>\n <code>tftp-root=/srv/tftp</code></p>\n<p>Creamos la carpeta en /srv<br>\n <code>sudo mkdir /srv/tftp</code></p>\n<p>a continuación instalamos el wget y lo usamos en /srv/tftp</p>\n<p><code>wget http://ftp.debian.org/debian/dists/bullseye/main/installer-amd64/current/images/netboot/netboot.tar.gz </code></p>\n<p><code>tar -zxf netboot.tar.gz</code>  (para descomprimir los archivos)<br>\n <code>rm netboot.tar.gz</code></p>\n<p><code>srv/tftp/debian-installer/amd64/boot-screens/txt.cfg</code></p>\n<p>En este fichero de configuración utilizamos los siguientes parámetros:</p>\n<pre><code>label install\n        menu label ^Install\n        kernel debian-installer/amd64/linux\n        append vga=788 initrd=debian-installer/amd64/initrd.gz --- quiet\nlabel unattended-gnome\n        menu label ^Instalacion Debian Desatendida Preseed\n        kernel debian-installer/amd64/linux\n        append vga=788 initrd=debian-installer/amd64/initrd.gz hostname=preseed domain=preseed preseed/url=192.168.100.5/preseed.cfg locale=en_US.UTF-8 console-setup/charmap=UTF-8 console-setup/ask_detect=false keyboard-configuration/xkb-keymap=us --\n</code></pre>\n<p>En este label he puesto la url del servidor apache que vamos a utilizar, para que descargue el preseed y lo inyecte en la instalación.</p>\n<p>Instalamos apache2:<br>\n <code>sudo apt install apache2</code></p>\n<p>luego copiamos el preseed, lo ponemos en  <code>/var/www/html/</code>  junto al index.html, hacemos la página HTML que albergue el preseed y la ruta ya está establecida en el txt.cfg</p>\n<p>Una vez hecho esto, para que nuestra máquina que se conecta a la tarjeta de red estática que hemos creado, necesitamos establecer unas reglas de nftables que nos ayudará a conseguir que la máquina que conecte con el servidor pxe salga al exterior para descargar las dependencias.</p>\n<p>Para ello, debemos activar el bit de forwarding que se halla en  <code>/etc/sysctl.conf</code>  y descomentamos  <code>#net.ipv4.ip_forward=1</code></p>\n<p>Instalamos y habilitamos nftables(Todo esto siendo root):</p>\n<p><code>apt install nftables</code> <br>\n <code>systemctl start nftables.service</code> <br>\n <code>systemctl enable nftables.service</code> <br>\n <code>nft add table nat</code> <br>\n <code>nft list tables</code></p>\n<p>ahora realizamos las reglas de nftables para conseguir que esas máquinas tengan internet:<br>\n <code>nft add chain nat postrouting &#123; type nat hook postrouting priority 100 \\; &#125;</code> <br>\n <code>nft add rule ip nat postrouting oifname &quot;eth0&quot; ip saddr 192.168.100.0/24 counter masquerade</code></p>\n<p>Ahora guardamos los cambios:  <code>nft list ruleset &gt; /etc/nftables.conf</code></p>\n<p>Ahora en virt-manager procedemos a crear y enlazar una máquina a una red aislada:</p>\n<pre><code>&lt;network connections=&quot;2&quot;&gt;\n  &lt;name&gt;red_muy_aislada&lt;/name&gt;\n  &lt;uuid&gt;b0083374-5cb6-4a8d-bd3c-32cf0d870b54&lt;/uuid&gt;\n  &lt;bridge name=&quot;virbr3&quot; stp=&quot;on&quot; delay=&quot;0&quot;/&gt;\n  &lt;mac address=&quot;52:54:00:e9:be:50&quot;/&gt;\n&lt;/network&gt;\n</code></pre>\n<p>debemos arrancarla por red como prioridad, luego de esto funcionará perfectamente nuestra instalación desatendida.</p>\n"},{"title":"Configurar un servidor DNS.","_content":"\n![Descripción de la imagen](/images/obelix-4.jpg)\n\n\n## Servidor maestro\n\nPrimero comenzaremos actualizando el sistema e instalando el servidor dns bind9, la máquina deberá tener un nombre full qualificated como en mi caso que sería **dns1.antonio.org**\n\n`apt update && apt install bind9 -y`\n\nVamos a forzar la salida de las peutciones por ipv4, ya que al no estar configurado de esta forma pueden perderse paquetes al tratar de viajar a través de ipv6, esto lo haremos en /etc/default/named, especificando esta sentencia en  `OPTIONS=\"-4 -f -u bind\"`.\n\nPrimero debemos permitir el tráfico desde las diferentes ip en el fichero /etc/bind/named.conf.options.\n\n```\nallow-query {172.29.0.0/16; 172.22.0.0/16;};\nallow-transfer { none ;};\n```\n\nAllow-query se encargará de permitir las consultas a través de los distintos rangos de ip, yo al estar conectado a una vpn debo poner también ese rango para así poder realizar las consultas desde casa.\n\nAllow-transfer none hará que no se realicen transpasos completos en la información de la zona, esto nos permitirá que no podamos exponer información sensible dentro del servidor dns al realizar las consultas con dig.\n\nTras esto, comenzaremos editando el fichero de configuración de zonas, el cual se encargará de administrar las plantillas a las que se les va a realizar una consulta dns con dig.\n\n/etc/bind/named.conf.local\n\n```shell\ninclude \"/etc/bind/zones.rfc1918\";\nzone \"antonio.org\" {\n    type master;\n    file \"db.antonio.org\";\n    allow-transfer { 172.22.7.171; };\n    notify yes;\n};\n\nzone \"22.172.in-addr.arpa\" {\n    type master;\n    file \"db.172.22.0.0\";\n    allow-transfer { 172.22.7.171; };\n    notify yes;\n};\n\n```\n\nNuestra zona será antonio.org, el cual tendrá el fichero db.antonio.org, hasta ahí será necesario para ralizar solo un dns, para realizar el dns respaldado por un esclavo necesitaremos conceder el traspaso a la ip 172.22.7.171 que será la ip de la máquina esclava, más abajo nos econtraremos con el fichero de zona de resolución inversa, el cual tendrá el nombre del rango de ip que abarcará, y la misma transferencia de zona y el notify que será lo que avise al esclavo que ha habido un cambio en el maestro.\n\nSi nos vamos al fichero /var/cache/bind/db.antonio.org podemos ver los siguientes componentes:\n\n```shell\n$TTL    86400\n@       IN      SOA     dns1.antonio.org. root.antonio.org. (\n                              6         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                          86400 )       ; Negative Cache TTL\n;\n\n@       IN      NS              dns1.antonio.org.\n@       IN      NS              dns2.antonio.org.\n@       IN      MX      10      correo.antonio.org.\n\n\n$ORIGIN antonio.org.\n\ndns1                    IN      A       172.22.7.155\ndns2                    IN      A       172.22.7.171\ncorreo                  IN      A       172.22.200.101\nasterix                 IN      A       172.22.200.102\nobelix                  IN      A       172.22.200.103\nprueba                  IN      A       172.22.200.120\nwww                     IN      CNAME   asterix\n;informatica             IN      CNAME   asterix\nftp                     IN      CNAME   obelix\nentrebytes              IN      A       172.22.200.166\n\n$ORIGIN informatica.antonio.org.\n@       IN      NS    dns\ndns     IN      A     172.22.7.177\n\n```\n\nPues bien, deberemos cumplimentar de la siguiente forma el fichero, el cual tiene las siguientes definiciones:\nLa primera parte es el SOA, que es fdqn de la máquina maestra, acompañado del correo del administrador, el cual será con puntos.\n\nEn la segunda parte podemos ver los nameservers, el cual tendrá el @, esto mostrará las máquinas a disposición del fdqn que hemos elegido, en nuestro caso tendremos el de la máquina maestra, la del esclavo y la del correo.\n\nOrigin es la variable que va a tener antonio.org. para no tener que repetir continuamente el nombre del dominio en los registros.\n\nLos registros de tipo A tendrán una ip asociada, estos se encargan de darle nombre a la ip de dentro del dominio, como dns1 que tiene una 172.22.7.155 o la del esclavo, que tendrá la 172.22.7.171\n\nLos registros de tipo CNAME son nombres relacionados a otros nombres, como por ejemplo ftp, que va relacionado al nombre obelix y que tendrá la ip 172.22.200.103. entonces al realizar la consulta en el apartado ANSWER nos daría el nombre completo al que está asociado.\n\n![Descripción de la imagen](/images/obelix.png)\n\n\nAhora vamos con el fichero de zona de resolución inversa, el cual crearemos en /var/cache/bind/db.172.22.0.0\n\n```shell\n$TTL    86400\n@       IN      SOA     dns1.antonio.org. root.antonio.org. (\n                              1         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                          86400 )       ; Negative Cache TTL\n;\n@      IN      NS              dns1.antonio.org.\n@      IN      NS              dns2.antonio.org.\n\n$ORIGIN 22.172.in-addr.arpa.\n\n155.7                  IN      PTR             dns1.antonio.org.\n171.7                  IN      PTR             dns2.antonio.org.\n101.200                IN      PTR             correo.antonio.org.\n102.200                IN      PTR             asterix.antonio.org.\n200.103                IN      PTR             obelix.antonio.org.\n200.166                IN      PTR             entrebytes.antonio.org.\n\n```\n\nEl fichero es muy similar al de la resolución directa, pero en este caso especificaremos la IP de la manera opuesta, con PTR conseguiremos obtener el nombre gracias a una petición inversa a la ip que hemos configurado, también pondremos la del servidor esclavo.\n\n![Descripción de la imagen](/images/obelix-2.png)\n\nPor último, debemos editar el fichero /etc/bind/zones.rfc1918 que se encarga de proporcionar la plantilla empty para las resoluciones no configuradas, de manera que debamos comentar el rango de ips de `//zone \"22.172.in-addr.arpa\"  { type master; file \"/etc/bind/db.empty\"; };` ya que nosotros hemos configurado anteriormente.\n\nahora solo nos queda realizar un `systemctl restart bind9` y `systemctl status bind9` para comprobar de que el servicio está activo y sin errores.\n\n## Servidor esclavo\n\nPrimero comenzaremos actualizando el sistema e instalando el servidor dns bind9, la máquina deberá tener un nombre full qualificated como en mi caso que sería **dns2.antonio.org**\n\n`apt update && apt install bind9 -y`\n\nVamos a forzar la salida de las peutciones por ipv4, ya que al no estar configurado de esta forma pueden perderse paquetes al tratar de viajar a través de ipv6, esto lo haremos en /etc/default/named, especificando esta sentencia en  `OPTIONS=\"-4 -f -u bind\"`.\n\n/etc/bind/named.conf.local\n\n```shell\ninclude \"/etc/bind/zones.rfc1918\";\nzone \"antonio.org\" {\n    type slave;\n    file \"db.antonio.org\";\n    masters { 172.22.7.155; };\n};\nzone \"22.172.in-addr.arpa\" {\n    type slave;\n    file \"db.172.22.0.0\";\n    masters { 172.22.7.155; };\n};\n```\n\nHacemos un `systemctl restart bind9` y `systemctl status bind9` para comprobar de que el servicio está activo y sin errores.\n\nTras esto, cuando modifiquemos el servidor maestro subimos el serial de tal forma que sea mayor al de la máquina esclava, y de esta manera realizará la transferencia.\n\n![Descripción de la imagen](/images/obelix-3.png)\n\n## Delegación de subdominio\n\nPra delegar un subdominio primero comenzaremos actualizando el sistema e instalando el servidor dns bind9, la máquina deberá tener un nombre full qualificated como en mi caso que sería **dns.informatica.antonio.org**\n\n`apt update && apt install bind9 -y`\n\nVamos a forzar la salida de las peutciones por ipv4, ya que al no estar configurado de esta forma pueden perderse paquetes al tratar de viajar a través de ipv6, esto lo haremos en /etc/default/named, especificando esta sentencia en  `OPTIONS=\"-4 -f -u bind\"`.\n\nUna vez hecho esto, como podemos ver en la máquina maestra, tenemos un apartado en db.antonio.org en el cual especificamos los siguientes parámetros:\n\n```shell\n$ORIGIN informatica.antonio.org.\n@       IN      NS    dns\ndns     IN      A     172.22.7.177\n```\n\nCon esto estaremos delegando el subdominio para que lo gestione dns.informatica.antonio.org, si nos vamos a esta máquina, debemos configurar el dominio de la siguiente forma:\n\n/etc/bind/named.conf.local\n```\nzone \"informatica.antonio.org\" {\n    type master;\n    file \"db.informatica.antonio.org\";\n};\n```\n\nLuego nos vamos a /var/cache/bind/db.informatica.antonio.org\n\n```shell\n$TTL    86400\n@       IN      SOA     dns.informatica.antonio.org. root.informatica.antonio.org. (\n                              1         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                          86400 )       ; Negative Cache TTL\n;\n@       IN      NS              dns.informatica.antonio.org.\n@       IN      MX      10      mail.informatica.antonio.org.\n\n$ORIGIN informatica.antonio.org.\n\ndns                     IN      A               172.22.7.177\nmail                    IN      A               172.22.7.177\nweb                     IN      A               172.22.7.177\nwww                     IN      CNAME           web\nentrebytes              IN      CNAME           web\n\n```\n\n\n## Tips\n\nSi realizamos cambios a veces no se verán reflejados ya que el servicio DNS la almacena en caché, para borrarla necesitaremos ejecutar `rndc flush` en la máquina maestra.\n\nPara poder realizar las consultas sin especificar la ip a través de @, necesitaremos agregar un nameserver XXX.XXX.XXX.XXX en /etc/resolv.conf\n\nEn el caso de dns.informatica.antonio.org no es necesario descomentar el include \"/etc/bind/zones.rfc1918\"; ya que se ocupará de gestionarlo la máquina maestra.\n\nPara detectar con información más detallada los errores de plantillas db, necesitaremos ejecutar `named-checkzone antonio.org /var/cache/bind/db.antonio.org`\n\nSi queremos detectar los errores del fichero de zonas, necesitaremos ejecutar `named-checkconf`\n\n","source":"_posts/dns.md","raw":"---\ntitle: Configurar un servidor DNS.\ncategories: Servicios de Red e Internet\ntags: Servicios de Red e Internet\n---\n\n![Descripción de la imagen](/images/obelix-4.jpg)\n\n\n## Servidor maestro\n\nPrimero comenzaremos actualizando el sistema e instalando el servidor dns bind9, la máquina deberá tener un nombre full qualificated como en mi caso que sería **dns1.antonio.org**\n\n`apt update && apt install bind9 -y`\n\nVamos a forzar la salida de las peutciones por ipv4, ya que al no estar configurado de esta forma pueden perderse paquetes al tratar de viajar a través de ipv6, esto lo haremos en /etc/default/named, especificando esta sentencia en  `OPTIONS=\"-4 -f -u bind\"`.\n\nPrimero debemos permitir el tráfico desde las diferentes ip en el fichero /etc/bind/named.conf.options.\n\n```\nallow-query {172.29.0.0/16; 172.22.0.0/16;};\nallow-transfer { none ;};\n```\n\nAllow-query se encargará de permitir las consultas a través de los distintos rangos de ip, yo al estar conectado a una vpn debo poner también ese rango para así poder realizar las consultas desde casa.\n\nAllow-transfer none hará que no se realicen transpasos completos en la información de la zona, esto nos permitirá que no podamos exponer información sensible dentro del servidor dns al realizar las consultas con dig.\n\nTras esto, comenzaremos editando el fichero de configuración de zonas, el cual se encargará de administrar las plantillas a las que se les va a realizar una consulta dns con dig.\n\n/etc/bind/named.conf.local\n\n```shell\ninclude \"/etc/bind/zones.rfc1918\";\nzone \"antonio.org\" {\n    type master;\n    file \"db.antonio.org\";\n    allow-transfer { 172.22.7.171; };\n    notify yes;\n};\n\nzone \"22.172.in-addr.arpa\" {\n    type master;\n    file \"db.172.22.0.0\";\n    allow-transfer { 172.22.7.171; };\n    notify yes;\n};\n\n```\n\nNuestra zona será antonio.org, el cual tendrá el fichero db.antonio.org, hasta ahí será necesario para ralizar solo un dns, para realizar el dns respaldado por un esclavo necesitaremos conceder el traspaso a la ip 172.22.7.171 que será la ip de la máquina esclava, más abajo nos econtraremos con el fichero de zona de resolución inversa, el cual tendrá el nombre del rango de ip que abarcará, y la misma transferencia de zona y el notify que será lo que avise al esclavo que ha habido un cambio en el maestro.\n\nSi nos vamos al fichero /var/cache/bind/db.antonio.org podemos ver los siguientes componentes:\n\n```shell\n$TTL    86400\n@       IN      SOA     dns1.antonio.org. root.antonio.org. (\n                              6         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                          86400 )       ; Negative Cache TTL\n;\n\n@       IN      NS              dns1.antonio.org.\n@       IN      NS              dns2.antonio.org.\n@       IN      MX      10      correo.antonio.org.\n\n\n$ORIGIN antonio.org.\n\ndns1                    IN      A       172.22.7.155\ndns2                    IN      A       172.22.7.171\ncorreo                  IN      A       172.22.200.101\nasterix                 IN      A       172.22.200.102\nobelix                  IN      A       172.22.200.103\nprueba                  IN      A       172.22.200.120\nwww                     IN      CNAME   asterix\n;informatica             IN      CNAME   asterix\nftp                     IN      CNAME   obelix\nentrebytes              IN      A       172.22.200.166\n\n$ORIGIN informatica.antonio.org.\n@       IN      NS    dns\ndns     IN      A     172.22.7.177\n\n```\n\nPues bien, deberemos cumplimentar de la siguiente forma el fichero, el cual tiene las siguientes definiciones:\nLa primera parte es el SOA, que es fdqn de la máquina maestra, acompañado del correo del administrador, el cual será con puntos.\n\nEn la segunda parte podemos ver los nameservers, el cual tendrá el @, esto mostrará las máquinas a disposición del fdqn que hemos elegido, en nuestro caso tendremos el de la máquina maestra, la del esclavo y la del correo.\n\nOrigin es la variable que va a tener antonio.org. para no tener que repetir continuamente el nombre del dominio en los registros.\n\nLos registros de tipo A tendrán una ip asociada, estos se encargan de darle nombre a la ip de dentro del dominio, como dns1 que tiene una 172.22.7.155 o la del esclavo, que tendrá la 172.22.7.171\n\nLos registros de tipo CNAME son nombres relacionados a otros nombres, como por ejemplo ftp, que va relacionado al nombre obelix y que tendrá la ip 172.22.200.103. entonces al realizar la consulta en el apartado ANSWER nos daría el nombre completo al que está asociado.\n\n![Descripción de la imagen](/images/obelix.png)\n\n\nAhora vamos con el fichero de zona de resolución inversa, el cual crearemos en /var/cache/bind/db.172.22.0.0\n\n```shell\n$TTL    86400\n@       IN      SOA     dns1.antonio.org. root.antonio.org. (\n                              1         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                          86400 )       ; Negative Cache TTL\n;\n@      IN      NS              dns1.antonio.org.\n@      IN      NS              dns2.antonio.org.\n\n$ORIGIN 22.172.in-addr.arpa.\n\n155.7                  IN      PTR             dns1.antonio.org.\n171.7                  IN      PTR             dns2.antonio.org.\n101.200                IN      PTR             correo.antonio.org.\n102.200                IN      PTR             asterix.antonio.org.\n200.103                IN      PTR             obelix.antonio.org.\n200.166                IN      PTR             entrebytes.antonio.org.\n\n```\n\nEl fichero es muy similar al de la resolución directa, pero en este caso especificaremos la IP de la manera opuesta, con PTR conseguiremos obtener el nombre gracias a una petición inversa a la ip que hemos configurado, también pondremos la del servidor esclavo.\n\n![Descripción de la imagen](/images/obelix-2.png)\n\nPor último, debemos editar el fichero /etc/bind/zones.rfc1918 que se encarga de proporcionar la plantilla empty para las resoluciones no configuradas, de manera que debamos comentar el rango de ips de `//zone \"22.172.in-addr.arpa\"  { type master; file \"/etc/bind/db.empty\"; };` ya que nosotros hemos configurado anteriormente.\n\nahora solo nos queda realizar un `systemctl restart bind9` y `systemctl status bind9` para comprobar de que el servicio está activo y sin errores.\n\n## Servidor esclavo\n\nPrimero comenzaremos actualizando el sistema e instalando el servidor dns bind9, la máquina deberá tener un nombre full qualificated como en mi caso que sería **dns2.antonio.org**\n\n`apt update && apt install bind9 -y`\n\nVamos a forzar la salida de las peutciones por ipv4, ya que al no estar configurado de esta forma pueden perderse paquetes al tratar de viajar a través de ipv6, esto lo haremos en /etc/default/named, especificando esta sentencia en  `OPTIONS=\"-4 -f -u bind\"`.\n\n/etc/bind/named.conf.local\n\n```shell\ninclude \"/etc/bind/zones.rfc1918\";\nzone \"antonio.org\" {\n    type slave;\n    file \"db.antonio.org\";\n    masters { 172.22.7.155; };\n};\nzone \"22.172.in-addr.arpa\" {\n    type slave;\n    file \"db.172.22.0.0\";\n    masters { 172.22.7.155; };\n};\n```\n\nHacemos un `systemctl restart bind9` y `systemctl status bind9` para comprobar de que el servicio está activo y sin errores.\n\nTras esto, cuando modifiquemos el servidor maestro subimos el serial de tal forma que sea mayor al de la máquina esclava, y de esta manera realizará la transferencia.\n\n![Descripción de la imagen](/images/obelix-3.png)\n\n## Delegación de subdominio\n\nPra delegar un subdominio primero comenzaremos actualizando el sistema e instalando el servidor dns bind9, la máquina deberá tener un nombre full qualificated como en mi caso que sería **dns.informatica.antonio.org**\n\n`apt update && apt install bind9 -y`\n\nVamos a forzar la salida de las peutciones por ipv4, ya que al no estar configurado de esta forma pueden perderse paquetes al tratar de viajar a través de ipv6, esto lo haremos en /etc/default/named, especificando esta sentencia en  `OPTIONS=\"-4 -f -u bind\"`.\n\nUna vez hecho esto, como podemos ver en la máquina maestra, tenemos un apartado en db.antonio.org en el cual especificamos los siguientes parámetros:\n\n```shell\n$ORIGIN informatica.antonio.org.\n@       IN      NS    dns\ndns     IN      A     172.22.7.177\n```\n\nCon esto estaremos delegando el subdominio para que lo gestione dns.informatica.antonio.org, si nos vamos a esta máquina, debemos configurar el dominio de la siguiente forma:\n\n/etc/bind/named.conf.local\n```\nzone \"informatica.antonio.org\" {\n    type master;\n    file \"db.informatica.antonio.org\";\n};\n```\n\nLuego nos vamos a /var/cache/bind/db.informatica.antonio.org\n\n```shell\n$TTL    86400\n@       IN      SOA     dns.informatica.antonio.org. root.informatica.antonio.org. (\n                              1         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                          86400 )       ; Negative Cache TTL\n;\n@       IN      NS              dns.informatica.antonio.org.\n@       IN      MX      10      mail.informatica.antonio.org.\n\n$ORIGIN informatica.antonio.org.\n\ndns                     IN      A               172.22.7.177\nmail                    IN      A               172.22.7.177\nweb                     IN      A               172.22.7.177\nwww                     IN      CNAME           web\nentrebytes              IN      CNAME           web\n\n```\n\n\n## Tips\n\nSi realizamos cambios a veces no se verán reflejados ya que el servicio DNS la almacena en caché, para borrarla necesitaremos ejecutar `rndc flush` en la máquina maestra.\n\nPara poder realizar las consultas sin especificar la ip a través de @, necesitaremos agregar un nameserver XXX.XXX.XXX.XXX en /etc/resolv.conf\n\nEn el caso de dns.informatica.antonio.org no es necesario descomentar el include \"/etc/bind/zones.rfc1918\"; ya que se ocupará de gestionarlo la máquina maestra.\n\nPara detectar con información más detallada los errores de plantillas db, necesitaremos ejecutar `named-checkzone antonio.org /var/cache/bind/db.antonio.org`\n\nSi queremos detectar los errores del fichero de zonas, necesitaremos ejecutar `named-checkconf`\n\n","slug":"dns","published":1,"date":"2022-12-13T21:49:01.673Z","updated":"2023-01-10T00:38:12.677Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cldl9ucgm000e0yi54atb1sxm","content":"<p><img src=\"/images/obelix-4.jpg\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"servidor-maestro\"><a class=\"markdownIt-Anchor\" href=\"#servidor-maestro\">#</a> Servidor maestro</h2>\n<p>Primero comenzaremos actualizando el sistema e instalando el servidor dns bind9, la máquina deberá tener un nombre full qualificated como en mi caso que sería <strong><a href=\"http://dns1.antonio.org\">dns1.antonio.org</a></strong></p>\n<p><code>apt update &amp;&amp; apt install bind9 -y</code></p>\n<p>Vamos a forzar la salida de las peutciones por ipv4, ya que al no estar configurado de esta forma pueden perderse paquetes al tratar de viajar a través de ipv6, esto lo haremos en /etc/default/named, especificando esta sentencia en   <code>OPTIONS=&quot;-4 -f -u bind&quot;</code> .</p>\n<p>Primero debemos permitir el tráfico desde las diferentes ip en el fichero /etc/bind/named.conf.options.</p>\n<pre><code>allow-query &#123;172.29.0.0/16; 172.22.0.0/16;&#125;;\nallow-transfer &#123; none ;&#125;;\n</code></pre>\n<p>Allow-query se encargará de permitir las consultas a través de los distintos rangos de ip, yo al estar conectado a una vpn debo poner también ese rango para así poder realizar las consultas desde casa.</p>\n<p>Allow-transfer none hará que no se realicen transpasos completos en la información de la zona, esto nos permitirá que no podamos exponer información sensible dentro del servidor dns al realizar las consultas con dig.</p>\n<p>Tras esto, comenzaremos editando el fichero de configuración de zonas, el cual se encargará de administrar las plantillas a las que se les va a realizar una consulta dns con dig.</p>\n<p>/etc/bind/named.conf.local</p>\n<figure class=\"highlight shell\"><figcaption data-lang=\"Bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>include <span class=\"token string\">\"/etc/bind/zones.rfc1918\"</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>zone <span class=\"token string\">\"antonio.org\"</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token builtin class-name\">type</span> master<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token function\">file</span> <span class=\"token string\">\"db.antonio.org\"</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    allow-transfer <span class=\"token punctuation\">&#123;</span> <span class=\"token number\">172.22</span>.7.171<span class=\"token punctuation\">;</span> <span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    notify <span class=\"token function\">yes</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>zone <span class=\"token string\">\"22.172.in-addr.arpa\"</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    <span class=\"token builtin class-name\">type</span> master<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    <span class=\"token function\">file</span> <span class=\"token string\">\"db.172.22.0.0\"</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    allow-transfer <span class=\"token punctuation\">&#123;</span> <span class=\"token number\">172.22</span>.7.171<span class=\"token punctuation\">;</span> <span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>    notify <span class=\"token function\">yes</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>Nuestra zona será <a href=\"http://antonio.org\">antonio.org</a>, el cual tendrá el fichero <a href=\"http://db.antonio.org\">db.antonio.org</a>, hasta ahí será necesario para ralizar solo un dns, para realizar el dns respaldado por un esclavo necesitaremos conceder el traspaso a la ip 172.22.7.171 que será la ip de la máquina esclava, más abajo nos econtraremos con el fichero de zona de resolución inversa, el cual tendrá el nombre del rango de ip que abarcará, y la misma transferencia de zona y el notify que será lo que avise al esclavo que ha habido un cambio en el maestro.</p>\n<p>Si nos vamos al fichero /var/cache/bind/db.antonio.org podemos ver los siguientes componentes:</p>\n<figure class=\"highlight shell\"><figcaption data-lang=\"Bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token variable\">$TTL</span>    <span class=\"token number\">86400</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>@       IN      SOA     dns1.antonio.org. root.antonio.org. <span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>                              <span class=\"token number\">6</span>         <span class=\"token punctuation\">;</span> Serial</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>                         <span class=\"token number\">604800</span>         <span class=\"token punctuation\">;</span> Refresh</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>                          <span class=\"token number\">86400</span>         <span class=\"token punctuation\">;</span> Retry</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>                        <span class=\"token number\">2419200</span>         <span class=\"token punctuation\">;</span> Expire</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>                          <span class=\"token number\">86400</span> <span class=\"token punctuation\">)</span>       <span class=\"token punctuation\">;</span> Negative Cache TTL</pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>@       IN      NS              dns1.antonio.org.</pre></td></tr><tr><td data-num=\"11\"></td><td><pre>@       IN      NS              dns2.antonio.org.</pre></td></tr><tr><td data-num=\"12\"></td><td><pre>@       IN      MX      <span class=\"token number\">10</span>      correo.antonio.org.</pre></td></tr><tr><td data-num=\"13\"></td><td><pre></pre></td></tr><tr><td data-num=\"14\"></td><td><pre></pre></td></tr><tr><td data-num=\"15\"></td><td><pre><span class=\"token variable\">$ORIGIN</span> antonio.org.</pre></td></tr><tr><td data-num=\"16\"></td><td><pre></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>dns1                    IN      A       <span class=\"token number\">172.22</span>.7.155</pre></td></tr><tr><td data-num=\"18\"></td><td><pre>dns2                    IN      A       <span class=\"token number\">172.22</span>.7.171</pre></td></tr><tr><td data-num=\"19\"></td><td><pre>correo                  IN      A       <span class=\"token number\">172.22</span>.200.101</pre></td></tr><tr><td data-num=\"20\"></td><td><pre>asterix                 IN      A       <span class=\"token number\">172.22</span>.200.102</pre></td></tr><tr><td data-num=\"21\"></td><td><pre>obelix                  IN      A       <span class=\"token number\">172.22</span>.200.103</pre></td></tr><tr><td data-num=\"22\"></td><td><pre>prueba                  IN      A       <span class=\"token number\">172.22</span>.200.120</pre></td></tr><tr><td data-num=\"23\"></td><td><pre>www                     IN      CNAME   asterix</pre></td></tr><tr><td data-num=\"24\"></td><td><pre><span class=\"token punctuation\">;</span>informatica             IN      CNAME   asterix</pre></td></tr><tr><td data-num=\"25\"></td><td><pre><span class=\"token function\">ftp</span>                     IN      CNAME   obelix</pre></td></tr><tr><td data-num=\"26\"></td><td><pre>entrebytes              IN      A       <span class=\"token number\">172.22</span>.200.166</pre></td></tr><tr><td data-num=\"27\"></td><td><pre></pre></td></tr><tr><td data-num=\"28\"></td><td><pre><span class=\"token variable\">$ORIGIN</span> informatica.antonio.org.</pre></td></tr><tr><td data-num=\"29\"></td><td><pre>@       IN      NS    dns</pre></td></tr><tr><td data-num=\"30\"></td><td><pre>dns     IN      A     <span class=\"token number\">172.22</span>.7.177</pre></td></tr></table></figure><p>Pues bien, deberemos cumplimentar de la siguiente forma el fichero, el cual tiene las siguientes definiciones:<br>\nLa primera parte es el SOA, que es fdqn de la máquina maestra, acompañado del correo del administrador, el cual será con puntos.</p>\n<p>En la segunda parte podemos ver los nameservers, el cual tendrá el @, esto mostrará las máquinas a disposición del fdqn que hemos elegido, en nuestro caso tendremos el de la máquina maestra, la del esclavo y la del correo.</p>\n<p>Origin es la variable que va a tener <a href=\"http://antonio.org\">antonio.org</a>. para no tener que repetir continuamente el nombre del dominio en los registros.</p>\n<p>Los registros de tipo A tendrán una ip asociada, estos se encargan de darle nombre a la ip de dentro del dominio, como dns1 que tiene una 172.22.7.155 o la del esclavo, que tendrá la 172.22.7.171</p>\n<p>Los registros de tipo CNAME son nombres relacionados a otros nombres, como por ejemplo ftp, que va relacionado al nombre obelix y que tendrá la ip 172.22.200.103. entonces al realizar la consulta en el apartado ANSWER nos daría el nombre completo al que está asociado.</p>\n<p><img src=\"/images/obelix.png\" alt=\"Descripción de la imagen\"></p>\n<p>Ahora vamos con el fichero de zona de resolución inversa, el cual crearemos en /var/cache/bind/db.172.22.0.0</p>\n<figure class=\"highlight shell\"><figcaption data-lang=\"Bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token variable\">$TTL</span>    <span class=\"token number\">86400</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>@       IN      SOA     dns1.antonio.org. root.antonio.org. <span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>                              <span class=\"token number\">1</span>         <span class=\"token punctuation\">;</span> Serial</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>                         <span class=\"token number\">604800</span>         <span class=\"token punctuation\">;</span> Refresh</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>                          <span class=\"token number\">86400</span>         <span class=\"token punctuation\">;</span> Retry</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>                        <span class=\"token number\">2419200</span>         <span class=\"token punctuation\">;</span> Expire</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>                          <span class=\"token number\">86400</span> <span class=\"token punctuation\">)</span>       <span class=\"token punctuation\">;</span> Negative Cache TTL</pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>@      IN      NS              dns1.antonio.org.</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>@      IN      NS              dns2.antonio.org.</pre></td></tr><tr><td data-num=\"11\"></td><td><pre></pre></td></tr><tr><td data-num=\"12\"></td><td><pre><span class=\"token variable\">$ORIGIN</span> <span class=\"token number\">22.172</span>.in-addr.arpa.</pre></td></tr><tr><td data-num=\"13\"></td><td><pre></pre></td></tr><tr><td data-num=\"14\"></td><td><pre><span class=\"token number\">155.7</span>                  IN      PTR             dns1.antonio.org.</pre></td></tr><tr><td data-num=\"15\"></td><td><pre><span class=\"token number\">171.7</span>                  IN      PTR             dns2.antonio.org.</pre></td></tr><tr><td data-num=\"16\"></td><td><pre><span class=\"token number\">101.200</span>                IN      PTR             correo.antonio.org.</pre></td></tr><tr><td data-num=\"17\"></td><td><pre><span class=\"token number\">102.200</span>                IN      PTR             asterix.antonio.org.</pre></td></tr><tr><td data-num=\"18\"></td><td><pre><span class=\"token number\">200.103</span>                IN      PTR             obelix.antonio.org.</pre></td></tr><tr><td data-num=\"19\"></td><td><pre><span class=\"token number\">200.166</span>                IN      PTR             entrebytes.antonio.org.</pre></td></tr></table></figure><p>El fichero es muy similar al de la resolución directa, pero en este caso especificaremos la IP de la manera opuesta, con PTR conseguiremos obtener el nombre gracias a una petición inversa a la ip que hemos configurado, también pondremos la del servidor esclavo.</p>\n<p><img src=\"/images/obelix-2.png\" alt=\"Descripción de la imagen\"></p>\n<p>Por último, debemos editar el fichero /etc/bind/zones.rfc1918 que se encarga de proporcionar la plantilla empty para las resoluciones no configuradas, de manera que debamos comentar el rango de ips de  <code>//zone &quot;22.172.in-addr.arpa&quot;  &#123; type master; file &quot;/etc/bind/db.empty&quot;; &#125;;</code>  ya que nosotros hemos configurado anteriormente.</p>\n<p>ahora solo nos queda realizar un  <code>systemctl restart bind9</code>  y  <code>systemctl status bind9</code>  para comprobar de que el servicio está activo y sin errores.</p>\n<h2 id=\"servidor-esclavo\"><a class=\"markdownIt-Anchor\" href=\"#servidor-esclavo\">#</a> Servidor esclavo</h2>\n<p>Primero comenzaremos actualizando el sistema e instalando el servidor dns bind9, la máquina deberá tener un nombre full qualificated como en mi caso que sería <strong><a href=\"http://dns2.antonio.org\">dns2.antonio.org</a></strong></p>\n<p><code>apt update &amp;&amp; apt install bind9 -y</code></p>\n<p>Vamos a forzar la salida de las peutciones por ipv4, ya que al no estar configurado de esta forma pueden perderse paquetes al tratar de viajar a través de ipv6, esto lo haremos en /etc/default/named, especificando esta sentencia en   <code>OPTIONS=&quot;-4 -f -u bind&quot;</code> .</p>\n<p>/etc/bind/named.conf.local</p>\n<figure class=\"highlight shell\"><figcaption data-lang=\"Bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>include <span class=\"token string\">\"/etc/bind/zones.rfc1918\"</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>zone <span class=\"token string\">\"antonio.org\"</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token builtin class-name\">type</span> slave<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token function\">file</span> <span class=\"token string\">\"db.antonio.org\"</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    masters <span class=\"token punctuation\">&#123;</span> <span class=\"token number\">172.22</span>.7.155<span class=\"token punctuation\">;</span> <span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>zone <span class=\"token string\">\"22.172.in-addr.arpa\"</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    <span class=\"token builtin class-name\">type</span> slave<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    <span class=\"token function\">file</span> <span class=\"token string\">\"db.172.22.0.0\"</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    masters <span class=\"token punctuation\">&#123;</span> <span class=\"token number\">172.22</span>.7.155<span class=\"token punctuation\">;</span> <span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>Hacemos un  <code>systemctl restart bind9</code>  y  <code>systemctl status bind9</code>  para comprobar de que el servicio está activo y sin errores.</p>\n<p>Tras esto, cuando modifiquemos el servidor maestro subimos el serial de tal forma que sea mayor al de la máquina esclava, y de esta manera realizará la transferencia.</p>\n<p><img src=\"/images/obelix-3.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"delegación-de-subdominio\"><a class=\"markdownIt-Anchor\" href=\"#delegación-de-subdominio\">#</a> Delegación de subdominio</h2>\n<p>Pra delegar un subdominio primero comenzaremos actualizando el sistema e instalando el servidor dns bind9, la máquina deberá tener un nombre full qualificated como en mi caso que sería <strong><a href=\"http://dns.informatica.antonio.org\">dns.informatica.antonio.org</a></strong></p>\n<p><code>apt update &amp;&amp; apt install bind9 -y</code></p>\n<p>Vamos a forzar la salida de las peutciones por ipv4, ya que al no estar configurado de esta forma pueden perderse paquetes al tratar de viajar a través de ipv6, esto lo haremos en /etc/default/named, especificando esta sentencia en   <code>OPTIONS=&quot;-4 -f -u bind&quot;</code> .</p>\n<p>Una vez hecho esto, como podemos ver en la máquina maestra, tenemos un apartado en <a href=\"http://db.antonio.org\">db.antonio.org</a> en el cual especificamos los siguientes parámetros:</p>\n<figure class=\"highlight shell\"><figcaption data-lang=\"Bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token variable\">$ORIGIN</span> informatica.antonio.org.</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>@       IN      NS    dns</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>dns     IN      A     <span class=\"token number\">172.22</span>.7.177</pre></td></tr></table></figure><p>Con esto estaremos delegando el subdominio para que lo gestione <a href=\"http://dns.informatica.antonio.org\">dns.informatica.antonio.org</a>, si nos vamos a esta máquina, debemos configurar el dominio de la siguiente forma:</p>\n<p>/etc/bind/named.conf.local</p>\n<pre><code>zone &quot;informatica.antonio.org&quot; &#123;\n    type master;\n    file &quot;db.informatica.antonio.org&quot;;\n&#125;;\n</code></pre>\n<p>Luego nos vamos a /var/cache/bind/db.informatica.antonio.org</p>\n<figure class=\"highlight shell\"><figcaption data-lang=\"Bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token variable\">$TTL</span>    <span class=\"token number\">86400</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>@       IN      SOA     dns.informatica.antonio.org. root.informatica.antonio.org. <span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>                              <span class=\"token number\">1</span>         <span class=\"token punctuation\">;</span> Serial</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>                         <span class=\"token number\">604800</span>         <span class=\"token punctuation\">;</span> Refresh</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>                          <span class=\"token number\">86400</span>         <span class=\"token punctuation\">;</span> Retry</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>                        <span class=\"token number\">2419200</span>         <span class=\"token punctuation\">;</span> Expire</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>                          <span class=\"token number\">86400</span> <span class=\"token punctuation\">)</span>       <span class=\"token punctuation\">;</span> Negative Cache TTL</pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>@       IN      NS              dns.informatica.antonio.org.</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>@       IN      MX      <span class=\"token number\">10</span>      mail.informatica.antonio.org.</pre></td></tr><tr><td data-num=\"11\"></td><td><pre></pre></td></tr><tr><td data-num=\"12\"></td><td><pre><span class=\"token variable\">$ORIGIN</span> informatica.antonio.org.</pre></td></tr><tr><td data-num=\"13\"></td><td><pre></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>dns                     IN      A               <span class=\"token number\">172.22</span>.7.177</pre></td></tr><tr><td data-num=\"15\"></td><td><pre>mail                    IN      A               <span class=\"token number\">172.22</span>.7.177</pre></td></tr><tr><td data-num=\"16\"></td><td><pre>web                     IN      A               <span class=\"token number\">172.22</span>.7.177</pre></td></tr><tr><td data-num=\"17\"></td><td><pre>www                     IN      CNAME           web</pre></td></tr><tr><td data-num=\"18\"></td><td><pre>entrebytes              IN      CNAME           web</pre></td></tr></table></figure><h2 id=\"tips\"><a class=\"markdownIt-Anchor\" href=\"#tips\">#</a> Tips</h2>\n<p>Si realizamos cambios a veces no se verán reflejados ya que el servicio DNS la almacena en caché, para borrarla necesitaremos ejecutar  <code>rndc flush</code>  en la máquina maestra.</p>\n<p>Para poder realizar las consultas sin especificar la ip a través de @, necesitaremos agregar un nameserver <a href=\"http://XXX.XXX.XXX.XXX\">XXX.XXX.XXX.XXX</a> en /etc/resolv.conf</p>\n<p>En el caso de <a href=\"http://dns.informatica.antonio.org\">dns.informatica.antonio.org</a> no es necesario descomentar el include “/etc/bind/zones.rfc1918”; ya que se ocupará de gestionarlo la máquina maestra.</p>\n<p>Para detectar con información más detallada los errores de plantillas db, necesitaremos ejecutar  <code>named-checkzone antonio.org /var/cache/bind/db.antonio.org</code></p>\n<p>Si queremos detectar los errores del fichero de zonas, necesitaremos ejecutar  <code>named-checkconf</code></p>\n","site":{"data":{}},"length":7240,"excerpt":"","more":"<p><img src=\"/images/obelix-4.jpg\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"servidor-maestro\"><a class=\"markdownIt-Anchor\" href=\"#servidor-maestro\">#</a> Servidor maestro</h2>\n<p>Primero comenzaremos actualizando el sistema e instalando el servidor dns bind9, la máquina deberá tener un nombre full qualificated como en mi caso que sería <strong><a href=\"http://dns1.antonio.org\">dns1.antonio.org</a></strong></p>\n<p><code>apt update &amp;&amp; apt install bind9 -y</code></p>\n<p>Vamos a forzar la salida de las peutciones por ipv4, ya que al no estar configurado de esta forma pueden perderse paquetes al tratar de viajar a través de ipv6, esto lo haremos en /etc/default/named, especificando esta sentencia en   <code>OPTIONS=&quot;-4 -f -u bind&quot;</code> .</p>\n<p>Primero debemos permitir el tráfico desde las diferentes ip en el fichero /etc/bind/named.conf.options.</p>\n<pre><code>allow-query &#123;172.29.0.0/16; 172.22.0.0/16;&#125;;\nallow-transfer &#123; none ;&#125;;\n</code></pre>\n<p>Allow-query se encargará de permitir las consultas a través de los distintos rangos de ip, yo al estar conectado a una vpn debo poner también ese rango para así poder realizar las consultas desde casa.</p>\n<p>Allow-transfer none hará que no se realicen transpasos completos en la información de la zona, esto nos permitirá que no podamos exponer información sensible dentro del servidor dns al realizar las consultas con dig.</p>\n<p>Tras esto, comenzaremos editando el fichero de configuración de zonas, el cual se encargará de administrar las plantillas a las que se les va a realizar una consulta dns con dig.</p>\n<p>/etc/bind/named.conf.local</p>\n<figure class=\"highlight shell\"><figcaption data-lang=\"Bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>include <span class=\"token string\">\"/etc/bind/zones.rfc1918\"</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>zone <span class=\"token string\">\"antonio.org\"</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token builtin class-name\">type</span> master<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token function\">file</span> <span class=\"token string\">\"db.antonio.org\"</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    allow-transfer <span class=\"token punctuation\">&#123;</span> <span class=\"token number\">172.22</span>.7.171<span class=\"token punctuation\">;</span> <span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    notify <span class=\"token function\">yes</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>zone <span class=\"token string\">\"22.172.in-addr.arpa\"</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    <span class=\"token builtin class-name\">type</span> master<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    <span class=\"token function\">file</span> <span class=\"token string\">\"db.172.22.0.0\"</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    allow-transfer <span class=\"token punctuation\">&#123;</span> <span class=\"token number\">172.22</span>.7.171<span class=\"token punctuation\">;</span> <span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre>    notify <span class=\"token function\">yes</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"14\"></td><td><pre><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>Nuestra zona será <a href=\"http://antonio.org\">antonio.org</a>, el cual tendrá el fichero <a href=\"http://db.antonio.org\">db.antonio.org</a>, hasta ahí será necesario para ralizar solo un dns, para realizar el dns respaldado por un esclavo necesitaremos conceder el traspaso a la ip 172.22.7.171 que será la ip de la máquina esclava, más abajo nos econtraremos con el fichero de zona de resolución inversa, el cual tendrá el nombre del rango de ip que abarcará, y la misma transferencia de zona y el notify que será lo que avise al esclavo que ha habido un cambio en el maestro.</p>\n<p>Si nos vamos al fichero /var/cache/bind/db.antonio.org podemos ver los siguientes componentes:</p>\n<figure class=\"highlight shell\"><figcaption data-lang=\"Bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token variable\">$TTL</span>    <span class=\"token number\">86400</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>@       IN      SOA     dns1.antonio.org. root.antonio.org. <span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>                              <span class=\"token number\">6</span>         <span class=\"token punctuation\">;</span> Serial</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>                         <span class=\"token number\">604800</span>         <span class=\"token punctuation\">;</span> Refresh</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>                          <span class=\"token number\">86400</span>         <span class=\"token punctuation\">;</span> Retry</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>                        <span class=\"token number\">2419200</span>         <span class=\"token punctuation\">;</span> Expire</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>                          <span class=\"token number\">86400</span> <span class=\"token punctuation\">)</span>       <span class=\"token punctuation\">;</span> Negative Cache TTL</pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>@       IN      NS              dns1.antonio.org.</pre></td></tr><tr><td data-num=\"11\"></td><td><pre>@       IN      NS              dns2.antonio.org.</pre></td></tr><tr><td data-num=\"12\"></td><td><pre>@       IN      MX      <span class=\"token number\">10</span>      correo.antonio.org.</pre></td></tr><tr><td data-num=\"13\"></td><td><pre></pre></td></tr><tr><td data-num=\"14\"></td><td><pre></pre></td></tr><tr><td data-num=\"15\"></td><td><pre><span class=\"token variable\">$ORIGIN</span> antonio.org.</pre></td></tr><tr><td data-num=\"16\"></td><td><pre></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>dns1                    IN      A       <span class=\"token number\">172.22</span>.7.155</pre></td></tr><tr><td data-num=\"18\"></td><td><pre>dns2                    IN      A       <span class=\"token number\">172.22</span>.7.171</pre></td></tr><tr><td data-num=\"19\"></td><td><pre>correo                  IN      A       <span class=\"token number\">172.22</span>.200.101</pre></td></tr><tr><td data-num=\"20\"></td><td><pre>asterix                 IN      A       <span class=\"token number\">172.22</span>.200.102</pre></td></tr><tr><td data-num=\"21\"></td><td><pre>obelix                  IN      A       <span class=\"token number\">172.22</span>.200.103</pre></td></tr><tr><td data-num=\"22\"></td><td><pre>prueba                  IN      A       <span class=\"token number\">172.22</span>.200.120</pre></td></tr><tr><td data-num=\"23\"></td><td><pre>www                     IN      CNAME   asterix</pre></td></tr><tr><td data-num=\"24\"></td><td><pre><span class=\"token punctuation\">;</span>informatica             IN      CNAME   asterix</pre></td></tr><tr><td data-num=\"25\"></td><td><pre><span class=\"token function\">ftp</span>                     IN      CNAME   obelix</pre></td></tr><tr><td data-num=\"26\"></td><td><pre>entrebytes              IN      A       <span class=\"token number\">172.22</span>.200.166</pre></td></tr><tr><td data-num=\"27\"></td><td><pre></pre></td></tr><tr><td data-num=\"28\"></td><td><pre><span class=\"token variable\">$ORIGIN</span> informatica.antonio.org.</pre></td></tr><tr><td data-num=\"29\"></td><td><pre>@       IN      NS    dns</pre></td></tr><tr><td data-num=\"30\"></td><td><pre>dns     IN      A     <span class=\"token number\">172.22</span>.7.177</pre></td></tr></table></figure><p>Pues bien, deberemos cumplimentar de la siguiente forma el fichero, el cual tiene las siguientes definiciones:<br>\nLa primera parte es el SOA, que es fdqn de la máquina maestra, acompañado del correo del administrador, el cual será con puntos.</p>\n<p>En la segunda parte podemos ver los nameservers, el cual tendrá el @, esto mostrará las máquinas a disposición del fdqn que hemos elegido, en nuestro caso tendremos el de la máquina maestra, la del esclavo y la del correo.</p>\n<p>Origin es la variable que va a tener <a href=\"http://antonio.org\">antonio.org</a>. para no tener que repetir continuamente el nombre del dominio en los registros.</p>\n<p>Los registros de tipo A tendrán una ip asociada, estos se encargan de darle nombre a la ip de dentro del dominio, como dns1 que tiene una 172.22.7.155 o la del esclavo, que tendrá la 172.22.7.171</p>\n<p>Los registros de tipo CNAME son nombres relacionados a otros nombres, como por ejemplo ftp, que va relacionado al nombre obelix y que tendrá la ip 172.22.200.103. entonces al realizar la consulta en el apartado ANSWER nos daría el nombre completo al que está asociado.</p>\n<p><img src=\"/images/obelix.png\" alt=\"Descripción de la imagen\"></p>\n<p>Ahora vamos con el fichero de zona de resolución inversa, el cual crearemos en /var/cache/bind/db.172.22.0.0</p>\n<figure class=\"highlight shell\"><figcaption data-lang=\"Bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token variable\">$TTL</span>    <span class=\"token number\">86400</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>@       IN      SOA     dns1.antonio.org. root.antonio.org. <span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>                              <span class=\"token number\">1</span>         <span class=\"token punctuation\">;</span> Serial</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>                         <span class=\"token number\">604800</span>         <span class=\"token punctuation\">;</span> Refresh</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>                          <span class=\"token number\">86400</span>         <span class=\"token punctuation\">;</span> Retry</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>                        <span class=\"token number\">2419200</span>         <span class=\"token punctuation\">;</span> Expire</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>                          <span class=\"token number\">86400</span> <span class=\"token punctuation\">)</span>       <span class=\"token punctuation\">;</span> Negative Cache TTL</pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>@      IN      NS              dns1.antonio.org.</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>@      IN      NS              dns2.antonio.org.</pre></td></tr><tr><td data-num=\"11\"></td><td><pre></pre></td></tr><tr><td data-num=\"12\"></td><td><pre><span class=\"token variable\">$ORIGIN</span> <span class=\"token number\">22.172</span>.in-addr.arpa.</pre></td></tr><tr><td data-num=\"13\"></td><td><pre></pre></td></tr><tr><td data-num=\"14\"></td><td><pre><span class=\"token number\">155.7</span>                  IN      PTR             dns1.antonio.org.</pre></td></tr><tr><td data-num=\"15\"></td><td><pre><span class=\"token number\">171.7</span>                  IN      PTR             dns2.antonio.org.</pre></td></tr><tr><td data-num=\"16\"></td><td><pre><span class=\"token number\">101.200</span>                IN      PTR             correo.antonio.org.</pre></td></tr><tr><td data-num=\"17\"></td><td><pre><span class=\"token number\">102.200</span>                IN      PTR             asterix.antonio.org.</pre></td></tr><tr><td data-num=\"18\"></td><td><pre><span class=\"token number\">200.103</span>                IN      PTR             obelix.antonio.org.</pre></td></tr><tr><td data-num=\"19\"></td><td><pre><span class=\"token number\">200.166</span>                IN      PTR             entrebytes.antonio.org.</pre></td></tr></table></figure><p>El fichero es muy similar al de la resolución directa, pero en este caso especificaremos la IP de la manera opuesta, con PTR conseguiremos obtener el nombre gracias a una petición inversa a la ip que hemos configurado, también pondremos la del servidor esclavo.</p>\n<p><img src=\"/images/obelix-2.png\" alt=\"Descripción de la imagen\"></p>\n<p>Por último, debemos editar el fichero /etc/bind/zones.rfc1918 que se encarga de proporcionar la plantilla empty para las resoluciones no configuradas, de manera que debamos comentar el rango de ips de  <code>//zone &quot;22.172.in-addr.arpa&quot;  &#123; type master; file &quot;/etc/bind/db.empty&quot;; &#125;;</code>  ya que nosotros hemos configurado anteriormente.</p>\n<p>ahora solo nos queda realizar un  <code>systemctl restart bind9</code>  y  <code>systemctl status bind9</code>  para comprobar de que el servicio está activo y sin errores.</p>\n<h2 id=\"servidor-esclavo\"><a class=\"markdownIt-Anchor\" href=\"#servidor-esclavo\">#</a> Servidor esclavo</h2>\n<p>Primero comenzaremos actualizando el sistema e instalando el servidor dns bind9, la máquina deberá tener un nombre full qualificated como en mi caso que sería <strong><a href=\"http://dns2.antonio.org\">dns2.antonio.org</a></strong></p>\n<p><code>apt update &amp;&amp; apt install bind9 -y</code></p>\n<p>Vamos a forzar la salida de las peutciones por ipv4, ya que al no estar configurado de esta forma pueden perderse paquetes al tratar de viajar a través de ipv6, esto lo haremos en /etc/default/named, especificando esta sentencia en   <code>OPTIONS=&quot;-4 -f -u bind&quot;</code> .</p>\n<p>/etc/bind/named.conf.local</p>\n<figure class=\"highlight shell\"><figcaption data-lang=\"Bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>include <span class=\"token string\">\"/etc/bind/zones.rfc1918\"</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>zone <span class=\"token string\">\"antonio.org\"</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token builtin class-name\">type</span> slave<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token function\">file</span> <span class=\"token string\">\"db.antonio.org\"</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    masters <span class=\"token punctuation\">&#123;</span> <span class=\"token number\">172.22</span>.7.155<span class=\"token punctuation\">;</span> <span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>zone <span class=\"token string\">\"22.172.in-addr.arpa\"</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    <span class=\"token builtin class-name\">type</span> slave<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    <span class=\"token function\">file</span> <span class=\"token string\">\"db.172.22.0.0\"</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    masters <span class=\"token punctuation\">&#123;</span> <span class=\"token number\">172.22</span>.7.155<span class=\"token punctuation\">;</span> <span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>Hacemos un  <code>systemctl restart bind9</code>  y  <code>systemctl status bind9</code>  para comprobar de que el servicio está activo y sin errores.</p>\n<p>Tras esto, cuando modifiquemos el servidor maestro subimos el serial de tal forma que sea mayor al de la máquina esclava, y de esta manera realizará la transferencia.</p>\n<p><img src=\"/images/obelix-3.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"delegación-de-subdominio\"><a class=\"markdownIt-Anchor\" href=\"#delegación-de-subdominio\">#</a> Delegación de subdominio</h2>\n<p>Pra delegar un subdominio primero comenzaremos actualizando el sistema e instalando el servidor dns bind9, la máquina deberá tener un nombre full qualificated como en mi caso que sería <strong><a href=\"http://dns.informatica.antonio.org\">dns.informatica.antonio.org</a></strong></p>\n<p><code>apt update &amp;&amp; apt install bind9 -y</code></p>\n<p>Vamos a forzar la salida de las peutciones por ipv4, ya que al no estar configurado de esta forma pueden perderse paquetes al tratar de viajar a través de ipv6, esto lo haremos en /etc/default/named, especificando esta sentencia en   <code>OPTIONS=&quot;-4 -f -u bind&quot;</code> .</p>\n<p>Una vez hecho esto, como podemos ver en la máquina maestra, tenemos un apartado en <a href=\"http://db.antonio.org\">db.antonio.org</a> en el cual especificamos los siguientes parámetros:</p>\n<figure class=\"highlight shell\"><figcaption data-lang=\"Bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token variable\">$ORIGIN</span> informatica.antonio.org.</pre></td></tr><tr><td data-num=\"2\"></td><td><pre>@       IN      NS    dns</pre></td></tr><tr><td data-num=\"3\"></td><td><pre>dns     IN      A     <span class=\"token number\">172.22</span>.7.177</pre></td></tr></table></figure><p>Con esto estaremos delegando el subdominio para que lo gestione <a href=\"http://dns.informatica.antonio.org\">dns.informatica.antonio.org</a>, si nos vamos a esta máquina, debemos configurar el dominio de la siguiente forma:</p>\n<p>/etc/bind/named.conf.local</p>\n<pre><code>zone &quot;informatica.antonio.org&quot; &#123;\n    type master;\n    file &quot;db.informatica.antonio.org&quot;;\n&#125;;\n</code></pre>\n<p>Luego nos vamos a /var/cache/bind/db.informatica.antonio.org</p>\n<figure class=\"highlight shell\"><figcaption data-lang=\"Bash\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token variable\">$TTL</span>    <span class=\"token number\">86400</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>@       IN      SOA     dns.informatica.antonio.org. root.informatica.antonio.org. <span class=\"token punctuation\">(</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>                              <span class=\"token number\">1</span>         <span class=\"token punctuation\">;</span> Serial</pre></td></tr><tr><td data-num=\"4\"></td><td><pre>                         <span class=\"token number\">604800</span>         <span class=\"token punctuation\">;</span> Refresh</pre></td></tr><tr><td data-num=\"5\"></td><td><pre>                          <span class=\"token number\">86400</span>         <span class=\"token punctuation\">;</span> Retry</pre></td></tr><tr><td data-num=\"6\"></td><td><pre>                        <span class=\"token number\">2419200</span>         <span class=\"token punctuation\">;</span> Expire</pre></td></tr><tr><td data-num=\"7\"></td><td><pre>                          <span class=\"token number\">86400</span> <span class=\"token punctuation\">)</span>       <span class=\"token punctuation\">;</span> Negative Cache TTL</pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>@       IN      NS              dns.informatica.antonio.org.</pre></td></tr><tr><td data-num=\"10\"></td><td><pre>@       IN      MX      <span class=\"token number\">10</span>      mail.informatica.antonio.org.</pre></td></tr><tr><td data-num=\"11\"></td><td><pre></pre></td></tr><tr><td data-num=\"12\"></td><td><pre><span class=\"token variable\">$ORIGIN</span> informatica.antonio.org.</pre></td></tr><tr><td data-num=\"13\"></td><td><pre></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>dns                     IN      A               <span class=\"token number\">172.22</span>.7.177</pre></td></tr><tr><td data-num=\"15\"></td><td><pre>mail                    IN      A               <span class=\"token number\">172.22</span>.7.177</pre></td></tr><tr><td data-num=\"16\"></td><td><pre>web                     IN      A               <span class=\"token number\">172.22</span>.7.177</pre></td></tr><tr><td data-num=\"17\"></td><td><pre>www                     IN      CNAME           web</pre></td></tr><tr><td data-num=\"18\"></td><td><pre>entrebytes              IN      CNAME           web</pre></td></tr></table></figure><h2 id=\"tips\"><a class=\"markdownIt-Anchor\" href=\"#tips\">#</a> Tips</h2>\n<p>Si realizamos cambios a veces no se verán reflejados ya que el servicio DNS la almacena en caché, para borrarla necesitaremos ejecutar  <code>rndc flush</code>  en la máquina maestra.</p>\n<p>Para poder realizar las consultas sin especificar la ip a través de @, necesitaremos agregar un nameserver <a href=\"http://XXX.XXX.XXX.XXX\">XXX.XXX.XXX.XXX</a> en /etc/resolv.conf</p>\n<p>En el caso de <a href=\"http://dns.informatica.antonio.org\">dns.informatica.antonio.org</a> no es necesario descomentar el include “/etc/bind/zones.rfc1918”; ya que se ocupará de gestionarlo la máquina maestra.</p>\n<p>Para detectar con información más detallada los errores de plantillas db, necesitaremos ejecutar  <code>named-checkzone antonio.org /var/cache/bind/db.antonio.org</code></p>\n<p>Si queremos detectar los errores del fichero de zonas, necesitaremos ejecutar  <code>named-checkconf</code></p>\n"},{"title":"Configurar un entorno DNS con vistas.","_content":"\n\n![Descripción de la imagen](/images/vistas-dns-1.png)\n\n\n\nInstalaremos un servidor DNS en charlie, de tal forma que todos los nombres de las máquinas deben tener resolución unas con otras al preguntar a charlie.\n\n![Descripción de la imagen](/images/Untitled-2023-01-10-0143.png)\n\nLas vistas sirven para que cada máquina en un entorno pueda ver las correspondientes salidas a nombres que se hallan dentro del entorno, para esto debemos hacer una configuración en el /etc/bind/named.conf.local, que quedaría de la siguiente manera:\n\n```\nview interna {\n    match-clients { 192.168.0.0/24; 127.0.0.1; };\n    allow-recursion { any; };\n        zone \"antonio.gonzalonazareno.org\"\n        {\n               type master;\n               file \"db.interna.antonio.gonzalonazareno.org\";\n        };\n        zone \"0.168.192.in-addr.arpa\"\n        {\n               type master;\n               file \"db.0.168.192\";\n        };\n        zone \"16.172.in-addr.arpa\"\n        {\n               type master;\n               file \"db.16.172\";\n        };\n        include \"/etc/bind/zones.rfc1918\";\n        include \"/etc/bind/named.conf.default-zones\";\n};\n\nview externa {\n    match-clients { 172.22.0.0/16; 192.168.202.2; 172.29.0.0/16;};\n    allow-recursion { any; };\n        zone \"antonio.gonzalonazareno.org\"\n        {\n               type master;\n               file \"db.externa.antonio.gonzalonazareno.org\";\n        };\n        include \"/etc/bind/zones.rfc1918\";\n        include \"/etc/bind/named.conf.default-zones\";\n};\n\nview dmz {\n    match-clients {172.22.0.0/16; 172.16.0.0/16; 172.29.0.0/16;};\n    allow-recursion { any; };\n        zone \"antonio.gonzalonazareno.org\"\n        {\n               type master;\n               file \"db.dmz.antonio.gonzalonazareno.org\";\n        };\n        zone \"16.172.in-addr.arpa\"\n        {\n               type master;\n               file \"db.16.172\";\n        };\n        zone \"0.168.192.in-addr.arpa\"\n        {\n               type master;\n               file \"db.0.168.192\";\n        };\n        include \"/etc/bind/zones.rfc1918\";\n        include \"/etc/bind/named.conf.default-zones\";\n};\n\n```\n\nPor cada rango de ips, tenemos una vista, ¿por qué tenemos 5 vistas? pues la respuesta sería la siguiente:\n- La vista interna que será la vista que tendrán alfa, charlie y delta que contendrá 192.168.0.0\n- La vista externa que será la que se muestre al exterior con 172.22.0.0\n- La vista dmz que tendrá a bravo con 172.16.0.0\n- Tanto la vista dmz como la interna tendrán respuesta sobre resoluciones inversas, pero en la externa no la tenemos, esto es debido a que no debemos proporcionar más información de la esencial a las preguntas desde la vista externa, ya que proviene del exterior y por tanto es menos seguro.\n\nUna vez creada las zonas debemos crear los ficheros en /var/cache/bind/\n\n## Zona externa:\n\n```\n$TTL    86400\n@       IN      SOA     alfa.antonio.gonzalonazareno.org. root.antonio.gonzalonazareno.org. (\n                              1         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                          86400 )       ; Negative Cache TTL\n;\n@       IN      NS              alfa.antonio.gonzalonazareno.org.\n\n$ORIGIN antonio.gonzalonazareno.org.\n\nalfa                    IN      A               172.22.200.193\ndns                     IN      CNAME           alfa\nwww                     IN      CNAME           alfa\n```\n\nComo podemos ver, hay varios cname, esto significa que en las preguntas dns que se realizarán desde el exterior a alfa, la respuesta sería tanto que alfa es el dns como el www, ya que no hay que proporcionar la información del interior.\n\n## Zona interna:\n\n```\n$TTL    86400\n@       IN      SOA     charlie.antonio.gonzalonazareno.org. root.antonio.gonzalonazareno.org. (\n                              1         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                          86400 )       ; Negative Cache TTL\n;\n@       IN      NS              charlie.antonio.gonzalonazareno.org.\n\n$ORIGIN antonio.gonzalonazareno.org.\n\nalfa                    IN      A               192.168.0.1\nbravo                   IN      A               172.16.0.200\ncharlie                 IN      A               192.168.0.2\ndelta                   IN      A               192.168.0.3\nbd                      IN      CNAME           delta\ndns                     IN      CNAME           charlie\nwww                     IN      CNAME           bravo\n```\n\nAhora en la vista interna podemos ver la información de las ip de las máquinas ya que es un entorno de producción seguro.\n\n## Zona interna inversa:\n\n```\n$TTL    86400\n@       IN      SOA     charlie.antonio.gonzalonazareno.org. root.antonio.gonzalonazareno.org. (\n                              1         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                          86400 )       ; Negative Cache TTL\n;\n@       IN      NS              charlie.antonio.gonzalonazareno.org.\n\n$ORIGIN 0.168.192.in-addr.arpa.\n\n1                       IN      PTR             alfa.antonio.gonzalonazareno.org.\n2                       IN      PTR             charlie.antonio.gonzalonazareno.org.\n3                       IN      PTR             delta.antonio.gonzalonazareno.org.\n```\n\nEs importante el '.' después del nombre del fdqn de la máquina ya que si no lo hacemos lo concatenará en la resolución con la ip inversa.\n\n\n## Zona DMZ:\n\n```\n$TTL    86400\n@       IN      SOA     charlie.antonio.gonzalonazareno.org. root.antonio.gonzalonazareno.org. (\n                              1         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                          86400 )       ; Negative Cache TTL\n;\n@       IN      NS              charlie.antonio.gonzalonazareno.org.\n\n$ORIGIN antonio.gonzalonazareno.org.\n\nalfa                    IN      A               172.16.0.1\nbravo                   IN      A               172.16.0.200\ncharlie                 IN      A               192.168.0.2\ndelta                   IN      A               192.168.0.3\nbd                      IN      CNAME           delta\ndns                     IN      CNAME           charlie\nwww                     IN      CNAME           bravo\n```\n\nLa diferencia que podemos apreciar de esta vista es que alfa posee el gateway 172.16.0.1, que es la que verá bravo.\n\n## Zona DMZ inversa:\n\n```\n$TTL    86400\n@       IN      SOA     charlie.antonio.gonzalonazareno.org. root.antonio.gonzalonazareno.org. (\n                              1         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                          86400 )       ; Negative Cache TTL\n;\n@       IN      NS              charlie.antonio.gonzalonazareno.org.\n\n$ORIGIN 16.172.in-addr.arpa.\n\n0.200                   IN      PTR             bravo.antonio.gonzalonazareno.org\n```\n\nUna vez hecho esto debemos hacer systemctl restart bind9 y comprobamos que no haya errores de sintaxis, después podemos porbar a realizar consultas con dig.\n\nAhora una vez realizadas las configuraciones, podemos jugar un poco con esto! y es que por ejemplo si tenemos una base de datos en delta y el cliente de esta base de datos está en bravo, podemos entrar poniendo el cname que especificamos en el dns.\n\n\n![Descripción de la imagen](/images/prueba-dns-mysql.png)\n\n\nY si en el caso que en el /etc/resolv.conf ponemos un search con el nombre del dominio `search antonio.gonzalonazareno.org` pues no haría falta especificar siquiera el dominio, como en el siguiente ejemplo:\n\n![Descripción de la imagen](/images/prueba-dns-mysql2.png)\n\nPor último dejamos la web de alfa que realmente estará alojada en bravo:\n\n![Descripción de la imagen](/images/web-alfa.png)\n\n\n## Tips\n\nSi queremos servir una web que está en un servidor que no pasa por alfa pero no es alfa, debemos poner una regla de iptables que nos permita dirigir el tráfico por el puerto que especifiquemos a bravo, para poder así acceder desde fuera.\n\nSi necesitamos acceder a este entorno desde un servidor dns que lo controle, debemos editar el archivo /etc/bind/named.conf.options\n\n```\n forwarders {\n      192.168.202.2;\n };\n\n```","source":"_posts/dns-vistas.md","raw":"---\ntitle: Configurar un entorno DNS con vistas.\ncategories: Servicios de Red e Internet\ntags: Servicios de Red e Internet\n---\n\n\n![Descripción de la imagen](/images/vistas-dns-1.png)\n\n\n\nInstalaremos un servidor DNS en charlie, de tal forma que todos los nombres de las máquinas deben tener resolución unas con otras al preguntar a charlie.\n\n![Descripción de la imagen](/images/Untitled-2023-01-10-0143.png)\n\nLas vistas sirven para que cada máquina en un entorno pueda ver las correspondientes salidas a nombres que se hallan dentro del entorno, para esto debemos hacer una configuración en el /etc/bind/named.conf.local, que quedaría de la siguiente manera:\n\n```\nview interna {\n    match-clients { 192.168.0.0/24; 127.0.0.1; };\n    allow-recursion { any; };\n        zone \"antonio.gonzalonazareno.org\"\n        {\n               type master;\n               file \"db.interna.antonio.gonzalonazareno.org\";\n        };\n        zone \"0.168.192.in-addr.arpa\"\n        {\n               type master;\n               file \"db.0.168.192\";\n        };\n        zone \"16.172.in-addr.arpa\"\n        {\n               type master;\n               file \"db.16.172\";\n        };\n        include \"/etc/bind/zones.rfc1918\";\n        include \"/etc/bind/named.conf.default-zones\";\n};\n\nview externa {\n    match-clients { 172.22.0.0/16; 192.168.202.2; 172.29.0.0/16;};\n    allow-recursion { any; };\n        zone \"antonio.gonzalonazareno.org\"\n        {\n               type master;\n               file \"db.externa.antonio.gonzalonazareno.org\";\n        };\n        include \"/etc/bind/zones.rfc1918\";\n        include \"/etc/bind/named.conf.default-zones\";\n};\n\nview dmz {\n    match-clients {172.22.0.0/16; 172.16.0.0/16; 172.29.0.0/16;};\n    allow-recursion { any; };\n        zone \"antonio.gonzalonazareno.org\"\n        {\n               type master;\n               file \"db.dmz.antonio.gonzalonazareno.org\";\n        };\n        zone \"16.172.in-addr.arpa\"\n        {\n               type master;\n               file \"db.16.172\";\n        };\n        zone \"0.168.192.in-addr.arpa\"\n        {\n               type master;\n               file \"db.0.168.192\";\n        };\n        include \"/etc/bind/zones.rfc1918\";\n        include \"/etc/bind/named.conf.default-zones\";\n};\n\n```\n\nPor cada rango de ips, tenemos una vista, ¿por qué tenemos 5 vistas? pues la respuesta sería la siguiente:\n- La vista interna que será la vista que tendrán alfa, charlie y delta que contendrá 192.168.0.0\n- La vista externa que será la que se muestre al exterior con 172.22.0.0\n- La vista dmz que tendrá a bravo con 172.16.0.0\n- Tanto la vista dmz como la interna tendrán respuesta sobre resoluciones inversas, pero en la externa no la tenemos, esto es debido a que no debemos proporcionar más información de la esencial a las preguntas desde la vista externa, ya que proviene del exterior y por tanto es menos seguro.\n\nUna vez creada las zonas debemos crear los ficheros en /var/cache/bind/\n\n## Zona externa:\n\n```\n$TTL    86400\n@       IN      SOA     alfa.antonio.gonzalonazareno.org. root.antonio.gonzalonazareno.org. (\n                              1         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                          86400 )       ; Negative Cache TTL\n;\n@       IN      NS              alfa.antonio.gonzalonazareno.org.\n\n$ORIGIN antonio.gonzalonazareno.org.\n\nalfa                    IN      A               172.22.200.193\ndns                     IN      CNAME           alfa\nwww                     IN      CNAME           alfa\n```\n\nComo podemos ver, hay varios cname, esto significa que en las preguntas dns que se realizarán desde el exterior a alfa, la respuesta sería tanto que alfa es el dns como el www, ya que no hay que proporcionar la información del interior.\n\n## Zona interna:\n\n```\n$TTL    86400\n@       IN      SOA     charlie.antonio.gonzalonazareno.org. root.antonio.gonzalonazareno.org. (\n                              1         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                          86400 )       ; Negative Cache TTL\n;\n@       IN      NS              charlie.antonio.gonzalonazareno.org.\n\n$ORIGIN antonio.gonzalonazareno.org.\n\nalfa                    IN      A               192.168.0.1\nbravo                   IN      A               172.16.0.200\ncharlie                 IN      A               192.168.0.2\ndelta                   IN      A               192.168.0.3\nbd                      IN      CNAME           delta\ndns                     IN      CNAME           charlie\nwww                     IN      CNAME           bravo\n```\n\nAhora en la vista interna podemos ver la información de las ip de las máquinas ya que es un entorno de producción seguro.\n\n## Zona interna inversa:\n\n```\n$TTL    86400\n@       IN      SOA     charlie.antonio.gonzalonazareno.org. root.antonio.gonzalonazareno.org. (\n                              1         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                          86400 )       ; Negative Cache TTL\n;\n@       IN      NS              charlie.antonio.gonzalonazareno.org.\n\n$ORIGIN 0.168.192.in-addr.arpa.\n\n1                       IN      PTR             alfa.antonio.gonzalonazareno.org.\n2                       IN      PTR             charlie.antonio.gonzalonazareno.org.\n3                       IN      PTR             delta.antonio.gonzalonazareno.org.\n```\n\nEs importante el '.' después del nombre del fdqn de la máquina ya que si no lo hacemos lo concatenará en la resolución con la ip inversa.\n\n\n## Zona DMZ:\n\n```\n$TTL    86400\n@       IN      SOA     charlie.antonio.gonzalonazareno.org. root.antonio.gonzalonazareno.org. (\n                              1         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                          86400 )       ; Negative Cache TTL\n;\n@       IN      NS              charlie.antonio.gonzalonazareno.org.\n\n$ORIGIN antonio.gonzalonazareno.org.\n\nalfa                    IN      A               172.16.0.1\nbravo                   IN      A               172.16.0.200\ncharlie                 IN      A               192.168.0.2\ndelta                   IN      A               192.168.0.3\nbd                      IN      CNAME           delta\ndns                     IN      CNAME           charlie\nwww                     IN      CNAME           bravo\n```\n\nLa diferencia que podemos apreciar de esta vista es que alfa posee el gateway 172.16.0.1, que es la que verá bravo.\n\n## Zona DMZ inversa:\n\n```\n$TTL    86400\n@       IN      SOA     charlie.antonio.gonzalonazareno.org. root.antonio.gonzalonazareno.org. (\n                              1         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                          86400 )       ; Negative Cache TTL\n;\n@       IN      NS              charlie.antonio.gonzalonazareno.org.\n\n$ORIGIN 16.172.in-addr.arpa.\n\n0.200                   IN      PTR             bravo.antonio.gonzalonazareno.org\n```\n\nUna vez hecho esto debemos hacer systemctl restart bind9 y comprobamos que no haya errores de sintaxis, después podemos porbar a realizar consultas con dig.\n\nAhora una vez realizadas las configuraciones, podemos jugar un poco con esto! y es que por ejemplo si tenemos una base de datos en delta y el cliente de esta base de datos está en bravo, podemos entrar poniendo el cname que especificamos en el dns.\n\n\n![Descripción de la imagen](/images/prueba-dns-mysql.png)\n\n\nY si en el caso que en el /etc/resolv.conf ponemos un search con el nombre del dominio `search antonio.gonzalonazareno.org` pues no haría falta especificar siquiera el dominio, como en el siguiente ejemplo:\n\n![Descripción de la imagen](/images/prueba-dns-mysql2.png)\n\nPor último dejamos la web de alfa que realmente estará alojada en bravo:\n\n![Descripción de la imagen](/images/web-alfa.png)\n\n\n## Tips\n\nSi queremos servir una web que está en un servidor que no pasa por alfa pero no es alfa, debemos poner una regla de iptables que nos permita dirigir el tráfico por el puerto que especifiquemos a bravo, para poder así acceder desde fuera.\n\nSi necesitamos acceder a este entorno desde un servidor dns que lo controle, debemos editar el archivo /etc/bind/named.conf.options\n\n```\n forwarders {\n      192.168.202.2;\n };\n\n```","slug":"dns-vistas","published":1,"date":"2023-01-10T00:38:26.921Z","updated":"2023-01-15T13:42:33.828Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cldl9ucgm000f0yi5d17u6m4k","content":"<p><img src=\"/images/vistas-dns-1.png\" alt=\"Descripción de la imagen\"></p>\n<p>Instalaremos un servidor DNS en charlie, de tal forma que todos los nombres de las máquinas deben tener resolución unas con otras al preguntar a charlie.</p>\n<p><img src=\"/images/Untitled-2023-01-10-0143.png\" alt=\"Descripción de la imagen\"></p>\n<p>Las vistas sirven para que cada máquina en un entorno pueda ver las correspondientes salidas a nombres que se hallan dentro del entorno, para esto debemos hacer una configuración en el /etc/bind/named.conf.local, que quedaría de la siguiente manera:</p>\n<pre><code>view interna &#123;\n    match-clients &#123; 192.168.0.0/24; 127.0.0.1; &#125;;\n    allow-recursion &#123; any; &#125;;\n        zone &quot;antonio.gonzalonazareno.org&quot;\n        &#123;\n               type master;\n               file &quot;db.interna.antonio.gonzalonazareno.org&quot;;\n        &#125;;\n        zone &quot;0.168.192.in-addr.arpa&quot;\n        &#123;\n               type master;\n               file &quot;db.0.168.192&quot;;\n        &#125;;\n        zone &quot;16.172.in-addr.arpa&quot;\n        &#123;\n               type master;\n               file &quot;db.16.172&quot;;\n        &#125;;\n        include &quot;/etc/bind/zones.rfc1918&quot;;\n        include &quot;/etc/bind/named.conf.default-zones&quot;;\n&#125;;\n\nview externa &#123;\n    match-clients &#123; 172.22.0.0/16; 192.168.202.2; 172.29.0.0/16;&#125;;\n    allow-recursion &#123; any; &#125;;\n        zone &quot;antonio.gonzalonazareno.org&quot;\n        &#123;\n               type master;\n               file &quot;db.externa.antonio.gonzalonazareno.org&quot;;\n        &#125;;\n        include &quot;/etc/bind/zones.rfc1918&quot;;\n        include &quot;/etc/bind/named.conf.default-zones&quot;;\n&#125;;\n\nview dmz &#123;\n    match-clients &#123;172.22.0.0/16; 172.16.0.0/16; 172.29.0.0/16;&#125;;\n    allow-recursion &#123; any; &#125;;\n        zone &quot;antonio.gonzalonazareno.org&quot;\n        &#123;\n               type master;\n               file &quot;db.dmz.antonio.gonzalonazareno.org&quot;;\n        &#125;;\n        zone &quot;16.172.in-addr.arpa&quot;\n        &#123;\n               type master;\n               file &quot;db.16.172&quot;;\n        &#125;;\n        zone &quot;0.168.192.in-addr.arpa&quot;\n        &#123;\n               type master;\n               file &quot;db.0.168.192&quot;;\n        &#125;;\n        include &quot;/etc/bind/zones.rfc1918&quot;;\n        include &quot;/etc/bind/named.conf.default-zones&quot;;\n&#125;;\n\n</code></pre>\n<p>Por cada rango de ips, tenemos una vista, ¿por qué tenemos 5 vistas? pues la respuesta sería la siguiente:</p>\n<ul>\n<li>La vista interna que será la vista que tendrán alfa, charlie y delta que contendrá 192.168.0.0</li>\n<li>La vista externa que será la que se muestre al exterior con 172.22.0.0</li>\n<li>La vista dmz que tendrá a bravo con 172.16.0.0</li>\n<li>Tanto la vista dmz como la interna tendrán respuesta sobre resoluciones inversas, pero en la externa no la tenemos, esto es debido a que no debemos proporcionar más información de la esencial a las preguntas desde la vista externa, ya que proviene del exterior y por tanto es menos seguro.</li>\n</ul>\n<p>Una vez creada las zonas debemos crear los ficheros en /var/cache/bind/</p>\n<h2 id=\"zona-externa\"><a class=\"markdownIt-Anchor\" href=\"#zona-externa\">#</a> Zona externa:</h2>\n<pre><code>$TTL    86400\n@       IN      SOA     alfa.antonio.gonzalonazareno.org. root.antonio.gonzalonazareno.org. (\n                              1         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                          86400 )       ; Negative Cache TTL\n;\n@       IN      NS              alfa.antonio.gonzalonazareno.org.\n\n$ORIGIN antonio.gonzalonazareno.org.\n\nalfa                    IN      A               172.22.200.193\ndns                     IN      CNAME           alfa\nwww                     IN      CNAME           alfa\n</code></pre>\n<p>Como podemos ver, hay varios cname, esto significa que en las preguntas dns que se realizarán desde el exterior a alfa, la respuesta sería tanto que alfa es el dns como el www, ya que no hay que proporcionar la información del interior.</p>\n<h2 id=\"zona-interna\"><a class=\"markdownIt-Anchor\" href=\"#zona-interna\">#</a> Zona interna:</h2>\n<pre><code>$TTL    86400\n@       IN      SOA     charlie.antonio.gonzalonazareno.org. root.antonio.gonzalonazareno.org. (\n                              1         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                          86400 )       ; Negative Cache TTL\n;\n@       IN      NS              charlie.antonio.gonzalonazareno.org.\n\n$ORIGIN antonio.gonzalonazareno.org.\n\nalfa                    IN      A               192.168.0.1\nbravo                   IN      A               172.16.0.200\ncharlie                 IN      A               192.168.0.2\ndelta                   IN      A               192.168.0.3\nbd                      IN      CNAME           delta\ndns                     IN      CNAME           charlie\nwww                     IN      CNAME           bravo\n</code></pre>\n<p>Ahora en la vista interna podemos ver la información de las ip de las máquinas ya que es un entorno de producción seguro.</p>\n<h2 id=\"zona-interna-inversa\"><a class=\"markdownIt-Anchor\" href=\"#zona-interna-inversa\">#</a> Zona interna inversa:</h2>\n<pre><code>$TTL    86400\n@       IN      SOA     charlie.antonio.gonzalonazareno.org. root.antonio.gonzalonazareno.org. (\n                              1         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                          86400 )       ; Negative Cache TTL\n;\n@       IN      NS              charlie.antonio.gonzalonazareno.org.\n\n$ORIGIN 0.168.192.in-addr.arpa.\n\n1                       IN      PTR             alfa.antonio.gonzalonazareno.org.\n2                       IN      PTR             charlie.antonio.gonzalonazareno.org.\n3                       IN      PTR             delta.antonio.gonzalonazareno.org.\n</code></pre>\n<p>Es importante el ‘.’ después del nombre del fdqn de la máquina ya que si no lo hacemos lo concatenará en la resolución con la ip inversa.</p>\n<h2 id=\"zona-dmz\"><a class=\"markdownIt-Anchor\" href=\"#zona-dmz\">#</a> Zona DMZ:</h2>\n<pre><code>$TTL    86400\n@       IN      SOA     charlie.antonio.gonzalonazareno.org. root.antonio.gonzalonazareno.org. (\n                              1         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                          86400 )       ; Negative Cache TTL\n;\n@       IN      NS              charlie.antonio.gonzalonazareno.org.\n\n$ORIGIN antonio.gonzalonazareno.org.\n\nalfa                    IN      A               172.16.0.1\nbravo                   IN      A               172.16.0.200\ncharlie                 IN      A               192.168.0.2\ndelta                   IN      A               192.168.0.3\nbd                      IN      CNAME           delta\ndns                     IN      CNAME           charlie\nwww                     IN      CNAME           bravo\n</code></pre>\n<p>La diferencia que podemos apreciar de esta vista es que alfa posee el gateway 172.16.0.1, que es la que verá bravo.</p>\n<h2 id=\"zona-dmz-inversa\"><a class=\"markdownIt-Anchor\" href=\"#zona-dmz-inversa\">#</a> Zona DMZ inversa:</h2>\n<pre><code>$TTL    86400\n@       IN      SOA     charlie.antonio.gonzalonazareno.org. root.antonio.gonzalonazareno.org. (\n                              1         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                          86400 )       ; Negative Cache TTL\n;\n@       IN      NS              charlie.antonio.gonzalonazareno.org.\n\n$ORIGIN 16.172.in-addr.arpa.\n\n0.200                   IN      PTR             bravo.antonio.gonzalonazareno.org\n</code></pre>\n<p>Una vez hecho esto debemos hacer systemctl restart bind9 y comprobamos que no haya errores de sintaxis, después podemos porbar a realizar consultas con dig.</p>\n<p>Ahora una vez realizadas las configuraciones, podemos jugar un poco con esto! y es que por ejemplo si tenemos una base de datos en delta y el cliente de esta base de datos está en bravo, podemos entrar poniendo el cname que especificamos en el dns.</p>\n<p><img src=\"/images/prueba-dns-mysql.png\" alt=\"Descripción de la imagen\"></p>\n<p>Y si en el caso que en el /etc/resolv.conf ponemos un search con el nombre del dominio  <code>search antonio.gonzalonazareno.org</code>  pues no haría falta especificar siquiera el dominio, como en el siguiente ejemplo:</p>\n<p><img src=\"/images/prueba-dns-mysql2.png\" alt=\"Descripción de la imagen\"></p>\n<p>Por último dejamos la web de alfa que realmente estará alojada en bravo:</p>\n<p><img src=\"/images/web-alfa.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"tips\"><a class=\"markdownIt-Anchor\" href=\"#tips\">#</a> Tips</h2>\n<p>Si queremos servir una web que está en un servidor que no pasa por alfa pero no es alfa, debemos poner una regla de iptables que nos permita dirigir el tráfico por el puerto que especifiquemos a bravo, para poder así acceder desde fuera.</p>\n<p>Si necesitamos acceder a este entorno desde un servidor dns que lo controle, debemos editar el archivo /etc/bind/named.conf.options</p>\n<pre><code> forwarders &#123;\n      192.168.202.2;\n &#125;;\n\n</code></pre>\n","site":{"data":{}},"length":5349,"excerpt":"","more":"<p><img src=\"/images/vistas-dns-1.png\" alt=\"Descripción de la imagen\"></p>\n<p>Instalaremos un servidor DNS en charlie, de tal forma que todos los nombres de las máquinas deben tener resolución unas con otras al preguntar a charlie.</p>\n<p><img src=\"/images/Untitled-2023-01-10-0143.png\" alt=\"Descripción de la imagen\"></p>\n<p>Las vistas sirven para que cada máquina en un entorno pueda ver las correspondientes salidas a nombres que se hallan dentro del entorno, para esto debemos hacer una configuración en el /etc/bind/named.conf.local, que quedaría de la siguiente manera:</p>\n<pre><code>view interna &#123;\n    match-clients &#123; 192.168.0.0/24; 127.0.0.1; &#125;;\n    allow-recursion &#123; any; &#125;;\n        zone &quot;antonio.gonzalonazareno.org&quot;\n        &#123;\n               type master;\n               file &quot;db.interna.antonio.gonzalonazareno.org&quot;;\n        &#125;;\n        zone &quot;0.168.192.in-addr.arpa&quot;\n        &#123;\n               type master;\n               file &quot;db.0.168.192&quot;;\n        &#125;;\n        zone &quot;16.172.in-addr.arpa&quot;\n        &#123;\n               type master;\n               file &quot;db.16.172&quot;;\n        &#125;;\n        include &quot;/etc/bind/zones.rfc1918&quot;;\n        include &quot;/etc/bind/named.conf.default-zones&quot;;\n&#125;;\n\nview externa &#123;\n    match-clients &#123; 172.22.0.0/16; 192.168.202.2; 172.29.0.0/16;&#125;;\n    allow-recursion &#123; any; &#125;;\n        zone &quot;antonio.gonzalonazareno.org&quot;\n        &#123;\n               type master;\n               file &quot;db.externa.antonio.gonzalonazareno.org&quot;;\n        &#125;;\n        include &quot;/etc/bind/zones.rfc1918&quot;;\n        include &quot;/etc/bind/named.conf.default-zones&quot;;\n&#125;;\n\nview dmz &#123;\n    match-clients &#123;172.22.0.0/16; 172.16.0.0/16; 172.29.0.0/16;&#125;;\n    allow-recursion &#123; any; &#125;;\n        zone &quot;antonio.gonzalonazareno.org&quot;\n        &#123;\n               type master;\n               file &quot;db.dmz.antonio.gonzalonazareno.org&quot;;\n        &#125;;\n        zone &quot;16.172.in-addr.arpa&quot;\n        &#123;\n               type master;\n               file &quot;db.16.172&quot;;\n        &#125;;\n        zone &quot;0.168.192.in-addr.arpa&quot;\n        &#123;\n               type master;\n               file &quot;db.0.168.192&quot;;\n        &#125;;\n        include &quot;/etc/bind/zones.rfc1918&quot;;\n        include &quot;/etc/bind/named.conf.default-zones&quot;;\n&#125;;\n\n</code></pre>\n<p>Por cada rango de ips, tenemos una vista, ¿por qué tenemos 5 vistas? pues la respuesta sería la siguiente:</p>\n<ul>\n<li>La vista interna que será la vista que tendrán alfa, charlie y delta que contendrá 192.168.0.0</li>\n<li>La vista externa que será la que se muestre al exterior con 172.22.0.0</li>\n<li>La vista dmz que tendrá a bravo con 172.16.0.0</li>\n<li>Tanto la vista dmz como la interna tendrán respuesta sobre resoluciones inversas, pero en la externa no la tenemos, esto es debido a que no debemos proporcionar más información de la esencial a las preguntas desde la vista externa, ya que proviene del exterior y por tanto es menos seguro.</li>\n</ul>\n<p>Una vez creada las zonas debemos crear los ficheros en /var/cache/bind/</p>\n<h2 id=\"zona-externa\"><a class=\"markdownIt-Anchor\" href=\"#zona-externa\">#</a> Zona externa:</h2>\n<pre><code>$TTL    86400\n@       IN      SOA     alfa.antonio.gonzalonazareno.org. root.antonio.gonzalonazareno.org. (\n                              1         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                          86400 )       ; Negative Cache TTL\n;\n@       IN      NS              alfa.antonio.gonzalonazareno.org.\n\n$ORIGIN antonio.gonzalonazareno.org.\n\nalfa                    IN      A               172.22.200.193\ndns                     IN      CNAME           alfa\nwww                     IN      CNAME           alfa\n</code></pre>\n<p>Como podemos ver, hay varios cname, esto significa que en las preguntas dns que se realizarán desde el exterior a alfa, la respuesta sería tanto que alfa es el dns como el www, ya que no hay que proporcionar la información del interior.</p>\n<h2 id=\"zona-interna\"><a class=\"markdownIt-Anchor\" href=\"#zona-interna\">#</a> Zona interna:</h2>\n<pre><code>$TTL    86400\n@       IN      SOA     charlie.antonio.gonzalonazareno.org. root.antonio.gonzalonazareno.org. (\n                              1         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                          86400 )       ; Negative Cache TTL\n;\n@       IN      NS              charlie.antonio.gonzalonazareno.org.\n\n$ORIGIN antonio.gonzalonazareno.org.\n\nalfa                    IN      A               192.168.0.1\nbravo                   IN      A               172.16.0.200\ncharlie                 IN      A               192.168.0.2\ndelta                   IN      A               192.168.0.3\nbd                      IN      CNAME           delta\ndns                     IN      CNAME           charlie\nwww                     IN      CNAME           bravo\n</code></pre>\n<p>Ahora en la vista interna podemos ver la información de las ip de las máquinas ya que es un entorno de producción seguro.</p>\n<h2 id=\"zona-interna-inversa\"><a class=\"markdownIt-Anchor\" href=\"#zona-interna-inversa\">#</a> Zona interna inversa:</h2>\n<pre><code>$TTL    86400\n@       IN      SOA     charlie.antonio.gonzalonazareno.org. root.antonio.gonzalonazareno.org. (\n                              1         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                          86400 )       ; Negative Cache TTL\n;\n@       IN      NS              charlie.antonio.gonzalonazareno.org.\n\n$ORIGIN 0.168.192.in-addr.arpa.\n\n1                       IN      PTR             alfa.antonio.gonzalonazareno.org.\n2                       IN      PTR             charlie.antonio.gonzalonazareno.org.\n3                       IN      PTR             delta.antonio.gonzalonazareno.org.\n</code></pre>\n<p>Es importante el ‘.’ después del nombre del fdqn de la máquina ya que si no lo hacemos lo concatenará en la resolución con la ip inversa.</p>\n<h2 id=\"zona-dmz\"><a class=\"markdownIt-Anchor\" href=\"#zona-dmz\">#</a> Zona DMZ:</h2>\n<pre><code>$TTL    86400\n@       IN      SOA     charlie.antonio.gonzalonazareno.org. root.antonio.gonzalonazareno.org. (\n                              1         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                          86400 )       ; Negative Cache TTL\n;\n@       IN      NS              charlie.antonio.gonzalonazareno.org.\n\n$ORIGIN antonio.gonzalonazareno.org.\n\nalfa                    IN      A               172.16.0.1\nbravo                   IN      A               172.16.0.200\ncharlie                 IN      A               192.168.0.2\ndelta                   IN      A               192.168.0.3\nbd                      IN      CNAME           delta\ndns                     IN      CNAME           charlie\nwww                     IN      CNAME           bravo\n</code></pre>\n<p>La diferencia que podemos apreciar de esta vista es que alfa posee el gateway 172.16.0.1, que es la que verá bravo.</p>\n<h2 id=\"zona-dmz-inversa\"><a class=\"markdownIt-Anchor\" href=\"#zona-dmz-inversa\">#</a> Zona DMZ inversa:</h2>\n<pre><code>$TTL    86400\n@       IN      SOA     charlie.antonio.gonzalonazareno.org. root.antonio.gonzalonazareno.org. (\n                              1         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                          86400 )       ; Negative Cache TTL\n;\n@       IN      NS              charlie.antonio.gonzalonazareno.org.\n\n$ORIGIN 16.172.in-addr.arpa.\n\n0.200                   IN      PTR             bravo.antonio.gonzalonazareno.org\n</code></pre>\n<p>Una vez hecho esto debemos hacer systemctl restart bind9 y comprobamos que no haya errores de sintaxis, después podemos porbar a realizar consultas con dig.</p>\n<p>Ahora una vez realizadas las configuraciones, podemos jugar un poco con esto! y es que por ejemplo si tenemos una base de datos en delta y el cliente de esta base de datos está en bravo, podemos entrar poniendo el cname que especificamos en el dns.</p>\n<p><img src=\"/images/prueba-dns-mysql.png\" alt=\"Descripción de la imagen\"></p>\n<p>Y si en el caso que en el /etc/resolv.conf ponemos un search con el nombre del dominio  <code>search antonio.gonzalonazareno.org</code>  pues no haría falta especificar siquiera el dominio, como en el siguiente ejemplo:</p>\n<p><img src=\"/images/prueba-dns-mysql2.png\" alt=\"Descripción de la imagen\"></p>\n<p>Por último dejamos la web de alfa que realmente estará alojada en bravo:</p>\n<p><img src=\"/images/web-alfa.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"tips\"><a class=\"markdownIt-Anchor\" href=\"#tips\">#</a> Tips</h2>\n<p>Si queremos servir una web que está en un servidor que no pasa por alfa pero no es alfa, debemos poner una regla de iptables que nos permita dirigir el tráfico por el puerto que especifiquemos a bravo, para poder así acceder desde fuera.</p>\n<p>Si necesitamos acceder a este entorno desde un servidor dns que lo controle, debemos editar el archivo /etc/bind/named.conf.options</p>\n<pre><code> forwarders &#123;\n      192.168.202.2;\n &#125;;\n\n</code></pre>\n"},{"title":"Montaje de volumen nfs a partir de systemd","_content":"\n![status](/images/systemd-title.jpg)\n\n\nVamos a empezar en la máquina servidor, que en nuestro caso será alfa, actualizamos el sistema e instalamos los paquetes necesarios para la instalación nfs en la máquina servidora que en nuestro caso será alfa.\n\n```\napt install nfs-kernel-server nfs-common\n```\n\nTras esto vamos a ingresar el nuevo volumen, en el escenario podría ser tanto físico como virtualizado, pero antes de realizar la configuración de systemd necesitaremos darle formato al sistema de archivos, que en nuestro caso será ext4.\n\n`mkfs.ext4 /dev/vdb`\n\nUna vez hecho esto podemos crear el archivo en /etc/systemd/system/srv-compartida.mount, es necesario que pongamos la ruta en la que va a estar la carpeta compartida a partir de '-' en vez de '/' en el nombre del fichero a crear, .mount indica a systemd que es un archivo de montaje.\n\nAhora vamos a ver la sintaxis del archivo:\n\n\n```\n[Unit]\nDescription= volumen que va a ser montado para compartir nfs\n\n[Mount]\nWhat= /dev/vdb\nWhere= /srv/compartida/\nType=ext4\nOptions=defaults\n\n[Install]\nWantedBy=multi-user.target\n```\n\nEn [Unit] podemos poner la descripción de lo que va a realizar el servicio\nEn [Mount] es como una forma diferente de poner una línea del fstab, ya que se especifica el qué se va a montar, donde se va a montar, el tipo de archivo que va a ser y sus propias opciones de montaje.\nEn [Install] especificamos los usuarios a los que va a ser dirigido este servicio.\n\nUna vez hecho esto vamos a ejecutar `systemctl enable srv-compartida.mount` para activar el servicio permanentemente y `systemctl start srv-compartida.mount` para iniciarlo.\n\nTras esto si hacemos systemctl status srv-compartida podemos ver que está activo el servicio\n\n![status](/images/systemd-1.png)\n\nAhora vamos a configurar el servidor nfs, en el cual debemos escribir la siguiente línea en el archivo de /etc/exports, pero antes debe estar creada la carpeta compartida.\n\n`/srv/compartida 172.16.0.200(rw,sync,no_subtree_check,all_squash)`\n\nluego ejecutamos `exportfs -a` para que el servicio nfs lea el fichero de /etc/exports.\n\n\nAhora vamos a pasar a la máquina cliente:\n\ncrearemos la carpeta en /srv/nfs y escribiremos en el archivo de /etc/systemd/system/srv-nfs.mount lo siguiente:\n\n```\n[Unit]\nDescription= Montaje de carpeta compartida NFS  \n\n[Mount]\nWhat=172.16.0.1:/srv/compartida\nWhere=/srv/nfs\nType=nfs\nOptions=defaults\n\n[Install]\nWantedBy=multi-user.target\n```\n\nY tras esto:\n\n```\nsystemctl enable srv-nfs.mount\nsystemctl start srv-nfs.mount\n```\n\nAhora podemos comprobar que el servicio permanece activo:\n\n![status](/images/systemd-2.png)\n\n\nY vemos con un archivo de prueba que el servidor nfs funciona:\n\n\n![nfs](/images/systemd-3.png)","source":"_posts/nfs-systemd.md","raw":"---\ntitle: Montaje de volumen nfs a partir de systemd\ncategories: Sistemas Operativos\n---\n\n![status](/images/systemd-title.jpg)\n\n\nVamos a empezar en la máquina servidor, que en nuestro caso será alfa, actualizamos el sistema e instalamos los paquetes necesarios para la instalación nfs en la máquina servidora que en nuestro caso será alfa.\n\n```\napt install nfs-kernel-server nfs-common\n```\n\nTras esto vamos a ingresar el nuevo volumen, en el escenario podría ser tanto físico como virtualizado, pero antes de realizar la configuración de systemd necesitaremos darle formato al sistema de archivos, que en nuestro caso será ext4.\n\n`mkfs.ext4 /dev/vdb`\n\nUna vez hecho esto podemos crear el archivo en /etc/systemd/system/srv-compartida.mount, es necesario que pongamos la ruta en la que va a estar la carpeta compartida a partir de '-' en vez de '/' en el nombre del fichero a crear, .mount indica a systemd que es un archivo de montaje.\n\nAhora vamos a ver la sintaxis del archivo:\n\n\n```\n[Unit]\nDescription= volumen que va a ser montado para compartir nfs\n\n[Mount]\nWhat= /dev/vdb\nWhere= /srv/compartida/\nType=ext4\nOptions=defaults\n\n[Install]\nWantedBy=multi-user.target\n```\n\nEn [Unit] podemos poner la descripción de lo que va a realizar el servicio\nEn [Mount] es como una forma diferente de poner una línea del fstab, ya que se especifica el qué se va a montar, donde se va a montar, el tipo de archivo que va a ser y sus propias opciones de montaje.\nEn [Install] especificamos los usuarios a los que va a ser dirigido este servicio.\n\nUna vez hecho esto vamos a ejecutar `systemctl enable srv-compartida.mount` para activar el servicio permanentemente y `systemctl start srv-compartida.mount` para iniciarlo.\n\nTras esto si hacemos systemctl status srv-compartida podemos ver que está activo el servicio\n\n![status](/images/systemd-1.png)\n\nAhora vamos a configurar el servidor nfs, en el cual debemos escribir la siguiente línea en el archivo de /etc/exports, pero antes debe estar creada la carpeta compartida.\n\n`/srv/compartida 172.16.0.200(rw,sync,no_subtree_check,all_squash)`\n\nluego ejecutamos `exportfs -a` para que el servicio nfs lea el fichero de /etc/exports.\n\n\nAhora vamos a pasar a la máquina cliente:\n\ncrearemos la carpeta en /srv/nfs y escribiremos en el archivo de /etc/systemd/system/srv-nfs.mount lo siguiente:\n\n```\n[Unit]\nDescription= Montaje de carpeta compartida NFS  \n\n[Mount]\nWhat=172.16.0.1:/srv/compartida\nWhere=/srv/nfs\nType=nfs\nOptions=defaults\n\n[Install]\nWantedBy=multi-user.target\n```\n\nY tras esto:\n\n```\nsystemctl enable srv-nfs.mount\nsystemctl start srv-nfs.mount\n```\n\nAhora podemos comprobar que el servicio permanece activo:\n\n![status](/images/systemd-2.png)\n\n\nY vemos con un archivo de prueba que el servidor nfs funciona:\n\n\n![nfs](/images/systemd-3.png)","slug":"nfs-systemd","published":1,"date":"2023-01-03T13:43:02.309Z","updated":"2023-01-04T13:34:26.899Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cldl9ucgo000j0yi56s67411j","content":"<p><img src=\"/images/systemd-title.jpg\" alt=\"status\"></p>\n<p>Vamos a empezar en la máquina servidor, que en nuestro caso será alfa, actualizamos el sistema e instalamos los paquetes necesarios para la instalación nfs en la máquina servidora que en nuestro caso será alfa.</p>\n<pre><code>apt install nfs-kernel-server nfs-common\n</code></pre>\n<p>Tras esto vamos a ingresar el nuevo volumen, en el escenario podría ser tanto físico como virtualizado, pero antes de realizar la configuración de systemd necesitaremos darle formato al sistema de archivos, que en nuestro caso será ext4.</p>\n<p><code>mkfs.ext4 /dev/vdb</code></p>\n<p>Una vez hecho esto podemos crear el archivo en /etc/systemd/system/srv-compartida.mount, es necesario que pongamos la ruta en la que va a estar la carpeta compartida a partir de ‘-’ en vez de ‘/’ en el nombre del fichero a crear, .mount indica a systemd que es un archivo de montaje.</p>\n<p>Ahora vamos a ver la sintaxis del archivo:</p>\n<pre><code>[Unit]\nDescription= volumen que va a ser montado para compartir nfs\n\n[Mount]\nWhat= /dev/vdb\nWhere= /srv/compartida/\nType=ext4\nOptions=defaults\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>\n<p>En [Unit] podemos poner la descripción de lo que va a realizar el servicio<br>\nEn [Mount] es como una forma diferente de poner una línea del fstab, ya que se especifica el qué se va a montar, donde se va a montar, el tipo de archivo que va a ser y sus propias opciones de montaje.<br>\nEn [Install] especificamos los usuarios a los que va a ser dirigido este servicio.</p>\n<p>Una vez hecho esto vamos a ejecutar  <code>systemctl enable srv-compartida.mount</code>  para activar el servicio permanentemente y  <code>systemctl start srv-compartida.mount</code>  para iniciarlo.</p>\n<p>Tras esto si hacemos systemctl status srv-compartida podemos ver que está activo el servicio</p>\n<p><img src=\"/images/systemd-1.png\" alt=\"status\"></p>\n<p>Ahora vamos a configurar el servidor nfs, en el cual debemos escribir la siguiente línea en el archivo de /etc/exports, pero antes debe estar creada la carpeta compartida.</p>\n<p><code>/srv/compartida 172.16.0.200(rw,sync,no_subtree_check,all_squash)</code></p>\n<p>luego ejecutamos  <code>exportfs -a</code>  para que el servicio nfs lea el fichero de /etc/exports.</p>\n<p>Ahora vamos a pasar a la máquina cliente:</p>\n<p>crearemos la carpeta en /srv/nfs y escribiremos en el archivo de /etc/systemd/system/srv-nfs.mount lo siguiente:</p>\n<pre><code>[Unit]\nDescription= Montaje de carpeta compartida NFS  \n\n[Mount]\nWhat=172.16.0.1:/srv/compartida\nWhere=/srv/nfs\nType=nfs\nOptions=defaults\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>\n<p>Y tras esto:</p>\n<pre><code>systemctl enable srv-nfs.mount\nsystemctl start srv-nfs.mount\n</code></pre>\n<p>Ahora podemos comprobar que el servicio permanece activo:</p>\n<p><img src=\"/images/systemd-2.png\" alt=\"status\"></p>\n<p>Y vemos con un archivo de prueba que el servidor nfs funciona:</p>\n<p><img src=\"/images/systemd-3.png\" alt=\"nfs\"></p>\n","site":{"data":{}},"length":2113,"excerpt":"","more":"<p><img src=\"/images/systemd-title.jpg\" alt=\"status\"></p>\n<p>Vamos a empezar en la máquina servidor, que en nuestro caso será alfa, actualizamos el sistema e instalamos los paquetes necesarios para la instalación nfs en la máquina servidora que en nuestro caso será alfa.</p>\n<pre><code>apt install nfs-kernel-server nfs-common\n</code></pre>\n<p>Tras esto vamos a ingresar el nuevo volumen, en el escenario podría ser tanto físico como virtualizado, pero antes de realizar la configuración de systemd necesitaremos darle formato al sistema de archivos, que en nuestro caso será ext4.</p>\n<p><code>mkfs.ext4 /dev/vdb</code></p>\n<p>Una vez hecho esto podemos crear el archivo en /etc/systemd/system/srv-compartida.mount, es necesario que pongamos la ruta en la que va a estar la carpeta compartida a partir de ‘-’ en vez de ‘/’ en el nombre del fichero a crear, .mount indica a systemd que es un archivo de montaje.</p>\n<p>Ahora vamos a ver la sintaxis del archivo:</p>\n<pre><code>[Unit]\nDescription= volumen que va a ser montado para compartir nfs\n\n[Mount]\nWhat= /dev/vdb\nWhere= /srv/compartida/\nType=ext4\nOptions=defaults\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>\n<p>En [Unit] podemos poner la descripción de lo que va a realizar el servicio<br>\nEn [Mount] es como una forma diferente de poner una línea del fstab, ya que se especifica el qué se va a montar, donde se va a montar, el tipo de archivo que va a ser y sus propias opciones de montaje.<br>\nEn [Install] especificamos los usuarios a los que va a ser dirigido este servicio.</p>\n<p>Una vez hecho esto vamos a ejecutar  <code>systemctl enable srv-compartida.mount</code>  para activar el servicio permanentemente y  <code>systemctl start srv-compartida.mount</code>  para iniciarlo.</p>\n<p>Tras esto si hacemos systemctl status srv-compartida podemos ver que está activo el servicio</p>\n<p><img src=\"/images/systemd-1.png\" alt=\"status\"></p>\n<p>Ahora vamos a configurar el servidor nfs, en el cual debemos escribir la siguiente línea en el archivo de /etc/exports, pero antes debe estar creada la carpeta compartida.</p>\n<p><code>/srv/compartida 172.16.0.200(rw,sync,no_subtree_check,all_squash)</code></p>\n<p>luego ejecutamos  <code>exportfs -a</code>  para que el servicio nfs lea el fichero de /etc/exports.</p>\n<p>Ahora vamos a pasar a la máquina cliente:</p>\n<p>crearemos la carpeta en /srv/nfs y escribiremos en el archivo de /etc/systemd/system/srv-nfs.mount lo siguiente:</p>\n<pre><code>[Unit]\nDescription= Montaje de carpeta compartida NFS  \n\n[Mount]\nWhat=172.16.0.1:/srv/compartida\nWhere=/srv/nfs\nType=nfs\nOptions=defaults\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>\n<p>Y tras esto:</p>\n<pre><code>systemctl enable srv-nfs.mount\nsystemctl start srv-nfs.mount\n</code></pre>\n<p>Ahora podemos comprobar que el servicio permanece activo:</p>\n<p><img src=\"/images/systemd-2.png\" alt=\"status\"></p>\n<p>Y vemos con un archivo de prueba que el servidor nfs funciona:</p>\n<p><img src=\"/images/systemd-3.png\" alt=\"nfs\"></p>\n"},{"title":"Procedimientos en Oracle y Postgres","_content":"\n![remoto](/images/oraclepostgres.jpg)\n\n## ORACLE\n\nComenzaremos adjuntando el script de creación de tablas e inserciones de Oracle:\n\n```\nCREATE TABLE DEPT\n(\n DEPTNO NUMBER(2),\n DNAME VARCHAR2(14),\n LOC VARCHAR2(13),\n CONSTRAINT PK_DEPT PRIMARY KEY (DEPTNO)\n);\nCREATE TABLE EMP\n(\n EMPNO NUMBER(4),\n ENAME VARCHAR2(10),\n JOB VARCHAR2(9),\n MGR NUMBER(4),\n HIREDATE DATE,\n SAL NUMBER(7, 2),\n COMM NUMBER(7, 2),\n DEPTNO NUMBER(2),\n CONSTRAINT FK_DEPTNO FOREIGN KEY (DEPTNO) REFERENCES DEPT (DEPTNO),\n CONSTRAINT PK_EMP PRIMARY KEY (EMPNO)\n);\nINSERT INTO DEPT VALUES (10, 'ACCOUNTING', 'NEW YORK');\nINSERT INTO DEPT VALUES (20, 'RESEARCH', 'DALLAS');\nINSERT INTO DEPT VALUES (30, 'SALES', 'CHICAGO');\nINSERT INTO DEPT VALUES (40, 'OPERATIONS', 'BOSTON');\nINSERT INTO EMP VALUES(7369, 'SMITH', 'CLERK', 7902,TO_DATE('17-DIC-1980', 'DD-MON-YYYY'), 800, NULL, 20);\nINSERT INTO EMP VALUES(7499, 'ALLEN', 'SALESMAN', 7698,TO_DATE('20-FEB-1981', 'DD-MON-YYYY'), 1600, 300, 30);\nINSERT INTO EMP VALUES(7521, 'WARD', 'SALESMAN', 7698,TO_DATE('22-FEB-1981', 'DD-MON-YYYY'), 1250, 500, 30);\nINSERT INTO EMP VALUES(7566, 'JONES', 'MANAGER', 7839,TO_DATE('2-ABR-1981', 'DD-MON-YYYY'), 2975, NULL, 20);\nINSERT INTO EMP VALUES(7654, 'MARTIN', 'SALESMAN', 7698,TO_DATE('28-SEP-1981', 'DD-MON-YYYY'), 1250, 1400, 30);\nINSERT INTO EMP VALUES(7698, 'BLAKE', 'MANAGER', 7839,TO_DATE('1-MAY-1981', 'DD-MON-YYYY'), 2850, NULL, 30);\nINSERT INTO EMP VALUES(7782, 'CLARK', 'MANAGER', 7839,TO_DATE('9-JUN-1981', 'DD-MON-YYYY'), 2450, NULL, 10);\nINSERT INTO EMP VALUES(7788, 'SCOTT', 'ANALYST', 7566,TO_DATE('09-DIC-1982', 'DD-MON-YYYY'), 3000, NULL, 20);\nINSERT INTO EMP VALUES(7839, 'KING', 'PRESIDENT', NULL,TO_DATE('17-NOV-1981', 'DD-MON-YYYY'), 5000, NULL, 10);\nINSERT INTO EMP VALUES(7844, 'TURNER', 'SALESMAN', 7698,TO_DATE('8-SEP-1981', 'DD-MON-YYYY'), 1500, 0, 30);\nINSERT INTO EMP VALUES(7876, 'ADAMS', 'CLERK', 7788,TO_DATE('12-ENE-1983', 'DD-MON-YYYY'), 1100, NULL, 20);\nINSERT INTO EMP VALUES(7900, 'JAMES', 'CLERK', 7698,TO_DATE('3-DIC-1981', 'DD-MON-YYYY'), 950, NULL, 30);\nINSERT INTO EMP VALUES(7902, 'FORD', 'ANALYST', 7566,TO_DATE('3-DIC-1981', 'DD-MON-YYYY'), 3000, NULL, 20);\nINSERT INTO EMP VALUES(7934, 'MILLER', 'CLERK', 7782,TO_DATE('23-ENE-1982', 'DD-MON-YYYY'), 1300, NULL, 10);\n\nCOMMIT;\n```\n\n\n\n### 1. Hacer un procedimiento que muestre el nombre y el salario del empleado cuyo código es 7082\n```\ncreate or replace procedure mostrar_7082\nIS\n    v_nombre emp.ename%type;\n    v_sal emp.sal%type;\nBEGIN\n    select ename,sal into v_nombre,v_sal \n    from emp\n    where empno= 7782;\n    dbms_output.put_line('El nombre del empleado 7082 es ' || v_nombre || ' y su salario es ' || v_sal );\nEND;\n/\n```\n\n![remoto](/images/oracle-ejercicio1.png)\n\n### 2. Hacer un procedimiento que reciba como parámetro un código de empleado y devuelva su nombre\n```\nCreate or replace procedure codigoanombreemp (p_codempleado emp.empno%type)\nIS\n    v_nombre emp.ename%type;\nBEGIN\n    select ename into v_nombre from emp where empno=p_codempleado;\n    dbms_output.put_line ('El empleado con el código ' || p_codempleado || ' es ' || v_nombre);\nEND;\n/\n```\n\n![remoto](/images/oracle-ejercicio2.png)\n\n### 3. Hacer un procedimiento que devuelva los nombres de los tres empleados más antiguos\n```\ncreate or replace procedure tresempleadosmasantiguos\nIS\ncursor c_empleados is\nselect ename from emp WHERE ROWNUM <= 3 order by hiredate asc;\nBEGIN\nFOR v_empleados in c_empleados loop\n    dbms_output.put_line (v_empleados.ename);\nend loop;\nEND;\n/\n```\n\n![remoto](/images/oracle-ejercicio5.png)\n\n### 4. Hacer un procedimiento que reciba el nombre de un tablespace y muestre los nombres de los usuarios que lo tienen como tablespace por defecto (Vista DBA_USERS)\n```\ncreate or replace procedure tablespacedefecto (p_tablespace DBA_USERS.DEFAULT_TABLESPACE%type)\nIS\ncursor c_tablespace is\nSELECT USERNAME from DBA_USERS where DEFAULT_TABLESPACE=p_tablespace;\nBEGIN\nFOR v_usuarios in c_tablespace loop\n    dbms_output.put_line (v_usuarios.USERNAME);\nend loop;\nEND;\n/\n```\n\n![remoto](/images/oracle-ejercicio3.png)\n\n### 5. Modificar el procedimiento anterior para que haga lo mismo pero devolviendo el número de usuarios que tienen ese tablespace como tablespace por defecto. Nota: Hay que convertir el procedimiento en función\n```\ncreate or replace function tablespacedefecto (p_tablespace DBA_USERS.DEFAULT_TABLESPACE%type)\nreturn number\nIS\nv_num number (4);\nBEGIN\nSELECT count(USERNAME) into v_num from DBA_USERS where DEFAULT_TABLESPACE=p_tablespace;\nreturn v_num;\nEND;\n/\n\ncreate or replace procedure mostrarfunciontablespacedefecto (p_tablespace DBA_USERS.DEFAULT_TABLESPACE%type)\nis\nv_num number;\nBEGIN\n    v_num:=tablespacedefecto(p_tablespace);\n    dbms_output.put_line ('El tablespace ' || p_tablespace || ' lo tienen ' || v_num || ' usuarios.');\nend;\n/\n```\n\n![remoto](/images/oracle-ejercicio4.png)\n\n### 6. Hacer un procedimiento llamado mostrar_usuarios_por_tablespace que muestre por pantalla un listado de los tablespaces existentes con la lista de usuarios de cada uno y el número de los mismos, así: (Vistas DBA_TABLESPACES y DBA_USERS)\n\nEn  este ejercicio en concreto utilizaremos una función creada en el anterior ejercicio para este propósito.\n\n```\ncreate or replace procedure mostrar_usuarios_por_tablespace\nis\ncursor c_tablespace is\nselect DISTINCT DEFAULT_TABLESPACE from DBA_USERS;\nBEGIN\nfor v_tablespace in c_tablespace loop\ndbms_output.put_line('Tablespace ' || v_tablespace.DEFAULT_TABLESPACE || ':');\nMOSTRARUSUARIOS(v_tablespace.DEFAULT_TABLESPACE);\ndbms_output.put_line('Total Usuarios Tablespace '|| v_tablespace.DEFAULT_TABLESPACE || ': ' || tablespacedefecto(v_tablespace.DEFAULT_TABLESPACE));\nend loop;\nend;\n/\n\n\nCREATE OR REPLACE PROCEDURE MOSTRARUSUARIOS (p_tablespace in out varchar2)\nis\ncursor c_nombre is\nselect USERNAME FROM DBA_USERS WHERE DEFAULT_TABLESPACE=p_tablespace;\nBEGIN\nFOR v_nombre in c_nombre loop\n    dbms_output.put_line('Usuario ' || v_nombre.USERNAME );\nend loop;\nend;\n/\n```\n\n![remoto](/images/oracle-ejercicio6.png)\n\n### 7. Hacer un procedimiento llamado mostrar_codigo_fuente  que reciba el nombre de otro procedimiento y muestre su código fuente. (DBA_SOURCE)\n```\ncreate or replace procedure mostrar_codigo_fuente (p_procedimiento varchar2)\nIS\ncursor c_fuente is\nselect text from DBA_SOURCE where NAME=p_procedimiento;\nBEGIN\nFOR v_fuente in c_fuente loop\n    dbms_output.put_line(v_fuente.text);\nend loop;\nend;\n/\n```\n\n![remoto](/images/oracle-ejercicio7.png)\n\n### 8. Hacer un procedimiento llamado mostrar_privilegios_usuario que reciba el nombre de un usuario y muestre sus privilegios de sistema y sus privilegios sobre objetos. (DBA_SYS_PRIVS y DBA_TAB_PRIVS)\n\n```\nCREATE OR REPLACE PROCEDURE mostrar_privilegios_usuario (p_usuario DBA_USERS.USERNAME%TYPE)\nis\ncursor c_sistema is\nSELECT GRANTEE,PRIVILEGE FROM DBA_SYS_PRIVS WHERE GRANTEE=p_usuario;\ncursor c_objeto is\nSELECT GRANTEE,PRIVILEGE FROM DBA_TAB_PRIVS WHERE GRANTEE=p_usuario;\nBEGIN\nFOR v_sistema in c_sistema loop\n    dbms_output.put_line('Privilegio de sistema: ' || v_sistema.PRIVILEGE);\nend loop;\nFOR v_objeto in c_objeto loop\n    dbms_output.put_line('Privilegiode objetos: ' || v_objeto.PRIVILEGE);\nend loop;\nEND;\n/\n```\n\n![remoto](/images/oracle-ejercicio8.png)\n\n### 9. Realiza un procedimiento llamado listar_comisiones que nos muestre por pantalla un listado de las comisiones de los empleados agrupados según la localidad donde está ubicado su departamento con el siguiente formato:\n```\nCREATE OR REPLACE PROCEDURE Listar_comisiones\nIS\ncursor c_localidad is\nselect dname,loc from dept;\nv_total number(5);\nBEGIN\nselect sum(comm) into v_total from emp; \nFOR v_localidad in c_localidad loop\n    dbms_output.put_line('Localidad: ' || v_localidad.loc);\n    dbms_output.put_line('Departamento: ' || v_localidad.dname);\n    MOSTRARCOMISIONES(v_localidad.loc);\nend loop;\ndbms_output.put_line('Total comisiones en la empresa es de: ' || v_total);\nexception\nWHEN NO_DATA_FOUND then\ndbms_output.put_line('Hay tablas vacías');\nend;\n/\n\nCREATE OR REPLACE PROCEDURE MOSTRARCOMISIONES (p_localidad in out varchar2)\nIS\ncursor c_comisiones is\nselect ename,comm from emp where deptno in (select deptno from dept where loc = p_localidad);\nv_total number(5);\nBEGIN\nselect sum(comm) into v_total from emp where deptno in  (select deptno from dept where loc = p_localidad);\nFOR v_empleado in c_comisiones loop\n    dbms_output.put_line('Empleado: ' || v_empleado.ename || '..................' || v_empleado.comm);\n    if v_empleado.comm > 10000 then\n        raise_application_error(-20001,'Hay algún empleado con más de 10.000 de comisión');\n    end if;\nend loop;\ndbms_output.put_line('Total comisiones departamento: ' || p_localidad || ' es de: ' || v_total);\nEND;\n/\n```\n\nPodemos ver en la imagen que se produce un raise ya que hay un usuario con más de 10.000 de comm.\n\n![remoto](/images/oracle-ejercicio9.png)\n\n### 10. Realiza un procedimiento que reciba el nombre de una tabla y muestre los nombres de las restricciones que tiene, a qué columna afectan y en qué consisten exactamente. (DBA_TABLES, DBA_CONSTRAINTS, DBA_CONS_COLUMNS)\n```\nSELECT CONSTRAINT_NAME,CONSTRAINT_TYPE,SEARCH_CONDITION_VC FROM DBA_CONSTRAINTS WHERE TABLE_NAME='EQUIPAR';\nSELECT CONSTRAINT_NAME,COLUMN_NAME FROM DBA_CONS_COLUMNS WHERE TABLE_NAME = 'PERSONAJE';\n\nCREATE OR REPLACE PROCEDURE MOSTRARRESTRICCIONES (p_tabla varchar2)\nis\nv_tabla varchar2(50);\nBEGIN\nv_tabla:=p_tabla;\nMOSTRARCONSSYS (v_tabla);\nMOSTRARCONSTABS (v_tabla);\nend;\n/\n\nCREATE OR REPLACE PROCEDURE MOSTRARCONSSYS (p_tabla in out varchar2)\nIS\ncursor c_system is\nSELECT CONSTRAINT_NAME,CONSTRAINT_TYPE,SEARCH_CONDITION_VC FROM DBA_CONSTRAINTS WHERE TABLE_NAME=p_tabla;\nBEGIN\nFOR v_system in c_system loop\n    dbms_output.put_line(v_system.CONSTRAINT_NAME || 'Tipo de restricción: ' || v_system.CONSTRAINT_TYPE || v_system.SEARCH_CONDITION_VC);\nend loop;\nEND;\n/\n\n\nCREATE OR REPLACE PROCEDURE MOSTRARCONSTABS (p_tabla in out varchar2)\nIS\ncursor c_tabs is\nSELECT CONSTRAINT_NAME,COLUMN_NAME FROM DBA_CONS_COLUMNS WHERE TABLE_NAME = p_tabla;\nBEGIN\nFOR v_tabs in c_tabs loop\n    dbms_output.put_line('Restricción: ' || v_tabs.CONSTRAINT_NAME || ' y la columna a la que hace referencia es: ' || v_tabs.COLUMN_NAME);\nend loop;\nEND;\n/\n```\n\n![remoto](/images/oracle-ejercicio10.png)\n\n## POSTGRESQL\n\nComenzaremos adjuntando el script de creación de tablas e inserciones de Postgres:\n\n```\ncreate table dept(\n  deptno   decimal(2,0) not null,\n  dname    varchar(14),\n  loc      varchar(13));\ncreate table emp(\n  empno    decimal(4,0) not null,\n  ename    varchar(10),\n  job      varchar(9),\n  mgr      decimal(4,0),\n  hiredate date,\n  sal      decimal(7,2),\n  comm     decimal(7,2),  \n  deptno   decimal(2,0) not null);\ncreate table bonus(\n  ename    varchar(10),\n  job      varchar(9),\n  sal      decimal,\n  comm     decimal);\ncreate table salgrade(\n  grade    decimal,\n  losal    decimal,\n  hisal    decimal);\ncreate table dummy (\n  dummy    decimal);\ninsert into dummy values (0);\ninsert into DEPT (DEPTNO, DNAME, LOC)\n  select 10, 'ACCOUNTING', 'NEW YORK' from dummy union all\n  select 20, 'RESEARCH',   'DALLAS'   from dummy union all\n  select 30, 'SALES',      'CHICAGO'  from dummy union all\n  select 40, 'OPERATIONS', 'BOSTON'   from dummy;\ninsert into emp (EMPNO, ENAME, JOB, MGR, HIREDATE, SAL, COMM, DEPTNO)\n  select 7839, 'KING',   'PRESIDENT', cast(null as integer), to_date('17-11-1981','dd-mm-yyyy'),    5000, cast(null as integer), 10 from dummy union all\n  select 7698, 'BLAKE',  'MANAGER',   7839, to_date('1-5-1981','dd-mm-yyyy'),      2850, cast(null as integer), 30 from dummy union all\n  select 7782, 'CLARK',  'MANAGER',   7839, to_date('9-6-1981','dd-mm-yyyy'),      2450, cast(null as integer), 10 from dummy union all\n  select 7566, 'JONES',  'MANAGER',   7839, to_date('2-4-1981','dd-mm-yyyy'),      2975, cast(null as integer), 20 from dummy union all\n  select 7788, 'SCOTT',  'ANALYST',   7566, to_date('13-7-87','dd-mm-rr') - 85,  3000, cast(null as integer), 20 from dummy union all\n  select 7902, 'FORD',   'ANALYST',   7566, to_date('3-12-1981','dd-mm-yyyy'),     3000, cast(null as integer), 20 from dummy union all\n  select 7369, 'SMITH',  'CLERK',     7902, to_date('17-12-1980','dd-mm-yyyy'),     800, cast(null as integer), 20 from dummy union all\n  select 7499, 'ALLEN',  'SALESMAN',  7698, to_date('20-2-1981','dd-mm-yyyy'),     1600,  300, 30 from dummy union all\n  select 7521, 'WARD',   'SALESMAN',  7698, to_date('22-2-1981','dd-mm-yyyy'),     1250,  500, 30 from dummy union all\n  select 7654, 'MARTIN', 'SALESMAN',  7698, to_date('28-9-1981','dd-mm-yyyy'),     1250, 1400, 30 from dummy union all\n  select 7844, 'TURNER', 'SALESMAN',  7698, to_date('8-9-1981','dd-mm-yyyy'),      1500,    0, 30 from dummy union all\n  select 7876, 'ADAMS',  'CLERK',     7788, to_date('13-7-87', 'dd-mm-rr') - 51, 1100, cast(null as integer), 20 from dummy union all\n  select 7900, 'JAMES',  'CLERK',     7698, to_date('3-12-1981','dd-mm-yyyy'),      950, cast(null as integer), 30 from dummy union all\n  select 7934, 'MILLER', 'CLERK',     7782, to_date('23-1-1982','dd-mm-yyyy'),     1300, cast(null as integer), 10 from dummy;\ninsert into salgrade\n  select 1,  700, 1200 from dummy union all\n  select 2, 1201, 1400 from dummy union all\n  select 3, 1401, 2000 from dummy union all\n  select 4, 2001, 3000 from dummy union all\n  select 5, 3001, 9999 from dummy;\ncommit;\n```\n\n\n\n\n### 1. Hacer un procedimiento que muestre el nombre y el salario del empleado cuyo código es 7082\n```\nCREATE or replace PROCEDURE mostrar_7082() \nAS $$\nDECLARE\n    v_nombre emp.ename%type;\n    v_salario emp.sal%type;\nBEGIN\n    select ename,sal into v_nombre,v_salario from emp where empno=7782;\n    RAISE NOTICE 'El nombre del empleado es %, y su salario es %', v_nombre,v_salario;\nEND;\n$$ LANGUAGE plpgsql;\n```\n\n![remoto](/images/postgres-ejercicio2.png)\n\n### 2. Hacer un procedimiento que reciba como parámetro un código de empleado y devuelva su nombre\n```sql\nCreate or replace procedure codigoanombreemp (p_codempleado emp.empno%type) \nAS $$\nDECLARE\n    v_nombre emp.ename%type;\nBEGIN\n    select ename into v_nombre from emp where empno=p_codempleado;\n    RAISE NOTICE 'El empleado con el código %, es %', p_codempleado,v_nombre;\nEND;\n$$ LANGUAGE plpgsql;\n```\n\n![remoto](/images/postgres-ejercicio1.png)","source":"_posts/plsql_basico.md","raw":"---\ntitle: Procedimientos en Oracle y Postgres\ncategories: Bases de Datos\n---\n\n![remoto](/images/oraclepostgres.jpg)\n\n## ORACLE\n\nComenzaremos adjuntando el script de creación de tablas e inserciones de Oracle:\n\n```\nCREATE TABLE DEPT\n(\n DEPTNO NUMBER(2),\n DNAME VARCHAR2(14),\n LOC VARCHAR2(13),\n CONSTRAINT PK_DEPT PRIMARY KEY (DEPTNO)\n);\nCREATE TABLE EMP\n(\n EMPNO NUMBER(4),\n ENAME VARCHAR2(10),\n JOB VARCHAR2(9),\n MGR NUMBER(4),\n HIREDATE DATE,\n SAL NUMBER(7, 2),\n COMM NUMBER(7, 2),\n DEPTNO NUMBER(2),\n CONSTRAINT FK_DEPTNO FOREIGN KEY (DEPTNO) REFERENCES DEPT (DEPTNO),\n CONSTRAINT PK_EMP PRIMARY KEY (EMPNO)\n);\nINSERT INTO DEPT VALUES (10, 'ACCOUNTING', 'NEW YORK');\nINSERT INTO DEPT VALUES (20, 'RESEARCH', 'DALLAS');\nINSERT INTO DEPT VALUES (30, 'SALES', 'CHICAGO');\nINSERT INTO DEPT VALUES (40, 'OPERATIONS', 'BOSTON');\nINSERT INTO EMP VALUES(7369, 'SMITH', 'CLERK', 7902,TO_DATE('17-DIC-1980', 'DD-MON-YYYY'), 800, NULL, 20);\nINSERT INTO EMP VALUES(7499, 'ALLEN', 'SALESMAN', 7698,TO_DATE('20-FEB-1981', 'DD-MON-YYYY'), 1600, 300, 30);\nINSERT INTO EMP VALUES(7521, 'WARD', 'SALESMAN', 7698,TO_DATE('22-FEB-1981', 'DD-MON-YYYY'), 1250, 500, 30);\nINSERT INTO EMP VALUES(7566, 'JONES', 'MANAGER', 7839,TO_DATE('2-ABR-1981', 'DD-MON-YYYY'), 2975, NULL, 20);\nINSERT INTO EMP VALUES(7654, 'MARTIN', 'SALESMAN', 7698,TO_DATE('28-SEP-1981', 'DD-MON-YYYY'), 1250, 1400, 30);\nINSERT INTO EMP VALUES(7698, 'BLAKE', 'MANAGER', 7839,TO_DATE('1-MAY-1981', 'DD-MON-YYYY'), 2850, NULL, 30);\nINSERT INTO EMP VALUES(7782, 'CLARK', 'MANAGER', 7839,TO_DATE('9-JUN-1981', 'DD-MON-YYYY'), 2450, NULL, 10);\nINSERT INTO EMP VALUES(7788, 'SCOTT', 'ANALYST', 7566,TO_DATE('09-DIC-1982', 'DD-MON-YYYY'), 3000, NULL, 20);\nINSERT INTO EMP VALUES(7839, 'KING', 'PRESIDENT', NULL,TO_DATE('17-NOV-1981', 'DD-MON-YYYY'), 5000, NULL, 10);\nINSERT INTO EMP VALUES(7844, 'TURNER', 'SALESMAN', 7698,TO_DATE('8-SEP-1981', 'DD-MON-YYYY'), 1500, 0, 30);\nINSERT INTO EMP VALUES(7876, 'ADAMS', 'CLERK', 7788,TO_DATE('12-ENE-1983', 'DD-MON-YYYY'), 1100, NULL, 20);\nINSERT INTO EMP VALUES(7900, 'JAMES', 'CLERK', 7698,TO_DATE('3-DIC-1981', 'DD-MON-YYYY'), 950, NULL, 30);\nINSERT INTO EMP VALUES(7902, 'FORD', 'ANALYST', 7566,TO_DATE('3-DIC-1981', 'DD-MON-YYYY'), 3000, NULL, 20);\nINSERT INTO EMP VALUES(7934, 'MILLER', 'CLERK', 7782,TO_DATE('23-ENE-1982', 'DD-MON-YYYY'), 1300, NULL, 10);\n\nCOMMIT;\n```\n\n\n\n### 1. Hacer un procedimiento que muestre el nombre y el salario del empleado cuyo código es 7082\n```\ncreate or replace procedure mostrar_7082\nIS\n    v_nombre emp.ename%type;\n    v_sal emp.sal%type;\nBEGIN\n    select ename,sal into v_nombre,v_sal \n    from emp\n    where empno= 7782;\n    dbms_output.put_line('El nombre del empleado 7082 es ' || v_nombre || ' y su salario es ' || v_sal );\nEND;\n/\n```\n\n![remoto](/images/oracle-ejercicio1.png)\n\n### 2. Hacer un procedimiento que reciba como parámetro un código de empleado y devuelva su nombre\n```\nCreate or replace procedure codigoanombreemp (p_codempleado emp.empno%type)\nIS\n    v_nombre emp.ename%type;\nBEGIN\n    select ename into v_nombre from emp where empno=p_codempleado;\n    dbms_output.put_line ('El empleado con el código ' || p_codempleado || ' es ' || v_nombre);\nEND;\n/\n```\n\n![remoto](/images/oracle-ejercicio2.png)\n\n### 3. Hacer un procedimiento que devuelva los nombres de los tres empleados más antiguos\n```\ncreate or replace procedure tresempleadosmasantiguos\nIS\ncursor c_empleados is\nselect ename from emp WHERE ROWNUM <= 3 order by hiredate asc;\nBEGIN\nFOR v_empleados in c_empleados loop\n    dbms_output.put_line (v_empleados.ename);\nend loop;\nEND;\n/\n```\n\n![remoto](/images/oracle-ejercicio5.png)\n\n### 4. Hacer un procedimiento que reciba el nombre de un tablespace y muestre los nombres de los usuarios que lo tienen como tablespace por defecto (Vista DBA_USERS)\n```\ncreate or replace procedure tablespacedefecto (p_tablespace DBA_USERS.DEFAULT_TABLESPACE%type)\nIS\ncursor c_tablespace is\nSELECT USERNAME from DBA_USERS where DEFAULT_TABLESPACE=p_tablespace;\nBEGIN\nFOR v_usuarios in c_tablespace loop\n    dbms_output.put_line (v_usuarios.USERNAME);\nend loop;\nEND;\n/\n```\n\n![remoto](/images/oracle-ejercicio3.png)\n\n### 5. Modificar el procedimiento anterior para que haga lo mismo pero devolviendo el número de usuarios que tienen ese tablespace como tablespace por defecto. Nota: Hay que convertir el procedimiento en función\n```\ncreate or replace function tablespacedefecto (p_tablespace DBA_USERS.DEFAULT_TABLESPACE%type)\nreturn number\nIS\nv_num number (4);\nBEGIN\nSELECT count(USERNAME) into v_num from DBA_USERS where DEFAULT_TABLESPACE=p_tablespace;\nreturn v_num;\nEND;\n/\n\ncreate or replace procedure mostrarfunciontablespacedefecto (p_tablespace DBA_USERS.DEFAULT_TABLESPACE%type)\nis\nv_num number;\nBEGIN\n    v_num:=tablespacedefecto(p_tablespace);\n    dbms_output.put_line ('El tablespace ' || p_tablespace || ' lo tienen ' || v_num || ' usuarios.');\nend;\n/\n```\n\n![remoto](/images/oracle-ejercicio4.png)\n\n### 6. Hacer un procedimiento llamado mostrar_usuarios_por_tablespace que muestre por pantalla un listado de los tablespaces existentes con la lista de usuarios de cada uno y el número de los mismos, así: (Vistas DBA_TABLESPACES y DBA_USERS)\n\nEn  este ejercicio en concreto utilizaremos una función creada en el anterior ejercicio para este propósito.\n\n```\ncreate or replace procedure mostrar_usuarios_por_tablespace\nis\ncursor c_tablespace is\nselect DISTINCT DEFAULT_TABLESPACE from DBA_USERS;\nBEGIN\nfor v_tablespace in c_tablespace loop\ndbms_output.put_line('Tablespace ' || v_tablespace.DEFAULT_TABLESPACE || ':');\nMOSTRARUSUARIOS(v_tablespace.DEFAULT_TABLESPACE);\ndbms_output.put_line('Total Usuarios Tablespace '|| v_tablespace.DEFAULT_TABLESPACE || ': ' || tablespacedefecto(v_tablespace.DEFAULT_TABLESPACE));\nend loop;\nend;\n/\n\n\nCREATE OR REPLACE PROCEDURE MOSTRARUSUARIOS (p_tablespace in out varchar2)\nis\ncursor c_nombre is\nselect USERNAME FROM DBA_USERS WHERE DEFAULT_TABLESPACE=p_tablespace;\nBEGIN\nFOR v_nombre in c_nombre loop\n    dbms_output.put_line('Usuario ' || v_nombre.USERNAME );\nend loop;\nend;\n/\n```\n\n![remoto](/images/oracle-ejercicio6.png)\n\n### 7. Hacer un procedimiento llamado mostrar_codigo_fuente  que reciba el nombre de otro procedimiento y muestre su código fuente. (DBA_SOURCE)\n```\ncreate or replace procedure mostrar_codigo_fuente (p_procedimiento varchar2)\nIS\ncursor c_fuente is\nselect text from DBA_SOURCE where NAME=p_procedimiento;\nBEGIN\nFOR v_fuente in c_fuente loop\n    dbms_output.put_line(v_fuente.text);\nend loop;\nend;\n/\n```\n\n![remoto](/images/oracle-ejercicio7.png)\n\n### 8. Hacer un procedimiento llamado mostrar_privilegios_usuario que reciba el nombre de un usuario y muestre sus privilegios de sistema y sus privilegios sobre objetos. (DBA_SYS_PRIVS y DBA_TAB_PRIVS)\n\n```\nCREATE OR REPLACE PROCEDURE mostrar_privilegios_usuario (p_usuario DBA_USERS.USERNAME%TYPE)\nis\ncursor c_sistema is\nSELECT GRANTEE,PRIVILEGE FROM DBA_SYS_PRIVS WHERE GRANTEE=p_usuario;\ncursor c_objeto is\nSELECT GRANTEE,PRIVILEGE FROM DBA_TAB_PRIVS WHERE GRANTEE=p_usuario;\nBEGIN\nFOR v_sistema in c_sistema loop\n    dbms_output.put_line('Privilegio de sistema: ' || v_sistema.PRIVILEGE);\nend loop;\nFOR v_objeto in c_objeto loop\n    dbms_output.put_line('Privilegiode objetos: ' || v_objeto.PRIVILEGE);\nend loop;\nEND;\n/\n```\n\n![remoto](/images/oracle-ejercicio8.png)\n\n### 9. Realiza un procedimiento llamado listar_comisiones que nos muestre por pantalla un listado de las comisiones de los empleados agrupados según la localidad donde está ubicado su departamento con el siguiente formato:\n```\nCREATE OR REPLACE PROCEDURE Listar_comisiones\nIS\ncursor c_localidad is\nselect dname,loc from dept;\nv_total number(5);\nBEGIN\nselect sum(comm) into v_total from emp; \nFOR v_localidad in c_localidad loop\n    dbms_output.put_line('Localidad: ' || v_localidad.loc);\n    dbms_output.put_line('Departamento: ' || v_localidad.dname);\n    MOSTRARCOMISIONES(v_localidad.loc);\nend loop;\ndbms_output.put_line('Total comisiones en la empresa es de: ' || v_total);\nexception\nWHEN NO_DATA_FOUND then\ndbms_output.put_line('Hay tablas vacías');\nend;\n/\n\nCREATE OR REPLACE PROCEDURE MOSTRARCOMISIONES (p_localidad in out varchar2)\nIS\ncursor c_comisiones is\nselect ename,comm from emp where deptno in (select deptno from dept where loc = p_localidad);\nv_total number(5);\nBEGIN\nselect sum(comm) into v_total from emp where deptno in  (select deptno from dept where loc = p_localidad);\nFOR v_empleado in c_comisiones loop\n    dbms_output.put_line('Empleado: ' || v_empleado.ename || '..................' || v_empleado.comm);\n    if v_empleado.comm > 10000 then\n        raise_application_error(-20001,'Hay algún empleado con más de 10.000 de comisión');\n    end if;\nend loop;\ndbms_output.put_line('Total comisiones departamento: ' || p_localidad || ' es de: ' || v_total);\nEND;\n/\n```\n\nPodemos ver en la imagen que se produce un raise ya que hay un usuario con más de 10.000 de comm.\n\n![remoto](/images/oracle-ejercicio9.png)\n\n### 10. Realiza un procedimiento que reciba el nombre de una tabla y muestre los nombres de las restricciones que tiene, a qué columna afectan y en qué consisten exactamente. (DBA_TABLES, DBA_CONSTRAINTS, DBA_CONS_COLUMNS)\n```\nSELECT CONSTRAINT_NAME,CONSTRAINT_TYPE,SEARCH_CONDITION_VC FROM DBA_CONSTRAINTS WHERE TABLE_NAME='EQUIPAR';\nSELECT CONSTRAINT_NAME,COLUMN_NAME FROM DBA_CONS_COLUMNS WHERE TABLE_NAME = 'PERSONAJE';\n\nCREATE OR REPLACE PROCEDURE MOSTRARRESTRICCIONES (p_tabla varchar2)\nis\nv_tabla varchar2(50);\nBEGIN\nv_tabla:=p_tabla;\nMOSTRARCONSSYS (v_tabla);\nMOSTRARCONSTABS (v_tabla);\nend;\n/\n\nCREATE OR REPLACE PROCEDURE MOSTRARCONSSYS (p_tabla in out varchar2)\nIS\ncursor c_system is\nSELECT CONSTRAINT_NAME,CONSTRAINT_TYPE,SEARCH_CONDITION_VC FROM DBA_CONSTRAINTS WHERE TABLE_NAME=p_tabla;\nBEGIN\nFOR v_system in c_system loop\n    dbms_output.put_line(v_system.CONSTRAINT_NAME || 'Tipo de restricción: ' || v_system.CONSTRAINT_TYPE || v_system.SEARCH_CONDITION_VC);\nend loop;\nEND;\n/\n\n\nCREATE OR REPLACE PROCEDURE MOSTRARCONSTABS (p_tabla in out varchar2)\nIS\ncursor c_tabs is\nSELECT CONSTRAINT_NAME,COLUMN_NAME FROM DBA_CONS_COLUMNS WHERE TABLE_NAME = p_tabla;\nBEGIN\nFOR v_tabs in c_tabs loop\n    dbms_output.put_line('Restricción: ' || v_tabs.CONSTRAINT_NAME || ' y la columna a la que hace referencia es: ' || v_tabs.COLUMN_NAME);\nend loop;\nEND;\n/\n```\n\n![remoto](/images/oracle-ejercicio10.png)\n\n## POSTGRESQL\n\nComenzaremos adjuntando el script de creación de tablas e inserciones de Postgres:\n\n```\ncreate table dept(\n  deptno   decimal(2,0) not null,\n  dname    varchar(14),\n  loc      varchar(13));\ncreate table emp(\n  empno    decimal(4,0) not null,\n  ename    varchar(10),\n  job      varchar(9),\n  mgr      decimal(4,0),\n  hiredate date,\n  sal      decimal(7,2),\n  comm     decimal(7,2),  \n  deptno   decimal(2,0) not null);\ncreate table bonus(\n  ename    varchar(10),\n  job      varchar(9),\n  sal      decimal,\n  comm     decimal);\ncreate table salgrade(\n  grade    decimal,\n  losal    decimal,\n  hisal    decimal);\ncreate table dummy (\n  dummy    decimal);\ninsert into dummy values (0);\ninsert into DEPT (DEPTNO, DNAME, LOC)\n  select 10, 'ACCOUNTING', 'NEW YORK' from dummy union all\n  select 20, 'RESEARCH',   'DALLAS'   from dummy union all\n  select 30, 'SALES',      'CHICAGO'  from dummy union all\n  select 40, 'OPERATIONS', 'BOSTON'   from dummy;\ninsert into emp (EMPNO, ENAME, JOB, MGR, HIREDATE, SAL, COMM, DEPTNO)\n  select 7839, 'KING',   'PRESIDENT', cast(null as integer), to_date('17-11-1981','dd-mm-yyyy'),    5000, cast(null as integer), 10 from dummy union all\n  select 7698, 'BLAKE',  'MANAGER',   7839, to_date('1-5-1981','dd-mm-yyyy'),      2850, cast(null as integer), 30 from dummy union all\n  select 7782, 'CLARK',  'MANAGER',   7839, to_date('9-6-1981','dd-mm-yyyy'),      2450, cast(null as integer), 10 from dummy union all\n  select 7566, 'JONES',  'MANAGER',   7839, to_date('2-4-1981','dd-mm-yyyy'),      2975, cast(null as integer), 20 from dummy union all\n  select 7788, 'SCOTT',  'ANALYST',   7566, to_date('13-7-87','dd-mm-rr') - 85,  3000, cast(null as integer), 20 from dummy union all\n  select 7902, 'FORD',   'ANALYST',   7566, to_date('3-12-1981','dd-mm-yyyy'),     3000, cast(null as integer), 20 from dummy union all\n  select 7369, 'SMITH',  'CLERK',     7902, to_date('17-12-1980','dd-mm-yyyy'),     800, cast(null as integer), 20 from dummy union all\n  select 7499, 'ALLEN',  'SALESMAN',  7698, to_date('20-2-1981','dd-mm-yyyy'),     1600,  300, 30 from dummy union all\n  select 7521, 'WARD',   'SALESMAN',  7698, to_date('22-2-1981','dd-mm-yyyy'),     1250,  500, 30 from dummy union all\n  select 7654, 'MARTIN', 'SALESMAN',  7698, to_date('28-9-1981','dd-mm-yyyy'),     1250, 1400, 30 from dummy union all\n  select 7844, 'TURNER', 'SALESMAN',  7698, to_date('8-9-1981','dd-mm-yyyy'),      1500,    0, 30 from dummy union all\n  select 7876, 'ADAMS',  'CLERK',     7788, to_date('13-7-87', 'dd-mm-rr') - 51, 1100, cast(null as integer), 20 from dummy union all\n  select 7900, 'JAMES',  'CLERK',     7698, to_date('3-12-1981','dd-mm-yyyy'),      950, cast(null as integer), 30 from dummy union all\n  select 7934, 'MILLER', 'CLERK',     7782, to_date('23-1-1982','dd-mm-yyyy'),     1300, cast(null as integer), 10 from dummy;\ninsert into salgrade\n  select 1,  700, 1200 from dummy union all\n  select 2, 1201, 1400 from dummy union all\n  select 3, 1401, 2000 from dummy union all\n  select 4, 2001, 3000 from dummy union all\n  select 5, 3001, 9999 from dummy;\ncommit;\n```\n\n\n\n\n### 1. Hacer un procedimiento que muestre el nombre y el salario del empleado cuyo código es 7082\n```\nCREATE or replace PROCEDURE mostrar_7082() \nAS $$\nDECLARE\n    v_nombre emp.ename%type;\n    v_salario emp.sal%type;\nBEGIN\n    select ename,sal into v_nombre,v_salario from emp where empno=7782;\n    RAISE NOTICE 'El nombre del empleado es %, y su salario es %', v_nombre,v_salario;\nEND;\n$$ LANGUAGE plpgsql;\n```\n\n![remoto](/images/postgres-ejercicio2.png)\n\n### 2. Hacer un procedimiento que reciba como parámetro un código de empleado y devuelva su nombre\n```sql\nCreate or replace procedure codigoanombreemp (p_codempleado emp.empno%type) \nAS $$\nDECLARE\n    v_nombre emp.ename%type;\nBEGIN\n    select ename into v_nombre from emp where empno=p_codempleado;\n    RAISE NOTICE 'El empleado con el código %, es %', p_codempleado,v_nombre;\nEND;\n$$ LANGUAGE plpgsql;\n```\n\n![remoto](/images/postgres-ejercicio1.png)","slug":"plsql_basico","published":1,"date":"2022-12-07T01:39:06.680Z","updated":"2023-02-17T02:01:08.792Z","_id":"cldl9ucgo000l0yi5cieaakom","comments":1,"layout":"post","photos":[],"link":"","content":"<p><img src=\"/images/oraclepostgres.jpg\" alt=\"remoto\"></p>\n<h2 id=\"ORACLE\"><a href=\"#ORACLE\" class=\"headerlink\" title=\"ORACLE\"></a>ORACLE</h2><p>Comenzaremos adjuntando el script de creación de tablas e inserciones de Oracle:</p>\n<pre><code>CREATE TABLE DEPT\n(\n DEPTNO NUMBER(2),\n DNAME VARCHAR2(14),\n LOC VARCHAR2(13),\n CONSTRAINT PK_DEPT PRIMARY KEY (DEPTNO)\n);\nCREATE TABLE EMP\n(\n EMPNO NUMBER(4),\n ENAME VARCHAR2(10),\n JOB VARCHAR2(9),\n MGR NUMBER(4),\n HIREDATE DATE,\n SAL NUMBER(7, 2),\n COMM NUMBER(7, 2),\n DEPTNO NUMBER(2),\n CONSTRAINT FK_DEPTNO FOREIGN KEY (DEPTNO) REFERENCES DEPT (DEPTNO),\n CONSTRAINT PK_EMP PRIMARY KEY (EMPNO)\n);\nINSERT INTO DEPT VALUES (10, &#39;ACCOUNTING&#39;, &#39;NEW YORK&#39;);\nINSERT INTO DEPT VALUES (20, &#39;RESEARCH&#39;, &#39;DALLAS&#39;);\nINSERT INTO DEPT VALUES (30, &#39;SALES&#39;, &#39;CHICAGO&#39;);\nINSERT INTO DEPT VALUES (40, &#39;OPERATIONS&#39;, &#39;BOSTON&#39;);\nINSERT INTO EMP VALUES(7369, &#39;SMITH&#39;, &#39;CLERK&#39;, 7902,TO_DATE(&#39;17-DIC-1980&#39;, &#39;DD-MON-YYYY&#39;), 800, NULL, 20);\nINSERT INTO EMP VALUES(7499, &#39;ALLEN&#39;, &#39;SALESMAN&#39;, 7698,TO_DATE(&#39;20-FEB-1981&#39;, &#39;DD-MON-YYYY&#39;), 1600, 300, 30);\nINSERT INTO EMP VALUES(7521, &#39;WARD&#39;, &#39;SALESMAN&#39;, 7698,TO_DATE(&#39;22-FEB-1981&#39;, &#39;DD-MON-YYYY&#39;), 1250, 500, 30);\nINSERT INTO EMP VALUES(7566, &#39;JONES&#39;, &#39;MANAGER&#39;, 7839,TO_DATE(&#39;2-ABR-1981&#39;, &#39;DD-MON-YYYY&#39;), 2975, NULL, 20);\nINSERT INTO EMP VALUES(7654, &#39;MARTIN&#39;, &#39;SALESMAN&#39;, 7698,TO_DATE(&#39;28-SEP-1981&#39;, &#39;DD-MON-YYYY&#39;), 1250, 1400, 30);\nINSERT INTO EMP VALUES(7698, &#39;BLAKE&#39;, &#39;MANAGER&#39;, 7839,TO_DATE(&#39;1-MAY-1981&#39;, &#39;DD-MON-YYYY&#39;), 2850, NULL, 30);\nINSERT INTO EMP VALUES(7782, &#39;CLARK&#39;, &#39;MANAGER&#39;, 7839,TO_DATE(&#39;9-JUN-1981&#39;, &#39;DD-MON-YYYY&#39;), 2450, NULL, 10);\nINSERT INTO EMP VALUES(7788, &#39;SCOTT&#39;, &#39;ANALYST&#39;, 7566,TO_DATE(&#39;09-DIC-1982&#39;, &#39;DD-MON-YYYY&#39;), 3000, NULL, 20);\nINSERT INTO EMP VALUES(7839, &#39;KING&#39;, &#39;PRESIDENT&#39;, NULL,TO_DATE(&#39;17-NOV-1981&#39;, &#39;DD-MON-YYYY&#39;), 5000, NULL, 10);\nINSERT INTO EMP VALUES(7844, &#39;TURNER&#39;, &#39;SALESMAN&#39;, 7698,TO_DATE(&#39;8-SEP-1981&#39;, &#39;DD-MON-YYYY&#39;), 1500, 0, 30);\nINSERT INTO EMP VALUES(7876, &#39;ADAMS&#39;, &#39;CLERK&#39;, 7788,TO_DATE(&#39;12-ENE-1983&#39;, &#39;DD-MON-YYYY&#39;), 1100, NULL, 20);\nINSERT INTO EMP VALUES(7900, &#39;JAMES&#39;, &#39;CLERK&#39;, 7698,TO_DATE(&#39;3-DIC-1981&#39;, &#39;DD-MON-YYYY&#39;), 950, NULL, 30);\nINSERT INTO EMP VALUES(7902, &#39;FORD&#39;, &#39;ANALYST&#39;, 7566,TO_DATE(&#39;3-DIC-1981&#39;, &#39;DD-MON-YYYY&#39;), 3000, NULL, 20);\nINSERT INTO EMP VALUES(7934, &#39;MILLER&#39;, &#39;CLERK&#39;, 7782,TO_DATE(&#39;23-ENE-1982&#39;, &#39;DD-MON-YYYY&#39;), 1300, NULL, 10);\n\nCOMMIT;\n</code></pre>\n<h3 id=\"1-Hacer-un-procedimiento-que-muestre-el-nombre-y-el-salario-del-empleado-cuyo-codigo-es-7082\"><a href=\"#1-Hacer-un-procedimiento-que-muestre-el-nombre-y-el-salario-del-empleado-cuyo-codigo-es-7082\" class=\"headerlink\" title=\"1. Hacer un procedimiento que muestre el nombre y el salario del empleado cuyo código es 7082\"></a>1. Hacer un procedimiento que muestre el nombre y el salario del empleado cuyo código es 7082</h3><pre><code>create or replace procedure mostrar_7082\nIS\n    v_nombre emp.ename%type;\n    v_sal emp.sal%type;\nBEGIN\n    select ename,sal into v_nombre,v_sal \n    from emp\n    where empno= 7782;\n    dbms_output.put_line(&#39;El nombre del empleado 7082 es &#39; || v_nombre || &#39; y su salario es &#39; || v_sal );\nEND;\n/\n</code></pre>\n<p><img src=\"/images/oracle-ejercicio1.png\" alt=\"remoto\"></p>\n<h3 id=\"2-Hacer-un-procedimiento-que-reciba-como-parametro-un-codigo-de-empleado-y-devuelva-su-nombre\"><a href=\"#2-Hacer-un-procedimiento-que-reciba-como-parametro-un-codigo-de-empleado-y-devuelva-su-nombre\" class=\"headerlink\" title=\"2. Hacer un procedimiento que reciba como parámetro un código de empleado y devuelva su nombre\"></a>2. Hacer un procedimiento que reciba como parámetro un código de empleado y devuelva su nombre</h3><pre><code>Create or replace procedure codigoanombreemp (p_codempleado emp.empno%type)\nIS\n    v_nombre emp.ename%type;\nBEGIN\n    select ename into v_nombre from emp where empno=p_codempleado;\n    dbms_output.put_line (&#39;El empleado con el código &#39; || p_codempleado || &#39; es &#39; || v_nombre);\nEND;\n/\n</code></pre>\n<p><img src=\"/images/oracle-ejercicio2.png\" alt=\"remoto\"></p>\n<h3 id=\"3-Hacer-un-procedimiento-que-devuelva-los-nombres-de-los-tres-empleados-mas-antiguos\"><a href=\"#3-Hacer-un-procedimiento-que-devuelva-los-nombres-de-los-tres-empleados-mas-antiguos\" class=\"headerlink\" title=\"3. Hacer un procedimiento que devuelva los nombres de los tres empleados más antiguos\"></a>3. Hacer un procedimiento que devuelva los nombres de los tres empleados más antiguos</h3><pre><code>create or replace procedure tresempleadosmasantiguos\nIS\ncursor c_empleados is\nselect ename from emp WHERE ROWNUM &lt;= 3 order by hiredate asc;\nBEGIN\nFOR v_empleados in c_empleados loop\n    dbms_output.put_line (v_empleados.ename);\nend loop;\nEND;\n/\n</code></pre>\n<p><img src=\"/images/oracle-ejercicio5.png\" alt=\"remoto\"></p>\n<h3 id=\"4-Hacer-un-procedimiento-que-reciba-el-nombre-de-un-tablespace-y-muestre-los-nombres-de-los-usuarios-que-lo-tienen-como-tablespace-por-defecto-Vista-DBA-USERS\"><a href=\"#4-Hacer-un-procedimiento-que-reciba-el-nombre-de-un-tablespace-y-muestre-los-nombres-de-los-usuarios-que-lo-tienen-como-tablespace-por-defecto-Vista-DBA-USERS\" class=\"headerlink\" title=\"4. Hacer un procedimiento que reciba el nombre de un tablespace y muestre los nombres de los usuarios que lo tienen como tablespace por defecto (Vista DBA_USERS)\"></a>4. Hacer un procedimiento que reciba el nombre de un tablespace y muestre los nombres de los usuarios que lo tienen como tablespace por defecto (Vista DBA_USERS)</h3><pre><code>create or replace procedure tablespacedefecto (p_tablespace DBA_USERS.DEFAULT_TABLESPACE%type)\nIS\ncursor c_tablespace is\nSELECT USERNAME from DBA_USERS where DEFAULT_TABLESPACE=p_tablespace;\nBEGIN\nFOR v_usuarios in c_tablespace loop\n    dbms_output.put_line (v_usuarios.USERNAME);\nend loop;\nEND;\n/\n</code></pre>\n<p><img src=\"/images/oracle-ejercicio3.png\" alt=\"remoto\"></p>\n<h3 id=\"5-Modificar-el-procedimiento-anterior-para-que-haga-lo-mismo-pero-devolviendo-el-numero-de-usuarios-que-tienen-ese-tablespace-como-tablespace-por-defecto-Nota-Hay-que-convertir-el-procedimiento-en-funcion\"><a href=\"#5-Modificar-el-procedimiento-anterior-para-que-haga-lo-mismo-pero-devolviendo-el-numero-de-usuarios-que-tienen-ese-tablespace-como-tablespace-por-defecto-Nota-Hay-que-convertir-el-procedimiento-en-funcion\" class=\"headerlink\" title=\"5. Modificar el procedimiento anterior para que haga lo mismo pero devolviendo el número de usuarios que tienen ese tablespace como tablespace por defecto. Nota: Hay que convertir el procedimiento en función\"></a>5. Modificar el procedimiento anterior para que haga lo mismo pero devolviendo el número de usuarios que tienen ese tablespace como tablespace por defecto. Nota: Hay que convertir el procedimiento en función</h3><pre><code>create or replace function tablespacedefecto (p_tablespace DBA_USERS.DEFAULT_TABLESPACE%type)\nreturn number\nIS\nv_num number (4);\nBEGIN\nSELECT count(USERNAME) into v_num from DBA_USERS where DEFAULT_TABLESPACE=p_tablespace;\nreturn v_num;\nEND;\n/\n\ncreate or replace procedure mostrarfunciontablespacedefecto (p_tablespace DBA_USERS.DEFAULT_TABLESPACE%type)\nis\nv_num number;\nBEGIN\n    v_num:=tablespacedefecto(p_tablespace);\n    dbms_output.put_line (&#39;El tablespace &#39; || p_tablespace || &#39; lo tienen &#39; || v_num || &#39; usuarios.&#39;);\nend;\n/\n</code></pre>\n<p><img src=\"/images/oracle-ejercicio4.png\" alt=\"remoto\"></p>\n<h3 id=\"6-Hacer-un-procedimiento-llamado-mostrar-usuarios-por-tablespace-que-muestre-por-pantalla-un-listado-de-los-tablespaces-existentes-con-la-lista-de-usuarios-de-cada-uno-y-el-numero-de-los-mismos-asi-Vistas-DBA-TABLESPACES-y-DBA-USERS\"><a href=\"#6-Hacer-un-procedimiento-llamado-mostrar-usuarios-por-tablespace-que-muestre-por-pantalla-un-listado-de-los-tablespaces-existentes-con-la-lista-de-usuarios-de-cada-uno-y-el-numero-de-los-mismos-asi-Vistas-DBA-TABLESPACES-y-DBA-USERS\" class=\"headerlink\" title=\"6. Hacer un procedimiento llamado mostrar_usuarios_por_tablespace que muestre por pantalla un listado de los tablespaces existentes con la lista de usuarios de cada uno y el número de los mismos, así: (Vistas DBA_TABLESPACES y DBA_USERS)\"></a>6. Hacer un procedimiento llamado mostrar_usuarios_por_tablespace que muestre por pantalla un listado de los tablespaces existentes con la lista de usuarios de cada uno y el número de los mismos, así: (Vistas DBA_TABLESPACES y DBA_USERS)</h3><p>En  este ejercicio en concreto utilizaremos una función creada en el anterior ejercicio para este propósito.</p>\n<pre><code>create or replace procedure mostrar_usuarios_por_tablespace\nis\ncursor c_tablespace is\nselect DISTINCT DEFAULT_TABLESPACE from DBA_USERS;\nBEGIN\nfor v_tablespace in c_tablespace loop\ndbms_output.put_line(&#39;Tablespace &#39; || v_tablespace.DEFAULT_TABLESPACE || &#39;:&#39;);\nMOSTRARUSUARIOS(v_tablespace.DEFAULT_TABLESPACE);\ndbms_output.put_line(&#39;Total Usuarios Tablespace &#39;|| v_tablespace.DEFAULT_TABLESPACE || &#39;: &#39; || tablespacedefecto(v_tablespace.DEFAULT_TABLESPACE));\nend loop;\nend;\n/\n\n\nCREATE OR REPLACE PROCEDURE MOSTRARUSUARIOS (p_tablespace in out varchar2)\nis\ncursor c_nombre is\nselect USERNAME FROM DBA_USERS WHERE DEFAULT_TABLESPACE=p_tablespace;\nBEGIN\nFOR v_nombre in c_nombre loop\n    dbms_output.put_line(&#39;Usuario &#39; || v_nombre.USERNAME );\nend loop;\nend;\n/\n</code></pre>\n<p><img src=\"/images/oracle-ejercicio6.png\" alt=\"remoto\"></p>\n<h3 id=\"7-Hacer-un-procedimiento-llamado-mostrar-codigo-fuente-que-reciba-el-nombre-de-otro-procedimiento-y-muestre-su-codigo-fuente-DBA-SOURCE\"><a href=\"#7-Hacer-un-procedimiento-llamado-mostrar-codigo-fuente-que-reciba-el-nombre-de-otro-procedimiento-y-muestre-su-codigo-fuente-DBA-SOURCE\" class=\"headerlink\" title=\"7. Hacer un procedimiento llamado mostrar_codigo_fuente  que reciba el nombre de otro procedimiento y muestre su código fuente. (DBA_SOURCE)\"></a>7. Hacer un procedimiento llamado mostrar_codigo_fuente  que reciba el nombre de otro procedimiento y muestre su código fuente. (DBA_SOURCE)</h3><pre><code>create or replace procedure mostrar_codigo_fuente (p_procedimiento varchar2)\nIS\ncursor c_fuente is\nselect text from DBA_SOURCE where NAME=p_procedimiento;\nBEGIN\nFOR v_fuente in c_fuente loop\n    dbms_output.put_line(v_fuente.text);\nend loop;\nend;\n/\n</code></pre>\n<p><img src=\"/images/oracle-ejercicio7.png\" alt=\"remoto\"></p>\n<h3 id=\"8-Hacer-un-procedimiento-llamado-mostrar-privilegios-usuario-que-reciba-el-nombre-de-un-usuario-y-muestre-sus-privilegios-de-sistema-y-sus-privilegios-sobre-objetos-DBA-SYS-PRIVS-y-DBA-TAB-PRIVS\"><a href=\"#8-Hacer-un-procedimiento-llamado-mostrar-privilegios-usuario-que-reciba-el-nombre-de-un-usuario-y-muestre-sus-privilegios-de-sistema-y-sus-privilegios-sobre-objetos-DBA-SYS-PRIVS-y-DBA-TAB-PRIVS\" class=\"headerlink\" title=\"8. Hacer un procedimiento llamado mostrar_privilegios_usuario que reciba el nombre de un usuario y muestre sus privilegios de sistema y sus privilegios sobre objetos. (DBA_SYS_PRIVS y DBA_TAB_PRIVS)\"></a>8. Hacer un procedimiento llamado mostrar_privilegios_usuario que reciba el nombre de un usuario y muestre sus privilegios de sistema y sus privilegios sobre objetos. (DBA_SYS_PRIVS y DBA_TAB_PRIVS)</h3><pre><code>CREATE OR REPLACE PROCEDURE mostrar_privilegios_usuario (p_usuario DBA_USERS.USERNAME%TYPE)\nis\ncursor c_sistema is\nSELECT GRANTEE,PRIVILEGE FROM DBA_SYS_PRIVS WHERE GRANTEE=p_usuario;\ncursor c_objeto is\nSELECT GRANTEE,PRIVILEGE FROM DBA_TAB_PRIVS WHERE GRANTEE=p_usuario;\nBEGIN\nFOR v_sistema in c_sistema loop\n    dbms_output.put_line(&#39;Privilegio de sistema: &#39; || v_sistema.PRIVILEGE);\nend loop;\nFOR v_objeto in c_objeto loop\n    dbms_output.put_line(&#39;Privilegiode objetos: &#39; || v_objeto.PRIVILEGE);\nend loop;\nEND;\n/\n</code></pre>\n<p><img src=\"/images/oracle-ejercicio8.png\" alt=\"remoto\"></p>\n<h3 id=\"9-Realiza-un-procedimiento-llamado-listar-comisiones-que-nos-muestre-por-pantalla-un-listado-de-las-comisiones-de-los-empleados-agrupados-segun-la-localidad-donde-esta-ubicado-su-departamento-con-el-siguiente-formato\"><a href=\"#9-Realiza-un-procedimiento-llamado-listar-comisiones-que-nos-muestre-por-pantalla-un-listado-de-las-comisiones-de-los-empleados-agrupados-segun-la-localidad-donde-esta-ubicado-su-departamento-con-el-siguiente-formato\" class=\"headerlink\" title=\"9. Realiza un procedimiento llamado listar_comisiones que nos muestre por pantalla un listado de las comisiones de los empleados agrupados según la localidad donde está ubicado su departamento con el siguiente formato:\"></a>9. Realiza un procedimiento llamado listar_comisiones que nos muestre por pantalla un listado de las comisiones de los empleados agrupados según la localidad donde está ubicado su departamento con el siguiente formato:</h3><pre><code>CREATE OR REPLACE PROCEDURE Listar_comisiones\nIS\ncursor c_localidad is\nselect dname,loc from dept;\nv_total number(5);\nBEGIN\nselect sum(comm) into v_total from emp; \nFOR v_localidad in c_localidad loop\n    dbms_output.put_line(&#39;Localidad: &#39; || v_localidad.loc);\n    dbms_output.put_line(&#39;Departamento: &#39; || v_localidad.dname);\n    MOSTRARCOMISIONES(v_localidad.loc);\nend loop;\ndbms_output.put_line(&#39;Total comisiones en la empresa es de: &#39; || v_total);\nexception\nWHEN NO_DATA_FOUND then\ndbms_output.put_line(&#39;Hay tablas vacías&#39;);\nend;\n/\n\nCREATE OR REPLACE PROCEDURE MOSTRARCOMISIONES (p_localidad in out varchar2)\nIS\ncursor c_comisiones is\nselect ename,comm from emp where deptno in (select deptno from dept where loc = p_localidad);\nv_total number(5);\nBEGIN\nselect sum(comm) into v_total from emp where deptno in  (select deptno from dept where loc = p_localidad);\nFOR v_empleado in c_comisiones loop\n    dbms_output.put_line(&#39;Empleado: &#39; || v_empleado.ename || &#39;..................&#39; || v_empleado.comm);\n    if v_empleado.comm &gt; 10000 then\n        raise_application_error(-20001,&#39;Hay algún empleado con más de 10.000 de comisión&#39;);\n    end if;\nend loop;\ndbms_output.put_line(&#39;Total comisiones departamento: &#39; || p_localidad || &#39; es de: &#39; || v_total);\nEND;\n/\n</code></pre>\n<p>Podemos ver en la imagen que se produce un raise ya que hay un usuario con más de 10.000 de comm.</p>\n<p><img src=\"/images/oracle-ejercicio9.png\" alt=\"remoto\"></p>\n<h3 id=\"10-Realiza-un-procedimiento-que-reciba-el-nombre-de-una-tabla-y-muestre-los-nombres-de-las-restricciones-que-tiene-a-que-columna-afectan-y-en-que-consisten-exactamente-DBA-TABLES-DBA-CONSTRAINTS-DBA-CONS-COLUMNS\"><a href=\"#10-Realiza-un-procedimiento-que-reciba-el-nombre-de-una-tabla-y-muestre-los-nombres-de-las-restricciones-que-tiene-a-que-columna-afectan-y-en-que-consisten-exactamente-DBA-TABLES-DBA-CONSTRAINTS-DBA-CONS-COLUMNS\" class=\"headerlink\" title=\"10. Realiza un procedimiento que reciba el nombre de una tabla y muestre los nombres de las restricciones que tiene, a qué columna afectan y en qué consisten exactamente. (DBA_TABLES, DBA_CONSTRAINTS, DBA_CONS_COLUMNS)\"></a>10. Realiza un procedimiento que reciba el nombre de una tabla y muestre los nombres de las restricciones que tiene, a qué columna afectan y en qué consisten exactamente. (DBA_TABLES, DBA_CONSTRAINTS, DBA_CONS_COLUMNS)</h3><pre><code>SELECT CONSTRAINT_NAME,CONSTRAINT_TYPE,SEARCH_CONDITION_VC FROM DBA_CONSTRAINTS WHERE TABLE_NAME=&#39;EQUIPAR&#39;;\nSELECT CONSTRAINT_NAME,COLUMN_NAME FROM DBA_CONS_COLUMNS WHERE TABLE_NAME = &#39;PERSONAJE&#39;;\n\nCREATE OR REPLACE PROCEDURE MOSTRARRESTRICCIONES (p_tabla varchar2)\nis\nv_tabla varchar2(50);\nBEGIN\nv_tabla:=p_tabla;\nMOSTRARCONSSYS (v_tabla);\nMOSTRARCONSTABS (v_tabla);\nend;\n/\n\nCREATE OR REPLACE PROCEDURE MOSTRARCONSSYS (p_tabla in out varchar2)\nIS\ncursor c_system is\nSELECT CONSTRAINT_NAME,CONSTRAINT_TYPE,SEARCH_CONDITION_VC FROM DBA_CONSTRAINTS WHERE TABLE_NAME=p_tabla;\nBEGIN\nFOR v_system in c_system loop\n    dbms_output.put_line(v_system.CONSTRAINT_NAME || &#39;Tipo de restricción: &#39; || v_system.CONSTRAINT_TYPE || v_system.SEARCH_CONDITION_VC);\nend loop;\nEND;\n/\n\n\nCREATE OR REPLACE PROCEDURE MOSTRARCONSTABS (p_tabla in out varchar2)\nIS\ncursor c_tabs is\nSELECT CONSTRAINT_NAME,COLUMN_NAME FROM DBA_CONS_COLUMNS WHERE TABLE_NAME = p_tabla;\nBEGIN\nFOR v_tabs in c_tabs loop\n    dbms_output.put_line(&#39;Restricción: &#39; || v_tabs.CONSTRAINT_NAME || &#39; y la columna a la que hace referencia es: &#39; || v_tabs.COLUMN_NAME);\nend loop;\nEND;\n/\n</code></pre>\n<p><img src=\"/images/oracle-ejercicio10.png\" alt=\"remoto\"></p>\n<h2 id=\"POSTGRESQL\"><a href=\"#POSTGRESQL\" class=\"headerlink\" title=\"POSTGRESQL\"></a>POSTGRESQL</h2><p>Comenzaremos adjuntando el script de creación de tablas e inserciones de Postgres:</p>\n<pre><code>create table dept(\n  deptno   decimal(2,0) not null,\n  dname    varchar(14),\n  loc      varchar(13));\ncreate table emp(\n  empno    decimal(4,0) not null,\n  ename    varchar(10),\n  job      varchar(9),\n  mgr      decimal(4,0),\n  hiredate date,\n  sal      decimal(7,2),\n  comm     decimal(7,2),  \n  deptno   decimal(2,0) not null);\ncreate table bonus(\n  ename    varchar(10),\n  job      varchar(9),\n  sal      decimal,\n  comm     decimal);\ncreate table salgrade(\n  grade    decimal,\n  losal    decimal,\n  hisal    decimal);\ncreate table dummy (\n  dummy    decimal);\ninsert into dummy values (0);\ninsert into DEPT (DEPTNO, DNAME, LOC)\n  select 10, &#39;ACCOUNTING&#39;, &#39;NEW YORK&#39; from dummy union all\n  select 20, &#39;RESEARCH&#39;,   &#39;DALLAS&#39;   from dummy union all\n  select 30, &#39;SALES&#39;,      &#39;CHICAGO&#39;  from dummy union all\n  select 40, &#39;OPERATIONS&#39;, &#39;BOSTON&#39;   from dummy;\ninsert into emp (EMPNO, ENAME, JOB, MGR, HIREDATE, SAL, COMM, DEPTNO)\n  select 7839, &#39;KING&#39;,   &#39;PRESIDENT&#39;, cast(null as integer), to_date(&#39;17-11-1981&#39;,&#39;dd-mm-yyyy&#39;),    5000, cast(null as integer), 10 from dummy union all\n  select 7698, &#39;BLAKE&#39;,  &#39;MANAGER&#39;,   7839, to_date(&#39;1-5-1981&#39;,&#39;dd-mm-yyyy&#39;),      2850, cast(null as integer), 30 from dummy union all\n  select 7782, &#39;CLARK&#39;,  &#39;MANAGER&#39;,   7839, to_date(&#39;9-6-1981&#39;,&#39;dd-mm-yyyy&#39;),      2450, cast(null as integer), 10 from dummy union all\n  select 7566, &#39;JONES&#39;,  &#39;MANAGER&#39;,   7839, to_date(&#39;2-4-1981&#39;,&#39;dd-mm-yyyy&#39;),      2975, cast(null as integer), 20 from dummy union all\n  select 7788, &#39;SCOTT&#39;,  &#39;ANALYST&#39;,   7566, to_date(&#39;13-7-87&#39;,&#39;dd-mm-rr&#39;) - 85,  3000, cast(null as integer), 20 from dummy union all\n  select 7902, &#39;FORD&#39;,   &#39;ANALYST&#39;,   7566, to_date(&#39;3-12-1981&#39;,&#39;dd-mm-yyyy&#39;),     3000, cast(null as integer), 20 from dummy union all\n  select 7369, &#39;SMITH&#39;,  &#39;CLERK&#39;,     7902, to_date(&#39;17-12-1980&#39;,&#39;dd-mm-yyyy&#39;),     800, cast(null as integer), 20 from dummy union all\n  select 7499, &#39;ALLEN&#39;,  &#39;SALESMAN&#39;,  7698, to_date(&#39;20-2-1981&#39;,&#39;dd-mm-yyyy&#39;),     1600,  300, 30 from dummy union all\n  select 7521, &#39;WARD&#39;,   &#39;SALESMAN&#39;,  7698, to_date(&#39;22-2-1981&#39;,&#39;dd-mm-yyyy&#39;),     1250,  500, 30 from dummy union all\n  select 7654, &#39;MARTIN&#39;, &#39;SALESMAN&#39;,  7698, to_date(&#39;28-9-1981&#39;,&#39;dd-mm-yyyy&#39;),     1250, 1400, 30 from dummy union all\n  select 7844, &#39;TURNER&#39;, &#39;SALESMAN&#39;,  7698, to_date(&#39;8-9-1981&#39;,&#39;dd-mm-yyyy&#39;),      1500,    0, 30 from dummy union all\n  select 7876, &#39;ADAMS&#39;,  &#39;CLERK&#39;,     7788, to_date(&#39;13-7-87&#39;, &#39;dd-mm-rr&#39;) - 51, 1100, cast(null as integer), 20 from dummy union all\n  select 7900, &#39;JAMES&#39;,  &#39;CLERK&#39;,     7698, to_date(&#39;3-12-1981&#39;,&#39;dd-mm-yyyy&#39;),      950, cast(null as integer), 30 from dummy union all\n  select 7934, &#39;MILLER&#39;, &#39;CLERK&#39;,     7782, to_date(&#39;23-1-1982&#39;,&#39;dd-mm-yyyy&#39;),     1300, cast(null as integer), 10 from dummy;\ninsert into salgrade\n  select 1,  700, 1200 from dummy union all\n  select 2, 1201, 1400 from dummy union all\n  select 3, 1401, 2000 from dummy union all\n  select 4, 2001, 3000 from dummy union all\n  select 5, 3001, 9999 from dummy;\ncommit;\n</code></pre>\n<h3 id=\"1-Hacer-un-procedimiento-que-muestre-el-nombre-y-el-salario-del-empleado-cuyo-codigo-es-7082-1\"><a href=\"#1-Hacer-un-procedimiento-que-muestre-el-nombre-y-el-salario-del-empleado-cuyo-codigo-es-7082-1\" class=\"headerlink\" title=\"1. Hacer un procedimiento que muestre el nombre y el salario del empleado cuyo código es 7082\"></a>1. Hacer un procedimiento que muestre el nombre y el salario del empleado cuyo código es 7082</h3><pre><code>CREATE or replace PROCEDURE mostrar_7082() \nAS $$\nDECLARE\n    v_nombre emp.ename%type;\n    v_salario emp.sal%type;\nBEGIN\n    select ename,sal into v_nombre,v_salario from emp where empno=7782;\n    RAISE NOTICE &#39;El nombre del empleado es %, y su salario es %&#39;, v_nombre,v_salario;\nEND;\n$$ LANGUAGE plpgsql;\n</code></pre>\n<p><img src=\"/images/postgres-ejercicio2.png\" alt=\"remoto\"></p>\n<h3 id=\"2-Hacer-un-procedimiento-que-reciba-como-parametro-un-codigo-de-empleado-y-devuelva-su-nombre-1\"><a href=\"#2-Hacer-un-procedimiento-que-reciba-como-parametro-un-codigo-de-empleado-y-devuelva-su-nombre-1\" class=\"headerlink\" title=\"2. Hacer un procedimiento que reciba como parámetro un código de empleado y devuelva su nombre\"></a>2. Hacer un procedimiento que reciba como parámetro un código de empleado y devuelva su nombre</h3><pre><code class=\"sql\">Create or replace procedure codigoanombreemp (p_codempleado emp.empno%type) \nAS $$\nDECLARE\n    v_nombre emp.ename%type;\nBEGIN\n    select ename into v_nombre from emp where empno=p_codempleado;\n    RAISE NOTICE &#39;El empleado con el código %, es %&#39;, p_codempleado,v_nombre;\nEND;\n$$ LANGUAGE plpgsql;\n</code></pre>\n<p><img src=\"/images/postgres-ejercicio1.png\" alt=\"remoto\"></p>\n","site":{"data":{}},"length":12755,"excerpt":"","more":"<p><img src=\"/images/oraclepostgres.jpg\" alt=\"remoto\"></p>\n<h2 id=\"ORACLE\"><a href=\"#ORACLE\" class=\"headerlink\" title=\"ORACLE\"></a>ORACLE</h2><p>Comenzaremos adjuntando el script de creación de tablas e inserciones de Oracle:</p>\n<pre><code>CREATE TABLE DEPT\n(\n DEPTNO NUMBER(2),\n DNAME VARCHAR2(14),\n LOC VARCHAR2(13),\n CONSTRAINT PK_DEPT PRIMARY KEY (DEPTNO)\n);\nCREATE TABLE EMP\n(\n EMPNO NUMBER(4),\n ENAME VARCHAR2(10),\n JOB VARCHAR2(9),\n MGR NUMBER(4),\n HIREDATE DATE,\n SAL NUMBER(7, 2),\n COMM NUMBER(7, 2),\n DEPTNO NUMBER(2),\n CONSTRAINT FK_DEPTNO FOREIGN KEY (DEPTNO) REFERENCES DEPT (DEPTNO),\n CONSTRAINT PK_EMP PRIMARY KEY (EMPNO)\n);\nINSERT INTO DEPT VALUES (10, &#39;ACCOUNTING&#39;, &#39;NEW YORK&#39;);\nINSERT INTO DEPT VALUES (20, &#39;RESEARCH&#39;, &#39;DALLAS&#39;);\nINSERT INTO DEPT VALUES (30, &#39;SALES&#39;, &#39;CHICAGO&#39;);\nINSERT INTO DEPT VALUES (40, &#39;OPERATIONS&#39;, &#39;BOSTON&#39;);\nINSERT INTO EMP VALUES(7369, &#39;SMITH&#39;, &#39;CLERK&#39;, 7902,TO_DATE(&#39;17-DIC-1980&#39;, &#39;DD-MON-YYYY&#39;), 800, NULL, 20);\nINSERT INTO EMP VALUES(7499, &#39;ALLEN&#39;, &#39;SALESMAN&#39;, 7698,TO_DATE(&#39;20-FEB-1981&#39;, &#39;DD-MON-YYYY&#39;), 1600, 300, 30);\nINSERT INTO EMP VALUES(7521, &#39;WARD&#39;, &#39;SALESMAN&#39;, 7698,TO_DATE(&#39;22-FEB-1981&#39;, &#39;DD-MON-YYYY&#39;), 1250, 500, 30);\nINSERT INTO EMP VALUES(7566, &#39;JONES&#39;, &#39;MANAGER&#39;, 7839,TO_DATE(&#39;2-ABR-1981&#39;, &#39;DD-MON-YYYY&#39;), 2975, NULL, 20);\nINSERT INTO EMP VALUES(7654, &#39;MARTIN&#39;, &#39;SALESMAN&#39;, 7698,TO_DATE(&#39;28-SEP-1981&#39;, &#39;DD-MON-YYYY&#39;), 1250, 1400, 30);\nINSERT INTO EMP VALUES(7698, &#39;BLAKE&#39;, &#39;MANAGER&#39;, 7839,TO_DATE(&#39;1-MAY-1981&#39;, &#39;DD-MON-YYYY&#39;), 2850, NULL, 30);\nINSERT INTO EMP VALUES(7782, &#39;CLARK&#39;, &#39;MANAGER&#39;, 7839,TO_DATE(&#39;9-JUN-1981&#39;, &#39;DD-MON-YYYY&#39;), 2450, NULL, 10);\nINSERT INTO EMP VALUES(7788, &#39;SCOTT&#39;, &#39;ANALYST&#39;, 7566,TO_DATE(&#39;09-DIC-1982&#39;, &#39;DD-MON-YYYY&#39;), 3000, NULL, 20);\nINSERT INTO EMP VALUES(7839, &#39;KING&#39;, &#39;PRESIDENT&#39;, NULL,TO_DATE(&#39;17-NOV-1981&#39;, &#39;DD-MON-YYYY&#39;), 5000, NULL, 10);\nINSERT INTO EMP VALUES(7844, &#39;TURNER&#39;, &#39;SALESMAN&#39;, 7698,TO_DATE(&#39;8-SEP-1981&#39;, &#39;DD-MON-YYYY&#39;), 1500, 0, 30);\nINSERT INTO EMP VALUES(7876, &#39;ADAMS&#39;, &#39;CLERK&#39;, 7788,TO_DATE(&#39;12-ENE-1983&#39;, &#39;DD-MON-YYYY&#39;), 1100, NULL, 20);\nINSERT INTO EMP VALUES(7900, &#39;JAMES&#39;, &#39;CLERK&#39;, 7698,TO_DATE(&#39;3-DIC-1981&#39;, &#39;DD-MON-YYYY&#39;), 950, NULL, 30);\nINSERT INTO EMP VALUES(7902, &#39;FORD&#39;, &#39;ANALYST&#39;, 7566,TO_DATE(&#39;3-DIC-1981&#39;, &#39;DD-MON-YYYY&#39;), 3000, NULL, 20);\nINSERT INTO EMP VALUES(7934, &#39;MILLER&#39;, &#39;CLERK&#39;, 7782,TO_DATE(&#39;23-ENE-1982&#39;, &#39;DD-MON-YYYY&#39;), 1300, NULL, 10);\n\nCOMMIT;\n</code></pre>\n<h3 id=\"1-Hacer-un-procedimiento-que-muestre-el-nombre-y-el-salario-del-empleado-cuyo-codigo-es-7082\"><a href=\"#1-Hacer-un-procedimiento-que-muestre-el-nombre-y-el-salario-del-empleado-cuyo-codigo-es-7082\" class=\"headerlink\" title=\"1. Hacer un procedimiento que muestre el nombre y el salario del empleado cuyo código es 7082\"></a>1. Hacer un procedimiento que muestre el nombre y el salario del empleado cuyo código es 7082</h3><pre><code>create or replace procedure mostrar_7082\nIS\n    v_nombre emp.ename%type;\n    v_sal emp.sal%type;\nBEGIN\n    select ename,sal into v_nombre,v_sal \n    from emp\n    where empno= 7782;\n    dbms_output.put_line(&#39;El nombre del empleado 7082 es &#39; || v_nombre || &#39; y su salario es &#39; || v_sal );\nEND;\n/\n</code></pre>\n<p><img src=\"/images/oracle-ejercicio1.png\" alt=\"remoto\"></p>\n<h3 id=\"2-Hacer-un-procedimiento-que-reciba-como-parametro-un-codigo-de-empleado-y-devuelva-su-nombre\"><a href=\"#2-Hacer-un-procedimiento-que-reciba-como-parametro-un-codigo-de-empleado-y-devuelva-su-nombre\" class=\"headerlink\" title=\"2. Hacer un procedimiento que reciba como parámetro un código de empleado y devuelva su nombre\"></a>2. Hacer un procedimiento que reciba como parámetro un código de empleado y devuelva su nombre</h3><pre><code>Create or replace procedure codigoanombreemp (p_codempleado emp.empno%type)\nIS\n    v_nombre emp.ename%type;\nBEGIN\n    select ename into v_nombre from emp where empno=p_codempleado;\n    dbms_output.put_line (&#39;El empleado con el código &#39; || p_codempleado || &#39; es &#39; || v_nombre);\nEND;\n/\n</code></pre>\n<p><img src=\"/images/oracle-ejercicio2.png\" alt=\"remoto\"></p>\n<h3 id=\"3-Hacer-un-procedimiento-que-devuelva-los-nombres-de-los-tres-empleados-mas-antiguos\"><a href=\"#3-Hacer-un-procedimiento-que-devuelva-los-nombres-de-los-tres-empleados-mas-antiguos\" class=\"headerlink\" title=\"3. Hacer un procedimiento que devuelva los nombres de los tres empleados más antiguos\"></a>3. Hacer un procedimiento que devuelva los nombres de los tres empleados más antiguos</h3><pre><code>create or replace procedure tresempleadosmasantiguos\nIS\ncursor c_empleados is\nselect ename from emp WHERE ROWNUM &lt;= 3 order by hiredate asc;\nBEGIN\nFOR v_empleados in c_empleados loop\n    dbms_output.put_line (v_empleados.ename);\nend loop;\nEND;\n/\n</code></pre>\n<p><img src=\"/images/oracle-ejercicio5.png\" alt=\"remoto\"></p>\n<h3 id=\"4-Hacer-un-procedimiento-que-reciba-el-nombre-de-un-tablespace-y-muestre-los-nombres-de-los-usuarios-que-lo-tienen-como-tablespace-por-defecto-Vista-DBA-USERS\"><a href=\"#4-Hacer-un-procedimiento-que-reciba-el-nombre-de-un-tablespace-y-muestre-los-nombres-de-los-usuarios-que-lo-tienen-como-tablespace-por-defecto-Vista-DBA-USERS\" class=\"headerlink\" title=\"4. Hacer un procedimiento que reciba el nombre de un tablespace y muestre los nombres de los usuarios que lo tienen como tablespace por defecto (Vista DBA_USERS)\"></a>4. Hacer un procedimiento que reciba el nombre de un tablespace y muestre los nombres de los usuarios que lo tienen como tablespace por defecto (Vista DBA_USERS)</h3><pre><code>create or replace procedure tablespacedefecto (p_tablespace DBA_USERS.DEFAULT_TABLESPACE%type)\nIS\ncursor c_tablespace is\nSELECT USERNAME from DBA_USERS where DEFAULT_TABLESPACE=p_tablespace;\nBEGIN\nFOR v_usuarios in c_tablespace loop\n    dbms_output.put_line (v_usuarios.USERNAME);\nend loop;\nEND;\n/\n</code></pre>\n<p><img src=\"/images/oracle-ejercicio3.png\" alt=\"remoto\"></p>\n<h3 id=\"5-Modificar-el-procedimiento-anterior-para-que-haga-lo-mismo-pero-devolviendo-el-numero-de-usuarios-que-tienen-ese-tablespace-como-tablespace-por-defecto-Nota-Hay-que-convertir-el-procedimiento-en-funcion\"><a href=\"#5-Modificar-el-procedimiento-anterior-para-que-haga-lo-mismo-pero-devolviendo-el-numero-de-usuarios-que-tienen-ese-tablespace-como-tablespace-por-defecto-Nota-Hay-que-convertir-el-procedimiento-en-funcion\" class=\"headerlink\" title=\"5. Modificar el procedimiento anterior para que haga lo mismo pero devolviendo el número de usuarios que tienen ese tablespace como tablespace por defecto. Nota: Hay que convertir el procedimiento en función\"></a>5. Modificar el procedimiento anterior para que haga lo mismo pero devolviendo el número de usuarios que tienen ese tablespace como tablespace por defecto. Nota: Hay que convertir el procedimiento en función</h3><pre><code>create or replace function tablespacedefecto (p_tablespace DBA_USERS.DEFAULT_TABLESPACE%type)\nreturn number\nIS\nv_num number (4);\nBEGIN\nSELECT count(USERNAME) into v_num from DBA_USERS where DEFAULT_TABLESPACE=p_tablespace;\nreturn v_num;\nEND;\n/\n\ncreate or replace procedure mostrarfunciontablespacedefecto (p_tablespace DBA_USERS.DEFAULT_TABLESPACE%type)\nis\nv_num number;\nBEGIN\n    v_num:=tablespacedefecto(p_tablespace);\n    dbms_output.put_line (&#39;El tablespace &#39; || p_tablespace || &#39; lo tienen &#39; || v_num || &#39; usuarios.&#39;);\nend;\n/\n</code></pre>\n<p><img src=\"/images/oracle-ejercicio4.png\" alt=\"remoto\"></p>\n<h3 id=\"6-Hacer-un-procedimiento-llamado-mostrar-usuarios-por-tablespace-que-muestre-por-pantalla-un-listado-de-los-tablespaces-existentes-con-la-lista-de-usuarios-de-cada-uno-y-el-numero-de-los-mismos-asi-Vistas-DBA-TABLESPACES-y-DBA-USERS\"><a href=\"#6-Hacer-un-procedimiento-llamado-mostrar-usuarios-por-tablespace-que-muestre-por-pantalla-un-listado-de-los-tablespaces-existentes-con-la-lista-de-usuarios-de-cada-uno-y-el-numero-de-los-mismos-asi-Vistas-DBA-TABLESPACES-y-DBA-USERS\" class=\"headerlink\" title=\"6. Hacer un procedimiento llamado mostrar_usuarios_por_tablespace que muestre por pantalla un listado de los tablespaces existentes con la lista de usuarios de cada uno y el número de los mismos, así: (Vistas DBA_TABLESPACES y DBA_USERS)\"></a>6. Hacer un procedimiento llamado mostrar_usuarios_por_tablespace que muestre por pantalla un listado de los tablespaces existentes con la lista de usuarios de cada uno y el número de los mismos, así: (Vistas DBA_TABLESPACES y DBA_USERS)</h3><p>En  este ejercicio en concreto utilizaremos una función creada en el anterior ejercicio para este propósito.</p>\n<pre><code>create or replace procedure mostrar_usuarios_por_tablespace\nis\ncursor c_tablespace is\nselect DISTINCT DEFAULT_TABLESPACE from DBA_USERS;\nBEGIN\nfor v_tablespace in c_tablespace loop\ndbms_output.put_line(&#39;Tablespace &#39; || v_tablespace.DEFAULT_TABLESPACE || &#39;:&#39;);\nMOSTRARUSUARIOS(v_tablespace.DEFAULT_TABLESPACE);\ndbms_output.put_line(&#39;Total Usuarios Tablespace &#39;|| v_tablespace.DEFAULT_TABLESPACE || &#39;: &#39; || tablespacedefecto(v_tablespace.DEFAULT_TABLESPACE));\nend loop;\nend;\n/\n\n\nCREATE OR REPLACE PROCEDURE MOSTRARUSUARIOS (p_tablespace in out varchar2)\nis\ncursor c_nombre is\nselect USERNAME FROM DBA_USERS WHERE DEFAULT_TABLESPACE=p_tablespace;\nBEGIN\nFOR v_nombre in c_nombre loop\n    dbms_output.put_line(&#39;Usuario &#39; || v_nombre.USERNAME );\nend loop;\nend;\n/\n</code></pre>\n<p><img src=\"/images/oracle-ejercicio6.png\" alt=\"remoto\"></p>\n<h3 id=\"7-Hacer-un-procedimiento-llamado-mostrar-codigo-fuente-que-reciba-el-nombre-de-otro-procedimiento-y-muestre-su-codigo-fuente-DBA-SOURCE\"><a href=\"#7-Hacer-un-procedimiento-llamado-mostrar-codigo-fuente-que-reciba-el-nombre-de-otro-procedimiento-y-muestre-su-codigo-fuente-DBA-SOURCE\" class=\"headerlink\" title=\"7. Hacer un procedimiento llamado mostrar_codigo_fuente  que reciba el nombre de otro procedimiento y muestre su código fuente. (DBA_SOURCE)\"></a>7. Hacer un procedimiento llamado mostrar_codigo_fuente  que reciba el nombre de otro procedimiento y muestre su código fuente. (DBA_SOURCE)</h3><pre><code>create or replace procedure mostrar_codigo_fuente (p_procedimiento varchar2)\nIS\ncursor c_fuente is\nselect text from DBA_SOURCE where NAME=p_procedimiento;\nBEGIN\nFOR v_fuente in c_fuente loop\n    dbms_output.put_line(v_fuente.text);\nend loop;\nend;\n/\n</code></pre>\n<p><img src=\"/images/oracle-ejercicio7.png\" alt=\"remoto\"></p>\n<h3 id=\"8-Hacer-un-procedimiento-llamado-mostrar-privilegios-usuario-que-reciba-el-nombre-de-un-usuario-y-muestre-sus-privilegios-de-sistema-y-sus-privilegios-sobre-objetos-DBA-SYS-PRIVS-y-DBA-TAB-PRIVS\"><a href=\"#8-Hacer-un-procedimiento-llamado-mostrar-privilegios-usuario-que-reciba-el-nombre-de-un-usuario-y-muestre-sus-privilegios-de-sistema-y-sus-privilegios-sobre-objetos-DBA-SYS-PRIVS-y-DBA-TAB-PRIVS\" class=\"headerlink\" title=\"8. Hacer un procedimiento llamado mostrar_privilegios_usuario que reciba el nombre de un usuario y muestre sus privilegios de sistema y sus privilegios sobre objetos. (DBA_SYS_PRIVS y DBA_TAB_PRIVS)\"></a>8. Hacer un procedimiento llamado mostrar_privilegios_usuario que reciba el nombre de un usuario y muestre sus privilegios de sistema y sus privilegios sobre objetos. (DBA_SYS_PRIVS y DBA_TAB_PRIVS)</h3><pre><code>CREATE OR REPLACE PROCEDURE mostrar_privilegios_usuario (p_usuario DBA_USERS.USERNAME%TYPE)\nis\ncursor c_sistema is\nSELECT GRANTEE,PRIVILEGE FROM DBA_SYS_PRIVS WHERE GRANTEE=p_usuario;\ncursor c_objeto is\nSELECT GRANTEE,PRIVILEGE FROM DBA_TAB_PRIVS WHERE GRANTEE=p_usuario;\nBEGIN\nFOR v_sistema in c_sistema loop\n    dbms_output.put_line(&#39;Privilegio de sistema: &#39; || v_sistema.PRIVILEGE);\nend loop;\nFOR v_objeto in c_objeto loop\n    dbms_output.put_line(&#39;Privilegiode objetos: &#39; || v_objeto.PRIVILEGE);\nend loop;\nEND;\n/\n</code></pre>\n<p><img src=\"/images/oracle-ejercicio8.png\" alt=\"remoto\"></p>\n<h3 id=\"9-Realiza-un-procedimiento-llamado-listar-comisiones-que-nos-muestre-por-pantalla-un-listado-de-las-comisiones-de-los-empleados-agrupados-segun-la-localidad-donde-esta-ubicado-su-departamento-con-el-siguiente-formato\"><a href=\"#9-Realiza-un-procedimiento-llamado-listar-comisiones-que-nos-muestre-por-pantalla-un-listado-de-las-comisiones-de-los-empleados-agrupados-segun-la-localidad-donde-esta-ubicado-su-departamento-con-el-siguiente-formato\" class=\"headerlink\" title=\"9. Realiza un procedimiento llamado listar_comisiones que nos muestre por pantalla un listado de las comisiones de los empleados agrupados según la localidad donde está ubicado su departamento con el siguiente formato:\"></a>9. Realiza un procedimiento llamado listar_comisiones que nos muestre por pantalla un listado de las comisiones de los empleados agrupados según la localidad donde está ubicado su departamento con el siguiente formato:</h3><pre><code>CREATE OR REPLACE PROCEDURE Listar_comisiones\nIS\ncursor c_localidad is\nselect dname,loc from dept;\nv_total number(5);\nBEGIN\nselect sum(comm) into v_total from emp; \nFOR v_localidad in c_localidad loop\n    dbms_output.put_line(&#39;Localidad: &#39; || v_localidad.loc);\n    dbms_output.put_line(&#39;Departamento: &#39; || v_localidad.dname);\n    MOSTRARCOMISIONES(v_localidad.loc);\nend loop;\ndbms_output.put_line(&#39;Total comisiones en la empresa es de: &#39; || v_total);\nexception\nWHEN NO_DATA_FOUND then\ndbms_output.put_line(&#39;Hay tablas vacías&#39;);\nend;\n/\n\nCREATE OR REPLACE PROCEDURE MOSTRARCOMISIONES (p_localidad in out varchar2)\nIS\ncursor c_comisiones is\nselect ename,comm from emp where deptno in (select deptno from dept where loc = p_localidad);\nv_total number(5);\nBEGIN\nselect sum(comm) into v_total from emp where deptno in  (select deptno from dept where loc = p_localidad);\nFOR v_empleado in c_comisiones loop\n    dbms_output.put_line(&#39;Empleado: &#39; || v_empleado.ename || &#39;..................&#39; || v_empleado.comm);\n    if v_empleado.comm &gt; 10000 then\n        raise_application_error(-20001,&#39;Hay algún empleado con más de 10.000 de comisión&#39;);\n    end if;\nend loop;\ndbms_output.put_line(&#39;Total comisiones departamento: &#39; || p_localidad || &#39; es de: &#39; || v_total);\nEND;\n/\n</code></pre>\n<p>Podemos ver en la imagen que se produce un raise ya que hay un usuario con más de 10.000 de comm.</p>\n<p><img src=\"/images/oracle-ejercicio9.png\" alt=\"remoto\"></p>\n<h3 id=\"10-Realiza-un-procedimiento-que-reciba-el-nombre-de-una-tabla-y-muestre-los-nombres-de-las-restricciones-que-tiene-a-que-columna-afectan-y-en-que-consisten-exactamente-DBA-TABLES-DBA-CONSTRAINTS-DBA-CONS-COLUMNS\"><a href=\"#10-Realiza-un-procedimiento-que-reciba-el-nombre-de-una-tabla-y-muestre-los-nombres-de-las-restricciones-que-tiene-a-que-columna-afectan-y-en-que-consisten-exactamente-DBA-TABLES-DBA-CONSTRAINTS-DBA-CONS-COLUMNS\" class=\"headerlink\" title=\"10. Realiza un procedimiento que reciba el nombre de una tabla y muestre los nombres de las restricciones que tiene, a qué columna afectan y en qué consisten exactamente. (DBA_TABLES, DBA_CONSTRAINTS, DBA_CONS_COLUMNS)\"></a>10. Realiza un procedimiento que reciba el nombre de una tabla y muestre los nombres de las restricciones que tiene, a qué columna afectan y en qué consisten exactamente. (DBA_TABLES, DBA_CONSTRAINTS, DBA_CONS_COLUMNS)</h3><pre><code>SELECT CONSTRAINT_NAME,CONSTRAINT_TYPE,SEARCH_CONDITION_VC FROM DBA_CONSTRAINTS WHERE TABLE_NAME=&#39;EQUIPAR&#39;;\nSELECT CONSTRAINT_NAME,COLUMN_NAME FROM DBA_CONS_COLUMNS WHERE TABLE_NAME = &#39;PERSONAJE&#39;;\n\nCREATE OR REPLACE PROCEDURE MOSTRARRESTRICCIONES (p_tabla varchar2)\nis\nv_tabla varchar2(50);\nBEGIN\nv_tabla:=p_tabla;\nMOSTRARCONSSYS (v_tabla);\nMOSTRARCONSTABS (v_tabla);\nend;\n/\n\nCREATE OR REPLACE PROCEDURE MOSTRARCONSSYS (p_tabla in out varchar2)\nIS\ncursor c_system is\nSELECT CONSTRAINT_NAME,CONSTRAINT_TYPE,SEARCH_CONDITION_VC FROM DBA_CONSTRAINTS WHERE TABLE_NAME=p_tabla;\nBEGIN\nFOR v_system in c_system loop\n    dbms_output.put_line(v_system.CONSTRAINT_NAME || &#39;Tipo de restricción: &#39; || v_system.CONSTRAINT_TYPE || v_system.SEARCH_CONDITION_VC);\nend loop;\nEND;\n/\n\n\nCREATE OR REPLACE PROCEDURE MOSTRARCONSTABS (p_tabla in out varchar2)\nIS\ncursor c_tabs is\nSELECT CONSTRAINT_NAME,COLUMN_NAME FROM DBA_CONS_COLUMNS WHERE TABLE_NAME = p_tabla;\nBEGIN\nFOR v_tabs in c_tabs loop\n    dbms_output.put_line(&#39;Restricción: &#39; || v_tabs.CONSTRAINT_NAME || &#39; y la columna a la que hace referencia es: &#39; || v_tabs.COLUMN_NAME);\nend loop;\nEND;\n/\n</code></pre>\n<p><img src=\"/images/oracle-ejercicio10.png\" alt=\"remoto\"></p>\n<h2 id=\"POSTGRESQL\"><a href=\"#POSTGRESQL\" class=\"headerlink\" title=\"POSTGRESQL\"></a>POSTGRESQL</h2><p>Comenzaremos adjuntando el script de creación de tablas e inserciones de Postgres:</p>\n<pre><code>create table dept(\n  deptno   decimal(2,0) not null,\n  dname    varchar(14),\n  loc      varchar(13));\ncreate table emp(\n  empno    decimal(4,0) not null,\n  ename    varchar(10),\n  job      varchar(9),\n  mgr      decimal(4,0),\n  hiredate date,\n  sal      decimal(7,2),\n  comm     decimal(7,2),  \n  deptno   decimal(2,0) not null);\ncreate table bonus(\n  ename    varchar(10),\n  job      varchar(9),\n  sal      decimal,\n  comm     decimal);\ncreate table salgrade(\n  grade    decimal,\n  losal    decimal,\n  hisal    decimal);\ncreate table dummy (\n  dummy    decimal);\ninsert into dummy values (0);\ninsert into DEPT (DEPTNO, DNAME, LOC)\n  select 10, &#39;ACCOUNTING&#39;, &#39;NEW YORK&#39; from dummy union all\n  select 20, &#39;RESEARCH&#39;,   &#39;DALLAS&#39;   from dummy union all\n  select 30, &#39;SALES&#39;,      &#39;CHICAGO&#39;  from dummy union all\n  select 40, &#39;OPERATIONS&#39;, &#39;BOSTON&#39;   from dummy;\ninsert into emp (EMPNO, ENAME, JOB, MGR, HIREDATE, SAL, COMM, DEPTNO)\n  select 7839, &#39;KING&#39;,   &#39;PRESIDENT&#39;, cast(null as integer), to_date(&#39;17-11-1981&#39;,&#39;dd-mm-yyyy&#39;),    5000, cast(null as integer), 10 from dummy union all\n  select 7698, &#39;BLAKE&#39;,  &#39;MANAGER&#39;,   7839, to_date(&#39;1-5-1981&#39;,&#39;dd-mm-yyyy&#39;),      2850, cast(null as integer), 30 from dummy union all\n  select 7782, &#39;CLARK&#39;,  &#39;MANAGER&#39;,   7839, to_date(&#39;9-6-1981&#39;,&#39;dd-mm-yyyy&#39;),      2450, cast(null as integer), 10 from dummy union all\n  select 7566, &#39;JONES&#39;,  &#39;MANAGER&#39;,   7839, to_date(&#39;2-4-1981&#39;,&#39;dd-mm-yyyy&#39;),      2975, cast(null as integer), 20 from dummy union all\n  select 7788, &#39;SCOTT&#39;,  &#39;ANALYST&#39;,   7566, to_date(&#39;13-7-87&#39;,&#39;dd-mm-rr&#39;) - 85,  3000, cast(null as integer), 20 from dummy union all\n  select 7902, &#39;FORD&#39;,   &#39;ANALYST&#39;,   7566, to_date(&#39;3-12-1981&#39;,&#39;dd-mm-yyyy&#39;),     3000, cast(null as integer), 20 from dummy union all\n  select 7369, &#39;SMITH&#39;,  &#39;CLERK&#39;,     7902, to_date(&#39;17-12-1980&#39;,&#39;dd-mm-yyyy&#39;),     800, cast(null as integer), 20 from dummy union all\n  select 7499, &#39;ALLEN&#39;,  &#39;SALESMAN&#39;,  7698, to_date(&#39;20-2-1981&#39;,&#39;dd-mm-yyyy&#39;),     1600,  300, 30 from dummy union all\n  select 7521, &#39;WARD&#39;,   &#39;SALESMAN&#39;,  7698, to_date(&#39;22-2-1981&#39;,&#39;dd-mm-yyyy&#39;),     1250,  500, 30 from dummy union all\n  select 7654, &#39;MARTIN&#39;, &#39;SALESMAN&#39;,  7698, to_date(&#39;28-9-1981&#39;,&#39;dd-mm-yyyy&#39;),     1250, 1400, 30 from dummy union all\n  select 7844, &#39;TURNER&#39;, &#39;SALESMAN&#39;,  7698, to_date(&#39;8-9-1981&#39;,&#39;dd-mm-yyyy&#39;),      1500,    0, 30 from dummy union all\n  select 7876, &#39;ADAMS&#39;,  &#39;CLERK&#39;,     7788, to_date(&#39;13-7-87&#39;, &#39;dd-mm-rr&#39;) - 51, 1100, cast(null as integer), 20 from dummy union all\n  select 7900, &#39;JAMES&#39;,  &#39;CLERK&#39;,     7698, to_date(&#39;3-12-1981&#39;,&#39;dd-mm-yyyy&#39;),      950, cast(null as integer), 30 from dummy union all\n  select 7934, &#39;MILLER&#39;, &#39;CLERK&#39;,     7782, to_date(&#39;23-1-1982&#39;,&#39;dd-mm-yyyy&#39;),     1300, cast(null as integer), 10 from dummy;\ninsert into salgrade\n  select 1,  700, 1200 from dummy union all\n  select 2, 1201, 1400 from dummy union all\n  select 3, 1401, 2000 from dummy union all\n  select 4, 2001, 3000 from dummy union all\n  select 5, 3001, 9999 from dummy;\ncommit;\n</code></pre>\n<h3 id=\"1-Hacer-un-procedimiento-que-muestre-el-nombre-y-el-salario-del-empleado-cuyo-codigo-es-7082-1\"><a href=\"#1-Hacer-un-procedimiento-que-muestre-el-nombre-y-el-salario-del-empleado-cuyo-codigo-es-7082-1\" class=\"headerlink\" title=\"1. Hacer un procedimiento que muestre el nombre y el salario del empleado cuyo código es 7082\"></a>1. Hacer un procedimiento que muestre el nombre y el salario del empleado cuyo código es 7082</h3><pre><code>CREATE or replace PROCEDURE mostrar_7082() \nAS $$\nDECLARE\n    v_nombre emp.ename%type;\n    v_salario emp.sal%type;\nBEGIN\n    select ename,sal into v_nombre,v_salario from emp where empno=7782;\n    RAISE NOTICE &#39;El nombre del empleado es %, y su salario es %&#39;, v_nombre,v_salario;\nEND;\n$$ LANGUAGE plpgsql;\n</code></pre>\n<p><img src=\"/images/postgres-ejercicio2.png\" alt=\"remoto\"></p>\n<h3 id=\"2-Hacer-un-procedimiento-que-reciba-como-parametro-un-codigo-de-empleado-y-devuelva-su-nombre-1\"><a href=\"#2-Hacer-un-procedimiento-que-reciba-como-parametro-un-codigo-de-empleado-y-devuelva-su-nombre-1\" class=\"headerlink\" title=\"2. Hacer un procedimiento que reciba como parámetro un código de empleado y devuelva su nombre\"></a>2. Hacer un procedimiento que reciba como parámetro un código de empleado y devuelva su nombre</h3><pre><code class=\"sql\">Create or replace procedure codigoanombreemp (p_codempleado emp.empno%type) \nAS $$\nDECLARE\n    v_nombre emp.ename%type;\nBEGIN\n    select ename into v_nombre from emp where empno=p_codempleado;\n    RAISE NOTICE &#39;El empleado con el código %, es %&#39;, p_codempleado,v_nombre;\nEND;\n$$ LANGUAGE plpgsql;\n</code></pre>\n<p><img src=\"/images/postgres-ejercicio1.png\" alt=\"remoto\"></p>\n"},{"title":"Directorios centralizados con LDAP y NFS","_content":"\n\n![Descripción de la imagen](/images/LOGO-LDAP.png)\n\n\n# Directorios centralizados con LDAP y NFS\n\n## Introducción\n\nEn este post vamos a ver como crear un directorio centralizado con LDAP y NFS.\n\n## Instalación de LDAP\n\nPara instalar LDAP vamos a usar el paquete slapd, que es el servidor LDAP.\n\n```\napt install slapd\n```\n\nUna vez instalado vamos a configurarlo, para ello ejecutamos el comando:\n\n```\ndpkg-reconfigure slap-utils\n```\n\nNos pedirá que introduzcamos la contraseña de del usuario root del servidor slapd, y nos preguntará si queremos usar el dominio de la máquina o no, en este caso vamos a usar el dominio de la máquina.\n\nCon el siguiente comando podremos ver la información del usuario root en el dominio gonzanonazareno.org\n\n```\nldapsearch -x -D \"cn=admin,dc=antonio,dc=gonzalonazareno,dc=org\" -b \"dc=antonio,dc=gonzalonazareno,dc=org\" -W\n```\n\n\n![Descripción de la imagen](/images/slap-1-1.png)\n\nAhora crearemos una unidad organizativa, en este caso la llamaremos Organizacion.ldif, y le daremos el siguiente contenido:\n\n```\ndn: ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: organizationalUnit\nou: Personas\n\ndn: ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: organizationalUnit\nou: Grupos\n```\n\n\"dn\" significa Distinguished Name, e indica el nombre distintivo que el objeto tendrá dentro de la jerarquía de directorios, y \"objectClass\" es la clase de objeto, en este caso es una unidad organizativa.\n\nProcedemos a ejecutar el siguiente comando para inyectar los nuevos objetos en el árbol de slapd:\n\n```\nldapadd -x -D \"cn=admin,dc=antonio,dc=gonzalonazareno,dc=org\" -f UnidadesOrganizativas.ldif -W\n```\n\n![Descripción de la imagen](/images/slap-1-2.png)\n\n\nAhora si volvemos a ejecutar el comando \n```\nldapsearch -x -D \"cn=admin,dc=antonio,dc=gonzalonazareno,dc=org\" -b \"dc=antonio,dc=gonzalonazareno,dc=org\" -W\n```\n\nPodremos ver que se han creado los nuevos objetos llamados Personas y Grupos.\n\n![Descripción de la imagen](/images/slap-1-3.png)\n\nAhora vamos a crear un usuario, para ello crearemos un fichero llamado usuarios.ldif, y le daremos el siguiente contenido:\n\n```\ndn: uid=prueba,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: posixAccount\nobjectClass: inetOrgPerson\nobjectClass: top\ncn: prueba\ngidNumber: 2001\nhomeDirectory: /home/prueba\nloginShell: /bin/\nsn: prueba\nuid: prueba\nuidNumber: 2001\nuserPassword: {SSHA}sfqp8j+/1HHe7N6qcbDIrLkf3T2c4wIW\n\ndn: uid=macarena,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: posixAccount\nobjectClass: inetOrgPerson\nobjectClass: top\ncn: macarena\ngidNumber: 2002\nhomeDirectory: /home/macarena\nloginShell: /bin/\nsn: macarena\nuid: macarena\nuidNumber: 2002\nuserPassword: {SSHA}sCwMT7CqCloD4bzvED/1QB9xvUnZ0N5P\n\n```\n\nPara los hash de contraseñas la hemos creado con la utilidad slappasswd, que viene instalada con slapd.\n\n```\nroot@alfa:/home/antonio# slappasswd\nNew password: \nRe-enter new password: \n{SSHA}sfqp8j+/1HHe7N6qcbDIrLkf3T2c4wIW\n```\n\nPara agregar al usuario prueba y al usuario macarena debemos de volver a inyectar el fichero Usuario.ldif en el árbol de slapd, para ello ejecutamos el siguiente comando:\n\n```\nldapadd -x -D \"cn=admin,dc=antonio,dc=gonzalonazareno,dc=org\" -f usuarios.ldif -W\n```\n\n![Descripción de la imagen](/images/slap-1-4.png)\n\nLo que hemos hecho ha sido insertar registros en el objeto de personas, ahora vamos a crear un grupo, para ello crearemos un fichero llamado grupos.ldif, y le daremos el siguiente contenido:\n\n```\ndn: cn=desarrollo,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: top\nobjectClass: groupOfNames\ncn: desarrollo\nmember:\n\ndn: cn=sistemas,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: top\nobjectClass: groupOfNames\ncn: sistemas\nmember:\n```\n\nA continuación vamos a inyectar el fichero grupos.ldif en el árbol de slapd, para ello ejecutamos el siguiente comando:\n\n```\nldapadd -x -D \"cn=admin,dc=antonio,dc=gonzalonazareno,dc=org\" -f grupos.ldif -W\n```\n\n![Descripción de la imagen](/images/slap-1-5.png)\n\nLuego vamos a añadir a los usuarios a los grupos, para ello crearemos un fichero llamado personas-grupos.ldif, y le daremos el siguiente contenido:\n\n```\n# Al grupo de desarrollo\ndn: cn=desarrollo,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nchangetype:modify\nadd: member\nmember: uid=prueba,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\n\n# Al grupo de desarrollo y sistemas\ndn: cn=desarrollo,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nchangetype:modify\nadd: member\nmember: uid=macarena,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\n\ndn: cn=sistemas,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nchangetype:modify\nadd: member\nmember: uid=macarena,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\n```\n\nA continuación vamos a inyectar el fichero personas-grupos.ldif en el árbol de slapd, para ello ejecutamos el siguiente comando:\n\n```\nldapmodify -x -D \"cn=admin,dc=antonio,dc=gonzalonazareno,dc=org\" -f personas-grupos.ldif -W\n```\n\n![Descripción de la imagen](/images/slap-1-6.png)\n\nPodríamos usar también ldapmodify que es una herramiente enfocada a la modificación, pero para nuestro caso ambas nos sirven.\n\nUsando el comando ldapsearch podemos ver que los usuarios están en los grupos:\n\n```\nldapsearch -x -D \"cn=admin,dc=antonio,dc=gonzalonazareno,dc=org\" -b \"cn=desarrollo,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\" -W\n```\n\n```\nroot@alfa:/home/antonio# ldapsearch -x -b ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\n# extended LDIF\n#\n# LDAPv3\n# base <ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org> with scope subtree\n# filter: (objectclass=*)\n# requesting: ALL\n#\n\n# Grupos, antonio.gonzalonazareno.org\ndn: ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: organizationalUnit\nou: Grupos\n\n# sistemas, Grupos, antonio.gonzalonazareno.org\ndn: cn=sistemas,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: top\nobjectClass: groupOfNames\ncn: sistemas\nmember:\nmember: uid=macarena,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\n\n# desarrollo, Grupos, antonio.gonzalonazareno.org\ndn: cn=desarrollo,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: top\nobjectClass: groupOfNames\ncn: desarrollo\nmember:\nmember: uid=prueba,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\nmember: uid=macarena,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\n\n# search result\nsearch: 2\nresult: 0 Success\n\n# numResponses: 6\n# numEntries: 5\n```\n\nSi queremos borrar un elemento del árbol podemos realizarlo gracias a la siguiente instrucción:\n\n```\nldapdelete -x -D 'cn=admin,dc=antonio,dc=gonzalonazareno,dc=org' -W cn=reabastecimiento,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\n```\n\n\nDesplegar árbol a través de NFS:\n\n\napt-get install nfs-kernel-server -y\n\nNos vamos a /etc/exportfs y añadimos la siguiente línea:\n```\n/home/antonio/nfs *(rw,fsid=0,subtree_check,no_root_squash)\n```\n\nAhora ejecutamos `exportfs -a`\n\n```\nroot@alfa:/home/antonio# mkdir nfs\nroot@alfa:/home/antonio# mkdir nfs/almacenamiento\n```\n\n\nComenzamos con la configuración del paquete nscd. Este es un demonio de caché para el servicio de nombres, lo cual evitará repetir consultas de las bases de datos de passwd, group y hosts.\n\n\n```\napt install libnss-ldapd libpam-ldapd nscd -y\n```\n\nLuego de configurar el instalador de forma que capture la ip 127.0.0.1 y el nombre dc=antonio,dc=gonzalonazareno,dc=org, debemos editar el fichero /etc/nsswitch.conf, y añadir las siguientes líneas:\n\n![Descripción de la imagen](/images/slap-1-7.png)\n\n\n## Cliente Ubuntu\n\n```\napt-get install libnss-ldapd libpam-ldapd nscd nfs-kernel-server -y\n```\n\nIntroducimos la dirección IP del servidor LDAP y el nombre del dominio:\n\n![Descripción de la imagen](/images/slap-1-8.png)\n\nEn el fichero /etc/ldap/ldap.conf se establecen los parámetros de configuración del cliente LDAP. En este fichero se establece la dirección del servidor LDAP, el puerto, el dominio, el tipo de autenticación, etc.\n\n```\n#\n# LDAP Defaults\n#\n\n# See ldap.conf(5) for details\n# This file should be world readable but not world writable.\n\nBASE    dc=antonio,dc=gonzalonazareno,dc=org\nURI     ldap://192.168.0.1\n\nSIZELIMIT       12\nTIMELIMIT       15\nDEREF           never\n\n# TLS certificates (needed for GnuTLS)\nTLS_CACERT      /etc/ssl/certs/ca-certificates.crt\n```\n\n\nAhora necesitaremos configurar el cliente para que al iniciar sesión cree el home del usuario. Para ello editamos el fichero /etc/pam.d/common-account y añadimos la siguiente línea:\n\n```\nsession required pam_mkhomedir.so skel=/etc/skel/ umask=0022\n\n```\n\nVamos a probar montando de manera efímera el directorio en el cual se va a crear el home del usuario macarena:\n\n```\nmount -t nfs 192.168.0.1:/home/antonio/nfs/ /home\n```\n\n\nAhora cuando el usuario macarena inicie sesión este se verá reflejado en nuestro servidor nfs, probaremos creando un documento txt:\n\n\n![Descripción de la imagen](/images/slap-1-9.png)\n\nAhora vamos a hacer que este recurso funcione de manera permanente, para ello podríamos editar el fichero fstab, o bien crear una unidad de systemd, que en este caso es lo que vamos a emplear.\n\n\nnano /etc/systemd/system/home.mount\n```\n[Unit]\nDescription= Montaje de carpeta home para NFS\n\n[Mount]\nWhat=192.168.0.1:/home/antonio/nfs\nWhere=/home   \nType=nfs\nOptions=defaults\n\n[Install]\nWantedBy=multi-user.target\n\n```\n\nsystemctl daemon-reload\nsystemctl enable home.mount\nsystemctl start home.mount\nsystemctl status home.mount\n\n![Descripción de la imagen](/images/slap-1-10.png)\n\n## Cliente Rocky Linux\n\n```\ndnf install openldap-clients sssd sssd-ldap oddjob-mkhomedir sssd-tools -y\n```\n\n```\nauthselect list\n```\n\n```\n[root@bravo antonio]# authselect list\n- minimal\t Local users only for minimal installations\n- sssd   \t Enable SSSD for system authentication (also for local users only)\n- winbind\t Enable winbind for system authentication\n\n```\n\n```\nauthselect select sssd with-mkhomedir --force\n```\n\nvolvemos a especificar la dirección IP del servidor LDAP y el nombre del dominio en /etc/openldap/ldap.conf:\n\n```\nBASE dc=antonio,dc=gonzalonazareno,dc=org\nURI ldap://172.16.0.1\n\n\nSIZELIMIT       12\nTIMELIMIT       15\nDEREF           never\n```\n\nsudo nano /etc/sssd/sssd.conf\n\n```\n[domain/default]\nid_provider = ldap\nautofs_provider = ldap\nauth_provider = ldap\nchpass_provider = ldap\nldap_uri = ldap://172.0.16.1\nldap_search_base = dc=antonio,dc=gonzalonazareno,dc=org\nldap_id_use_start_tls = True\nldap_tls_cacertdir = /etc/openldap/cacerts\ncache_credentials = True\nldap_tls_reqcert = allow\n\n[sssd]\nservices = nss, pam, autofs\ndomains = default\n\n[nss]\nhomedir_substring = /home/nfs\n\n```\n\n\n```\nchmod 0600 /etc/sssd/sssd.conf\nsystemctl restart sssd\n```\n\nauthconfig --enablemkhomedir --updateall\n\n\n\n```\nauthconfig --enableldap \\\n--enableldapauth \\\n--ldapserver=antonio.gonzalonazareno.org \\\n--ldapbasedn=\"dc=antonio,dc=gonzalonazareno,dc=org\" \\\n--enablemkhomedir \\\n--update\n```\n\n![Descripción de la imagen](/images/slap-1-11.png)\n\n","source":"_posts/slap-nfs.md","raw":"---\ntitle: Directorios centralizados con LDAP y NFS\ncategories: Administración de Sistemas\n---\n\n\n![Descripción de la imagen](/images/LOGO-LDAP.png)\n\n\n# Directorios centralizados con LDAP y NFS\n\n## Introducción\n\nEn este post vamos a ver como crear un directorio centralizado con LDAP y NFS.\n\n## Instalación de LDAP\n\nPara instalar LDAP vamos a usar el paquete slapd, que es el servidor LDAP.\n\n```\napt install slapd\n```\n\nUna vez instalado vamos a configurarlo, para ello ejecutamos el comando:\n\n```\ndpkg-reconfigure slap-utils\n```\n\nNos pedirá que introduzcamos la contraseña de del usuario root del servidor slapd, y nos preguntará si queremos usar el dominio de la máquina o no, en este caso vamos a usar el dominio de la máquina.\n\nCon el siguiente comando podremos ver la información del usuario root en el dominio gonzanonazareno.org\n\n```\nldapsearch -x -D \"cn=admin,dc=antonio,dc=gonzalonazareno,dc=org\" -b \"dc=antonio,dc=gonzalonazareno,dc=org\" -W\n```\n\n\n![Descripción de la imagen](/images/slap-1-1.png)\n\nAhora crearemos una unidad organizativa, en este caso la llamaremos Organizacion.ldif, y le daremos el siguiente contenido:\n\n```\ndn: ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: organizationalUnit\nou: Personas\n\ndn: ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: organizationalUnit\nou: Grupos\n```\n\n\"dn\" significa Distinguished Name, e indica el nombre distintivo que el objeto tendrá dentro de la jerarquía de directorios, y \"objectClass\" es la clase de objeto, en este caso es una unidad organizativa.\n\nProcedemos a ejecutar el siguiente comando para inyectar los nuevos objetos en el árbol de slapd:\n\n```\nldapadd -x -D \"cn=admin,dc=antonio,dc=gonzalonazareno,dc=org\" -f UnidadesOrganizativas.ldif -W\n```\n\n![Descripción de la imagen](/images/slap-1-2.png)\n\n\nAhora si volvemos a ejecutar el comando \n```\nldapsearch -x -D \"cn=admin,dc=antonio,dc=gonzalonazareno,dc=org\" -b \"dc=antonio,dc=gonzalonazareno,dc=org\" -W\n```\n\nPodremos ver que se han creado los nuevos objetos llamados Personas y Grupos.\n\n![Descripción de la imagen](/images/slap-1-3.png)\n\nAhora vamos a crear un usuario, para ello crearemos un fichero llamado usuarios.ldif, y le daremos el siguiente contenido:\n\n```\ndn: uid=prueba,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: posixAccount\nobjectClass: inetOrgPerson\nobjectClass: top\ncn: prueba\ngidNumber: 2001\nhomeDirectory: /home/prueba\nloginShell: /bin/\nsn: prueba\nuid: prueba\nuidNumber: 2001\nuserPassword: {SSHA}sfqp8j+/1HHe7N6qcbDIrLkf3T2c4wIW\n\ndn: uid=macarena,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: posixAccount\nobjectClass: inetOrgPerson\nobjectClass: top\ncn: macarena\ngidNumber: 2002\nhomeDirectory: /home/macarena\nloginShell: /bin/\nsn: macarena\nuid: macarena\nuidNumber: 2002\nuserPassword: {SSHA}sCwMT7CqCloD4bzvED/1QB9xvUnZ0N5P\n\n```\n\nPara los hash de contraseñas la hemos creado con la utilidad slappasswd, que viene instalada con slapd.\n\n```\nroot@alfa:/home/antonio# slappasswd\nNew password: \nRe-enter new password: \n{SSHA}sfqp8j+/1HHe7N6qcbDIrLkf3T2c4wIW\n```\n\nPara agregar al usuario prueba y al usuario macarena debemos de volver a inyectar el fichero Usuario.ldif en el árbol de slapd, para ello ejecutamos el siguiente comando:\n\n```\nldapadd -x -D \"cn=admin,dc=antonio,dc=gonzalonazareno,dc=org\" -f usuarios.ldif -W\n```\n\n![Descripción de la imagen](/images/slap-1-4.png)\n\nLo que hemos hecho ha sido insertar registros en el objeto de personas, ahora vamos a crear un grupo, para ello crearemos un fichero llamado grupos.ldif, y le daremos el siguiente contenido:\n\n```\ndn: cn=desarrollo,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: top\nobjectClass: groupOfNames\ncn: desarrollo\nmember:\n\ndn: cn=sistemas,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: top\nobjectClass: groupOfNames\ncn: sistemas\nmember:\n```\n\nA continuación vamos a inyectar el fichero grupos.ldif en el árbol de slapd, para ello ejecutamos el siguiente comando:\n\n```\nldapadd -x -D \"cn=admin,dc=antonio,dc=gonzalonazareno,dc=org\" -f grupos.ldif -W\n```\n\n![Descripción de la imagen](/images/slap-1-5.png)\n\nLuego vamos a añadir a los usuarios a los grupos, para ello crearemos un fichero llamado personas-grupos.ldif, y le daremos el siguiente contenido:\n\n```\n# Al grupo de desarrollo\ndn: cn=desarrollo,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nchangetype:modify\nadd: member\nmember: uid=prueba,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\n\n# Al grupo de desarrollo y sistemas\ndn: cn=desarrollo,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nchangetype:modify\nadd: member\nmember: uid=macarena,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\n\ndn: cn=sistemas,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nchangetype:modify\nadd: member\nmember: uid=macarena,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\n```\n\nA continuación vamos a inyectar el fichero personas-grupos.ldif en el árbol de slapd, para ello ejecutamos el siguiente comando:\n\n```\nldapmodify -x -D \"cn=admin,dc=antonio,dc=gonzalonazareno,dc=org\" -f personas-grupos.ldif -W\n```\n\n![Descripción de la imagen](/images/slap-1-6.png)\n\nPodríamos usar también ldapmodify que es una herramiente enfocada a la modificación, pero para nuestro caso ambas nos sirven.\n\nUsando el comando ldapsearch podemos ver que los usuarios están en los grupos:\n\n```\nldapsearch -x -D \"cn=admin,dc=antonio,dc=gonzalonazareno,dc=org\" -b \"cn=desarrollo,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\" -W\n```\n\n```\nroot@alfa:/home/antonio# ldapsearch -x -b ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\n# extended LDIF\n#\n# LDAPv3\n# base <ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org> with scope subtree\n# filter: (objectclass=*)\n# requesting: ALL\n#\n\n# Grupos, antonio.gonzalonazareno.org\ndn: ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: organizationalUnit\nou: Grupos\n\n# sistemas, Grupos, antonio.gonzalonazareno.org\ndn: cn=sistemas,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: top\nobjectClass: groupOfNames\ncn: sistemas\nmember:\nmember: uid=macarena,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\n\n# desarrollo, Grupos, antonio.gonzalonazareno.org\ndn: cn=desarrollo,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: top\nobjectClass: groupOfNames\ncn: desarrollo\nmember:\nmember: uid=prueba,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\nmember: uid=macarena,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\n\n# search result\nsearch: 2\nresult: 0 Success\n\n# numResponses: 6\n# numEntries: 5\n```\n\nSi queremos borrar un elemento del árbol podemos realizarlo gracias a la siguiente instrucción:\n\n```\nldapdelete -x -D 'cn=admin,dc=antonio,dc=gonzalonazareno,dc=org' -W cn=reabastecimiento,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\n```\n\n\nDesplegar árbol a través de NFS:\n\n\napt-get install nfs-kernel-server -y\n\nNos vamos a /etc/exportfs y añadimos la siguiente línea:\n```\n/home/antonio/nfs *(rw,fsid=0,subtree_check,no_root_squash)\n```\n\nAhora ejecutamos `exportfs -a`\n\n```\nroot@alfa:/home/antonio# mkdir nfs\nroot@alfa:/home/antonio# mkdir nfs/almacenamiento\n```\n\n\nComenzamos con la configuración del paquete nscd. Este es un demonio de caché para el servicio de nombres, lo cual evitará repetir consultas de las bases de datos de passwd, group y hosts.\n\n\n```\napt install libnss-ldapd libpam-ldapd nscd -y\n```\n\nLuego de configurar el instalador de forma que capture la ip 127.0.0.1 y el nombre dc=antonio,dc=gonzalonazareno,dc=org, debemos editar el fichero /etc/nsswitch.conf, y añadir las siguientes líneas:\n\n![Descripción de la imagen](/images/slap-1-7.png)\n\n\n## Cliente Ubuntu\n\n```\napt-get install libnss-ldapd libpam-ldapd nscd nfs-kernel-server -y\n```\n\nIntroducimos la dirección IP del servidor LDAP y el nombre del dominio:\n\n![Descripción de la imagen](/images/slap-1-8.png)\n\nEn el fichero /etc/ldap/ldap.conf se establecen los parámetros de configuración del cliente LDAP. En este fichero se establece la dirección del servidor LDAP, el puerto, el dominio, el tipo de autenticación, etc.\n\n```\n#\n# LDAP Defaults\n#\n\n# See ldap.conf(5) for details\n# This file should be world readable but not world writable.\n\nBASE    dc=antonio,dc=gonzalonazareno,dc=org\nURI     ldap://192.168.0.1\n\nSIZELIMIT       12\nTIMELIMIT       15\nDEREF           never\n\n# TLS certificates (needed for GnuTLS)\nTLS_CACERT      /etc/ssl/certs/ca-certificates.crt\n```\n\n\nAhora necesitaremos configurar el cliente para que al iniciar sesión cree el home del usuario. Para ello editamos el fichero /etc/pam.d/common-account y añadimos la siguiente línea:\n\n```\nsession required pam_mkhomedir.so skel=/etc/skel/ umask=0022\n\n```\n\nVamos a probar montando de manera efímera el directorio en el cual se va a crear el home del usuario macarena:\n\n```\nmount -t nfs 192.168.0.1:/home/antonio/nfs/ /home\n```\n\n\nAhora cuando el usuario macarena inicie sesión este se verá reflejado en nuestro servidor nfs, probaremos creando un documento txt:\n\n\n![Descripción de la imagen](/images/slap-1-9.png)\n\nAhora vamos a hacer que este recurso funcione de manera permanente, para ello podríamos editar el fichero fstab, o bien crear una unidad de systemd, que en este caso es lo que vamos a emplear.\n\n\nnano /etc/systemd/system/home.mount\n```\n[Unit]\nDescription= Montaje de carpeta home para NFS\n\n[Mount]\nWhat=192.168.0.1:/home/antonio/nfs\nWhere=/home   \nType=nfs\nOptions=defaults\n\n[Install]\nWantedBy=multi-user.target\n\n```\n\nsystemctl daemon-reload\nsystemctl enable home.mount\nsystemctl start home.mount\nsystemctl status home.mount\n\n![Descripción de la imagen](/images/slap-1-10.png)\n\n## Cliente Rocky Linux\n\n```\ndnf install openldap-clients sssd sssd-ldap oddjob-mkhomedir sssd-tools -y\n```\n\n```\nauthselect list\n```\n\n```\n[root@bravo antonio]# authselect list\n- minimal\t Local users only for minimal installations\n- sssd   \t Enable SSSD for system authentication (also for local users only)\n- winbind\t Enable winbind for system authentication\n\n```\n\n```\nauthselect select sssd with-mkhomedir --force\n```\n\nvolvemos a especificar la dirección IP del servidor LDAP y el nombre del dominio en /etc/openldap/ldap.conf:\n\n```\nBASE dc=antonio,dc=gonzalonazareno,dc=org\nURI ldap://172.16.0.1\n\n\nSIZELIMIT       12\nTIMELIMIT       15\nDEREF           never\n```\n\nsudo nano /etc/sssd/sssd.conf\n\n```\n[domain/default]\nid_provider = ldap\nautofs_provider = ldap\nauth_provider = ldap\nchpass_provider = ldap\nldap_uri = ldap://172.0.16.1\nldap_search_base = dc=antonio,dc=gonzalonazareno,dc=org\nldap_id_use_start_tls = True\nldap_tls_cacertdir = /etc/openldap/cacerts\ncache_credentials = True\nldap_tls_reqcert = allow\n\n[sssd]\nservices = nss, pam, autofs\ndomains = default\n\n[nss]\nhomedir_substring = /home/nfs\n\n```\n\n\n```\nchmod 0600 /etc/sssd/sssd.conf\nsystemctl restart sssd\n```\n\nauthconfig --enablemkhomedir --updateall\n\n\n\n```\nauthconfig --enableldap \\\n--enableldapauth \\\n--ldapserver=antonio.gonzalonazareno.org \\\n--ldapbasedn=\"dc=antonio,dc=gonzalonazareno,dc=org\" \\\n--enablemkhomedir \\\n--update\n```\n\n![Descripción de la imagen](/images/slap-1-11.png)\n\n","slug":"slap-nfs","published":1,"date":"2023-01-31T23:48:29.644Z","updated":"2023-02-01T07:31:33.784Z","_id":"cldl9ucgr000p0yi51470589v","comments":1,"layout":"post","photos":[],"link":"","content":"<p><img src=\"/images/LOGO-LDAP.png\" alt=\"Descripción de la imagen\"></p>\n<h1 id=\"directorios-centralizados-con-ldap-y-nfs\"><a class=\"markdownIt-Anchor\" href=\"#directorios-centralizados-con-ldap-y-nfs\">#</a> Directorios centralizados con LDAP y NFS</h1>\n<h2 id=\"introducción\"><a class=\"markdownIt-Anchor\" href=\"#introducción\">#</a> Introducción</h2>\n<p>En este post vamos a ver como crear un directorio centralizado con LDAP y NFS.</p>\n<h2 id=\"instalación-de-ldap\"><a class=\"markdownIt-Anchor\" href=\"#instalación-de-ldap\">#</a> Instalación de LDAP</h2>\n<p>Para instalar LDAP vamos a usar el paquete slapd, que es el servidor LDAP.</p>\n<pre><code>apt install slapd\n</code></pre>\n<p>Una vez instalado vamos a configurarlo, para ello ejecutamos el comando:</p>\n<pre><code>dpkg-reconfigure slap-utils\n</code></pre>\n<p>Nos pedirá que introduzcamos la contraseña de del usuario root del servidor slapd, y nos preguntará si queremos usar el dominio de la máquina o no, en este caso vamos a usar el dominio de la máquina.</p>\n<p>Con el siguiente comando podremos ver la información del usuario root en el dominio <a href=\"http://gonzanonazareno.org\">gonzanonazareno.org</a></p>\n<pre><code>ldapsearch -x -D &quot;cn=admin,dc=antonio,dc=gonzalonazareno,dc=org&quot; -b &quot;dc=antonio,dc=gonzalonazareno,dc=org&quot; -W\n</code></pre>\n<p><img src=\"/images/slap-1-1.png\" alt=\"Descripción de la imagen\"></p>\n<p>Ahora crearemos una unidad organizativa, en este caso la llamaremos Organizacion.ldif, y le daremos el siguiente contenido:</p>\n<pre><code>dn: ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: organizationalUnit\nou: Personas\n\ndn: ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: organizationalUnit\nou: Grupos\n</code></pre>\n<p>“dn” significa Distinguished Name, e indica el nombre distintivo que el objeto tendrá dentro de la jerarquía de directorios, y “objectClass” es la clase de objeto, en este caso es una unidad organizativa.</p>\n<p>Procedemos a ejecutar el siguiente comando para inyectar los nuevos objetos en el árbol de slapd:</p>\n<pre><code>ldapadd -x -D &quot;cn=admin,dc=antonio,dc=gonzalonazareno,dc=org&quot; -f UnidadesOrganizativas.ldif -W\n</code></pre>\n<p><img src=\"/images/slap-1-2.png\" alt=\"Descripción de la imagen\"></p>\n<p>Ahora si volvemos a ejecutar el comando</p>\n<pre><code>ldapsearch -x -D &quot;cn=admin,dc=antonio,dc=gonzalonazareno,dc=org&quot; -b &quot;dc=antonio,dc=gonzalonazareno,dc=org&quot; -W\n</code></pre>\n<p>Podremos ver que se han creado los nuevos objetos llamados Personas y Grupos.</p>\n<p><img src=\"/images/slap-1-3.png\" alt=\"Descripción de la imagen\"></p>\n<p>Ahora vamos a crear un usuario, para ello crearemos un fichero llamado usuarios.ldif, y le daremos el siguiente contenido:</p>\n<pre><code>dn: uid=prueba,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: posixAccount\nobjectClass: inetOrgPerson\nobjectClass: top\ncn: prueba\ngidNumber: 2001\nhomeDirectory: /home/prueba\nloginShell: /bin/\nsn: prueba\nuid: prueba\nuidNumber: 2001\nuserPassword: &#123;SSHA&#125;sfqp8j+/1HHe7N6qcbDIrLkf3T2c4wIW\n\ndn: uid=macarena,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: posixAccount\nobjectClass: inetOrgPerson\nobjectClass: top\ncn: macarena\ngidNumber: 2002\nhomeDirectory: /home/macarena\nloginShell: /bin/\nsn: macarena\nuid: macarena\nuidNumber: 2002\nuserPassword: &#123;SSHA&#125;sCwMT7CqCloD4bzvED/1QB9xvUnZ0N5P\n\n</code></pre>\n<p>Para los hash de contraseñas la hemos creado con la utilidad slappasswd, que viene instalada con slapd.</p>\n<pre><code>root@alfa:/home/antonio# slappasswd\nNew password: \nRe-enter new password: \n&#123;SSHA&#125;sfqp8j+/1HHe7N6qcbDIrLkf3T2c4wIW\n</code></pre>\n<p>Para agregar al usuario prueba y al usuario macarena debemos de volver a inyectar el fichero Usuario.ldif en el árbol de slapd, para ello ejecutamos el siguiente comando:</p>\n<pre><code>ldapadd -x -D &quot;cn=admin,dc=antonio,dc=gonzalonazareno,dc=org&quot; -f usuarios.ldif -W\n</code></pre>\n<p><img src=\"/images/slap-1-4.png\" alt=\"Descripción de la imagen\"></p>\n<p>Lo que hemos hecho ha sido insertar registros en el objeto de personas, ahora vamos a crear un grupo, para ello crearemos un fichero llamado grupos.ldif, y le daremos el siguiente contenido:</p>\n<pre><code>dn: cn=desarrollo,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: top\nobjectClass: groupOfNames\ncn: desarrollo\nmember:\n\ndn: cn=sistemas,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: top\nobjectClass: groupOfNames\ncn: sistemas\nmember:\n</code></pre>\n<p>A continuación vamos a inyectar el fichero grupos.ldif en el árbol de slapd, para ello ejecutamos el siguiente comando:</p>\n<pre><code>ldapadd -x -D &quot;cn=admin,dc=antonio,dc=gonzalonazareno,dc=org&quot; -f grupos.ldif -W\n</code></pre>\n<p><img src=\"/images/slap-1-5.png\" alt=\"Descripción de la imagen\"></p>\n<p>Luego vamos a añadir a los usuarios a los grupos, para ello crearemos un fichero llamado personas-grupos.ldif, y le daremos el siguiente contenido:</p>\n<pre><code># Al grupo de desarrollo\ndn: cn=desarrollo,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nchangetype:modify\nadd: member\nmember: uid=prueba,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\n\n# Al grupo de desarrollo y sistemas\ndn: cn=desarrollo,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nchangetype:modify\nadd: member\nmember: uid=macarena,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\n\ndn: cn=sistemas,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nchangetype:modify\nadd: member\nmember: uid=macarena,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\n</code></pre>\n<p>A continuación vamos a inyectar el fichero personas-grupos.ldif en el árbol de slapd, para ello ejecutamos el siguiente comando:</p>\n<pre><code>ldapmodify -x -D &quot;cn=admin,dc=antonio,dc=gonzalonazareno,dc=org&quot; -f personas-grupos.ldif -W\n</code></pre>\n<p><img src=\"/images/slap-1-6.png\" alt=\"Descripción de la imagen\"></p>\n<p>Podríamos usar también ldapmodify que es una herramiente enfocada a la modificación, pero para nuestro caso ambas nos sirven.</p>\n<p>Usando el comando ldapsearch podemos ver que los usuarios están en los grupos:</p>\n<pre><code>ldapsearch -x -D &quot;cn=admin,dc=antonio,dc=gonzalonazareno,dc=org&quot; -b &quot;cn=desarrollo,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org&quot; -W\n</code></pre>\n<pre><code>root@alfa:/home/antonio# ldapsearch -x -b ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\n# extended LDIF\n#\n# LDAPv3\n# base &lt;ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org&gt; with scope subtree\n# filter: (objectclass=*)\n# requesting: ALL\n#\n\n# Grupos, antonio.gonzalonazareno.org\ndn: ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: organizationalUnit\nou: Grupos\n\n# sistemas, Grupos, antonio.gonzalonazareno.org\ndn: cn=sistemas,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: top\nobjectClass: groupOfNames\ncn: sistemas\nmember:\nmember: uid=macarena,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\n\n# desarrollo, Grupos, antonio.gonzalonazareno.org\ndn: cn=desarrollo,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: top\nobjectClass: groupOfNames\ncn: desarrollo\nmember:\nmember: uid=prueba,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\nmember: uid=macarena,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\n\n# search result\nsearch: 2\nresult: 0 Success\n\n# numResponses: 6\n# numEntries: 5\n</code></pre>\n<p>Si queremos borrar un elemento del árbol podemos realizarlo gracias a la siguiente instrucción:</p>\n<pre><code>ldapdelete -x -D 'cn=admin,dc=antonio,dc=gonzalonazareno,dc=org' -W cn=reabastecimiento,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\n</code></pre>\n<p>Desplegar árbol a través de NFS:</p>\n<p>apt-get install nfs-kernel-server -y</p>\n<p>Nos vamos a /etc/exportfs y añadimos la siguiente línea:</p>\n<pre><code>/home/antonio/nfs *(rw,fsid=0,subtree_check,no_root_squash)\n</code></pre>\n<p>Ahora ejecutamos  <code>exportfs -a</code></p>\n<pre><code>root@alfa:/home/antonio# mkdir nfs\nroot@alfa:/home/antonio# mkdir nfs/almacenamiento\n</code></pre>\n<p>Comenzamos con la configuración del paquete nscd. Este es un demonio de caché para el servicio de nombres, lo cual evitará repetir consultas de las bases de datos de passwd, group y hosts.</p>\n<pre><code>apt install libnss-ldapd libpam-ldapd nscd -y\n</code></pre>\n<p>Luego de configurar el instalador de forma que capture la ip 127.0.0.1 y el nombre dc=antonio,dc=gonzalonazareno,dc=org, debemos editar el fichero /etc/nsswitch.conf, y añadir las siguientes líneas:</p>\n<p><img src=\"/images/slap-1-7.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"cliente-ubuntu\"><a class=\"markdownIt-Anchor\" href=\"#cliente-ubuntu\">#</a> Cliente Ubuntu</h2>\n<pre><code>apt-get install libnss-ldapd libpam-ldapd nscd nfs-kernel-server -y\n</code></pre>\n<p>Introducimos la dirección IP del servidor LDAP y el nombre del dominio:</p>\n<p><img src=\"/images/slap-1-8.png\" alt=\"Descripción de la imagen\"></p>\n<p>En el fichero /etc/ldap/ldap.conf se establecen los parámetros de configuración del cliente LDAP. En este fichero se establece la dirección del servidor LDAP, el puerto, el dominio, el tipo de autenticación, etc.</p>\n<pre><code>#\n# LDAP Defaults\n#\n\n# See ldap.conf(5) for details\n# This file should be world readable but not world writable.\n\nBASE    dc=antonio,dc=gonzalonazareno,dc=org\nURI     ldap://192.168.0.1\n\nSIZELIMIT       12\nTIMELIMIT       15\nDEREF           never\n\n# TLS certificates (needed for GnuTLS)\nTLS_CACERT      /etc/ssl/certs/ca-certificates.crt\n</code></pre>\n<p>Ahora necesitaremos configurar el cliente para que al iniciar sesión cree el home del usuario. Para ello editamos el fichero /etc/pam.d/common-account y añadimos la siguiente línea:</p>\n<pre><code>session required pam_mkhomedir.so skel=/etc/skel/ umask=0022\n\n</code></pre>\n<p>Vamos a probar montando de manera efímera el directorio en el cual se va a crear el home del usuario macarena:</p>\n<pre><code>mount -t nfs 192.168.0.1:/home/antonio/nfs/ /home\n</code></pre>\n<p>Ahora cuando el usuario macarena inicie sesión este se verá reflejado en nuestro servidor nfs, probaremos creando un documento txt:</p>\n<p><img src=\"/images/slap-1-9.png\" alt=\"Descripción de la imagen\"></p>\n<p>Ahora vamos a hacer que este recurso funcione de manera permanente, para ello podríamos editar el fichero fstab, o bien crear una unidad de systemd, que en este caso es lo que vamos a emplear.</p>\n<p>nano /etc/systemd/system/home.mount</p>\n<pre><code>[Unit]\nDescription= Montaje de carpeta home para NFS\n\n[Mount]\nWhat=192.168.0.1:/home/antonio/nfs\nWhere=/home   \nType=nfs\nOptions=defaults\n\n[Install]\nWantedBy=multi-user.target\n\n</code></pre>\n<p>systemctl daemon-reload<br>\nsystemctl enable home.mount<br>\nsystemctl start home.mount<br>\nsystemctl status home.mount</p>\n<p><img src=\"/images/slap-1-10.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"cliente-rocky-linux\"><a class=\"markdownIt-Anchor\" href=\"#cliente-rocky-linux\">#</a> Cliente Rocky Linux</h2>\n<pre><code>dnf install openldap-clients sssd sssd-ldap oddjob-mkhomedir sssd-tools -y\n</code></pre>\n<pre><code>authselect list\n</code></pre>\n<pre><code>[root@bravo antonio]# authselect list\n- minimal\t Local users only for minimal installations\n- sssd   \t Enable SSSD for system authentication (also for local users only)\n- winbind\t Enable winbind for system authentication\n\n</code></pre>\n<pre><code>authselect select sssd with-mkhomedir --force\n</code></pre>\n<p>volvemos a especificar la dirección IP del servidor LDAP y el nombre del dominio en /etc/openldap/ldap.conf:</p>\n<pre><code>BASE dc=antonio,dc=gonzalonazareno,dc=org\nURI ldap://172.16.0.1\n\n\nSIZELIMIT       12\nTIMELIMIT       15\nDEREF           never\n</code></pre>\n<p>sudo nano /etc/sssd/sssd.conf</p>\n<pre><code>[domain/default]\nid_provider = ldap\nautofs_provider = ldap\nauth_provider = ldap\nchpass_provider = ldap\nldap_uri = ldap://172.0.16.1\nldap_search_base = dc=antonio,dc=gonzalonazareno,dc=org\nldap_id_use_start_tls = True\nldap_tls_cacertdir = /etc/openldap/cacerts\ncache_credentials = True\nldap_tls_reqcert = allow\n\n[sssd]\nservices = nss, pam, autofs\ndomains = default\n\n[nss]\nhomedir_substring = /home/nfs\n\n</code></pre>\n<pre><code>chmod 0600 /etc/sssd/sssd.conf\nsystemctl restart sssd\n</code></pre>\n<p>authconfig --enablemkhomedir --updateall</p>\n<pre><code>authconfig --enableldap \\\n--enableldapauth \\\n--ldapserver=antonio.gonzalonazareno.org \\\n--ldapbasedn=&quot;dc=antonio,dc=gonzalonazareno,dc=org&quot; \\\n--enablemkhomedir \\\n--update\n</code></pre>\n<p><img src=\"/images/slap-1-11.png\" alt=\"Descripción de la imagen\"></p>\n","site":{"data":{}},"length":8809,"excerpt":"","more":"<p><img src=\"/images/LOGO-LDAP.png\" alt=\"Descripción de la imagen\"></p>\n<h1 id=\"directorios-centralizados-con-ldap-y-nfs\"><a class=\"markdownIt-Anchor\" href=\"#directorios-centralizados-con-ldap-y-nfs\">#</a> Directorios centralizados con LDAP y NFS</h1>\n<h2 id=\"introducción\"><a class=\"markdownIt-Anchor\" href=\"#introducción\">#</a> Introducción</h2>\n<p>En este post vamos a ver como crear un directorio centralizado con LDAP y NFS.</p>\n<h2 id=\"instalación-de-ldap\"><a class=\"markdownIt-Anchor\" href=\"#instalación-de-ldap\">#</a> Instalación de LDAP</h2>\n<p>Para instalar LDAP vamos a usar el paquete slapd, que es el servidor LDAP.</p>\n<pre><code>apt install slapd\n</code></pre>\n<p>Una vez instalado vamos a configurarlo, para ello ejecutamos el comando:</p>\n<pre><code>dpkg-reconfigure slap-utils\n</code></pre>\n<p>Nos pedirá que introduzcamos la contraseña de del usuario root del servidor slapd, y nos preguntará si queremos usar el dominio de la máquina o no, en este caso vamos a usar el dominio de la máquina.</p>\n<p>Con el siguiente comando podremos ver la información del usuario root en el dominio <a href=\"http://gonzanonazareno.org\">gonzanonazareno.org</a></p>\n<pre><code>ldapsearch -x -D &quot;cn=admin,dc=antonio,dc=gonzalonazareno,dc=org&quot; -b &quot;dc=antonio,dc=gonzalonazareno,dc=org&quot; -W\n</code></pre>\n<p><img src=\"/images/slap-1-1.png\" alt=\"Descripción de la imagen\"></p>\n<p>Ahora crearemos una unidad organizativa, en este caso la llamaremos Organizacion.ldif, y le daremos el siguiente contenido:</p>\n<pre><code>dn: ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: organizationalUnit\nou: Personas\n\ndn: ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: organizationalUnit\nou: Grupos\n</code></pre>\n<p>“dn” significa Distinguished Name, e indica el nombre distintivo que el objeto tendrá dentro de la jerarquía de directorios, y “objectClass” es la clase de objeto, en este caso es una unidad organizativa.</p>\n<p>Procedemos a ejecutar el siguiente comando para inyectar los nuevos objetos en el árbol de slapd:</p>\n<pre><code>ldapadd -x -D &quot;cn=admin,dc=antonio,dc=gonzalonazareno,dc=org&quot; -f UnidadesOrganizativas.ldif -W\n</code></pre>\n<p><img src=\"/images/slap-1-2.png\" alt=\"Descripción de la imagen\"></p>\n<p>Ahora si volvemos a ejecutar el comando</p>\n<pre><code>ldapsearch -x -D &quot;cn=admin,dc=antonio,dc=gonzalonazareno,dc=org&quot; -b &quot;dc=antonio,dc=gonzalonazareno,dc=org&quot; -W\n</code></pre>\n<p>Podremos ver que se han creado los nuevos objetos llamados Personas y Grupos.</p>\n<p><img src=\"/images/slap-1-3.png\" alt=\"Descripción de la imagen\"></p>\n<p>Ahora vamos a crear un usuario, para ello crearemos un fichero llamado usuarios.ldif, y le daremos el siguiente contenido:</p>\n<pre><code>dn: uid=prueba,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: posixAccount\nobjectClass: inetOrgPerson\nobjectClass: top\ncn: prueba\ngidNumber: 2001\nhomeDirectory: /home/prueba\nloginShell: /bin/\nsn: prueba\nuid: prueba\nuidNumber: 2001\nuserPassword: &#123;SSHA&#125;sfqp8j+/1HHe7N6qcbDIrLkf3T2c4wIW\n\ndn: uid=macarena,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: posixAccount\nobjectClass: inetOrgPerson\nobjectClass: top\ncn: macarena\ngidNumber: 2002\nhomeDirectory: /home/macarena\nloginShell: /bin/\nsn: macarena\nuid: macarena\nuidNumber: 2002\nuserPassword: &#123;SSHA&#125;sCwMT7CqCloD4bzvED/1QB9xvUnZ0N5P\n\n</code></pre>\n<p>Para los hash de contraseñas la hemos creado con la utilidad slappasswd, que viene instalada con slapd.</p>\n<pre><code>root@alfa:/home/antonio# slappasswd\nNew password: \nRe-enter new password: \n&#123;SSHA&#125;sfqp8j+/1HHe7N6qcbDIrLkf3T2c4wIW\n</code></pre>\n<p>Para agregar al usuario prueba y al usuario macarena debemos de volver a inyectar el fichero Usuario.ldif en el árbol de slapd, para ello ejecutamos el siguiente comando:</p>\n<pre><code>ldapadd -x -D &quot;cn=admin,dc=antonio,dc=gonzalonazareno,dc=org&quot; -f usuarios.ldif -W\n</code></pre>\n<p><img src=\"/images/slap-1-4.png\" alt=\"Descripción de la imagen\"></p>\n<p>Lo que hemos hecho ha sido insertar registros en el objeto de personas, ahora vamos a crear un grupo, para ello crearemos un fichero llamado grupos.ldif, y le daremos el siguiente contenido:</p>\n<pre><code>dn: cn=desarrollo,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: top\nobjectClass: groupOfNames\ncn: desarrollo\nmember:\n\ndn: cn=sistemas,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: top\nobjectClass: groupOfNames\ncn: sistemas\nmember:\n</code></pre>\n<p>A continuación vamos a inyectar el fichero grupos.ldif en el árbol de slapd, para ello ejecutamos el siguiente comando:</p>\n<pre><code>ldapadd -x -D &quot;cn=admin,dc=antonio,dc=gonzalonazareno,dc=org&quot; -f grupos.ldif -W\n</code></pre>\n<p><img src=\"/images/slap-1-5.png\" alt=\"Descripción de la imagen\"></p>\n<p>Luego vamos a añadir a los usuarios a los grupos, para ello crearemos un fichero llamado personas-grupos.ldif, y le daremos el siguiente contenido:</p>\n<pre><code># Al grupo de desarrollo\ndn: cn=desarrollo,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nchangetype:modify\nadd: member\nmember: uid=prueba,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\n\n# Al grupo de desarrollo y sistemas\ndn: cn=desarrollo,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nchangetype:modify\nadd: member\nmember: uid=macarena,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\n\ndn: cn=sistemas,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nchangetype:modify\nadd: member\nmember: uid=macarena,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\n</code></pre>\n<p>A continuación vamos a inyectar el fichero personas-grupos.ldif en el árbol de slapd, para ello ejecutamos el siguiente comando:</p>\n<pre><code>ldapmodify -x -D &quot;cn=admin,dc=antonio,dc=gonzalonazareno,dc=org&quot; -f personas-grupos.ldif -W\n</code></pre>\n<p><img src=\"/images/slap-1-6.png\" alt=\"Descripción de la imagen\"></p>\n<p>Podríamos usar también ldapmodify que es una herramiente enfocada a la modificación, pero para nuestro caso ambas nos sirven.</p>\n<p>Usando el comando ldapsearch podemos ver que los usuarios están en los grupos:</p>\n<pre><code>ldapsearch -x -D &quot;cn=admin,dc=antonio,dc=gonzalonazareno,dc=org&quot; -b &quot;cn=desarrollo,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org&quot; -W\n</code></pre>\n<pre><code>root@alfa:/home/antonio# ldapsearch -x -b ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\n# extended LDIF\n#\n# LDAPv3\n# base &lt;ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org&gt; with scope subtree\n# filter: (objectclass=*)\n# requesting: ALL\n#\n\n# Grupos, antonio.gonzalonazareno.org\ndn: ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: organizationalUnit\nou: Grupos\n\n# sistemas, Grupos, antonio.gonzalonazareno.org\ndn: cn=sistemas,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: top\nobjectClass: groupOfNames\ncn: sistemas\nmember:\nmember: uid=macarena,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\n\n# desarrollo, Grupos, antonio.gonzalonazareno.org\ndn: cn=desarrollo,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\nobjectClass: top\nobjectClass: groupOfNames\ncn: desarrollo\nmember:\nmember: uid=prueba,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\nmember: uid=macarena,ou=Personas,dc=antonio,dc=gonzalonazareno,dc=org\n\n# search result\nsearch: 2\nresult: 0 Success\n\n# numResponses: 6\n# numEntries: 5\n</code></pre>\n<p>Si queremos borrar un elemento del árbol podemos realizarlo gracias a la siguiente instrucción:</p>\n<pre><code>ldapdelete -x -D 'cn=admin,dc=antonio,dc=gonzalonazareno,dc=org' -W cn=reabastecimiento,ou=Grupos,dc=antonio,dc=gonzalonazareno,dc=org\n</code></pre>\n<p>Desplegar árbol a través de NFS:</p>\n<p>apt-get install nfs-kernel-server -y</p>\n<p>Nos vamos a /etc/exportfs y añadimos la siguiente línea:</p>\n<pre><code>/home/antonio/nfs *(rw,fsid=0,subtree_check,no_root_squash)\n</code></pre>\n<p>Ahora ejecutamos  <code>exportfs -a</code></p>\n<pre><code>root@alfa:/home/antonio# mkdir nfs\nroot@alfa:/home/antonio# mkdir nfs/almacenamiento\n</code></pre>\n<p>Comenzamos con la configuración del paquete nscd. Este es un demonio de caché para el servicio de nombres, lo cual evitará repetir consultas de las bases de datos de passwd, group y hosts.</p>\n<pre><code>apt install libnss-ldapd libpam-ldapd nscd -y\n</code></pre>\n<p>Luego de configurar el instalador de forma que capture la ip 127.0.0.1 y el nombre dc=antonio,dc=gonzalonazareno,dc=org, debemos editar el fichero /etc/nsswitch.conf, y añadir las siguientes líneas:</p>\n<p><img src=\"/images/slap-1-7.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"cliente-ubuntu\"><a class=\"markdownIt-Anchor\" href=\"#cliente-ubuntu\">#</a> Cliente Ubuntu</h2>\n<pre><code>apt-get install libnss-ldapd libpam-ldapd nscd nfs-kernel-server -y\n</code></pre>\n<p>Introducimos la dirección IP del servidor LDAP y el nombre del dominio:</p>\n<p><img src=\"/images/slap-1-8.png\" alt=\"Descripción de la imagen\"></p>\n<p>En el fichero /etc/ldap/ldap.conf se establecen los parámetros de configuración del cliente LDAP. En este fichero se establece la dirección del servidor LDAP, el puerto, el dominio, el tipo de autenticación, etc.</p>\n<pre><code>#\n# LDAP Defaults\n#\n\n# See ldap.conf(5) for details\n# This file should be world readable but not world writable.\n\nBASE    dc=antonio,dc=gonzalonazareno,dc=org\nURI     ldap://192.168.0.1\n\nSIZELIMIT       12\nTIMELIMIT       15\nDEREF           never\n\n# TLS certificates (needed for GnuTLS)\nTLS_CACERT      /etc/ssl/certs/ca-certificates.crt\n</code></pre>\n<p>Ahora necesitaremos configurar el cliente para que al iniciar sesión cree el home del usuario. Para ello editamos el fichero /etc/pam.d/common-account y añadimos la siguiente línea:</p>\n<pre><code>session required pam_mkhomedir.so skel=/etc/skel/ umask=0022\n\n</code></pre>\n<p>Vamos a probar montando de manera efímera el directorio en el cual se va a crear el home del usuario macarena:</p>\n<pre><code>mount -t nfs 192.168.0.1:/home/antonio/nfs/ /home\n</code></pre>\n<p>Ahora cuando el usuario macarena inicie sesión este se verá reflejado en nuestro servidor nfs, probaremos creando un documento txt:</p>\n<p><img src=\"/images/slap-1-9.png\" alt=\"Descripción de la imagen\"></p>\n<p>Ahora vamos a hacer que este recurso funcione de manera permanente, para ello podríamos editar el fichero fstab, o bien crear una unidad de systemd, que en este caso es lo que vamos a emplear.</p>\n<p>nano /etc/systemd/system/home.mount</p>\n<pre><code>[Unit]\nDescription= Montaje de carpeta home para NFS\n\n[Mount]\nWhat=192.168.0.1:/home/antonio/nfs\nWhere=/home   \nType=nfs\nOptions=defaults\n\n[Install]\nWantedBy=multi-user.target\n\n</code></pre>\n<p>systemctl daemon-reload<br>\nsystemctl enable home.mount<br>\nsystemctl start home.mount<br>\nsystemctl status home.mount</p>\n<p><img src=\"/images/slap-1-10.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"cliente-rocky-linux\"><a class=\"markdownIt-Anchor\" href=\"#cliente-rocky-linux\">#</a> Cliente Rocky Linux</h2>\n<pre><code>dnf install openldap-clients sssd sssd-ldap oddjob-mkhomedir sssd-tools -y\n</code></pre>\n<pre><code>authselect list\n</code></pre>\n<pre><code>[root@bravo antonio]# authselect list\n- minimal\t Local users only for minimal installations\n- sssd   \t Enable SSSD for system authentication (also for local users only)\n- winbind\t Enable winbind for system authentication\n\n</code></pre>\n<pre><code>authselect select sssd with-mkhomedir --force\n</code></pre>\n<p>volvemos a especificar la dirección IP del servidor LDAP y el nombre del dominio en /etc/openldap/ldap.conf:</p>\n<pre><code>BASE dc=antonio,dc=gonzalonazareno,dc=org\nURI ldap://172.16.0.1\n\n\nSIZELIMIT       12\nTIMELIMIT       15\nDEREF           never\n</code></pre>\n<p>sudo nano /etc/sssd/sssd.conf</p>\n<pre><code>[domain/default]\nid_provider = ldap\nautofs_provider = ldap\nauth_provider = ldap\nchpass_provider = ldap\nldap_uri = ldap://172.0.16.1\nldap_search_base = dc=antonio,dc=gonzalonazareno,dc=org\nldap_id_use_start_tls = True\nldap_tls_cacertdir = /etc/openldap/cacerts\ncache_credentials = True\nldap_tls_reqcert = allow\n\n[sssd]\nservices = nss, pam, autofs\ndomains = default\n\n[nss]\nhomedir_substring = /home/nfs\n\n</code></pre>\n<pre><code>chmod 0600 /etc/sssd/sssd.conf\nsystemctl restart sssd\n</code></pre>\n<p>authconfig --enablemkhomedir --updateall</p>\n<pre><code>authconfig --enableldap \\\n--enableldapauth \\\n--ldapserver=antonio.gonzalonazareno.org \\\n--ldapbasedn=&quot;dc=antonio,dc=gonzalonazareno,dc=org&quot; \\\n--enablemkhomedir \\\n--update\n</code></pre>\n<p><img src=\"/images/slap-1-11.png\" alt=\"Descripción de la imagen\"></p>\n"},{"title":"Instalación automatizada basada en medio de almacenamiento extraíble.","_content":"\nHe comenzado descargando el archivo iso para poder abrirlo y colocar el preseed en él, el comando que he utilizado es xorriso.\nTras esto he utilizado una plantilla de la web de debian\n\nhttps://www.debian.org/releases/buster/example-preseed.txt\n\nTras esto he estado configurando preseed.cfg para poner la hora, el país y el teclado en español y resulta que estuve un tiempo estancado en esto porque hay que corroborar los cambios en el archivo isofiles/isolinux/txt.cfg\nA su vez también debemos indicar la ruta donde vama a estar el preseed para que el sistema lo localice, en mi caso estará en la raíz de la ISO (CDROM)\n```\nlabel install\n        menu label ^Install\n        kernel /install.amd/vmlinuz\n        append vga=788 initrd=/install.amd/initrd.gz --- quiet\nlabel unattended-gnome\n menu label ^Instalación Debian Desatendida Preseed Antonio\n kernel /install.amd/gtk/vmlinuz\n append vga=788 initrd=/install.amd/gtk/initrd.gz preseed/file=/cdrom/preseed.cfg locale=es_ES console-setup/ask_detect=false keyboard-configuration/xkb-keymap=es\n```\nAl tener que desensamblar y ensamblar constantemente el iso para poner el preseed actualizado llegó un momento en el que se hacía inviable seguir probando sin hacer un script con los pasos que se repetían, entonces lo realicé:\n\n```\n#!/usr/bin/env bash\nfichero=/home/antonio/Descargas/preseed-instalacion/preseed-debian-10.1.0-amd64-script-netinst.iso\nchmod u+w isofiles\ncp preseed.cfg ~/Descargas/preseed-instalacion/isofiles\nchmod u-w isofiles\ncd ~/Descargas/preseed-instalacion\nchmod a+w isofiles/isolinux/isolinux.bin\nif [ -f $fichero ]\nthen\n        rm -f $fichero\nfi      \ngenisoimage -r -J -b isolinux/isolinux.bin -c isolinux/boot.cat -no-emul-boot -boot-load-size 4 -boot-info-table -o preseed-debian-10>\n```\nTuve que meter la condición de que si el iso creado existía lo borrara porque al ejecutar genisoimage si el nombre ya existe provoca conflictos.\n\nEntonces estuve probando, metiendo el usuario de la máquina con la contraseña sin encriptar, para ver el funcionamiento y que lo anterior configurado fuese por buen camino.\n\nEstuve probando formas de encriptar la contraseña, la plantilla me recomendaba que usara  **Crypt 3** pero es un método muy vulnerable, así que mirando la documentación vi que podía meter un hash **md5**.\n\nEntonces empecé a encriptar la contraseña, para ello utilicé `mkpasswd -m sha-512` el cual al ingresar la contraseña me la devuelve encriptada, activo la opción de `d-i passwd/user-password-crypted password` junto con la contraseña encriptada\n\nYa entonces, con la localización y el teclado en español, la cuenta del usuario con su contraseña encriptada decido comenzar a realizar las particiones de lvm.\nTuve muchísimos errores de sintaxis pero gracias al script podía probar de manera más rápida las diferentes combinaciones de particionado y ajustando la sintaxis conseguí realizarlo:\n\n![Descripción de la imagen](/images/ASO-PRACTICA1.png)\n","source":"_posts/preseed.md","raw":"---\ntitle: Instalación automatizada basada en medio de almacenamiento extraíble.\ncategories: Sistemas Operativos\n---\n\nHe comenzado descargando el archivo iso para poder abrirlo y colocar el preseed en él, el comando que he utilizado es xorriso.\nTras esto he utilizado una plantilla de la web de debian\n\nhttps://www.debian.org/releases/buster/example-preseed.txt\n\nTras esto he estado configurando preseed.cfg para poner la hora, el país y el teclado en español y resulta que estuve un tiempo estancado en esto porque hay que corroborar los cambios en el archivo isofiles/isolinux/txt.cfg\nA su vez también debemos indicar la ruta donde vama a estar el preseed para que el sistema lo localice, en mi caso estará en la raíz de la ISO (CDROM)\n```\nlabel install\n        menu label ^Install\n        kernel /install.amd/vmlinuz\n        append vga=788 initrd=/install.amd/initrd.gz --- quiet\nlabel unattended-gnome\n menu label ^Instalación Debian Desatendida Preseed Antonio\n kernel /install.amd/gtk/vmlinuz\n append vga=788 initrd=/install.amd/gtk/initrd.gz preseed/file=/cdrom/preseed.cfg locale=es_ES console-setup/ask_detect=false keyboard-configuration/xkb-keymap=es\n```\nAl tener que desensamblar y ensamblar constantemente el iso para poner el preseed actualizado llegó un momento en el que se hacía inviable seguir probando sin hacer un script con los pasos que se repetían, entonces lo realicé:\n\n```\n#!/usr/bin/env bash\nfichero=/home/antonio/Descargas/preseed-instalacion/preseed-debian-10.1.0-amd64-script-netinst.iso\nchmod u+w isofiles\ncp preseed.cfg ~/Descargas/preseed-instalacion/isofiles\nchmod u-w isofiles\ncd ~/Descargas/preseed-instalacion\nchmod a+w isofiles/isolinux/isolinux.bin\nif [ -f $fichero ]\nthen\n        rm -f $fichero\nfi      \ngenisoimage -r -J -b isolinux/isolinux.bin -c isolinux/boot.cat -no-emul-boot -boot-load-size 4 -boot-info-table -o preseed-debian-10>\n```\nTuve que meter la condición de que si el iso creado existía lo borrara porque al ejecutar genisoimage si el nombre ya existe provoca conflictos.\n\nEntonces estuve probando, metiendo el usuario de la máquina con la contraseña sin encriptar, para ver el funcionamiento y que lo anterior configurado fuese por buen camino.\n\nEstuve probando formas de encriptar la contraseña, la plantilla me recomendaba que usara  **Crypt 3** pero es un método muy vulnerable, así que mirando la documentación vi que podía meter un hash **md5**.\n\nEntonces empecé a encriptar la contraseña, para ello utilicé `mkpasswd -m sha-512` el cual al ingresar la contraseña me la devuelve encriptada, activo la opción de `d-i passwd/user-password-crypted password` junto con la contraseña encriptada\n\nYa entonces, con la localización y el teclado en español, la cuenta del usuario con su contraseña encriptada decido comenzar a realizar las particiones de lvm.\nTuve muchísimos errores de sintaxis pero gracias al script podía probar de manera más rápida las diferentes combinaciones de particionado y ajustando la sintaxis conseguí realizarlo:\n\n![Descripción de la imagen](/images/ASO-PRACTICA1.png)\n","slug":"preseed","published":1,"date":"2022-09-30T07:12:30.816Z","updated":"2023-01-04T13:35:06.211Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cldl9ucgs000r0yi59e1nf2e8","content":"<p>He comenzado descargando el archivo iso para poder abrirlo y colocar el preseed en él, el comando que he utilizado es xorriso.<br>\nTras esto he utilizado una plantilla de la web de debian</p>\n<p><a href=\"https://www.debian.org/releases/buster/example-preseed.txt\">https://www.debian.org/releases/buster/example-preseed.txt</a></p>\n<p>Tras esto he estado configurando preseed.cfg para poner la hora, el país y el teclado en español y resulta que estuve un tiempo estancado en esto porque hay que corroborar los cambios en el archivo isofiles/isolinux/txt.cfg<br>\nA su vez también debemos indicar la ruta donde vama a estar el preseed para que el sistema lo localice, en mi caso estará en la raíz de la ISO (CDROM)</p>\n<pre><code>label install\n        menu label ^Install\n        kernel /install.amd/vmlinuz\n        append vga=788 initrd=/install.amd/initrd.gz --- quiet\nlabel unattended-gnome\n menu label ^Instalación Debian Desatendida Preseed Antonio\n kernel /install.amd/gtk/vmlinuz\n append vga=788 initrd=/install.amd/gtk/initrd.gz preseed/file=/cdrom/preseed.cfg locale=es_ES console-setup/ask_detect=false keyboard-configuration/xkb-keymap=es\n</code></pre>\n<p>Al tener que desensamblar y ensamblar constantemente el iso para poner el preseed actualizado llegó un momento en el que se hacía inviable seguir probando sin hacer un script con los pasos que se repetían, entonces lo realicé:</p>\n<pre><code>#!/usr/bin/env bash\nfichero=/home/antonio/Descargas/preseed-instalacion/preseed-debian-10.1.0-amd64-script-netinst.iso\nchmod u+w isofiles\ncp preseed.cfg ~/Descargas/preseed-instalacion/isofiles\nchmod u-w isofiles\ncd ~/Descargas/preseed-instalacion\nchmod a+w isofiles/isolinux/isolinux.bin\nif [ -f $fichero ]\nthen\n        rm -f $fichero\nfi      \ngenisoimage -r -J -b isolinux/isolinux.bin -c isolinux/boot.cat -no-emul-boot -boot-load-size 4 -boot-info-table -o preseed-debian-10&gt;\n</code></pre>\n<p>Tuve que meter la condición de que si el iso creado existía lo borrara porque al ejecutar genisoimage si el nombre ya existe provoca conflictos.</p>\n<p>Entonces estuve probando, metiendo el usuario de la máquina con la contraseña sin encriptar, para ver el funcionamiento y que lo anterior configurado fuese por buen camino.</p>\n<p>Estuve probando formas de encriptar la contraseña, la plantilla me recomendaba que usara  <strong>Crypt 3</strong> pero es un método muy vulnerable, así que mirando la documentación vi que podía meter un hash <strong>md5</strong>.</p>\n<p>Entonces empecé a encriptar la contraseña, para ello utilicé  <code>mkpasswd -m sha-512</code>  el cual al ingresar la contraseña me la devuelve encriptada, activo la opción de  <code>d-i passwd/user-password-crypted password</code>  junto con la contraseña encriptada</p>\n<p>Ya entonces, con la localización y el teclado en español, la cuenta del usuario con su contraseña encriptada decido comenzar a realizar las particiones de lvm.<br>\nTuve muchísimos errores de sintaxis pero gracias al script podía probar de manera más rápida las diferentes combinaciones de particionado y ajustando la sintaxis conseguí realizarlo:</p>\n<p><img src=\"/images/ASO-PRACTICA1.png\" alt=\"Descripción de la imagen\"></p>\n","site":{"data":{}},"length":2423,"excerpt":"","more":"<p>He comenzado descargando el archivo iso para poder abrirlo y colocar el preseed en él, el comando que he utilizado es xorriso.<br>\nTras esto he utilizado una plantilla de la web de debian</p>\n<p><a href=\"https://www.debian.org/releases/buster/example-preseed.txt\">https://www.debian.org/releases/buster/example-preseed.txt</a></p>\n<p>Tras esto he estado configurando preseed.cfg para poner la hora, el país y el teclado en español y resulta que estuve un tiempo estancado en esto porque hay que corroborar los cambios en el archivo isofiles/isolinux/txt.cfg<br>\nA su vez también debemos indicar la ruta donde vama a estar el preseed para que el sistema lo localice, en mi caso estará en la raíz de la ISO (CDROM)</p>\n<pre><code>label install\n        menu label ^Install\n        kernel /install.amd/vmlinuz\n        append vga=788 initrd=/install.amd/initrd.gz --- quiet\nlabel unattended-gnome\n menu label ^Instalación Debian Desatendida Preseed Antonio\n kernel /install.amd/gtk/vmlinuz\n append vga=788 initrd=/install.amd/gtk/initrd.gz preseed/file=/cdrom/preseed.cfg locale=es_ES console-setup/ask_detect=false keyboard-configuration/xkb-keymap=es\n</code></pre>\n<p>Al tener que desensamblar y ensamblar constantemente el iso para poner el preseed actualizado llegó un momento en el que se hacía inviable seguir probando sin hacer un script con los pasos que se repetían, entonces lo realicé:</p>\n<pre><code>#!/usr/bin/env bash\nfichero=/home/antonio/Descargas/preseed-instalacion/preseed-debian-10.1.0-amd64-script-netinst.iso\nchmod u+w isofiles\ncp preseed.cfg ~/Descargas/preseed-instalacion/isofiles\nchmod u-w isofiles\ncd ~/Descargas/preseed-instalacion\nchmod a+w isofiles/isolinux/isolinux.bin\nif [ -f $fichero ]\nthen\n        rm -f $fichero\nfi      \ngenisoimage -r -J -b isolinux/isolinux.bin -c isolinux/boot.cat -no-emul-boot -boot-load-size 4 -boot-info-table -o preseed-debian-10&gt;\n</code></pre>\n<p>Tuve que meter la condición de que si el iso creado existía lo borrara porque al ejecutar genisoimage si el nombre ya existe provoca conflictos.</p>\n<p>Entonces estuve probando, metiendo el usuario de la máquina con la contraseña sin encriptar, para ver el funcionamiento y que lo anterior configurado fuese por buen camino.</p>\n<p>Estuve probando formas de encriptar la contraseña, la plantilla me recomendaba que usara  <strong>Crypt 3</strong> pero es un método muy vulnerable, así que mirando la documentación vi que podía meter un hash <strong>md5</strong>.</p>\n<p>Entonces empecé a encriptar la contraseña, para ello utilicé  <code>mkpasswd -m sha-512</code>  el cual al ingresar la contraseña me la devuelve encriptada, activo la opción de  <code>d-i passwd/user-password-crypted password</code>  junto con la contraseña encriptada</p>\n<p>Ya entonces, con la localización y el teclado en español, la cuenta del usuario con su contraseña encriptada decido comenzar a realizar las particiones de lvm.<br>\nTuve muchísimos errores de sintaxis pero gracias al script podía probar de manera más rápida las diferentes combinaciones de particionado y ajustando la sintaxis conseguí realizarlo:</p>\n<p><img src=\"/images/ASO-PRACTICA1.png\" alt=\"Descripción de la imagen\"></p>\n"},{"title":"VPN Wireguard","_content":"\n![wireguard-site-1.png](/images/logo-wireguard.png)\n\n# Site to Site\n\n## Linux\n\nPrimero vamos a cada cliente y vamos a establecer la ruta por defecto\n\n```\nCliente 1:\n    sudo ip route del default\n    sudo ip route add default via 192.168.200.1\n```\n\n```\nCliente 2:\n\n    sudo ip route del default\n    sudo ip route add default via 192.168.100.1\n```\n\n\nAhora nos conectarems a **cada servidor** de manera que en cada uno realizaremos los siguientes comandos:\n```\nInstalamos wireguard\n    sudo apt update\n    sudo apt install wireguard\n```\n\nCreamos la clave privada y pública\n\n`wg genkey | sudo tee /etc/wireguard/server_private.key | wg pubkey | sudo tee /etc/wireguard/server_public.key`\n\n```\ncat /etc/wireguard/server_private.key\ncat /etc/wireguard/server_public.key\n```\nEl resultado de los comandos será cada clave pública y privada de los servidores\n\nCreo el fichero de configuración en el que la interfaz se llamará wg0.conf\n\n    sudo nano /etc/wireguard/wg0.conf\n\nDespués de esto en vpn1 quedará el archivo de configuración de la siguiente manera:\n\n```\n[Interface]\nAddress = 10.99.99.1\nPrivateKey = UKn7oartqeJjRPk8jUtACSTYn/e23wszOBxT/Ymo1Uk=\nListenPort = 51820\n\n[Peer]\nPublicKey = PWrfuUd1UODnjTPuFCJfy/eixRTEsCq/KioI74/vDFo=\nAllowedIPs = 0.0.0.0/0\nEndpoint = 10.0.0.1:51820\nPersistentKeepAlive = 25\n\n```\n\n\nEl siguiente archivo de configuración es el de vpn2:\n\n```\n[Interface]\nAddress = 10.99.99.2\nPrivateKey = MCL13K+q/43eyF8qLtBxz9cNhvcFxQ2s98LOiseZy3w=\nListenPort = 51820\n\n[Peer]\nPublicKey = 2az5T5rW/7x1Z/YLRfX7saNteaOsoupFh07Z6VkeUjI=\nAllowedIPs = 0.0.0.0/0\nEndpoint = 10.0.0.10:51820\n```\n\nAhora en **cada servidor** emplearemos \n\n`wg-quick up wg0` para activar el servicio\n`wg-quick down wg0` para desactivar el servicio\n`wg` para poder ver el estado del servicio\n\nEn los servidores hay que intercambiar las respectivas claves públicas e ingresarlo en PublicKey.\nAddress es la ip del túnel que se va a asignar en cada extremo del servidor.\nAllowedIPs es las ip permitidas hacia el servidor\nEndpoint es la ip pública del servidor y el puerto que se ha configurado en el servidor opuesto.\nPersistentKeepAlive es el tiempo en el que se realizan las comprobaciones de conexión.\n\n\nAhora entraremos a cada cliente y realizaremos la comprobación de que pueden conectarse:\n\n\n![wireguard-site-1.png](/images/wireguard-site-1.png)\n\n\n## Cliente Windows\n\n\nAhora vamos a proceder a conectar un segundo cliente windows:\n\n\n![wireguard-site-2.png](/images/wireguard-site-2.png)\n\n\nAhora cambiaremos la interfaz para establecer una ip estática:\n\n\n![wireguard-site-2.png](/images/wireguard-site-3.png)\n\nUna vez hecho esto probamos a hacer un ping para ver que podemos comunicarnos en remoto a través de la VPN\n\n![wireguard-site-2.png](/images/wireguard-site-4.png)\n\n\n# Point to Site\n\nLa misma configuración que en el site to site, solo que no activaremos el bit de forwarding en el cliente final ya que este mismo no hará de router.\n\n\n```\n[Interface]\nAddress = 10.99.99.1\nPrivateKey = 4GLQzZT6G/Oq69aAitajxl7ZRtzuV1cFrsI0j4Cqjk4=\nListenPort = 51820\n\n[Peer]\nPublickey = fKWBm53DKrAAukk6nssSZ0DuVy9jEBIRKbqOS22sdg8=\nAllowedIPs = 0.0.0.0/0\nPersistentKeepAlive = 25\nEndpoint = 192.188.188.20:51820\n\n```\n\n\n![wireguard-site-1.png](/images/vpn-cliente-C-lin.png)\n\n\n\nLuego conectaremos la interfaz en windows como explicamos anteriormente y activaremos la configuración de la VPN como hemos hecho en linux, solo que esta vez su ip de la ruta será \n10.99.99.4/32\n\n![wireguard-site-1.png](/images/vpn-cliente-C-win2.png)\n\n\nFinalmente copiamos la configuración en el servidor con la clave pública de la vpn de windows y de esta manera reiniciando el servicio con wg-quick down wg0 y wg-quick up wg0 ya tendremos la vpn funcionando.\n\n```\n[Peer]\nPublickey = I/Gj50Ue+qmv+a4Q+C1VcJ4VptBVnU3QfDgo//vq+Fw=\nAllowedIPs = 0.0.0.0/0\nPersistentKeepAlive = 25\nEndpoint = 192.188.188.21:51820\n```\n\n\n![wireguard-site-1.png](/images/vpn-cliente-C-win.png)\n\n","source":"_posts/vpn-wireguard.md","raw":"---\ntitle: VPN Wireguard\ncategories: Seguridad\ntags: Seguridad\n---\n\n![wireguard-site-1.png](/images/logo-wireguard.png)\n\n# Site to Site\n\n## Linux\n\nPrimero vamos a cada cliente y vamos a establecer la ruta por defecto\n\n```\nCliente 1:\n    sudo ip route del default\n    sudo ip route add default via 192.168.200.1\n```\n\n```\nCliente 2:\n\n    sudo ip route del default\n    sudo ip route add default via 192.168.100.1\n```\n\n\nAhora nos conectarems a **cada servidor** de manera que en cada uno realizaremos los siguientes comandos:\n```\nInstalamos wireguard\n    sudo apt update\n    sudo apt install wireguard\n```\n\nCreamos la clave privada y pública\n\n`wg genkey | sudo tee /etc/wireguard/server_private.key | wg pubkey | sudo tee /etc/wireguard/server_public.key`\n\n```\ncat /etc/wireguard/server_private.key\ncat /etc/wireguard/server_public.key\n```\nEl resultado de los comandos será cada clave pública y privada de los servidores\n\nCreo el fichero de configuración en el que la interfaz se llamará wg0.conf\n\n    sudo nano /etc/wireguard/wg0.conf\n\nDespués de esto en vpn1 quedará el archivo de configuración de la siguiente manera:\n\n```\n[Interface]\nAddress = 10.99.99.1\nPrivateKey = UKn7oartqeJjRPk8jUtACSTYn/e23wszOBxT/Ymo1Uk=\nListenPort = 51820\n\n[Peer]\nPublicKey = PWrfuUd1UODnjTPuFCJfy/eixRTEsCq/KioI74/vDFo=\nAllowedIPs = 0.0.0.0/0\nEndpoint = 10.0.0.1:51820\nPersistentKeepAlive = 25\n\n```\n\n\nEl siguiente archivo de configuración es el de vpn2:\n\n```\n[Interface]\nAddress = 10.99.99.2\nPrivateKey = MCL13K+q/43eyF8qLtBxz9cNhvcFxQ2s98LOiseZy3w=\nListenPort = 51820\n\n[Peer]\nPublicKey = 2az5T5rW/7x1Z/YLRfX7saNteaOsoupFh07Z6VkeUjI=\nAllowedIPs = 0.0.0.0/0\nEndpoint = 10.0.0.10:51820\n```\n\nAhora en **cada servidor** emplearemos \n\n`wg-quick up wg0` para activar el servicio\n`wg-quick down wg0` para desactivar el servicio\n`wg` para poder ver el estado del servicio\n\nEn los servidores hay que intercambiar las respectivas claves públicas e ingresarlo en PublicKey.\nAddress es la ip del túnel que se va a asignar en cada extremo del servidor.\nAllowedIPs es las ip permitidas hacia el servidor\nEndpoint es la ip pública del servidor y el puerto que se ha configurado en el servidor opuesto.\nPersistentKeepAlive es el tiempo en el que se realizan las comprobaciones de conexión.\n\n\nAhora entraremos a cada cliente y realizaremos la comprobación de que pueden conectarse:\n\n\n![wireguard-site-1.png](/images/wireguard-site-1.png)\n\n\n## Cliente Windows\n\n\nAhora vamos a proceder a conectar un segundo cliente windows:\n\n\n![wireguard-site-2.png](/images/wireguard-site-2.png)\n\n\nAhora cambiaremos la interfaz para establecer una ip estática:\n\n\n![wireguard-site-2.png](/images/wireguard-site-3.png)\n\nUna vez hecho esto probamos a hacer un ping para ver que podemos comunicarnos en remoto a través de la VPN\n\n![wireguard-site-2.png](/images/wireguard-site-4.png)\n\n\n# Point to Site\n\nLa misma configuración que en el site to site, solo que no activaremos el bit de forwarding en el cliente final ya que este mismo no hará de router.\n\n\n```\n[Interface]\nAddress = 10.99.99.1\nPrivateKey = 4GLQzZT6G/Oq69aAitajxl7ZRtzuV1cFrsI0j4Cqjk4=\nListenPort = 51820\n\n[Peer]\nPublickey = fKWBm53DKrAAukk6nssSZ0DuVy9jEBIRKbqOS22sdg8=\nAllowedIPs = 0.0.0.0/0\nPersistentKeepAlive = 25\nEndpoint = 192.188.188.20:51820\n\n```\n\n\n![wireguard-site-1.png](/images/vpn-cliente-C-lin.png)\n\n\n\nLuego conectaremos la interfaz en windows como explicamos anteriormente y activaremos la configuración de la VPN como hemos hecho en linux, solo que esta vez su ip de la ruta será \n10.99.99.4/32\n\n![wireguard-site-1.png](/images/vpn-cliente-C-win2.png)\n\n\nFinalmente copiamos la configuración en el servidor con la clave pública de la vpn de windows y de esta manera reiniciando el servicio con wg-quick down wg0 y wg-quick up wg0 ya tendremos la vpn funcionando.\n\n```\n[Peer]\nPublickey = I/Gj50Ue+qmv+a4Q+C1VcJ4VptBVnU3QfDgo//vq+Fw=\nAllowedIPs = 0.0.0.0/0\nPersistentKeepAlive = 25\nEndpoint = 192.188.188.21:51820\n```\n\n\n![wireguard-site-1.png](/images/vpn-cliente-C-win.png)\n\n","slug":"vpn-wireguard","published":1,"date":"2023-01-26T18:57:47.828Z","updated":"2023-01-31T13:33:29.550Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cldl9ucgv00100yi59b3p524w","content":"<p><img src=\"/images/logo-wireguard.png\" alt=\"wireguard-site-1.png\"></p>\n<h1 id=\"site-to-site\"><a class=\"markdownIt-Anchor\" href=\"#site-to-site\">#</a> Site to Site</h1>\n<h2 id=\"linux\"><a class=\"markdownIt-Anchor\" href=\"#linux\">#</a> Linux</h2>\n<p>Primero vamos a cada cliente y vamos a establecer la ruta por defecto</p>\n<pre><code>Cliente 1:\n    sudo ip route del default\n    sudo ip route add default via 192.168.200.1\n</code></pre>\n<pre><code>Cliente 2:\n\n    sudo ip route del default\n    sudo ip route add default via 192.168.100.1\n</code></pre>\n<p>Ahora nos conectarems a <strong>cada servidor</strong> de manera que en cada uno realizaremos los siguientes comandos:</p>\n<pre><code>Instalamos wireguard\n    sudo apt update\n    sudo apt install wireguard\n</code></pre>\n<p>Creamos la clave privada y pública</p>\n<p><code>wg genkey | sudo tee /etc/wireguard/server_private.key | wg pubkey | sudo tee /etc/wireguard/server_public.key</code></p>\n<pre><code>cat /etc/wireguard/server_private.key\ncat /etc/wireguard/server_public.key\n</code></pre>\n<p>El resultado de los comandos será cada clave pública y privada de los servidores</p>\n<p>Creo el fichero de configuración en el que la interfaz se llamará wg0.conf</p>\n<pre><code>sudo nano /etc/wireguard/wg0.conf\n</code></pre>\n<p>Después de esto en vpn1 quedará el archivo de configuración de la siguiente manera:</p>\n<pre><code>[Interface]\nAddress = 10.99.99.1\nPrivateKey = UKn7oartqeJjRPk8jUtACSTYn/e23wszOBxT/Ymo1Uk=\nListenPort = 51820\n\n[Peer]\nPublicKey = PWrfuUd1UODnjTPuFCJfy/eixRTEsCq/KioI74/vDFo=\nAllowedIPs = 0.0.0.0/0\nEndpoint = 10.0.0.1:51820\nPersistentKeepAlive = 25\n\n</code></pre>\n<p>El siguiente archivo de configuración es el de vpn2:</p>\n<pre><code>[Interface]\nAddress = 10.99.99.2\nPrivateKey = MCL13K+q/43eyF8qLtBxz9cNhvcFxQ2s98LOiseZy3w=\nListenPort = 51820\n\n[Peer]\nPublicKey = 2az5T5rW/7x1Z/YLRfX7saNteaOsoupFh07Z6VkeUjI=\nAllowedIPs = 0.0.0.0/0\nEndpoint = 10.0.0.10:51820\n</code></pre>\n<p>Ahora en <strong>cada servidor</strong> emplearemos</p>\n<p><code>wg-quick up wg0</code>  para activar el servicio<br>\n <code>wg-quick down wg0</code>  para desactivar el servicio<br>\n <code>wg</code>  para poder ver el estado del servicio</p>\n<p>En los servidores hay que intercambiar las respectivas claves públicas e ingresarlo en PublicKey.<br>\nAddress es la ip del túnel que se va a asignar en cada extremo del servidor.<br>\nAllowedIPs es las ip permitidas hacia el servidor<br>\nEndpoint es la ip pública del servidor y el puerto que se ha configurado en el servidor opuesto.<br>\nPersistentKeepAlive es el tiempo en el que se realizan las comprobaciones de conexión.</p>\n<p>Ahora entraremos a cada cliente y realizaremos la comprobación de que pueden conectarse:</p>\n<p><img src=\"/images/wireguard-site-1.png\" alt=\"wireguard-site-1.png\"></p>\n<h2 id=\"cliente-windows\"><a class=\"markdownIt-Anchor\" href=\"#cliente-windows\">#</a> Cliente Windows</h2>\n<p>Ahora vamos a proceder a conectar un segundo cliente windows:</p>\n<p><img src=\"/images/wireguard-site-2.png\" alt=\"wireguard-site-2.png\"></p>\n<p>Ahora cambiaremos la interfaz para establecer una ip estática:</p>\n<p><img src=\"/images/wireguard-site-3.png\" alt=\"wireguard-site-2.png\"></p>\n<p>Una vez hecho esto probamos a hacer un ping para ver que podemos comunicarnos en remoto a través de la VPN</p>\n<p><img src=\"/images/wireguard-site-4.png\" alt=\"wireguard-site-2.png\"></p>\n<h1 id=\"point-to-site\"><a class=\"markdownIt-Anchor\" href=\"#point-to-site\">#</a> Point to Site</h1>\n<p>La misma configuración que en el site to site, solo que no activaremos el bit de forwarding en el cliente final ya que este mismo no hará de router.</p>\n<pre><code>[Interface]\nAddress = 10.99.99.1\nPrivateKey = 4GLQzZT6G/Oq69aAitajxl7ZRtzuV1cFrsI0j4Cqjk4=\nListenPort = 51820\n\n[Peer]\nPublickey = fKWBm53DKrAAukk6nssSZ0DuVy9jEBIRKbqOS22sdg8=\nAllowedIPs = 0.0.0.0/0\nPersistentKeepAlive = 25\nEndpoint = 192.188.188.20:51820\n\n</code></pre>\n<p><img src=\"/images/vpn-cliente-C-lin.png\" alt=\"wireguard-site-1.png\"></p>\n<p>Luego conectaremos la interfaz en windows como explicamos anteriormente y activaremos la configuración de la VPN como hemos hecho en linux, solo que esta vez su ip de la ruta será<br>\n10.99.99.4/32</p>\n<p><img src=\"/images/vpn-cliente-C-win2.png\" alt=\"wireguard-site-1.png\"></p>\n<p>Finalmente copiamos la configuración en el servidor con la clave pública de la vpn de windows y de esta manera reiniciando el servicio con wg-quick down wg0 y wg-quick up wg0 ya tendremos la vpn funcionando.</p>\n<pre><code>[Peer]\nPublickey = I/Gj50Ue+qmv+a4Q+C1VcJ4VptBVnU3QfDgo//vq+Fw=\nAllowedIPs = 0.0.0.0/0\nPersistentKeepAlive = 25\nEndpoint = 192.188.188.21:51820\n</code></pre>\n<p><img src=\"/images/vpn-cliente-C-win.png\" alt=\"wireguard-site-1.png\"></p>\n","site":{"data":{}},"length":2837,"excerpt":"","more":"<p><img src=\"/images/logo-wireguard.png\" alt=\"wireguard-site-1.png\"></p>\n<h1 id=\"site-to-site\"><a class=\"markdownIt-Anchor\" href=\"#site-to-site\">#</a> Site to Site</h1>\n<h2 id=\"linux\"><a class=\"markdownIt-Anchor\" href=\"#linux\">#</a> Linux</h2>\n<p>Primero vamos a cada cliente y vamos a establecer la ruta por defecto</p>\n<pre><code>Cliente 1:\n    sudo ip route del default\n    sudo ip route add default via 192.168.200.1\n</code></pre>\n<pre><code>Cliente 2:\n\n    sudo ip route del default\n    sudo ip route add default via 192.168.100.1\n</code></pre>\n<p>Ahora nos conectarems a <strong>cada servidor</strong> de manera que en cada uno realizaremos los siguientes comandos:</p>\n<pre><code>Instalamos wireguard\n    sudo apt update\n    sudo apt install wireguard\n</code></pre>\n<p>Creamos la clave privada y pública</p>\n<p><code>wg genkey | sudo tee /etc/wireguard/server_private.key | wg pubkey | sudo tee /etc/wireguard/server_public.key</code></p>\n<pre><code>cat /etc/wireguard/server_private.key\ncat /etc/wireguard/server_public.key\n</code></pre>\n<p>El resultado de los comandos será cada clave pública y privada de los servidores</p>\n<p>Creo el fichero de configuración en el que la interfaz se llamará wg0.conf</p>\n<pre><code>sudo nano /etc/wireguard/wg0.conf\n</code></pre>\n<p>Después de esto en vpn1 quedará el archivo de configuración de la siguiente manera:</p>\n<pre><code>[Interface]\nAddress = 10.99.99.1\nPrivateKey = UKn7oartqeJjRPk8jUtACSTYn/e23wszOBxT/Ymo1Uk=\nListenPort = 51820\n\n[Peer]\nPublicKey = PWrfuUd1UODnjTPuFCJfy/eixRTEsCq/KioI74/vDFo=\nAllowedIPs = 0.0.0.0/0\nEndpoint = 10.0.0.1:51820\nPersistentKeepAlive = 25\n\n</code></pre>\n<p>El siguiente archivo de configuración es el de vpn2:</p>\n<pre><code>[Interface]\nAddress = 10.99.99.2\nPrivateKey = MCL13K+q/43eyF8qLtBxz9cNhvcFxQ2s98LOiseZy3w=\nListenPort = 51820\n\n[Peer]\nPublicKey = 2az5T5rW/7x1Z/YLRfX7saNteaOsoupFh07Z6VkeUjI=\nAllowedIPs = 0.0.0.0/0\nEndpoint = 10.0.0.10:51820\n</code></pre>\n<p>Ahora en <strong>cada servidor</strong> emplearemos</p>\n<p><code>wg-quick up wg0</code>  para activar el servicio<br>\n <code>wg-quick down wg0</code>  para desactivar el servicio<br>\n <code>wg</code>  para poder ver el estado del servicio</p>\n<p>En los servidores hay que intercambiar las respectivas claves públicas e ingresarlo en PublicKey.<br>\nAddress es la ip del túnel que se va a asignar en cada extremo del servidor.<br>\nAllowedIPs es las ip permitidas hacia el servidor<br>\nEndpoint es la ip pública del servidor y el puerto que se ha configurado en el servidor opuesto.<br>\nPersistentKeepAlive es el tiempo en el que se realizan las comprobaciones de conexión.</p>\n<p>Ahora entraremos a cada cliente y realizaremos la comprobación de que pueden conectarse:</p>\n<p><img src=\"/images/wireguard-site-1.png\" alt=\"wireguard-site-1.png\"></p>\n<h2 id=\"cliente-windows\"><a class=\"markdownIt-Anchor\" href=\"#cliente-windows\">#</a> Cliente Windows</h2>\n<p>Ahora vamos a proceder a conectar un segundo cliente windows:</p>\n<p><img src=\"/images/wireguard-site-2.png\" alt=\"wireguard-site-2.png\"></p>\n<p>Ahora cambiaremos la interfaz para establecer una ip estática:</p>\n<p><img src=\"/images/wireguard-site-3.png\" alt=\"wireguard-site-2.png\"></p>\n<p>Una vez hecho esto probamos a hacer un ping para ver que podemos comunicarnos en remoto a través de la VPN</p>\n<p><img src=\"/images/wireguard-site-4.png\" alt=\"wireguard-site-2.png\"></p>\n<h1 id=\"point-to-site\"><a class=\"markdownIt-Anchor\" href=\"#point-to-site\">#</a> Point to Site</h1>\n<p>La misma configuración que en el site to site, solo que no activaremos el bit de forwarding en el cliente final ya que este mismo no hará de router.</p>\n<pre><code>[Interface]\nAddress = 10.99.99.1\nPrivateKey = 4GLQzZT6G/Oq69aAitajxl7ZRtzuV1cFrsI0j4Cqjk4=\nListenPort = 51820\n\n[Peer]\nPublickey = fKWBm53DKrAAukk6nssSZ0DuVy9jEBIRKbqOS22sdg8=\nAllowedIPs = 0.0.0.0/0\nPersistentKeepAlive = 25\nEndpoint = 192.188.188.20:51820\n\n</code></pre>\n<p><img src=\"/images/vpn-cliente-C-lin.png\" alt=\"wireguard-site-1.png\"></p>\n<p>Luego conectaremos la interfaz en windows como explicamos anteriormente y activaremos la configuración de la VPN como hemos hecho en linux, solo que esta vez su ip de la ruta será<br>\n10.99.99.4/32</p>\n<p><img src=\"/images/vpn-cliente-C-win2.png\" alt=\"wireguard-site-1.png\"></p>\n<p>Finalmente copiamos la configuración en el servidor con la clave pública de la vpn de windows y de esta manera reiniciando el servicio con wg-quick down wg0 y wg-quick up wg0 ya tendremos la vpn funcionando.</p>\n<pre><code>[Peer]\nPublickey = I/Gj50Ue+qmv+a4Q+C1VcJ4VptBVnU3QfDgo//vq+Fw=\nAllowedIPs = 0.0.0.0/0\nPersistentKeepAlive = 25\nEndpoint = 192.188.188.21:51820\n</code></pre>\n<p><img src=\"/images/vpn-cliente-C-win.png\" alt=\"wireguard-site-1.png\"></p>\n"},{"title":"Cliente-Servidor Openvpn","_content":"\n\n![Descripción de la imagen](/images/vpn-logo.png)\n\n\n# Cliente-Servidor Openvpn\n\n\n\n## Servidor\n\nTendremos un escenario en vagrant en el cual constará de 3 máquinas, un cliente externo, el servidor vpn \n\n\n\n\nEntramos en el servidor vpn y haremos apt update, y después instalaremos openvpn que servirá tanto para el cliente como para el servidor.\n\n\nActivamos el bit de forwarding en `/etc/sysctl.conf`  net.ipv4.ip_forward=1\nEjecutamos `sudo sysctl -p` para que lea el archivo sysctl.conf\n\n\n`sudo cp -r /usr/share/easy-rsa /etc/openvpn`\n\n\n`cd /etc/openvpn/easy-rsa`\n\nActivamos el servicio de infraestructura pública:\n\n`sudo ./easyrsa init-pki`\n\nTras esto generamos la entidad certificadora con su respectiva clave privada gracias al binario easyrsa.\n\n`./easyrsa build-ca`\n\nAhora vamos a montar el servidor de certificaciones:\n\n`./easyrsa build-server-full server nopass`\n\nGeneramos parámetros de Diffie-Helman, el objetivo del algoritmo de cifrado Diffie-Hellman es lograr el intercambio de una clave secreta por medio de un canal inseguro como es internet. Para que este algoritmo funcione, los datos informáticos deben traducirse a números, lo cual es posible por medio de sistemas como el código ASCII, combinado con otros.\n\n`sudo ./easyrsa gen-dh`\n\nGeneramos el par de claves del cliente:\n`./easyrsa build-client-full clientevpn nopass`\n\nAhora pasamos las claves al servidor cliente\n\n```\nsudo cp -rp /etc/openvpn/easy-rsa/pki/{ca.crt,issued/clientevpn.crt,private/clientevpn.key} /home/vagrant/\ncd /home/vagrant\nsudo chown vagrant:vagrant {ca.crt,clientevpn.crt,clientevpn.key}\nscp {ca.crt,clientevpn.crt,clientevpn.key} vagrant@vpn-cli:\n```\n\nAhora configuraremos los parámetros del servidor y sus saltos:\n\n\n`/etc/openvpn/server/servidor.conf`\n\n``` \nport 1194\nproto udp\ndev tun\n\n\nca /etc/openvpn/easy-rsa/pki/ca.crt\ncert /etc/openvpn/easy-rsa/pki/issued/server.crt\nkey /etc/openvpn/easy-rsa/pki/private/server.key\ndh /etc/openvpn/easy-rsa/pki/dh.pem\n\n\ntopology subnet\n\n\nserver 9.8.7.0 255.255.255.0\nifconfig-pool-persist /var/log/openvpn/ipp.txt\n\n\npush \"route 192.168.0.0 255.255.255.0\"\n\n\nkeepalive 10 120\ncipher AES-256-CBC\npersist-key\npersist-tun\nstatus /var/log/openvpn/openvpn-status.log\nverb 3\nexplicit-exit-notify 1\n\n```\n\n\n`sudo systemctl enable --now openvpn-server@servidor`\n\n\n## Cliente\n\n```\nsudo apt update\nsudo apt install openvpn\n```\n\nMovemos las claves al directorio de openvpn y le cambiamos el propietario:\n\n```\nsudo mv {ca.crt,clientevpn.crt,clientevpn.key} /etc/openvpn/client\nsudo chown root: /etc/openvpn/client/*\n```\n\nAhora vamos a crear el fichero /etc/openvpn/client/cliente.conf\n\n```\nclient\ndev tun\nproto udp\n\nremote 192.22.23.1 1194\nresolv-retry infinite\nnobind\n\npersist-key\npersist-tun\n\nca /etc/openvpn/client/ca.crt\ncert /etc/openvpn/client/clientevpn.crt\nkey /etc/openvpn/client/clientevpn.key\n\nremote-cert-tls server\ncipher AES-256-CBC\nverb 3\n```\n\nE iniciamos la el servicio de la configuración:\n\nsudo systemctl enable --now openvpn-client@cliente\n\n\n## Máquina interna\n\n\nQuitamos la ip de la ruta por defecto que viene en vagrant:\n\nsudo ip route del default\n\n\nAñadimos la ruta que creamos hacia la vpn:\n\nsudo ip route add default via 192.168.0.1\n\n\n\ncomprobaciones\n\n\n![Descripción de la imagen](/images/vpn-acceso-remoto-ssh-openvpn.png)\n\n\n![Descripción de la imagen](/images/traceroute-openvpn.png)\n\n\n\n# Site-To-Site Openvpn\n\n\n![Descripción de la imagen](/images/vpn-site-esquema.png)\n\n\n\n\n## Servidor\n\nEntramos en el servidor vpn y haremos apt update, y después instalaremos openvpn que servirá tanto para el cliente como para el servidor.\n\n\nActivamos el bit de forwarding en `/etc/sysctl.conf`  net.ipv4.ip_forward=1\nEjecutamos `sudo sysctl -p` para que lea el archivo sysctl.conf\n\n\n`sudo cp -r /usr/share/easy-rsa /etc/openvpn`\n\n\n`cd /etc/openvpn/easy-rsa`\n\nActivamos el servicio de infraestructura pública:\n\n`sudo ./easyrsa init-pki`\nTras esto generamos la entidad certificadora con su respectiva clave privada gracias al binario easyrsa.\n\n`./easyrsa build-ca`\nAhora vamos a montar el servidor de certificaciones:\n\n`./easyrsa build-server-full server nopass`\n\n\n`sudo ./easyrsa gen-dh`\n\nGeneramos el par de claves del cliente:\n`./easyrsa build-client-full clientevpn nopass`\n\nAhora pasamos las claves al servidor cliente\n\n```\nsudo cp -rp /etc/openvpn/easy-rsa/pki/{ca.crt,issued/clientevpn.crt,private/clientevpn.key} /home/vagrant/\ncd /home/vagrant\nsudo chown vagrant:vagrant {ca.crt,clientevpn.crt,clientevpn.key}\nscp {ca.crt,clientevpn.crt,clientevpn.key} vagrant@vpn-cli:\n```\n\nA partir de aquí la configuración varía respecto a la parte de cliente-servidor:\n\n``` \ndev tun\nifconfig 10.99.99.1 10.99.99.2\nroute 192.168.100.0 255.255.255.0\ntls-server\n\ndh /etc/openvpn/easy-rsa/pki/dh.pem\nca /etc/openvpn/easy-rsa/pki/ca.crt\ncert /etc/openvpn/easy-rsa/pki/issued/server.crt\nkey /etc/openvpn/easy-rsa/pki/private/server.key\n\ncomp-lzo\nkeepalive 10 60\n\nverb 3\n```\n\n\n`sudo systemctl enable --now openvpn-server@servidor`\n\n\n## Cliente\n\n``` \nsudo apt update\nsudo apt install openvpn\nsudo mv {ca.crt,clientevpn.crt,clientevpn.key} /etc/openvpn/client\nsudo chown root: /etc/openvpn/client/*\n```\n\nAhora vamos a crear el fichero /etc/openvpn/client/cliente.conf\n\n``` \ndev tun\nremote 10.0.0.1\nifconfig 10.99.99.2 10.99.99.1\nroute 192.168.200.0 255.255.255.0\ntls-client\n\nca /etc/openvpn/client/ca.crt\ncert /etc/openvpn/client/clientevpn.crt\nkey /etc/openvpn/client/clientevpn.key\n\ncomp-lzo\nkeepalive 10 60\n\nverb 3\n```\n\nsudo systemctl enable --now openvpn-client@cliente\n\n\n\n## Cliente 1\n\nsudo ip route del default\nsudo ip route add default via 192.168.200.1\n\n\n![Descripción de la imagen](/images/vpn-cliente2-traceroute.png)\n![Descripción de la imagen](/images/vpn-cliente1.png)\n\n## Cliente 2\n\nsudo ip route del default\nsudo ip route add default via 192.168.100.1\n\n\n![Descripción de la imagen](/images/vpn-cliente2-traceroute.png)\n![Descripción de la imagen](/images/vpn-cliente2.png)\n\n","source":"_posts/vpn.md","raw":"---\ntitle: Cliente-Servidor Openvpn\ncategories: Seguridad\ntags: Seguridad\n---\n\n\n![Descripción de la imagen](/images/vpn-logo.png)\n\n\n# Cliente-Servidor Openvpn\n\n\n\n## Servidor\n\nTendremos un escenario en vagrant en el cual constará de 3 máquinas, un cliente externo, el servidor vpn \n\n\n\n\nEntramos en el servidor vpn y haremos apt update, y después instalaremos openvpn que servirá tanto para el cliente como para el servidor.\n\n\nActivamos el bit de forwarding en `/etc/sysctl.conf`  net.ipv4.ip_forward=1\nEjecutamos `sudo sysctl -p` para que lea el archivo sysctl.conf\n\n\n`sudo cp -r /usr/share/easy-rsa /etc/openvpn`\n\n\n`cd /etc/openvpn/easy-rsa`\n\nActivamos el servicio de infraestructura pública:\n\n`sudo ./easyrsa init-pki`\n\nTras esto generamos la entidad certificadora con su respectiva clave privada gracias al binario easyrsa.\n\n`./easyrsa build-ca`\n\nAhora vamos a montar el servidor de certificaciones:\n\n`./easyrsa build-server-full server nopass`\n\nGeneramos parámetros de Diffie-Helman, el objetivo del algoritmo de cifrado Diffie-Hellman es lograr el intercambio de una clave secreta por medio de un canal inseguro como es internet. Para que este algoritmo funcione, los datos informáticos deben traducirse a números, lo cual es posible por medio de sistemas como el código ASCII, combinado con otros.\n\n`sudo ./easyrsa gen-dh`\n\nGeneramos el par de claves del cliente:\n`./easyrsa build-client-full clientevpn nopass`\n\nAhora pasamos las claves al servidor cliente\n\n```\nsudo cp -rp /etc/openvpn/easy-rsa/pki/{ca.crt,issued/clientevpn.crt,private/clientevpn.key} /home/vagrant/\ncd /home/vagrant\nsudo chown vagrant:vagrant {ca.crt,clientevpn.crt,clientevpn.key}\nscp {ca.crt,clientevpn.crt,clientevpn.key} vagrant@vpn-cli:\n```\n\nAhora configuraremos los parámetros del servidor y sus saltos:\n\n\n`/etc/openvpn/server/servidor.conf`\n\n``` \nport 1194\nproto udp\ndev tun\n\n\nca /etc/openvpn/easy-rsa/pki/ca.crt\ncert /etc/openvpn/easy-rsa/pki/issued/server.crt\nkey /etc/openvpn/easy-rsa/pki/private/server.key\ndh /etc/openvpn/easy-rsa/pki/dh.pem\n\n\ntopology subnet\n\n\nserver 9.8.7.0 255.255.255.0\nifconfig-pool-persist /var/log/openvpn/ipp.txt\n\n\npush \"route 192.168.0.0 255.255.255.0\"\n\n\nkeepalive 10 120\ncipher AES-256-CBC\npersist-key\npersist-tun\nstatus /var/log/openvpn/openvpn-status.log\nverb 3\nexplicit-exit-notify 1\n\n```\n\n\n`sudo systemctl enable --now openvpn-server@servidor`\n\n\n## Cliente\n\n```\nsudo apt update\nsudo apt install openvpn\n```\n\nMovemos las claves al directorio de openvpn y le cambiamos el propietario:\n\n```\nsudo mv {ca.crt,clientevpn.crt,clientevpn.key} /etc/openvpn/client\nsudo chown root: /etc/openvpn/client/*\n```\n\nAhora vamos a crear el fichero /etc/openvpn/client/cliente.conf\n\n```\nclient\ndev tun\nproto udp\n\nremote 192.22.23.1 1194\nresolv-retry infinite\nnobind\n\npersist-key\npersist-tun\n\nca /etc/openvpn/client/ca.crt\ncert /etc/openvpn/client/clientevpn.crt\nkey /etc/openvpn/client/clientevpn.key\n\nremote-cert-tls server\ncipher AES-256-CBC\nverb 3\n```\n\nE iniciamos la el servicio de la configuración:\n\nsudo systemctl enable --now openvpn-client@cliente\n\n\n## Máquina interna\n\n\nQuitamos la ip de la ruta por defecto que viene en vagrant:\n\nsudo ip route del default\n\n\nAñadimos la ruta que creamos hacia la vpn:\n\nsudo ip route add default via 192.168.0.1\n\n\n\ncomprobaciones\n\n\n![Descripción de la imagen](/images/vpn-acceso-remoto-ssh-openvpn.png)\n\n\n![Descripción de la imagen](/images/traceroute-openvpn.png)\n\n\n\n# Site-To-Site Openvpn\n\n\n![Descripción de la imagen](/images/vpn-site-esquema.png)\n\n\n\n\n## Servidor\n\nEntramos en el servidor vpn y haremos apt update, y después instalaremos openvpn que servirá tanto para el cliente como para el servidor.\n\n\nActivamos el bit de forwarding en `/etc/sysctl.conf`  net.ipv4.ip_forward=1\nEjecutamos `sudo sysctl -p` para que lea el archivo sysctl.conf\n\n\n`sudo cp -r /usr/share/easy-rsa /etc/openvpn`\n\n\n`cd /etc/openvpn/easy-rsa`\n\nActivamos el servicio de infraestructura pública:\n\n`sudo ./easyrsa init-pki`\nTras esto generamos la entidad certificadora con su respectiva clave privada gracias al binario easyrsa.\n\n`./easyrsa build-ca`\nAhora vamos a montar el servidor de certificaciones:\n\n`./easyrsa build-server-full server nopass`\n\n\n`sudo ./easyrsa gen-dh`\n\nGeneramos el par de claves del cliente:\n`./easyrsa build-client-full clientevpn nopass`\n\nAhora pasamos las claves al servidor cliente\n\n```\nsudo cp -rp /etc/openvpn/easy-rsa/pki/{ca.crt,issued/clientevpn.crt,private/clientevpn.key} /home/vagrant/\ncd /home/vagrant\nsudo chown vagrant:vagrant {ca.crt,clientevpn.crt,clientevpn.key}\nscp {ca.crt,clientevpn.crt,clientevpn.key} vagrant@vpn-cli:\n```\n\nA partir de aquí la configuración varía respecto a la parte de cliente-servidor:\n\n``` \ndev tun\nifconfig 10.99.99.1 10.99.99.2\nroute 192.168.100.0 255.255.255.0\ntls-server\n\ndh /etc/openvpn/easy-rsa/pki/dh.pem\nca /etc/openvpn/easy-rsa/pki/ca.crt\ncert /etc/openvpn/easy-rsa/pki/issued/server.crt\nkey /etc/openvpn/easy-rsa/pki/private/server.key\n\ncomp-lzo\nkeepalive 10 60\n\nverb 3\n```\n\n\n`sudo systemctl enable --now openvpn-server@servidor`\n\n\n## Cliente\n\n``` \nsudo apt update\nsudo apt install openvpn\nsudo mv {ca.crt,clientevpn.crt,clientevpn.key} /etc/openvpn/client\nsudo chown root: /etc/openvpn/client/*\n```\n\nAhora vamos a crear el fichero /etc/openvpn/client/cliente.conf\n\n``` \ndev tun\nremote 10.0.0.1\nifconfig 10.99.99.2 10.99.99.1\nroute 192.168.200.0 255.255.255.0\ntls-client\n\nca /etc/openvpn/client/ca.crt\ncert /etc/openvpn/client/clientevpn.crt\nkey /etc/openvpn/client/clientevpn.key\n\ncomp-lzo\nkeepalive 10 60\n\nverb 3\n```\n\nsudo systemctl enable --now openvpn-client@cliente\n\n\n\n## Cliente 1\n\nsudo ip route del default\nsudo ip route add default via 192.168.200.1\n\n\n![Descripción de la imagen](/images/vpn-cliente2-traceroute.png)\n![Descripción de la imagen](/images/vpn-cliente1.png)\n\n## Cliente 2\n\nsudo ip route del default\nsudo ip route add default via 192.168.100.1\n\n\n![Descripción de la imagen](/images/vpn-cliente2-traceroute.png)\n![Descripción de la imagen](/images/vpn-cliente2.png)\n\n","slug":"vpn","published":1,"date":"2023-01-24T10:06:01.371Z","updated":"2023-01-28T21:56:44.525Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cldl9ucgv00110yi5btc1d0dt","content":"<p><img src=\"/images/vpn-logo.png\" alt=\"Descripción de la imagen\"></p>\n<h1 id=\"cliente-servidor-openvpn\"><a class=\"markdownIt-Anchor\" href=\"#cliente-servidor-openvpn\">#</a> Cliente-Servidor Openvpn</h1>\n<h2 id=\"servidor\"><a class=\"markdownIt-Anchor\" href=\"#servidor\">#</a> Servidor</h2>\n<p>Tendremos un escenario en vagrant en el cual constará de 3 máquinas, un cliente externo, el servidor vpn</p>\n<p>Entramos en el servidor vpn y haremos apt update, y después instalaremos openvpn que servirá tanto para el cliente como para el servidor.</p>\n<p>Activamos el bit de forwarding en  <code>/etc/sysctl.conf</code>   net.ipv4.ip_forward=1<br>\nEjecutamos  <code>sudo sysctl -p</code>  para que lea el archivo sysctl.conf</p>\n<p><code>sudo cp -r /usr/share/easy-rsa /etc/openvpn</code></p>\n<p><code>cd /etc/openvpn/easy-rsa</code></p>\n<p>Activamos el servicio de infraestructura pública:</p>\n<p><code>sudo ./easyrsa init-pki</code></p>\n<p>Tras esto generamos la entidad certificadora con su respectiva clave privada gracias al binario easyrsa.</p>\n<p><code>./easyrsa build-ca</code></p>\n<p>Ahora vamos a montar el servidor de certificaciones:</p>\n<p><code>./easyrsa build-server-full server nopass</code></p>\n<p>Generamos parámetros de Diffie-Helman, el objetivo del algoritmo de cifrado Diffie-Hellman es lograr el intercambio de una clave secreta por medio de un canal inseguro como es internet. Para que este algoritmo funcione, los datos informáticos deben traducirse a números, lo cual es posible por medio de sistemas como el código ASCII, combinado con otros.</p>\n<p><code>sudo ./easyrsa gen-dh</code></p>\n<p>Generamos el par de claves del cliente:<br>\n <code>./easyrsa build-client-full clientevpn nopass</code></p>\n<p>Ahora pasamos las claves al servidor cliente</p>\n<pre><code>sudo cp -rp /etc/openvpn/easy-rsa/pki/&#123;ca.crt,issued/clientevpn.crt,private/clientevpn.key&#125; /home/vagrant/\ncd /home/vagrant\nsudo chown vagrant:vagrant &#123;ca.crt,clientevpn.crt,clientevpn.key&#125;\nscp &#123;ca.crt,clientevpn.crt,clientevpn.key&#125; vagrant@vpn-cli:\n</code></pre>\n<p>Ahora configuraremos los parámetros del servidor y sus saltos:</p>\n<p><code>/etc/openvpn/server/servidor.conf</code></p>\n<pre><code>port 1194\nproto udp\ndev tun\n\n\nca /etc/openvpn/easy-rsa/pki/ca.crt\ncert /etc/openvpn/easy-rsa/pki/issued/server.crt\nkey /etc/openvpn/easy-rsa/pki/private/server.key\ndh /etc/openvpn/easy-rsa/pki/dh.pem\n\n\ntopology subnet\n\n\nserver 9.8.7.0 255.255.255.0\nifconfig-pool-persist /var/log/openvpn/ipp.txt\n\n\npush &quot;route 192.168.0.0 255.255.255.0&quot;\n\n\nkeepalive 10 120\ncipher AES-256-CBC\npersist-key\npersist-tun\nstatus /var/log/openvpn/openvpn-status.log\nverb 3\nexplicit-exit-notify 1\n\n</code></pre>\n<p><code>sudo systemctl enable --now openvpn-server@servidor</code></p>\n<h2 id=\"cliente\"><a class=\"markdownIt-Anchor\" href=\"#cliente\">#</a> Cliente</h2>\n<pre><code>sudo apt update\nsudo apt install openvpn\n</code></pre>\n<p>Movemos las claves al directorio de openvpn y le cambiamos el propietario:</p>\n<pre><code>sudo mv &#123;ca.crt,clientevpn.crt,clientevpn.key&#125; /etc/openvpn/client\nsudo chown root: /etc/openvpn/client/*\n</code></pre>\n<p>Ahora vamos a crear el fichero /etc/openvpn/client/cliente.conf</p>\n<pre><code>client\ndev tun\nproto udp\n\nremote 192.22.23.1 1194\nresolv-retry infinite\nnobind\n\npersist-key\npersist-tun\n\nca /etc/openvpn/client/ca.crt\ncert /etc/openvpn/client/clientevpn.crt\nkey /etc/openvpn/client/clientevpn.key\n\nremote-cert-tls server\ncipher AES-256-CBC\nverb 3\n</code></pre>\n<p>E iniciamos la el servicio de la configuración:</p>\n<p>sudo systemctl enable --now openvpn-client@cliente</p>\n<h2 id=\"máquina-interna\"><a class=\"markdownIt-Anchor\" href=\"#máquina-interna\">#</a> Máquina interna</h2>\n<p>Quitamos la ip de la ruta por defecto que viene en vagrant:</p>\n<p>sudo ip route del default</p>\n<p>Añadimos la ruta que creamos hacia la vpn:</p>\n<p>sudo ip route add default via 192.168.0.1</p>\n<p>comprobaciones</p>\n<p><img src=\"/images/vpn-acceso-remoto-ssh-openvpn.png\" alt=\"Descripción de la imagen\"></p>\n<p><img src=\"/images/traceroute-openvpn.png\" alt=\"Descripción de la imagen\"></p>\n<h1 id=\"site-to-site-openvpn\"><a class=\"markdownIt-Anchor\" href=\"#site-to-site-openvpn\">#</a> Site-To-Site Openvpn</h1>\n<p><img src=\"/images/vpn-site-esquema.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"servidor-2\"><a class=\"markdownIt-Anchor\" href=\"#servidor-2\">#</a> Servidor</h2>\n<p>Entramos en el servidor vpn y haremos apt update, y después instalaremos openvpn que servirá tanto para el cliente como para el servidor.</p>\n<p>Activamos el bit de forwarding en  <code>/etc/sysctl.conf</code>   net.ipv4.ip_forward=1<br>\nEjecutamos  <code>sudo sysctl -p</code>  para que lea el archivo sysctl.conf</p>\n<p><code>sudo cp -r /usr/share/easy-rsa /etc/openvpn</code></p>\n<p><code>cd /etc/openvpn/easy-rsa</code></p>\n<p>Activamos el servicio de infraestructura pública:</p>\n<p><code>sudo ./easyrsa init-pki</code> <br>\nTras esto generamos la entidad certificadora con su respectiva clave privada gracias al binario easyrsa.</p>\n<p><code>./easyrsa build-ca</code> <br>\nAhora vamos a montar el servidor de certificaciones:</p>\n<p><code>./easyrsa build-server-full server nopass</code></p>\n<p><code>sudo ./easyrsa gen-dh</code></p>\n<p>Generamos el par de claves del cliente:<br>\n <code>./easyrsa build-client-full clientevpn nopass</code></p>\n<p>Ahora pasamos las claves al servidor cliente</p>\n<pre><code>sudo cp -rp /etc/openvpn/easy-rsa/pki/&#123;ca.crt,issued/clientevpn.crt,private/clientevpn.key&#125; /home/vagrant/\ncd /home/vagrant\nsudo chown vagrant:vagrant &#123;ca.crt,clientevpn.crt,clientevpn.key&#125;\nscp &#123;ca.crt,clientevpn.crt,clientevpn.key&#125; vagrant@vpn-cli:\n</code></pre>\n<p>A partir de aquí la configuración varía respecto a la parte de cliente-servidor:</p>\n<pre><code>dev tun\nifconfig 10.99.99.1 10.99.99.2\nroute 192.168.100.0 255.255.255.0\ntls-server\n\ndh /etc/openvpn/easy-rsa/pki/dh.pem\nca /etc/openvpn/easy-rsa/pki/ca.crt\ncert /etc/openvpn/easy-rsa/pki/issued/server.crt\nkey /etc/openvpn/easy-rsa/pki/private/server.key\n\ncomp-lzo\nkeepalive 10 60\n\nverb 3\n</code></pre>\n<p><code>sudo systemctl enable --now openvpn-server@servidor</code></p>\n<h2 id=\"cliente-2\"><a class=\"markdownIt-Anchor\" href=\"#cliente-2\">#</a> Cliente</h2>\n<pre><code>sudo apt update\nsudo apt install openvpn\nsudo mv &#123;ca.crt,clientevpn.crt,clientevpn.key&#125; /etc/openvpn/client\nsudo chown root: /etc/openvpn/client/*\n</code></pre>\n<p>Ahora vamos a crear el fichero /etc/openvpn/client/cliente.conf</p>\n<pre><code>dev tun\nremote 10.0.0.1\nifconfig 10.99.99.2 10.99.99.1\nroute 192.168.200.0 255.255.255.0\ntls-client\n\nca /etc/openvpn/client/ca.crt\ncert /etc/openvpn/client/clientevpn.crt\nkey /etc/openvpn/client/clientevpn.key\n\ncomp-lzo\nkeepalive 10 60\n\nverb 3\n</code></pre>\n<p>sudo systemctl enable --now openvpn-client@cliente</p>\n<h2 id=\"cliente-1\"><a class=\"markdownIt-Anchor\" href=\"#cliente-1\">#</a> Cliente 1</h2>\n<p>sudo ip route del default<br>\nsudo ip route add default via 192.168.200.1</p>\n<p><img src=\"/images/vpn-cliente2-traceroute.png\" alt=\"Descripción de la imagen\"><br>\n<img src=\"/images/vpn-cliente1.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"cliente-2\"><a class=\"markdownIt-Anchor\" href=\"#cliente-2\">#</a> Cliente 2</h2>\n<p>sudo ip route del default<br>\nsudo ip route add default via 192.168.100.1</p>\n<p><img src=\"/images/vpn-cliente2-traceroute.png\" alt=\"Descripción de la imagen\"><br>\n<img src=\"/images/vpn-cliente2.png\" alt=\"Descripción de la imagen\"></p>\n","site":{"data":{}},"length":4653,"excerpt":"","more":"<p><img src=\"/images/vpn-logo.png\" alt=\"Descripción de la imagen\"></p>\n<h1 id=\"cliente-servidor-openvpn\"><a class=\"markdownIt-Anchor\" href=\"#cliente-servidor-openvpn\">#</a> Cliente-Servidor Openvpn</h1>\n<h2 id=\"servidor\"><a class=\"markdownIt-Anchor\" href=\"#servidor\">#</a> Servidor</h2>\n<p>Tendremos un escenario en vagrant en el cual constará de 3 máquinas, un cliente externo, el servidor vpn</p>\n<p>Entramos en el servidor vpn y haremos apt update, y después instalaremos openvpn que servirá tanto para el cliente como para el servidor.</p>\n<p>Activamos el bit de forwarding en  <code>/etc/sysctl.conf</code>   net.ipv4.ip_forward=1<br>\nEjecutamos  <code>sudo sysctl -p</code>  para que lea el archivo sysctl.conf</p>\n<p><code>sudo cp -r /usr/share/easy-rsa /etc/openvpn</code></p>\n<p><code>cd /etc/openvpn/easy-rsa</code></p>\n<p>Activamos el servicio de infraestructura pública:</p>\n<p><code>sudo ./easyrsa init-pki</code></p>\n<p>Tras esto generamos la entidad certificadora con su respectiva clave privada gracias al binario easyrsa.</p>\n<p><code>./easyrsa build-ca</code></p>\n<p>Ahora vamos a montar el servidor de certificaciones:</p>\n<p><code>./easyrsa build-server-full server nopass</code></p>\n<p>Generamos parámetros de Diffie-Helman, el objetivo del algoritmo de cifrado Diffie-Hellman es lograr el intercambio de una clave secreta por medio de un canal inseguro como es internet. Para que este algoritmo funcione, los datos informáticos deben traducirse a números, lo cual es posible por medio de sistemas como el código ASCII, combinado con otros.</p>\n<p><code>sudo ./easyrsa gen-dh</code></p>\n<p>Generamos el par de claves del cliente:<br>\n <code>./easyrsa build-client-full clientevpn nopass</code></p>\n<p>Ahora pasamos las claves al servidor cliente</p>\n<pre><code>sudo cp -rp /etc/openvpn/easy-rsa/pki/&#123;ca.crt,issued/clientevpn.crt,private/clientevpn.key&#125; /home/vagrant/\ncd /home/vagrant\nsudo chown vagrant:vagrant &#123;ca.crt,clientevpn.crt,clientevpn.key&#125;\nscp &#123;ca.crt,clientevpn.crt,clientevpn.key&#125; vagrant@vpn-cli:\n</code></pre>\n<p>Ahora configuraremos los parámetros del servidor y sus saltos:</p>\n<p><code>/etc/openvpn/server/servidor.conf</code></p>\n<pre><code>port 1194\nproto udp\ndev tun\n\n\nca /etc/openvpn/easy-rsa/pki/ca.crt\ncert /etc/openvpn/easy-rsa/pki/issued/server.crt\nkey /etc/openvpn/easy-rsa/pki/private/server.key\ndh /etc/openvpn/easy-rsa/pki/dh.pem\n\n\ntopology subnet\n\n\nserver 9.8.7.0 255.255.255.0\nifconfig-pool-persist /var/log/openvpn/ipp.txt\n\n\npush &quot;route 192.168.0.0 255.255.255.0&quot;\n\n\nkeepalive 10 120\ncipher AES-256-CBC\npersist-key\npersist-tun\nstatus /var/log/openvpn/openvpn-status.log\nverb 3\nexplicit-exit-notify 1\n\n</code></pre>\n<p><code>sudo systemctl enable --now openvpn-server@servidor</code></p>\n<h2 id=\"cliente\"><a class=\"markdownIt-Anchor\" href=\"#cliente\">#</a> Cliente</h2>\n<pre><code>sudo apt update\nsudo apt install openvpn\n</code></pre>\n<p>Movemos las claves al directorio de openvpn y le cambiamos el propietario:</p>\n<pre><code>sudo mv &#123;ca.crt,clientevpn.crt,clientevpn.key&#125; /etc/openvpn/client\nsudo chown root: /etc/openvpn/client/*\n</code></pre>\n<p>Ahora vamos a crear el fichero /etc/openvpn/client/cliente.conf</p>\n<pre><code>client\ndev tun\nproto udp\n\nremote 192.22.23.1 1194\nresolv-retry infinite\nnobind\n\npersist-key\npersist-tun\n\nca /etc/openvpn/client/ca.crt\ncert /etc/openvpn/client/clientevpn.crt\nkey /etc/openvpn/client/clientevpn.key\n\nremote-cert-tls server\ncipher AES-256-CBC\nverb 3\n</code></pre>\n<p>E iniciamos la el servicio de la configuración:</p>\n<p>sudo systemctl enable --now openvpn-client@cliente</p>\n<h2 id=\"máquina-interna\"><a class=\"markdownIt-Anchor\" href=\"#máquina-interna\">#</a> Máquina interna</h2>\n<p>Quitamos la ip de la ruta por defecto que viene en vagrant:</p>\n<p>sudo ip route del default</p>\n<p>Añadimos la ruta que creamos hacia la vpn:</p>\n<p>sudo ip route add default via 192.168.0.1</p>\n<p>comprobaciones</p>\n<p><img src=\"/images/vpn-acceso-remoto-ssh-openvpn.png\" alt=\"Descripción de la imagen\"></p>\n<p><img src=\"/images/traceroute-openvpn.png\" alt=\"Descripción de la imagen\"></p>\n<h1 id=\"site-to-site-openvpn\"><a class=\"markdownIt-Anchor\" href=\"#site-to-site-openvpn\">#</a> Site-To-Site Openvpn</h1>\n<p><img src=\"/images/vpn-site-esquema.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"servidor-2\"><a class=\"markdownIt-Anchor\" href=\"#servidor-2\">#</a> Servidor</h2>\n<p>Entramos en el servidor vpn y haremos apt update, y después instalaremos openvpn que servirá tanto para el cliente como para el servidor.</p>\n<p>Activamos el bit de forwarding en  <code>/etc/sysctl.conf</code>   net.ipv4.ip_forward=1<br>\nEjecutamos  <code>sudo sysctl -p</code>  para que lea el archivo sysctl.conf</p>\n<p><code>sudo cp -r /usr/share/easy-rsa /etc/openvpn</code></p>\n<p><code>cd /etc/openvpn/easy-rsa</code></p>\n<p>Activamos el servicio de infraestructura pública:</p>\n<p><code>sudo ./easyrsa init-pki</code> <br>\nTras esto generamos la entidad certificadora con su respectiva clave privada gracias al binario easyrsa.</p>\n<p><code>./easyrsa build-ca</code> <br>\nAhora vamos a montar el servidor de certificaciones:</p>\n<p><code>./easyrsa build-server-full server nopass</code></p>\n<p><code>sudo ./easyrsa gen-dh</code></p>\n<p>Generamos el par de claves del cliente:<br>\n <code>./easyrsa build-client-full clientevpn nopass</code></p>\n<p>Ahora pasamos las claves al servidor cliente</p>\n<pre><code>sudo cp -rp /etc/openvpn/easy-rsa/pki/&#123;ca.crt,issued/clientevpn.crt,private/clientevpn.key&#125; /home/vagrant/\ncd /home/vagrant\nsudo chown vagrant:vagrant &#123;ca.crt,clientevpn.crt,clientevpn.key&#125;\nscp &#123;ca.crt,clientevpn.crt,clientevpn.key&#125; vagrant@vpn-cli:\n</code></pre>\n<p>A partir de aquí la configuración varía respecto a la parte de cliente-servidor:</p>\n<pre><code>dev tun\nifconfig 10.99.99.1 10.99.99.2\nroute 192.168.100.0 255.255.255.0\ntls-server\n\ndh /etc/openvpn/easy-rsa/pki/dh.pem\nca /etc/openvpn/easy-rsa/pki/ca.crt\ncert /etc/openvpn/easy-rsa/pki/issued/server.crt\nkey /etc/openvpn/easy-rsa/pki/private/server.key\n\ncomp-lzo\nkeepalive 10 60\n\nverb 3\n</code></pre>\n<p><code>sudo systemctl enable --now openvpn-server@servidor</code></p>\n<h2 id=\"cliente-2\"><a class=\"markdownIt-Anchor\" href=\"#cliente-2\">#</a> Cliente</h2>\n<pre><code>sudo apt update\nsudo apt install openvpn\nsudo mv &#123;ca.crt,clientevpn.crt,clientevpn.key&#125; /etc/openvpn/client\nsudo chown root: /etc/openvpn/client/*\n</code></pre>\n<p>Ahora vamos a crear el fichero /etc/openvpn/client/cliente.conf</p>\n<pre><code>dev tun\nremote 10.0.0.1\nifconfig 10.99.99.2 10.99.99.1\nroute 192.168.200.0 255.255.255.0\ntls-client\n\nca /etc/openvpn/client/ca.crt\ncert /etc/openvpn/client/clientevpn.crt\nkey /etc/openvpn/client/clientevpn.key\n\ncomp-lzo\nkeepalive 10 60\n\nverb 3\n</code></pre>\n<p>sudo systemctl enable --now openvpn-client@cliente</p>\n<h2 id=\"cliente-1\"><a class=\"markdownIt-Anchor\" href=\"#cliente-1\">#</a> Cliente 1</h2>\n<p>sudo ip route del default<br>\nsudo ip route add default via 192.168.200.1</p>\n<p><img src=\"/images/vpn-cliente2-traceroute.png\" alt=\"Descripción de la imagen\"><br>\n<img src=\"/images/vpn-cliente1.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"cliente-2\"><a class=\"markdownIt-Anchor\" href=\"#cliente-2\">#</a> Cliente 2</h2>\n<p>sudo ip route del default<br>\nsudo ip route add default via 192.168.100.1</p>\n<p><img src=\"/images/vpn-cliente2-traceroute.png\" alt=\"Descripción de la imagen\"><br>\n<img src=\"/images/vpn-cliente2.png\" alt=\"Descripción de la imagen\"></p>\n"},{"title":"iSCSI","_content":"\n![Descripción de la imagen](/images/iscsi-logo.png)\n\n## Servidor\n\nActualizamos los paquetes e instalamos:\n\n```\napt update\napt install tgt\n```\n\neste programa funciona con targets, crearemos uno:\n`sudo tgtadm --lld iscsi --op new --mode target --tid 1 -T iqn.2021-11.org.example:target1`\n\nAñadimos una unidad lógica llamada LUM:\n`sudo tgtadm --lld iscsi --op new --mode logicalunit --tid 1 --lun 1 -b /dev/vdb`\n\n![Descripción de la imagen](/images/iscsi-1.png)\n\n`sudo tgtadm --lld iscsi --op bind --mode target --tid 1 -I ALL`\n\npara hacerlo persistente:\n\n`tgt-admin -s`\n`tgt-admin --dump > /etc/tgt/conf.d/example.es.conf`\n\n\n\n## Cliente\n\nEscaneamos los dispositivos iSCSI disponibles, he empleado el nombre servidor porque Vagrant tiene resolución interna de nombres:\n\n```\nsudo iscsiadm --mode discovery --type sendtargets --portal servidor\n\n\niscsiadm --mode node -T iqn.2021-11.org.example:target1 --portal servidor --login\n```\n\n\nLuego le damos formato al nuevo dispositivo:\n\n```\nsudo mkfs.ext4 /dev/sda\nmkdir /mnt/iscsi\n```\n\nlo montamos en /mnt/iscsi\n\n\n![Descripción de la imagen](/images/iscsi-3.png)\n\nPara hacerlo persistente:\n\n```\nsudo iscsiadm --mode node -T iqn.2021-11.org.example:target1 --portal servidor -o update -n node.startup -v automatic\n```\n\n`sudo nano /etc/systemd/system/mnt-iscsi.mount`\n```\n[Unit]\nDescription=Disco iSCSI cliente\n\n[Mount]\nWhat=/dev/sda\nWhere=/mnt/iscsi\nType=ext4\nOptions=_netdev\n\n[Install]\nWantedBy=multi-user.target\n\n```\n\nAlternativa por si hay que esperar a la red antes de que arranque el disco:\n\n```\n[Unit]\nDescription=Disco iSCSI cliente\nRequires=network-online.target\nAfter=network-online.target\n[Mount]\nWhat=/dev/sda\nWhere=/mnt/iscsi\nType=ext4\nOptions=defaults\n[Install]\nWantedBy=multi-user.target\n```\n\n\n![Descripción de la imagen](/images/iscsi-2.png)\n\n\n## Cliente Windows\n\nPrimero vamos a crear un nuevo target en el servidor con dos LUM, lo haremos en un fichero de configuración:\n\n`/etc/tgt/conf.d/target2.conf`\n\n```\n<target iqn.2021-11.org.example:target2>\n    driver iscsi\n    controller_tid 2\n    backing-store /dev/vdc\n    backing-store /dev/vdd\n    incominguser antonio pruobandodisco\n</target>\n\n```\n\nal reiniciar el servicio este procesará el fichero que hemos creado y creará el target:\n\n`sudo systemctl restart tgt`\n\n\ncomprobamos el nuevo target definido con `sudo tgtadm --lld iscsi --op show --mode target`\n\n```\n        LUN: 1\n            Type: disk\n            SCSI ID: IET     00020001\n            SCSI SN: beaf21\n            Size: 2147 MB, Block size: 512\n            Online: Yes\n            Removable media: No\n            Prevent removal: No\n            Readonly: No\n            SWP: No\n            Thin-provisioning: No\n            Backing store type: rdwr\n            Backing store path: /dev/vdc\n            Backing store flags: \n        LUN: 2\n            Type: disk\n            SCSI ID: IET     00020002\n            SCSI SN: beaf22\n            Size: 3221 MB, Block size: 512\n            Online: Yes\n            Removable media: No\n            Prevent removal: No\n            Readonly: No\n            SWP: No\n            Thin-provisioning: No\n            Backing store type: rdwr\n            Backing store path: /dev/vdd\n            Backing store flags: \n    Account information:\n        antonio\n    ACL information:\n        ALL\n\n```\n\n\n\nPosteriormente entramos en el programa isci initiator de windows y nos vamos a la pestaña de discovery:\n\n![Descripción de la imagen](/images/iscsi-win-1.png)\n\nDespués nos vamos a targets, y veremos que tenemos los dos tarjets el cual el segundo será el que vayamos a utilizar:\n\n![Descripción de la imagen](/images/iscsi-win-2.png)\n\nComo tenemos que autentificarnos por CHAP iremos a avanzado, activaremos la casilla de log y pondremos el usuario y contraseña que hemos puesto en el servidor: \n\n\n![Descripción de la imagen](/images/iscsi-win-3.png)\n\n\nAhora podemos ver como está conectado al sistema:\n\n\n![Descripción de la imagen](/images/iscsi-win-4.png)\n\n\n\nEntraremos a la aplicación \"create and format hard disk partitions\" y marcamos los dos discos como GPT:\n\n\n![Descripción de la imagen](/images/iscsi-win-5.png)\n\n\nAhora podemos ver como tenemos dos discos nuevos sin formatear, quedaría formar un nuevo volumen simple en cada uno y darle el formato de NTFS:\n\n\n![Descripción de la imagen](/images/iscsi-win-6.png)\n\n\nY ya tendremos los dos nuevos discos en formato NTFS para almacenar la información persistente al reiniciar el sistema:.\n\n\n","source":"_posts/iscsi.md","raw":"---\ntitle: iSCSI\ncategories: Almacenamiento\n---\n\n![Descripción de la imagen](/images/iscsi-logo.png)\n\n## Servidor\n\nActualizamos los paquetes e instalamos:\n\n```\napt update\napt install tgt\n```\n\neste programa funciona con targets, crearemos uno:\n`sudo tgtadm --lld iscsi --op new --mode target --tid 1 -T iqn.2021-11.org.example:target1`\n\nAñadimos una unidad lógica llamada LUM:\n`sudo tgtadm --lld iscsi --op new --mode logicalunit --tid 1 --lun 1 -b /dev/vdb`\n\n![Descripción de la imagen](/images/iscsi-1.png)\n\n`sudo tgtadm --lld iscsi --op bind --mode target --tid 1 -I ALL`\n\npara hacerlo persistente:\n\n`tgt-admin -s`\n`tgt-admin --dump > /etc/tgt/conf.d/example.es.conf`\n\n\n\n## Cliente\n\nEscaneamos los dispositivos iSCSI disponibles, he empleado el nombre servidor porque Vagrant tiene resolución interna de nombres:\n\n```\nsudo iscsiadm --mode discovery --type sendtargets --portal servidor\n\n\niscsiadm --mode node -T iqn.2021-11.org.example:target1 --portal servidor --login\n```\n\n\nLuego le damos formato al nuevo dispositivo:\n\n```\nsudo mkfs.ext4 /dev/sda\nmkdir /mnt/iscsi\n```\n\nlo montamos en /mnt/iscsi\n\n\n![Descripción de la imagen](/images/iscsi-3.png)\n\nPara hacerlo persistente:\n\n```\nsudo iscsiadm --mode node -T iqn.2021-11.org.example:target1 --portal servidor -o update -n node.startup -v automatic\n```\n\n`sudo nano /etc/systemd/system/mnt-iscsi.mount`\n```\n[Unit]\nDescription=Disco iSCSI cliente\n\n[Mount]\nWhat=/dev/sda\nWhere=/mnt/iscsi\nType=ext4\nOptions=_netdev\n\n[Install]\nWantedBy=multi-user.target\n\n```\n\nAlternativa por si hay que esperar a la red antes de que arranque el disco:\n\n```\n[Unit]\nDescription=Disco iSCSI cliente\nRequires=network-online.target\nAfter=network-online.target\n[Mount]\nWhat=/dev/sda\nWhere=/mnt/iscsi\nType=ext4\nOptions=defaults\n[Install]\nWantedBy=multi-user.target\n```\n\n\n![Descripción de la imagen](/images/iscsi-2.png)\n\n\n## Cliente Windows\n\nPrimero vamos a crear un nuevo target en el servidor con dos LUM, lo haremos en un fichero de configuración:\n\n`/etc/tgt/conf.d/target2.conf`\n\n```\n<target iqn.2021-11.org.example:target2>\n    driver iscsi\n    controller_tid 2\n    backing-store /dev/vdc\n    backing-store /dev/vdd\n    incominguser antonio pruobandodisco\n</target>\n\n```\n\nal reiniciar el servicio este procesará el fichero que hemos creado y creará el target:\n\n`sudo systemctl restart tgt`\n\n\ncomprobamos el nuevo target definido con `sudo tgtadm --lld iscsi --op show --mode target`\n\n```\n        LUN: 1\n            Type: disk\n            SCSI ID: IET     00020001\n            SCSI SN: beaf21\n            Size: 2147 MB, Block size: 512\n            Online: Yes\n            Removable media: No\n            Prevent removal: No\n            Readonly: No\n            SWP: No\n            Thin-provisioning: No\n            Backing store type: rdwr\n            Backing store path: /dev/vdc\n            Backing store flags: \n        LUN: 2\n            Type: disk\n            SCSI ID: IET     00020002\n            SCSI SN: beaf22\n            Size: 3221 MB, Block size: 512\n            Online: Yes\n            Removable media: No\n            Prevent removal: No\n            Readonly: No\n            SWP: No\n            Thin-provisioning: No\n            Backing store type: rdwr\n            Backing store path: /dev/vdd\n            Backing store flags: \n    Account information:\n        antonio\n    ACL information:\n        ALL\n\n```\n\n\n\nPosteriormente entramos en el programa isci initiator de windows y nos vamos a la pestaña de discovery:\n\n![Descripción de la imagen](/images/iscsi-win-1.png)\n\nDespués nos vamos a targets, y veremos que tenemos los dos tarjets el cual el segundo será el que vayamos a utilizar:\n\n![Descripción de la imagen](/images/iscsi-win-2.png)\n\nComo tenemos que autentificarnos por CHAP iremos a avanzado, activaremos la casilla de log y pondremos el usuario y contraseña que hemos puesto en el servidor: \n\n\n![Descripción de la imagen](/images/iscsi-win-3.png)\n\n\nAhora podemos ver como está conectado al sistema:\n\n\n![Descripción de la imagen](/images/iscsi-win-4.png)\n\n\n\nEntraremos a la aplicación \"create and format hard disk partitions\" y marcamos los dos discos como GPT:\n\n\n![Descripción de la imagen](/images/iscsi-win-5.png)\n\n\nAhora podemos ver como tenemos dos discos nuevos sin formatear, quedaría formar un nuevo volumen simple en cada uno y darle el formato de NTFS:\n\n\n![Descripción de la imagen](/images/iscsi-win-6.png)\n\n\nY ya tendremos los dos nuevos discos en formato NTFS para almacenar la información persistente al reiniciar el sistema:.\n\n\n","slug":"iscsi","published":1,"date":"2023-01-26T07:49:37.974Z","updated":"2023-02-01T22:12:55.592Z","_id":"cldm4xm980000qni5eok90jyo","comments":1,"layout":"post","photos":[],"link":"","content":"<p><img src=\"/images/iscsi-logo.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"servidor\"><a class=\"markdownIt-Anchor\" href=\"#servidor\">#</a> Servidor</h2>\n<p>Actualizamos los paquetes e instalamos:</p>\n<pre><code>apt update\napt install tgt\n</code></pre>\n<p>este programa funciona con targets, crearemos uno:<br>\n <code>sudo tgtadm --lld iscsi --op new --mode target --tid 1 -T iqn.2021-11.org.example:target1</code></p>\n<p>Añadimos una unidad lógica llamada LUM:<br>\n <code>sudo tgtadm --lld iscsi --op new --mode logicalunit --tid 1 --lun 1 -b /dev/vdb</code></p>\n<p><img src=\"/images/iscsi-1.png\" alt=\"Descripción de la imagen\"></p>\n<p><code>sudo tgtadm --lld iscsi --op bind --mode target --tid 1 -I ALL</code></p>\n<p>para hacerlo persistente:</p>\n<p><code>tgt-admin -s</code> <br>\n <code>tgt-admin --dump &gt; /etc/tgt/conf.d/example.es.conf</code></p>\n<h2 id=\"cliente\"><a class=\"markdownIt-Anchor\" href=\"#cliente\">#</a> Cliente</h2>\n<p>Escaneamos los dispositivos iSCSI disponibles, he empleado el nombre servidor porque Vagrant tiene resolución interna de nombres:</p>\n<pre><code>sudo iscsiadm --mode discovery --type sendtargets --portal servidor\n\n\niscsiadm --mode node -T iqn.2021-11.org.example:target1 --portal servidor --login\n</code></pre>\n<p>Luego le damos formato al nuevo dispositivo:</p>\n<pre><code>sudo mkfs.ext4 /dev/sda\nmkdir /mnt/iscsi\n</code></pre>\n<p>lo montamos en /mnt/iscsi</p>\n<p><img src=\"/images/iscsi-3.png\" alt=\"Descripción de la imagen\"></p>\n<p>Para hacerlo persistente:</p>\n<pre><code>sudo iscsiadm --mode node -T iqn.2021-11.org.example:target1 --portal servidor -o update -n node.startup -v automatic\n</code></pre>\n<p><code>sudo nano /etc/systemd/system/mnt-iscsi.mount</code></p>\n<pre><code>[Unit]\nDescription=Disco iSCSI cliente\n\n[Mount]\nWhat=/dev/sda\nWhere=/mnt/iscsi\nType=ext4\nOptions=_netdev\n\n[Install]\nWantedBy=multi-user.target\n\n</code></pre>\n<p>Alternativa por si hay que esperar a la red antes de que arranque el disco:</p>\n<pre><code>[Unit]\nDescription=Disco iSCSI cliente\nRequires=network-online.target\nAfter=network-online.target\n[Mount]\nWhat=/dev/sda\nWhere=/mnt/iscsi\nType=ext4\nOptions=defaults\n[Install]\nWantedBy=multi-user.target\n</code></pre>\n<p><img src=\"/images/iscsi-2.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"cliente-windows\"><a class=\"markdownIt-Anchor\" href=\"#cliente-windows\">#</a> Cliente Windows</h2>\n<p>Primero vamos a crear un nuevo target en el servidor con dos LUM, lo haremos en un fichero de configuración:</p>\n<p><code>/etc/tgt/conf.d/target2.conf</code></p>\n<pre><code>&lt;target iqn.2021-11.org.example:target2&gt;\n    driver iscsi\n    controller_tid 2\n    backing-store /dev/vdc\n    backing-store /dev/vdd\n    incominguser antonio pruobandodisco\n&lt;/target&gt;\n\n</code></pre>\n<p>al reiniciar el servicio este procesará el fichero que hemos creado y creará el target:</p>\n<p><code>sudo systemctl restart tgt</code></p>\n<p>comprobamos el nuevo target definido con  <code>sudo tgtadm --lld iscsi --op show --mode target</code></p>\n<pre><code>        LUN: 1\n            Type: disk\n            SCSI ID: IET     00020001\n            SCSI SN: beaf21\n            Size: 2147 MB, Block size: 512\n            Online: Yes\n            Removable media: No\n            Prevent removal: No\n            Readonly: No\n            SWP: No\n            Thin-provisioning: No\n            Backing store type: rdwr\n            Backing store path: /dev/vdc\n            Backing store flags: \n        LUN: 2\n            Type: disk\n            SCSI ID: IET     00020002\n            SCSI SN: beaf22\n            Size: 3221 MB, Block size: 512\n            Online: Yes\n            Removable media: No\n            Prevent removal: No\n            Readonly: No\n            SWP: No\n            Thin-provisioning: No\n            Backing store type: rdwr\n            Backing store path: /dev/vdd\n            Backing store flags: \n    Account information:\n        antonio\n    ACL information:\n        ALL\n\n</code></pre>\n<p>Posteriormente entramos en el programa isci initiator de windows y nos vamos a la pestaña de discovery:</p>\n<p><img src=\"/images/iscsi-win-1.png\" alt=\"Descripción de la imagen\"></p>\n<p>Después nos vamos a targets, y veremos que tenemos los dos tarjets el cual el segundo será el que vayamos a utilizar:</p>\n<p><img src=\"/images/iscsi-win-2.png\" alt=\"Descripción de la imagen\"></p>\n<p>Como tenemos que autentificarnos por CHAP iremos a avanzado, activaremos la casilla de log y pondremos el usuario y contraseña que hemos puesto en el servidor:</p>\n<p><img src=\"/images/iscsi-win-3.png\" alt=\"Descripción de la imagen\"></p>\n<p>Ahora podemos ver como está conectado al sistema:</p>\n<p><img src=\"/images/iscsi-win-4.png\" alt=\"Descripción de la imagen\"></p>\n<p>Entraremos a la aplicación “create and format hard disk partitions” y marcamos los dos discos como GPT:</p>\n<p><img src=\"/images/iscsi-win-5.png\" alt=\"Descripción de la imagen\"></p>\n<p>Ahora podemos ver como tenemos dos discos nuevos sin formatear, quedaría formar un nuevo volumen simple en cada uno y darle el formato de NTFS:</p>\n<p><img src=\"/images/iscsi-win-6.png\" alt=\"Descripción de la imagen\"></p>\n<p>Y ya tendremos los dos nuevos discos en formato NTFS para almacenar la información persistente al reiniciar el sistema:.</p>\n","site":{"data":{}},"length":2928,"excerpt":"","more":"<p><img src=\"/images/iscsi-logo.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"servidor\"><a class=\"markdownIt-Anchor\" href=\"#servidor\">#</a> Servidor</h2>\n<p>Actualizamos los paquetes e instalamos:</p>\n<pre><code>apt update\napt install tgt\n</code></pre>\n<p>este programa funciona con targets, crearemos uno:<br>\n <code>sudo tgtadm --lld iscsi --op new --mode target --tid 1 -T iqn.2021-11.org.example:target1</code></p>\n<p>Añadimos una unidad lógica llamada LUM:<br>\n <code>sudo tgtadm --lld iscsi --op new --mode logicalunit --tid 1 --lun 1 -b /dev/vdb</code></p>\n<p><img src=\"/images/iscsi-1.png\" alt=\"Descripción de la imagen\"></p>\n<p><code>sudo tgtadm --lld iscsi --op bind --mode target --tid 1 -I ALL</code></p>\n<p>para hacerlo persistente:</p>\n<p><code>tgt-admin -s</code> <br>\n <code>tgt-admin --dump &gt; /etc/tgt/conf.d/example.es.conf</code></p>\n<h2 id=\"cliente\"><a class=\"markdownIt-Anchor\" href=\"#cliente\">#</a> Cliente</h2>\n<p>Escaneamos los dispositivos iSCSI disponibles, he empleado el nombre servidor porque Vagrant tiene resolución interna de nombres:</p>\n<pre><code>sudo iscsiadm --mode discovery --type sendtargets --portal servidor\n\n\niscsiadm --mode node -T iqn.2021-11.org.example:target1 --portal servidor --login\n</code></pre>\n<p>Luego le damos formato al nuevo dispositivo:</p>\n<pre><code>sudo mkfs.ext4 /dev/sda\nmkdir /mnt/iscsi\n</code></pre>\n<p>lo montamos en /mnt/iscsi</p>\n<p><img src=\"/images/iscsi-3.png\" alt=\"Descripción de la imagen\"></p>\n<p>Para hacerlo persistente:</p>\n<pre><code>sudo iscsiadm --mode node -T iqn.2021-11.org.example:target1 --portal servidor -o update -n node.startup -v automatic\n</code></pre>\n<p><code>sudo nano /etc/systemd/system/mnt-iscsi.mount</code></p>\n<pre><code>[Unit]\nDescription=Disco iSCSI cliente\n\n[Mount]\nWhat=/dev/sda\nWhere=/mnt/iscsi\nType=ext4\nOptions=_netdev\n\n[Install]\nWantedBy=multi-user.target\n\n</code></pre>\n<p>Alternativa por si hay que esperar a la red antes de que arranque el disco:</p>\n<pre><code>[Unit]\nDescription=Disco iSCSI cliente\nRequires=network-online.target\nAfter=network-online.target\n[Mount]\nWhat=/dev/sda\nWhere=/mnt/iscsi\nType=ext4\nOptions=defaults\n[Install]\nWantedBy=multi-user.target\n</code></pre>\n<p><img src=\"/images/iscsi-2.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"cliente-windows\"><a class=\"markdownIt-Anchor\" href=\"#cliente-windows\">#</a> Cliente Windows</h2>\n<p>Primero vamos a crear un nuevo target en el servidor con dos LUM, lo haremos en un fichero de configuración:</p>\n<p><code>/etc/tgt/conf.d/target2.conf</code></p>\n<pre><code>&lt;target iqn.2021-11.org.example:target2&gt;\n    driver iscsi\n    controller_tid 2\n    backing-store /dev/vdc\n    backing-store /dev/vdd\n    incominguser antonio pruobandodisco\n&lt;/target&gt;\n\n</code></pre>\n<p>al reiniciar el servicio este procesará el fichero que hemos creado y creará el target:</p>\n<p><code>sudo systemctl restart tgt</code></p>\n<p>comprobamos el nuevo target definido con  <code>sudo tgtadm --lld iscsi --op show --mode target</code></p>\n<pre><code>        LUN: 1\n            Type: disk\n            SCSI ID: IET     00020001\n            SCSI SN: beaf21\n            Size: 2147 MB, Block size: 512\n            Online: Yes\n            Removable media: No\n            Prevent removal: No\n            Readonly: No\n            SWP: No\n            Thin-provisioning: No\n            Backing store type: rdwr\n            Backing store path: /dev/vdc\n            Backing store flags: \n        LUN: 2\n            Type: disk\n            SCSI ID: IET     00020002\n            SCSI SN: beaf22\n            Size: 3221 MB, Block size: 512\n            Online: Yes\n            Removable media: No\n            Prevent removal: No\n            Readonly: No\n            SWP: No\n            Thin-provisioning: No\n            Backing store type: rdwr\n            Backing store path: /dev/vdd\n            Backing store flags: \n    Account information:\n        antonio\n    ACL information:\n        ALL\n\n</code></pre>\n<p>Posteriormente entramos en el programa isci initiator de windows y nos vamos a la pestaña de discovery:</p>\n<p><img src=\"/images/iscsi-win-1.png\" alt=\"Descripción de la imagen\"></p>\n<p>Después nos vamos a targets, y veremos que tenemos los dos tarjets el cual el segundo será el que vayamos a utilizar:</p>\n<p><img src=\"/images/iscsi-win-2.png\" alt=\"Descripción de la imagen\"></p>\n<p>Como tenemos que autentificarnos por CHAP iremos a avanzado, activaremos la casilla de log y pondremos el usuario y contraseña que hemos puesto en el servidor:</p>\n<p><img src=\"/images/iscsi-win-3.png\" alt=\"Descripción de la imagen\"></p>\n<p>Ahora podemos ver como está conectado al sistema:</p>\n<p><img src=\"/images/iscsi-win-4.png\" alt=\"Descripción de la imagen\"></p>\n<p>Entraremos a la aplicación “create and format hard disk partitions” y marcamos los dos discos como GPT:</p>\n<p><img src=\"/images/iscsi-win-5.png\" alt=\"Descripción de la imagen\"></p>\n<p>Ahora podemos ver como tenemos dos discos nuevos sin formatear, quedaría formar un nuevo volumen simple en cada uno y darle el formato de NTFS:</p>\n<p><img src=\"/images/iscsi-win-6.png\" alt=\"Descripción de la imagen\"></p>\n<p>Y ya tendremos los dos nuevos discos en formato NTFS para almacenar la información persistente al reiniciar el sistema:.</p>\n"},{"title":"Introducción a Kubernetes","_content":"\n\n![Descripción de la imagen](/images/k8s-logo.png)\n\n\n\n## Taller 1: Trabajando con Pods\n\nTrabajar con pods nos permite crear contenedores que se ejecutan en un mismo nodo. Los pods son la unidad mínima de despliegue en Kubernetes.\n\n1. Pantallazo del fichero yaml que has creado con la definición del Pod.\n\n![Descripción de la imagen](/images/k8s-taller-1-1.png)\n\n2. Pantallazo donde se comprueba que el Pod ha sido creado.\n\nkubectl get pods\n\n![Descripción de la imagen](/images/k8s-taller-1-2.png)\n\n3. Pantallazo donde se ve la información detallada del Pod.\n\nPodemos ver la información detallada del pod con `kubectl describe pod pod-nginx`\n\n![Descripción de la imagen](/images/k8s-taller-1-3.png)\n\n4. Pantallazo donde se ve el fichero index.html del DocumentRoot.\n\nPodemos acceder al interior del pod con `kubectl exec -it pod-nginx -- /bin/bash`\n\n![Descripción de la imagen](/images/k8s-taller-1-4.png)\n\n5. Pantallazo del navegador accediendo a la aplicación con el port-forward.\n\nPara poder acceder a través de un navegador, tenemos que hacer un port-forward al puerto 80 del pod.\n\n`kubectl port-forward pod-nginx 8080:80`\n\n![Descripción de la imagen](/images/k8s-taller-1-5.png)\n\n6. Pantallazo donde se ve los logs de acceso del Pod.\n\n`kubectl logs pod-nginx`\n\n![Descripción de la imagen](/images/k8s-taller-1-6.png)\n\n## Taller 2: Trabajando con ReplicaSets\n\nTrabajar con ReplicaSets nos permite crear réplicas de un mismo pod.\n\niesgn/test_web:latest\n\n```\napiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: iesgn-web\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n        - image: iesgn/test_web:latest\n          name: contenedor-nginx\n```\n\n![Descripción de la imagen](/images/k8s-taller-2-1.png)\n\nUna vez creado el replicaset podemos crearlo con `kubectl apply -f iesgn.yaml`\n\n\n\nTambién podemos crearlo con `kubectl create -f iesgn.yaml` pero en este caso no se puede modificar el replicaset una vez creado.\n\n\n\nPara borrarlo emplearemos `kubectl delete -f iesgn.yaml`\n\n![Descripción de la imagen](/images/k8s-taller-2-2.png)\n\n\nPara ver los replicaset creados emplearemos  `kubectl get rs,pods`\n\n\n```\n╭─antonio@debian ~/Documentos/k8s/replicasets  \n╰─➤  kubectl get rs,pods\nNAME                        DESIRED   CURRENT   READY   AGE\nreplicaset.apps/iesgn-web   3         3         3       55s\n\nNAME                      READY   STATUS    RESTARTS      AGE\npod/iesgn-web-g6s5g       1/1     Running   0             55s\npod/iesgn-web-sls5g       1/1     Running   0             55s\npod/iesgn-web-tnsff       1/1     Running   0             55s\n\n```\n\nPara ver la información detallada de un replicaset podemos emplear `kubectl describe rs iesgn-web`\n\n![Descripción de la imagen](/images/k8s-taller-2-3.png)\n\n\nPOdemos ver la tolerancia a fallos borrando un pod con `kubectl delete pod iesgn-web-vjckt`\n\n\n![Descripción de la imagen](/images/k8s-taller-2-4.png)\n\n\nKubernetes nos ofrece escalabilidad horizontal, es decir, podemos aumentar o disminuir el número de réplicas de un replicaset. Para ello emplearemos `kubectl scale --replicas=6 rs iesgn-web`\n\n![Descripción de la imagen](/images/k8s-taller-2-5.png)\n\n## Taller 3: Trabajando con Deployments\n\n### Ejercicio 1: Trabajando con Deployments\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: deployment-iesgn\n  labels:\n    app: nginx\nspec:\n  revisionHistoryLimit: 2\n  strategy:\n    type: RollingUpdate\n  replicas: 2\n  selector:\n    matchLabels:\n      app: iesgn\n  template:\n    metadata:\n      labels:\n        app: iesgn\n    spec:\n      containers:\n      - image: iesgn/test_web:latest\n        name: iesgn\n        ports:\n        - name: http\n          containerPort: 80\n```\n\n\n\n\n\n\n\n\nPantallazo del fichero yaml que has creado con la definición del Deployment.\n\n![Descripción de la imagen](/images/k8s-taller-3-1.png)\n\nPantallazo donde se comprueba los recursos que se han creado.\n\n`kubectl get deploy,rs,pod`\n\n![Descripción de la imagen](/images/k8s-taller-3-2.png)\n\nPantallazo donde se ve la información detallada del Deployment.\n\n`kubectl describe deployment/deployment-nginx`\n\n![Descripción de la imagen](/images/k8s-taller-3-3.png)\n\n\nPantallazo donde se vea el acceso desde un navegador web a la aplicación usando el port-forward.\n\n`kubectl port-forward deployment/deployment-iesgn 8080:80`\n\n\n![Descripción de la imagen](/images/k8s-taller-3-4.png)\n\nPantallazo donde se vea los logs del despliegue después del acceso.\n\n`kubectl logs deployment/deployment-iesgn`\n\n![Descripción de la imagen](/images/k8s-taller-3-5.png)\n\n### Ejercicio 2: Actualización y desactualización de nuestra aplicación\n\nPantallazo donde se vea el acceso desde un navegador web a la version 1 de la aplicación aplicación.\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: deployment-iesgn-v1\n  labels:\n    app: contendor-iesgn\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: contenedor-iesgn\n  template:\n    metadata:\n      labels:\n        app: contenedor-iesgn\n    spec:\n      containers:\n      - name: contenedor-iesgn\n        image: iesgn/test_web:version1\n        ports:\n        - containerPort: 80\n```\n\n```\nkubectl annotate deployment/deployment-iesgn-v1 kubernetes.io/change-cause=\"Primer despliegue de iesgn\"\n```\n\n![Descripción de la imagen](/images/k8s-taller-3-2-1.png)\n\n\n```\nkubectl port-forward deployment/deployment-iesgn-v1 8081:80\n```\n\nPantallazo donde se vea el acceso desde un navegador web a la version 2 de la aplicación aplicación.\n\n```\nkubectl apply -f deployment-iesgn-v1.yaml\n```\n\n![Descripción de la imagen](/images/k8s-taller-3-2-2.png)\n\n\nPantallazo donde se visualice el historial de actualización del despliegue después de actualizar a la versión 2.\n\n![Descripción de la imagen](/images/k8s-taller-3-2-3.png)\n\nPantallazo donde se vea el acceso desde un navegador web a la version 3 de la aplicación (¡¡¡No se visualiza bien la \nhoja de estilos!!!).\n\n![Descripción de la imagen](/images/k8s-taller-3-2-4.png)\n\nPantallazo donde se visualice el historial de actualización después de realizar el rollback del despliegue.\n\n`kubectl rollout undo deployment/deployment-iesgn-v1`\n\n\n![Descripción de la imagen](/images/k8s-taller-3-2-5.png)\n\nPantallazo donde se vea el acceso desde un navegador web a la version de la aplicación que queda después de hacer el rollout.\n\n![Descripción de la imagen](/images/k8s-taller-3-2-6.png)\n\n\n\n\n\n\n### Ejercicio 3: Despliegue de la aplicación GuestBook\n\nguestbook-deployment.yaml\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: guestbook\n  labels:\n    app: guestbook\n    tier: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: frontend\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: contenedor-guestbook\n        image: iesgn/guestbook\n        ports:\n          - name: http-server\n            containerPort: 5000\n\n```\n\nredis-deployment.yaml\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis\n  labels:\n    app: redis\n    tier: backend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: redis\n      tier: backend\n  template:\n    metadata:\n      labels:\n        app: redis\n        tier: backend\n    spec:\n      containers:\n        - name: contenedor-redis\n          image: redis\n          ports:\n            - name: redis-server\n              containerPort: 6379\n```\n\n\nCreamos el escenario ejecutando los siguientes comandos:\n\n`kubectl apply -f guestbook-deployment.yaml`\n\n`kubectl apply -f redis-deployment.yaml`\n\nTenemos dos deploys, uno con guestbook y otro con redis. Para acceder a la aplicación de guestbook, debemos hacer un port-forward al servicio de guestbook. Para ello, ejecutamos el siguiente comando:\n\n`kubectl port-forward deployment/guestbook 8082:5000`\n\n\nPodemos ver que los recursos están creados con el siguiente comando:\n\n`kubectl get all`, `kubectl get all -o wide` o bien `kubectl get deploy,rs,pod`\n\n![Descripción de la imagen](/images/k8s-taller-3-3-1.png)\n\nLo que ocurre es que no conecta a la base de datos porque los dos deployments no están relacionados entre sí.\n\n![Descripción de la imagen](/images/k8s-taller-3-3-2.png)\n\n\n\n## Taller 4: Trabajando con Services\n\n\n### Ejercicio 1: Despliegue y acceso de la aplicación GuestBook\n\n1. Pantallazo donde se vea el acceso desde un navegador web a la aplicación cuando sólo tenemos el servicio para acceder a la aplicación (tiene que aparecer el mensaje de error).\n\n![Descripción de la imagen](/images/k8s-taller-4-1.png)\n\n2. Pantallazo donde se vea el acceso desde un navegador web a la aplicación usando la ip del nodo master y el puerto asignado al Service.\n\n![Descripción de la imagen](/images/k8s-taller-4-2.png)\n\n3. Pantallazo donde se vea el acceso desde un navegador web a la aplicación usando el nombre que hemos configurado en el recurso Ingress.\n\nPara crear el recurso ingress debemos tener el siguiente yaml:\n\nnano ingress.yaml\n```\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: nginx\nspec:\n  rules:\n  - host: www.antonio.org\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: guestbook\n            port:\n              number: 80\n\n```\n\n![Descripción de la imagen](/images/k8s-taller-4-3.png)\n\n### Ejercicio 2: Despliegue y acceso de la Aplicación Lets-Chat\n\n1. Los ficheros yaml que has creado.\n\nHe creado varios yaml, voy a ordenarlos en sentido de conexión desde el frontend al backend:\n\ningress.yaml\n\n```\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: nginx\nspec:\n  rules:\n  - host: www.chat-antonio.org\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: letschat\n            port:\n              number: 8080\n\n```\n\nletschat-service.yaml\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: letschat\n  labels:\n    app: letschat\n    tier: frontend\nspec:\n  type: NodePort\n  ports: \n  - port: 8080\n    targetPort: letschat-server\n  selector:\n    app: letschat\n    tier: frontend\n```\n\nletschat-deployment.yaml\n\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: letschat\n  labels:\n    app: letschat\n    tier: frontend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: letschat\n      tier: frontend\n  template:\n    metadata:\n      labels:\n        app: letschat\n        tier: frontend\n    spec:\n      containers:\n      - name: contenedor-letschat\n        image: sdelements/lets-chat\n        ports:\n          - name: letschat-server\n            containerPort: 8080\n```\n\nmongo-srv.yaml\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: mongo\n  labels:\n    app: mongo\n    tier: backend\nspec:\n  type: ClusterIP\n  ports: \n  - port: 27017\n    targetPort: mongo-server\n  selector:\n    app: mongo\n    tier: backend\n```\n\nmongo-deployment.yaml\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mongo\n  labels:\n    app: mongo\n    tier: backend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mongo\n      tier: backend\n  template:\n    metadata:\n      labels:\n        app: mongo\n        tier: backend\n    spec:\n      containers:\n        - name: contenedor-mongo\n          image: mongo:4\n          ports:\n            - name: mongo-server\n              containerPort: 27017\n```\n\n\nA través de este esquema podemos ver como los diferentes deploys y pods se conectan entre sí para ofrecer el servicio:\n\n\n![Descripción de la imagen](/images/letschat-minikube-esquema.png)\n\n2. Un pantallazo donde se vea el acceso desde un navegador web a la aplicación usando la ip del nodo master y el puerto asignado al Service.\n\nSi usamos el comando `minikube service letschat` nos abre el navegador con la aplicación.\n\n![Descripción de la imagen](/images/k8s-taller-4-4.png)\n\n3. Un pantallazo donde se vea el acceso desde un navegador web a la aplicación usando el nombre que hemos configurado en el recurso Ingress.\n\n![Descripción de la imagen](/images/k8s-taller-4-5.png)\n\n\n\n## Taller 5: Trabajando con ConfigMaps\n\n### Ejercicio 1: Configurando nuestra aplicación Temperaturas\n\nCon el siguiente comando estaremos creando una variable de entorno en el cual indica el nombre SERVIDOR_TEMPERATURAS y el valor servidor-temperaturas:5000\n\n```\nkubectl create cm tempcm --from-literal=SERVIDOR_TEMPERATURAS=servidor-temperaturas:5000 -o yaml --dry-run=client > temperaturas_configmap.yaml\n```\n\nUNa vez ejecutado se crea un fichero que contiene en data el nombre y la clave de la variable de entorno:\n\ntemperaturas_configmap.yaml\n\n```\napiVersion: v1\ndata:\n  SERVIDOR_TEMPERATURAS: servidor-temperaturas:5000\nkind: ConfigMap\nmetadata:\n  creationTimestamp: null\n  name: tempcm\n\n```\n\nEl nombre lo debemos especificar en el deployment, y la key el nombre que va a llevar la variable de entorno, en nuestro caso tempcm y SERVIDOR_TEMPERATURAS respectivamente:\n\n\nEntonces en nuestro fichero yaml de nuestro deployment, quedaría de la siguiente manera:\n\ntempers-deployment.yaml\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: temperaturas-frontend\n  labels:\n    app: temperaturas\n    tier: frontend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: temperaturas\n      tier: frontend\n  template:\n    metadata:\n      labels:\n        app: temperaturas\n        tier: frontend\n    spec:\n      containers:\n      - name: contenedor-temperaturas\n        image: iesgn/temperaturas_frontend\n        ports:\n          - name: http-server\n            containerPort: 3000\n        env:\n          - name: TEMP_SERVER\n            valueFrom:\n              configMapKeyRef:\n                name: tempcm\n                key: SERVIDOR_TEMPERATURAS\n```\n\nAhora vamos a crear el servicio para el frontend por el cual vamos a ver que se puede acceder a la aplicación a través de un puerto aleatorio:\n\ntemperaturas-srv.yaml\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: temperaturas\n  labels:\n    app: temperaturas\n    tier: frontend\nspec:\n  type: NodePort\n  ports: \n  - port: 3000\n    targetPort: http-server\n  selector:\n    app: temperaturas\n    tier: frontend\n```\n\nTomará el puerto 3000 y hará un proxy para que lo veamos a través de un puerto aleatorio, pero a través del port y el targetPort crearemos un ingress para que se pueda acceder a través de un dominio, que será www.antonio.org\n\ningress.yaml\n\n```\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: acceso-frontend\nspec:\n  rules:\n  - host: www.antonio.org\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: temperaturas\n            port:\n              number: 3000\n\n```\n\nDentro del confimap que hemos mencionado más arriba hace referencia al backend-srv.yaml, que toma el nombre de TEMP_SERVER y coge el valor de la key SERVIDOR_TEMPERATURAS, que es el la clave del valor servidor-temperaturas:5000, que se halla en el tempeaturas-deployment.yaml, tomado del configmap tempcm.\n\nbackend-srv.yaml\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: servidor-temperaturas\n  labels:\n    app: temperaturas\n    tier: backend\nspec:\n  type: ClusterIP\n  ports:\n  - port: 5000\n    targetPort: api-server\n  selector:\n    app: temperaturas\n    tier: backend\n\n```\n\nPantallazo donde se vea la definición del recurso ConfigMap.\n\n![Descripción de la imagen](/images/k8s-taller-5-1.png)\n\nPantallazo donde se vea la modificación del fichero frontend-deployment.yaml.\n\n![Descripción de la imagen](/images/k8s-taller-5-2.png)\n\nPantallazo donde se vea la modificación del fichero backend-srv.yaml.\n\n![Descripción de la imagen](/images/k8s-taller-5-3.png)\n\nPantallazo donde se compruebe que la aplicación está funcionando.\n\n![Descripción de la imagen](/images/k8s-taller-5-4.png)\n\n### Ejercicio 2: Despliegue y acceso de la aplicación Nextcloud\n\n\nPrimero vamos a generar las claves para que la base de datos mariadb pueda cambiar los valores por defecto del usuario:\n\nEn el configmap cambiaremos:\n\n- nombre de usuario\n- nombre de la base de datos\n- nombre del host mariadb\n\nEn el secret que lo utilizaremos para convertir a base64 las contraseñas:\n\n- contraseña de usuario\n\n\n\n```\nkubectl create cm bd-datos --from-literal=bd_user=antonio \\\n                           --from-literal=bd_dbname=nextcloud \\\n                           --from-literal=bd_host=mariadb-service \\\n                           -o yaml --dry-run=client > bd_datos_configmap.yaml\n\n\n\nkubectl create secret generic bd-passwords --from-literal=bd_password=antonio \\\n                                           --from-literal=bd_rootpassword=root1234 \\\n                                           -o yaml --dry-run=client > bd_passwords_secret.yaml\n``` \n\nSeguidamente, tanto el deploy de nextcloud como el de mariadb van a tomar cada uno de estos datos para poder crear la base de datos y el usuario, y nextcloud va a tomar el usuario y la contraseña para poder conectarse a la base de datos.\n\nnextcloud-deployment.yaml\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nextcloud-deployment\n  labels:\n    app: nextcloud\n    type: frontend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nextcloud\n      type: frontend\n  template:\n    metadata:\n      labels:\n        app: nextcloud\n        type: frontend\n    spec:\n      containers:\n        - name: contenedor-nextcloud\n          image: nextcloud\n          ports:\n            - containerPort: 80\n              name: http-port\n            - containerPort: 443\n              name: https-port\n          env:\n            - name: MYSQL_USER\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_user\n            - name: MYSQL_DATABASE\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_dbname\n            - name: MYSQL_HOST\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_host\n            - name: MYSQL_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_password\n```\n\n\nmariadb-deployment.yaml\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mariadb-deployment\n  labels:\n    app: nextcloud\n    type: database\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nextcloud\n      type: database\n  template:\n    metadata:\n      labels:\n        app: nextcloud\n        type: database\n    spec:\n      containers:\n        - name: contenedor-mariadb\n          image: mariadb:10.5\n          ports:\n            - containerPort: 3306\n              name: db-port\n          env:\n            - name: MYSQL_USER\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_user\n            - name: MYSQL_DATABASE\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_dbname\n            - name: MYSQL_HOST\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_host\n            - name: MYSQL_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_password\n            - name: MYSQL_ROOT_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_rootpassword\n```\n\n\nComo podemos ver en el valor env tanto en nextcloud como en mariadb, se toman los valores de los configmaps y los secrets que hemos creado anteriormente, teniendo como '- name:' el valor que la aplicación toma por defecto.\n\nmaradb-srv.yaml\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: mariadb-service\n  labels:\n    app: nextcloud\n    type: database\nspec:\n  selector:\n    app: nextcloud\n    type: database\n  ports:\n  - port: 3306\n    targetPort: db-port\n  type: ClusterIP\n```\n\nnextclod-srv.yaml\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: nextcloud\n  labels:\n    app: nextcloud\n    type: frontend\nspec:\n  selector:\n    app: nextcloud\n    type: frontend\n  ports:\n  - name: http-sv-port\n    port: 80\n    targetPort: http-port\n  type: NodePort\n```\n\n\nPantallazo donde se vea el contenido del fichero de despliegue de NextCloud.\n\n![Descripción de la imagen](/images/k8s-taller-5-5.png)\n\nPantallazo donde se vean los recursos que se han creado.\n\n![Descripción de la imagen](/images/k8s-taller-5-6.png)\n\nPantallazo donde se compruebe que la aplicación está funcionando.\n\n![Descripción de la imagen](/images/k8s-taller-5-7.png)\n\n\n## Taller 6: Almacenamiento en Kubernetes\n\n### Ejercicio 1: Desplegando un servidor web persistente\n\nPara empezar debemos pedir el recurso de almacenamiento que vamos a utilizar, en este caso vamos a utilizar un recurso de tipo persistent volume claim, que es un recurso que nos permite pedir un recurso de almacenamiento, en este caso un disco duro, y que nos lo asigne a un nodo.\n\ncat apache-pvc.yaml\n\n```\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n    name: pvc-webserver\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 2Gi\n\n```\n\nComo podemos ver, pide un recurso de almacenamiento de 2Gi\n\ncat apache-deployment.yaml\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: apache-taller6\n  labels:\n    app: apache\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: apache\n  template:\n    metadata:\n      labels:\n        app: apache\n    spec:\n      volumes:\n        - name: pvc-webserver\n          persistentVolumeClaim:\n            claimName: pvc-webserver\n      containers:\n        - name: contenedor-apache\n          image: php:7.4-apache\n          ports:\n            - name: http-server\n              containerPort: 80\n          volumeMounts:\n            - mountPath: \"/var/www/html\"\n              name: pvc-webserver\n```\n\nEn el apartado spec nombra el volumen y lo monta en VolumeMounts.\n\nAhora vamos a crear el servicio nodeport por el cual vamos a entrar en la web:\n\ncat apache-srv.yaml\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: apache\nspec:\n  type: NodePort\n  ports:\n  - name: service-http\n    port: 80\n    targetPort: http-server\n  selector:\n    app: apache\n```\n\nTras esto vamos a ejecutar un comando que es un info.php por bash y lo va a poner en /var/www/html que es donde está el recurso solicitado montado:\n\n```\nkubectl exec pod/apache-taller6-5f78fbb47d-7rlzd -- bash -c \"echo '<?php phpinfo(); ?>' > /var/www/html/info.php\"\n```\n\nPantallazo con la definición del recurso PersistentVolumenClaim.\n\n![Descripción de la imagen](/images/k8s-taller-6-1.png)\n\nPantallazo donde se visualice los recursos pv y pvc que se han creado.\n\n![Descripción de la imagen](/images/k8s-taller-6-2.png)\n\nPantallazo donde se vea el fichero yaml para el despliegue.\n\n![Descripción de la imagen](/images/k8s-taller-6-3.png)\n\nPantallazo donde se vea el acceso a info.php.\n\n![Descripción de la imagen](/images/k8s-taller-6-4.png)\n\nPantallazo donde se vea que se ha eliminado y se ha vuelto a crear el despliegue y se sigue sirviendo el fichero info.php.\n\nAdjunto en una sola imagen la destrucción,creación y comprobación de que sigue funcionando a través de un curl:\n\n![Descripción de la imagen](/images/k8s-taller-6-5.png)\n\n### Ejercicio 2: Haciendo persistente la aplicación GuestBook\n\nVamos a modificar el recurso de despliegue de guestbook para que se pueda hacer persistente, a través de hacer una copia d ela base de datos redis en /data:\n\nredis-deployment.yaml\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis\n  labels:\n    app: redis\n    tier: backend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: redis\n      tier: backend\n  template:\n    metadata:\n      labels:\n        app: redis\n        tier: backend\n    spec:\n      volumes:\n        - name: volumen-redis\n          persistentVolumeClaim:\n            claimName: pvc-guestbook\n      containers:\n        - name: contenedor-redis\n          image: redis\n          command: [\"redis-server\"]\n          args: [\"--appendonly\", \"yes\"]\n          ports:\n            - name: redis-server\n              containerPort: 6379\n          volumeMounts:\n            - mountPath: /data\n              name: volumen-redis\n```\n\nY este sería el guestbook-pvc.yaml\n\n```\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n    name: pvc-guestbook\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 3Gi\n```\n\n\nPantallazo con la definición del recurso PersistentVolumenClaim.\n\nMostrado arriba.\n\nPantallazo donde se visualicen los recursos pv y pvc que se han creado.\n\n![Descripción de la imagen](/images/k8s-taller-6-6.png)\n\nPantallazo donde se vea el fichero yaml modificado para el despliegue de redis.\n\nMostrado arriba.\n\nPantallazo donde se vea el acceso a la aplicación con los mensajes escritos.\n\n![Descripción de la imagen](/images/k8s-taller-6-7.png)\n\nPantallazo donde se vea que se ha eliminado y se ha vuelto a crear el despliegue de redis y que se sigue sirviendo la aplicación con los mensajes.\n\n![Descripción de la imagen](/images/k8s-taller-6-8.gif)\n\n### Ejercicio 3: Haciendo persistente la aplicación Nextcloud\n\nVamos a utilizar los ficheros que anteriormente creamos en nextcloud, lo que haremos será proporcionar almacenamiento tanto en nextcloud como mariadb, para ello vamos a modificar los ficheros de despliegue en relación a los pvc:\n\nnextcloud-pvc.yaml\n\n```\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n    name: nextcloud-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 4Gi\n```\n\nnextcloud-deployment.yaml\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nextcloud-deployment\n  labels:\n    app: nextcloud\n    type: frontend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nextcloud\n      type: frontend\n  template:\n    metadata:\n      labels:\n        app: nextcloud\n        type: frontend\n    spec:\n      volumes:\n        - name: nextcloud-pvc\n          persistentVolumeClaim:\n            claimName: nextcloud-pvc\n      containers:\n        - name: contenedor-nextcloud\n          image: nextcloud\n          volumeMounts:\n            - mountPath: /var/www/html/\n              name: nextcloud-pvc\n          ports:\n            - containerPort: 80\n              name: http-port\n            - containerPort: 443\n              name: https-port\n          env:\n            - name: MYSQL_USER\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_user\n            - name: MYSQL_DATABASE\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_dbname\n            - name: MYSQL_HOST\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_host\n            - name: MYSQL_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_password\n```\n\nAhora vamos con mariadb:\n\nmariadb-pvc.yaml\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: mariadb-service\n  labels:\n    app: nextcloud\n    type: database\nspec:\n  selector:\n    app: nextcloud\n    type: database\n  ports:\n  - port: 3306\n    targetPort: db-port\n  type: ClusterIP\n```\n\n\ncat mariadb-deployment.yaml\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mariadb-deployment\n  labels:\n    app: nextcloud\n    type: database\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nextcloud\n      type: database\n  template:\n    metadata:\n      labels:\n        app: nextcloud\n        type: database\n    spec:\n      volumes:\n        - name: mariadb-pvc\n          persistentVolumeClaim:\n            claimName: mariadb-pvc\n      containers:\n        - name: contenedor-mariadb\n          image: mariadb:10.5\n          ports:\n            - containerPort: 3306\n              name: db-port\n          volumeMounts:\n            - mountPath: \"/var/lib/mysql\"\n              name: mariadb-pvc\n          env:\n            - name: MYSQL_USER\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_user\n            - name: MYSQL_DATABASE\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_dbname\n            - name: MYSQL_HOST\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_host\n            - name: MYSQL_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_password\n            - name: MYSQL_ROOT_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_rootpassword\n\n```\n\n\nPantallazo donde se vean los ficheros yaml modificados para los despliegues.\n\nSe muestra arriba.\n\nPantallazo donde se vea el acceso a la aplicación con el fichero que has subido.\n\n![Descripción de la imagen](/images/k8s-taller-6-8.png)\n\nPantallazo donde se vea que se han eliminado y se han vuelto a crear los despliegues y que la aplicación sigue sirviendo el fichero que habíamos subido.\n\n![Descripción de la imagen](/images/k8s-taller-6-9.gif)\n\n\n","source":"_posts/kubernetes.md","raw":"---\ntitle: Introducción a Kubernetes\ncategories: Contenedores\n---\n\n\n![Descripción de la imagen](/images/k8s-logo.png)\n\n\n\n## Taller 1: Trabajando con Pods\n\nTrabajar con pods nos permite crear contenedores que se ejecutan en un mismo nodo. Los pods son la unidad mínima de despliegue en Kubernetes.\n\n1. Pantallazo del fichero yaml que has creado con la definición del Pod.\n\n![Descripción de la imagen](/images/k8s-taller-1-1.png)\n\n2. Pantallazo donde se comprueba que el Pod ha sido creado.\n\nkubectl get pods\n\n![Descripción de la imagen](/images/k8s-taller-1-2.png)\n\n3. Pantallazo donde se ve la información detallada del Pod.\n\nPodemos ver la información detallada del pod con `kubectl describe pod pod-nginx`\n\n![Descripción de la imagen](/images/k8s-taller-1-3.png)\n\n4. Pantallazo donde se ve el fichero index.html del DocumentRoot.\n\nPodemos acceder al interior del pod con `kubectl exec -it pod-nginx -- /bin/bash`\n\n![Descripción de la imagen](/images/k8s-taller-1-4.png)\n\n5. Pantallazo del navegador accediendo a la aplicación con el port-forward.\n\nPara poder acceder a través de un navegador, tenemos que hacer un port-forward al puerto 80 del pod.\n\n`kubectl port-forward pod-nginx 8080:80`\n\n![Descripción de la imagen](/images/k8s-taller-1-5.png)\n\n6. Pantallazo donde se ve los logs de acceso del Pod.\n\n`kubectl logs pod-nginx`\n\n![Descripción de la imagen](/images/k8s-taller-1-6.png)\n\n## Taller 2: Trabajando con ReplicaSets\n\nTrabajar con ReplicaSets nos permite crear réplicas de un mismo pod.\n\niesgn/test_web:latest\n\n```\napiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: iesgn-web\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n        - image: iesgn/test_web:latest\n          name: contenedor-nginx\n```\n\n![Descripción de la imagen](/images/k8s-taller-2-1.png)\n\nUna vez creado el replicaset podemos crearlo con `kubectl apply -f iesgn.yaml`\n\n\n\nTambién podemos crearlo con `kubectl create -f iesgn.yaml` pero en este caso no se puede modificar el replicaset una vez creado.\n\n\n\nPara borrarlo emplearemos `kubectl delete -f iesgn.yaml`\n\n![Descripción de la imagen](/images/k8s-taller-2-2.png)\n\n\nPara ver los replicaset creados emplearemos  `kubectl get rs,pods`\n\n\n```\n╭─antonio@debian ~/Documentos/k8s/replicasets  \n╰─➤  kubectl get rs,pods\nNAME                        DESIRED   CURRENT   READY   AGE\nreplicaset.apps/iesgn-web   3         3         3       55s\n\nNAME                      READY   STATUS    RESTARTS      AGE\npod/iesgn-web-g6s5g       1/1     Running   0             55s\npod/iesgn-web-sls5g       1/1     Running   0             55s\npod/iesgn-web-tnsff       1/1     Running   0             55s\n\n```\n\nPara ver la información detallada de un replicaset podemos emplear `kubectl describe rs iesgn-web`\n\n![Descripción de la imagen](/images/k8s-taller-2-3.png)\n\n\nPOdemos ver la tolerancia a fallos borrando un pod con `kubectl delete pod iesgn-web-vjckt`\n\n\n![Descripción de la imagen](/images/k8s-taller-2-4.png)\n\n\nKubernetes nos ofrece escalabilidad horizontal, es decir, podemos aumentar o disminuir el número de réplicas de un replicaset. Para ello emplearemos `kubectl scale --replicas=6 rs iesgn-web`\n\n![Descripción de la imagen](/images/k8s-taller-2-5.png)\n\n## Taller 3: Trabajando con Deployments\n\n### Ejercicio 1: Trabajando con Deployments\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: deployment-iesgn\n  labels:\n    app: nginx\nspec:\n  revisionHistoryLimit: 2\n  strategy:\n    type: RollingUpdate\n  replicas: 2\n  selector:\n    matchLabels:\n      app: iesgn\n  template:\n    metadata:\n      labels:\n        app: iesgn\n    spec:\n      containers:\n      - image: iesgn/test_web:latest\n        name: iesgn\n        ports:\n        - name: http\n          containerPort: 80\n```\n\n\n\n\n\n\n\n\nPantallazo del fichero yaml que has creado con la definición del Deployment.\n\n![Descripción de la imagen](/images/k8s-taller-3-1.png)\n\nPantallazo donde se comprueba los recursos que se han creado.\n\n`kubectl get deploy,rs,pod`\n\n![Descripción de la imagen](/images/k8s-taller-3-2.png)\n\nPantallazo donde se ve la información detallada del Deployment.\n\n`kubectl describe deployment/deployment-nginx`\n\n![Descripción de la imagen](/images/k8s-taller-3-3.png)\n\n\nPantallazo donde se vea el acceso desde un navegador web a la aplicación usando el port-forward.\n\n`kubectl port-forward deployment/deployment-iesgn 8080:80`\n\n\n![Descripción de la imagen](/images/k8s-taller-3-4.png)\n\nPantallazo donde se vea los logs del despliegue después del acceso.\n\n`kubectl logs deployment/deployment-iesgn`\n\n![Descripción de la imagen](/images/k8s-taller-3-5.png)\n\n### Ejercicio 2: Actualización y desactualización de nuestra aplicación\n\nPantallazo donde se vea el acceso desde un navegador web a la version 1 de la aplicación aplicación.\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: deployment-iesgn-v1\n  labels:\n    app: contendor-iesgn\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: contenedor-iesgn\n  template:\n    metadata:\n      labels:\n        app: contenedor-iesgn\n    spec:\n      containers:\n      - name: contenedor-iesgn\n        image: iesgn/test_web:version1\n        ports:\n        - containerPort: 80\n```\n\n```\nkubectl annotate deployment/deployment-iesgn-v1 kubernetes.io/change-cause=\"Primer despliegue de iesgn\"\n```\n\n![Descripción de la imagen](/images/k8s-taller-3-2-1.png)\n\n\n```\nkubectl port-forward deployment/deployment-iesgn-v1 8081:80\n```\n\nPantallazo donde se vea el acceso desde un navegador web a la version 2 de la aplicación aplicación.\n\n```\nkubectl apply -f deployment-iesgn-v1.yaml\n```\n\n![Descripción de la imagen](/images/k8s-taller-3-2-2.png)\n\n\nPantallazo donde se visualice el historial de actualización del despliegue después de actualizar a la versión 2.\n\n![Descripción de la imagen](/images/k8s-taller-3-2-3.png)\n\nPantallazo donde se vea el acceso desde un navegador web a la version 3 de la aplicación (¡¡¡No se visualiza bien la \nhoja de estilos!!!).\n\n![Descripción de la imagen](/images/k8s-taller-3-2-4.png)\n\nPantallazo donde se visualice el historial de actualización después de realizar el rollback del despliegue.\n\n`kubectl rollout undo deployment/deployment-iesgn-v1`\n\n\n![Descripción de la imagen](/images/k8s-taller-3-2-5.png)\n\nPantallazo donde se vea el acceso desde un navegador web a la version de la aplicación que queda después de hacer el rollout.\n\n![Descripción de la imagen](/images/k8s-taller-3-2-6.png)\n\n\n\n\n\n\n### Ejercicio 3: Despliegue de la aplicación GuestBook\n\nguestbook-deployment.yaml\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: guestbook\n  labels:\n    app: guestbook\n    tier: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: frontend\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: contenedor-guestbook\n        image: iesgn/guestbook\n        ports:\n          - name: http-server\n            containerPort: 5000\n\n```\n\nredis-deployment.yaml\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis\n  labels:\n    app: redis\n    tier: backend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: redis\n      tier: backend\n  template:\n    metadata:\n      labels:\n        app: redis\n        tier: backend\n    spec:\n      containers:\n        - name: contenedor-redis\n          image: redis\n          ports:\n            - name: redis-server\n              containerPort: 6379\n```\n\n\nCreamos el escenario ejecutando los siguientes comandos:\n\n`kubectl apply -f guestbook-deployment.yaml`\n\n`kubectl apply -f redis-deployment.yaml`\n\nTenemos dos deploys, uno con guestbook y otro con redis. Para acceder a la aplicación de guestbook, debemos hacer un port-forward al servicio de guestbook. Para ello, ejecutamos el siguiente comando:\n\n`kubectl port-forward deployment/guestbook 8082:5000`\n\n\nPodemos ver que los recursos están creados con el siguiente comando:\n\n`kubectl get all`, `kubectl get all -o wide` o bien `kubectl get deploy,rs,pod`\n\n![Descripción de la imagen](/images/k8s-taller-3-3-1.png)\n\nLo que ocurre es que no conecta a la base de datos porque los dos deployments no están relacionados entre sí.\n\n![Descripción de la imagen](/images/k8s-taller-3-3-2.png)\n\n\n\n## Taller 4: Trabajando con Services\n\n\n### Ejercicio 1: Despliegue y acceso de la aplicación GuestBook\n\n1. Pantallazo donde se vea el acceso desde un navegador web a la aplicación cuando sólo tenemos el servicio para acceder a la aplicación (tiene que aparecer el mensaje de error).\n\n![Descripción de la imagen](/images/k8s-taller-4-1.png)\n\n2. Pantallazo donde se vea el acceso desde un navegador web a la aplicación usando la ip del nodo master y el puerto asignado al Service.\n\n![Descripción de la imagen](/images/k8s-taller-4-2.png)\n\n3. Pantallazo donde se vea el acceso desde un navegador web a la aplicación usando el nombre que hemos configurado en el recurso Ingress.\n\nPara crear el recurso ingress debemos tener el siguiente yaml:\n\nnano ingress.yaml\n```\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: nginx\nspec:\n  rules:\n  - host: www.antonio.org\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: guestbook\n            port:\n              number: 80\n\n```\n\n![Descripción de la imagen](/images/k8s-taller-4-3.png)\n\n### Ejercicio 2: Despliegue y acceso de la Aplicación Lets-Chat\n\n1. Los ficheros yaml que has creado.\n\nHe creado varios yaml, voy a ordenarlos en sentido de conexión desde el frontend al backend:\n\ningress.yaml\n\n```\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: nginx\nspec:\n  rules:\n  - host: www.chat-antonio.org\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: letschat\n            port:\n              number: 8080\n\n```\n\nletschat-service.yaml\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: letschat\n  labels:\n    app: letschat\n    tier: frontend\nspec:\n  type: NodePort\n  ports: \n  - port: 8080\n    targetPort: letschat-server\n  selector:\n    app: letschat\n    tier: frontend\n```\n\nletschat-deployment.yaml\n\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: letschat\n  labels:\n    app: letschat\n    tier: frontend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: letschat\n      tier: frontend\n  template:\n    metadata:\n      labels:\n        app: letschat\n        tier: frontend\n    spec:\n      containers:\n      - name: contenedor-letschat\n        image: sdelements/lets-chat\n        ports:\n          - name: letschat-server\n            containerPort: 8080\n```\n\nmongo-srv.yaml\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: mongo\n  labels:\n    app: mongo\n    tier: backend\nspec:\n  type: ClusterIP\n  ports: \n  - port: 27017\n    targetPort: mongo-server\n  selector:\n    app: mongo\n    tier: backend\n```\n\nmongo-deployment.yaml\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mongo\n  labels:\n    app: mongo\n    tier: backend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mongo\n      tier: backend\n  template:\n    metadata:\n      labels:\n        app: mongo\n        tier: backend\n    spec:\n      containers:\n        - name: contenedor-mongo\n          image: mongo:4\n          ports:\n            - name: mongo-server\n              containerPort: 27017\n```\n\n\nA través de este esquema podemos ver como los diferentes deploys y pods se conectan entre sí para ofrecer el servicio:\n\n\n![Descripción de la imagen](/images/letschat-minikube-esquema.png)\n\n2. Un pantallazo donde se vea el acceso desde un navegador web a la aplicación usando la ip del nodo master y el puerto asignado al Service.\n\nSi usamos el comando `minikube service letschat` nos abre el navegador con la aplicación.\n\n![Descripción de la imagen](/images/k8s-taller-4-4.png)\n\n3. Un pantallazo donde se vea el acceso desde un navegador web a la aplicación usando el nombre que hemos configurado en el recurso Ingress.\n\n![Descripción de la imagen](/images/k8s-taller-4-5.png)\n\n\n\n## Taller 5: Trabajando con ConfigMaps\n\n### Ejercicio 1: Configurando nuestra aplicación Temperaturas\n\nCon el siguiente comando estaremos creando una variable de entorno en el cual indica el nombre SERVIDOR_TEMPERATURAS y el valor servidor-temperaturas:5000\n\n```\nkubectl create cm tempcm --from-literal=SERVIDOR_TEMPERATURAS=servidor-temperaturas:5000 -o yaml --dry-run=client > temperaturas_configmap.yaml\n```\n\nUNa vez ejecutado se crea un fichero que contiene en data el nombre y la clave de la variable de entorno:\n\ntemperaturas_configmap.yaml\n\n```\napiVersion: v1\ndata:\n  SERVIDOR_TEMPERATURAS: servidor-temperaturas:5000\nkind: ConfigMap\nmetadata:\n  creationTimestamp: null\n  name: tempcm\n\n```\n\nEl nombre lo debemos especificar en el deployment, y la key el nombre que va a llevar la variable de entorno, en nuestro caso tempcm y SERVIDOR_TEMPERATURAS respectivamente:\n\n\nEntonces en nuestro fichero yaml de nuestro deployment, quedaría de la siguiente manera:\n\ntempers-deployment.yaml\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: temperaturas-frontend\n  labels:\n    app: temperaturas\n    tier: frontend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: temperaturas\n      tier: frontend\n  template:\n    metadata:\n      labels:\n        app: temperaturas\n        tier: frontend\n    spec:\n      containers:\n      - name: contenedor-temperaturas\n        image: iesgn/temperaturas_frontend\n        ports:\n          - name: http-server\n            containerPort: 3000\n        env:\n          - name: TEMP_SERVER\n            valueFrom:\n              configMapKeyRef:\n                name: tempcm\n                key: SERVIDOR_TEMPERATURAS\n```\n\nAhora vamos a crear el servicio para el frontend por el cual vamos a ver que se puede acceder a la aplicación a través de un puerto aleatorio:\n\ntemperaturas-srv.yaml\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: temperaturas\n  labels:\n    app: temperaturas\n    tier: frontend\nspec:\n  type: NodePort\n  ports: \n  - port: 3000\n    targetPort: http-server\n  selector:\n    app: temperaturas\n    tier: frontend\n```\n\nTomará el puerto 3000 y hará un proxy para que lo veamos a través de un puerto aleatorio, pero a través del port y el targetPort crearemos un ingress para que se pueda acceder a través de un dominio, que será www.antonio.org\n\ningress.yaml\n\n```\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: acceso-frontend\nspec:\n  rules:\n  - host: www.antonio.org\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: temperaturas\n            port:\n              number: 3000\n\n```\n\nDentro del confimap que hemos mencionado más arriba hace referencia al backend-srv.yaml, que toma el nombre de TEMP_SERVER y coge el valor de la key SERVIDOR_TEMPERATURAS, que es el la clave del valor servidor-temperaturas:5000, que se halla en el tempeaturas-deployment.yaml, tomado del configmap tempcm.\n\nbackend-srv.yaml\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: servidor-temperaturas\n  labels:\n    app: temperaturas\n    tier: backend\nspec:\n  type: ClusterIP\n  ports:\n  - port: 5000\n    targetPort: api-server\n  selector:\n    app: temperaturas\n    tier: backend\n\n```\n\nPantallazo donde se vea la definición del recurso ConfigMap.\n\n![Descripción de la imagen](/images/k8s-taller-5-1.png)\n\nPantallazo donde se vea la modificación del fichero frontend-deployment.yaml.\n\n![Descripción de la imagen](/images/k8s-taller-5-2.png)\n\nPantallazo donde se vea la modificación del fichero backend-srv.yaml.\n\n![Descripción de la imagen](/images/k8s-taller-5-3.png)\n\nPantallazo donde se compruebe que la aplicación está funcionando.\n\n![Descripción de la imagen](/images/k8s-taller-5-4.png)\n\n### Ejercicio 2: Despliegue y acceso de la aplicación Nextcloud\n\n\nPrimero vamos a generar las claves para que la base de datos mariadb pueda cambiar los valores por defecto del usuario:\n\nEn el configmap cambiaremos:\n\n- nombre de usuario\n- nombre de la base de datos\n- nombre del host mariadb\n\nEn el secret que lo utilizaremos para convertir a base64 las contraseñas:\n\n- contraseña de usuario\n\n\n\n```\nkubectl create cm bd-datos --from-literal=bd_user=antonio \\\n                           --from-literal=bd_dbname=nextcloud \\\n                           --from-literal=bd_host=mariadb-service \\\n                           -o yaml --dry-run=client > bd_datos_configmap.yaml\n\n\n\nkubectl create secret generic bd-passwords --from-literal=bd_password=antonio \\\n                                           --from-literal=bd_rootpassword=root1234 \\\n                                           -o yaml --dry-run=client > bd_passwords_secret.yaml\n``` \n\nSeguidamente, tanto el deploy de nextcloud como el de mariadb van a tomar cada uno de estos datos para poder crear la base de datos y el usuario, y nextcloud va a tomar el usuario y la contraseña para poder conectarse a la base de datos.\n\nnextcloud-deployment.yaml\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nextcloud-deployment\n  labels:\n    app: nextcloud\n    type: frontend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nextcloud\n      type: frontend\n  template:\n    metadata:\n      labels:\n        app: nextcloud\n        type: frontend\n    spec:\n      containers:\n        - name: contenedor-nextcloud\n          image: nextcloud\n          ports:\n            - containerPort: 80\n              name: http-port\n            - containerPort: 443\n              name: https-port\n          env:\n            - name: MYSQL_USER\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_user\n            - name: MYSQL_DATABASE\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_dbname\n            - name: MYSQL_HOST\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_host\n            - name: MYSQL_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_password\n```\n\n\nmariadb-deployment.yaml\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mariadb-deployment\n  labels:\n    app: nextcloud\n    type: database\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nextcloud\n      type: database\n  template:\n    metadata:\n      labels:\n        app: nextcloud\n        type: database\n    spec:\n      containers:\n        - name: contenedor-mariadb\n          image: mariadb:10.5\n          ports:\n            - containerPort: 3306\n              name: db-port\n          env:\n            - name: MYSQL_USER\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_user\n            - name: MYSQL_DATABASE\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_dbname\n            - name: MYSQL_HOST\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_host\n            - name: MYSQL_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_password\n            - name: MYSQL_ROOT_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_rootpassword\n```\n\n\nComo podemos ver en el valor env tanto en nextcloud como en mariadb, se toman los valores de los configmaps y los secrets que hemos creado anteriormente, teniendo como '- name:' el valor que la aplicación toma por defecto.\n\nmaradb-srv.yaml\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: mariadb-service\n  labels:\n    app: nextcloud\n    type: database\nspec:\n  selector:\n    app: nextcloud\n    type: database\n  ports:\n  - port: 3306\n    targetPort: db-port\n  type: ClusterIP\n```\n\nnextclod-srv.yaml\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: nextcloud\n  labels:\n    app: nextcloud\n    type: frontend\nspec:\n  selector:\n    app: nextcloud\n    type: frontend\n  ports:\n  - name: http-sv-port\n    port: 80\n    targetPort: http-port\n  type: NodePort\n```\n\n\nPantallazo donde se vea el contenido del fichero de despliegue de NextCloud.\n\n![Descripción de la imagen](/images/k8s-taller-5-5.png)\n\nPantallazo donde se vean los recursos que se han creado.\n\n![Descripción de la imagen](/images/k8s-taller-5-6.png)\n\nPantallazo donde se compruebe que la aplicación está funcionando.\n\n![Descripción de la imagen](/images/k8s-taller-5-7.png)\n\n\n## Taller 6: Almacenamiento en Kubernetes\n\n### Ejercicio 1: Desplegando un servidor web persistente\n\nPara empezar debemos pedir el recurso de almacenamiento que vamos a utilizar, en este caso vamos a utilizar un recurso de tipo persistent volume claim, que es un recurso que nos permite pedir un recurso de almacenamiento, en este caso un disco duro, y que nos lo asigne a un nodo.\n\ncat apache-pvc.yaml\n\n```\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n    name: pvc-webserver\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 2Gi\n\n```\n\nComo podemos ver, pide un recurso de almacenamiento de 2Gi\n\ncat apache-deployment.yaml\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: apache-taller6\n  labels:\n    app: apache\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: apache\n  template:\n    metadata:\n      labels:\n        app: apache\n    spec:\n      volumes:\n        - name: pvc-webserver\n          persistentVolumeClaim:\n            claimName: pvc-webserver\n      containers:\n        - name: contenedor-apache\n          image: php:7.4-apache\n          ports:\n            - name: http-server\n              containerPort: 80\n          volumeMounts:\n            - mountPath: \"/var/www/html\"\n              name: pvc-webserver\n```\n\nEn el apartado spec nombra el volumen y lo monta en VolumeMounts.\n\nAhora vamos a crear el servicio nodeport por el cual vamos a entrar en la web:\n\ncat apache-srv.yaml\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: apache\nspec:\n  type: NodePort\n  ports:\n  - name: service-http\n    port: 80\n    targetPort: http-server\n  selector:\n    app: apache\n```\n\nTras esto vamos a ejecutar un comando que es un info.php por bash y lo va a poner en /var/www/html que es donde está el recurso solicitado montado:\n\n```\nkubectl exec pod/apache-taller6-5f78fbb47d-7rlzd -- bash -c \"echo '<?php phpinfo(); ?>' > /var/www/html/info.php\"\n```\n\nPantallazo con la definición del recurso PersistentVolumenClaim.\n\n![Descripción de la imagen](/images/k8s-taller-6-1.png)\n\nPantallazo donde se visualice los recursos pv y pvc que se han creado.\n\n![Descripción de la imagen](/images/k8s-taller-6-2.png)\n\nPantallazo donde se vea el fichero yaml para el despliegue.\n\n![Descripción de la imagen](/images/k8s-taller-6-3.png)\n\nPantallazo donde se vea el acceso a info.php.\n\n![Descripción de la imagen](/images/k8s-taller-6-4.png)\n\nPantallazo donde se vea que se ha eliminado y se ha vuelto a crear el despliegue y se sigue sirviendo el fichero info.php.\n\nAdjunto en una sola imagen la destrucción,creación y comprobación de que sigue funcionando a través de un curl:\n\n![Descripción de la imagen](/images/k8s-taller-6-5.png)\n\n### Ejercicio 2: Haciendo persistente la aplicación GuestBook\n\nVamos a modificar el recurso de despliegue de guestbook para que se pueda hacer persistente, a través de hacer una copia d ela base de datos redis en /data:\n\nredis-deployment.yaml\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis\n  labels:\n    app: redis\n    tier: backend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: redis\n      tier: backend\n  template:\n    metadata:\n      labels:\n        app: redis\n        tier: backend\n    spec:\n      volumes:\n        - name: volumen-redis\n          persistentVolumeClaim:\n            claimName: pvc-guestbook\n      containers:\n        - name: contenedor-redis\n          image: redis\n          command: [\"redis-server\"]\n          args: [\"--appendonly\", \"yes\"]\n          ports:\n            - name: redis-server\n              containerPort: 6379\n          volumeMounts:\n            - mountPath: /data\n              name: volumen-redis\n```\n\nY este sería el guestbook-pvc.yaml\n\n```\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n    name: pvc-guestbook\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 3Gi\n```\n\n\nPantallazo con la definición del recurso PersistentVolumenClaim.\n\nMostrado arriba.\n\nPantallazo donde se visualicen los recursos pv y pvc que se han creado.\n\n![Descripción de la imagen](/images/k8s-taller-6-6.png)\n\nPantallazo donde se vea el fichero yaml modificado para el despliegue de redis.\n\nMostrado arriba.\n\nPantallazo donde se vea el acceso a la aplicación con los mensajes escritos.\n\n![Descripción de la imagen](/images/k8s-taller-6-7.png)\n\nPantallazo donde se vea que se ha eliminado y se ha vuelto a crear el despliegue de redis y que se sigue sirviendo la aplicación con los mensajes.\n\n![Descripción de la imagen](/images/k8s-taller-6-8.gif)\n\n### Ejercicio 3: Haciendo persistente la aplicación Nextcloud\n\nVamos a utilizar los ficheros que anteriormente creamos en nextcloud, lo que haremos será proporcionar almacenamiento tanto en nextcloud como mariadb, para ello vamos a modificar los ficheros de despliegue en relación a los pvc:\n\nnextcloud-pvc.yaml\n\n```\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n    name: nextcloud-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 4Gi\n```\n\nnextcloud-deployment.yaml\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nextcloud-deployment\n  labels:\n    app: nextcloud\n    type: frontend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nextcloud\n      type: frontend\n  template:\n    metadata:\n      labels:\n        app: nextcloud\n        type: frontend\n    spec:\n      volumes:\n        - name: nextcloud-pvc\n          persistentVolumeClaim:\n            claimName: nextcloud-pvc\n      containers:\n        - name: contenedor-nextcloud\n          image: nextcloud\n          volumeMounts:\n            - mountPath: /var/www/html/\n              name: nextcloud-pvc\n          ports:\n            - containerPort: 80\n              name: http-port\n            - containerPort: 443\n              name: https-port\n          env:\n            - name: MYSQL_USER\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_user\n            - name: MYSQL_DATABASE\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_dbname\n            - name: MYSQL_HOST\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_host\n            - name: MYSQL_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_password\n```\n\nAhora vamos con mariadb:\n\nmariadb-pvc.yaml\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: mariadb-service\n  labels:\n    app: nextcloud\n    type: database\nspec:\n  selector:\n    app: nextcloud\n    type: database\n  ports:\n  - port: 3306\n    targetPort: db-port\n  type: ClusterIP\n```\n\n\ncat mariadb-deployment.yaml\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mariadb-deployment\n  labels:\n    app: nextcloud\n    type: database\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nextcloud\n      type: database\n  template:\n    metadata:\n      labels:\n        app: nextcloud\n        type: database\n    spec:\n      volumes:\n        - name: mariadb-pvc\n          persistentVolumeClaim:\n            claimName: mariadb-pvc\n      containers:\n        - name: contenedor-mariadb\n          image: mariadb:10.5\n          ports:\n            - containerPort: 3306\n              name: db-port\n          volumeMounts:\n            - mountPath: \"/var/lib/mysql\"\n              name: mariadb-pvc\n          env:\n            - name: MYSQL_USER\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_user\n            - name: MYSQL_DATABASE\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_dbname\n            - name: MYSQL_HOST\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_host\n            - name: MYSQL_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_password\n            - name: MYSQL_ROOT_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_rootpassword\n\n```\n\n\nPantallazo donde se vean los ficheros yaml modificados para los despliegues.\n\nSe muestra arriba.\n\nPantallazo donde se vea el acceso a la aplicación con el fichero que has subido.\n\n![Descripción de la imagen](/images/k8s-taller-6-8.png)\n\nPantallazo donde se vea que se han eliminado y se han vuelto a crear los despliegues y que la aplicación sigue sirviendo el fichero que habíamos subido.\n\n![Descripción de la imagen](/images/k8s-taller-6-9.gif)\n\n\n","slug":"kubernetes","published":1,"date":"2023-02-02T08:10:15.643Z","updated":"2023-02-23T08:19:34.078Z","_id":"cldmvsvq60000m3i517ps0ez0","comments":1,"layout":"post","photos":[],"link":"","content":"<p><img src=\"/images/k8s-logo.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"taller-1-trabajando-con-pods\"><a class=\"markdownIt-Anchor\" href=\"#taller-1-trabajando-con-pods\">#</a> Taller 1: Trabajando con Pods</h2>\n<p>Trabajar con pods nos permite crear contenedores que se ejecutan en un mismo nodo. Los pods son la unidad mínima de despliegue en Kubernetes.</p>\n<ol>\n<li>Pantallazo del fichero yaml que has creado con la definición del Pod.</li>\n</ol>\n<p><img src=\"/images/k8s-taller-1-1.png\" alt=\"Descripción de la imagen\"></p>\n<ol start=\"2\">\n<li>Pantallazo donde se comprueba que el Pod ha sido creado.</li>\n</ol>\n<p>kubectl get pods</p>\n<p><img src=\"/images/k8s-taller-1-2.png\" alt=\"Descripción de la imagen\"></p>\n<ol start=\"3\">\n<li>Pantallazo donde se ve la información detallada del Pod.</li>\n</ol>\n<p>Podemos ver la información detallada del pod con  <code>kubectl describe pod pod-nginx</code></p>\n<p><img src=\"/images/k8s-taller-1-3.png\" alt=\"Descripción de la imagen\"></p>\n<ol start=\"4\">\n<li>Pantallazo donde se ve el fichero index.html del DocumentRoot.</li>\n</ol>\n<p>Podemos acceder al interior del pod con  <code>kubectl exec -it pod-nginx -- /bin/bash</code></p>\n<p><img src=\"/images/k8s-taller-1-4.png\" alt=\"Descripción de la imagen\"></p>\n<ol start=\"5\">\n<li>Pantallazo del navegador accediendo a la aplicación con el port-forward.</li>\n</ol>\n<p>Para poder acceder a través de un navegador, tenemos que hacer un port-forward al puerto 80 del pod.</p>\n<p><code>kubectl port-forward pod-nginx 8080:80</code></p>\n<p><img src=\"/images/k8s-taller-1-5.png\" alt=\"Descripción de la imagen\"></p>\n<ol start=\"6\">\n<li>Pantallazo donde se ve los logs de acceso del Pod.</li>\n</ol>\n<p><code>kubectl logs pod-nginx</code></p>\n<p><img src=\"/images/k8s-taller-1-6.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"taller-2-trabajando-con-replicasets\"><a class=\"markdownIt-Anchor\" href=\"#taller-2-trabajando-con-replicasets\">#</a> Taller 2: Trabajando con ReplicaSets</h2>\n<p>Trabajar con ReplicaSets nos permite crear réplicas de un mismo pod.</p>\n<p>iesgn/test_web:latest</p>\n<pre><code>apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: iesgn-web\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n        - image: iesgn/test_web:latest\n          name: contenedor-nginx\n</code></pre>\n<p><img src=\"/images/k8s-taller-2-1.png\" alt=\"Descripción de la imagen\"></p>\n<p>Una vez creado el replicaset podemos crearlo con  <code>kubectl apply -f iesgn.yaml</code></p>\n<p>También podemos crearlo con  <code>kubectl create -f iesgn.yaml</code>  pero en este caso no se puede modificar el replicaset una vez creado.</p>\n<p>Para borrarlo emplearemos  <code>kubectl delete -f iesgn.yaml</code></p>\n<p><img src=\"/images/k8s-taller-2-2.png\" alt=\"Descripción de la imagen\"></p>\n<p>Para ver los replicaset creados emplearemos   <code>kubectl get rs,pods</code></p>\n<pre><code>╭─antonio@debian ~/Documentos/k8s/replicasets  \n╰─➤  kubectl get rs,pods\nNAME                        DESIRED   CURRENT   READY   AGE\nreplicaset.apps/iesgn-web   3         3         3       55s\n\nNAME                      READY   STATUS    RESTARTS      AGE\npod/iesgn-web-g6s5g       1/1     Running   0             55s\npod/iesgn-web-sls5g       1/1     Running   0             55s\npod/iesgn-web-tnsff       1/1     Running   0             55s\n\n</code></pre>\n<p>Para ver la información detallada de un replicaset podemos emplear  <code>kubectl describe rs iesgn-web</code></p>\n<p><img src=\"/images/k8s-taller-2-3.png\" alt=\"Descripción de la imagen\"></p>\n<p>POdemos ver la tolerancia a fallos borrando un pod con  <code>kubectl delete pod iesgn-web-vjckt</code></p>\n<p><img src=\"/images/k8s-taller-2-4.png\" alt=\"Descripción de la imagen\"></p>\n<p>Kubernetes nos ofrece escalabilidad horizontal, es decir, podemos aumentar o disminuir el número de réplicas de un replicaset. Para ello emplearemos  <code>kubectl scale --replicas=6 rs iesgn-web</code></p>\n<p><img src=\"/images/k8s-taller-2-5.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"taller-3-trabajando-con-deployments\"><a class=\"markdownIt-Anchor\" href=\"#taller-3-trabajando-con-deployments\">#</a> Taller 3: Trabajando con Deployments</h2>\n<h3 id=\"ejercicio-1-trabajando-con-deployments\"><a class=\"markdownIt-Anchor\" href=\"#ejercicio-1-trabajando-con-deployments\">#</a> Ejercicio 1: Trabajando con Deployments</h3>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: deployment-iesgn\n  labels:\n    app: nginx\nspec:\n  revisionHistoryLimit: 2\n  strategy:\n    type: RollingUpdate\n  replicas: 2\n  selector:\n    matchLabels:\n      app: iesgn\n  template:\n    metadata:\n      labels:\n        app: iesgn\n    spec:\n      containers:\n      - image: iesgn/test_web:latest\n        name: iesgn\n        ports:\n        - name: http\n          containerPort: 80\n</code></pre>\n<p>Pantallazo del fichero yaml que has creado con la definición del Deployment.</p>\n<p><img src=\"/images/k8s-taller-3-1.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se comprueba los recursos que se han creado.</p>\n<p><code>kubectl get deploy,rs,pod</code></p>\n<p><img src=\"/images/k8s-taller-3-2.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se ve la información detallada del Deployment.</p>\n<p><code>kubectl describe deployment/deployment-nginx</code></p>\n<p><img src=\"/images/k8s-taller-3-3.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se vea el acceso desde un navegador web a la aplicación usando el port-forward.</p>\n<p><code>kubectl port-forward deployment/deployment-iesgn 8080:80</code></p>\n<p><img src=\"/images/k8s-taller-3-4.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se vea los logs del despliegue después del acceso.</p>\n<p><code>kubectl logs deployment/deployment-iesgn</code></p>\n<p><img src=\"/images/k8s-taller-3-5.png\" alt=\"Descripción de la imagen\"></p>\n<h3 id=\"ejercicio-2-actualización-y-desactualización-de-nuestra-aplicación\"><a class=\"markdownIt-Anchor\" href=\"#ejercicio-2-actualización-y-desactualización-de-nuestra-aplicación\">#</a> Ejercicio 2: Actualización y desactualización de nuestra aplicación</h3>\n<p>Pantallazo donde se vea el acceso desde un navegador web a la version 1 de la aplicación aplicación.</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: deployment-iesgn-v1\n  labels:\n    app: contendor-iesgn\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: contenedor-iesgn\n  template:\n    metadata:\n      labels:\n        app: contenedor-iesgn\n    spec:\n      containers:\n      - name: contenedor-iesgn\n        image: iesgn/test_web:version1\n        ports:\n        - containerPort: 80\n</code></pre>\n<pre><code>kubectl annotate deployment/deployment-iesgn-v1 kubernetes.io/change-cause=&quot;Primer despliegue de iesgn&quot;\n</code></pre>\n<p><img src=\"/images/k8s-taller-3-2-1.png\" alt=\"Descripción de la imagen\"></p>\n<pre><code>kubectl port-forward deployment/deployment-iesgn-v1 8081:80\n</code></pre>\n<p>Pantallazo donde se vea el acceso desde un navegador web a la version 2 de la aplicación aplicación.</p>\n<pre><code>kubectl apply -f deployment-iesgn-v1.yaml\n</code></pre>\n<p><img src=\"/images/k8s-taller-3-2-2.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se visualice el historial de actualización del despliegue después de actualizar a la versión 2.</p>\n<p><img src=\"/images/k8s-taller-3-2-3.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se vea el acceso desde un navegador web a la version 3 de la aplicación (¡¡¡No se visualiza bien la<br>\nhoja de estilos!!!).</p>\n<p><img src=\"/images/k8s-taller-3-2-4.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se visualice el historial de actualización después de realizar el rollback del despliegue.</p>\n<p><code>kubectl rollout undo deployment/deployment-iesgn-v1</code></p>\n<p><img src=\"/images/k8s-taller-3-2-5.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se vea el acceso desde un navegador web a la version de la aplicación que queda después de hacer el rollout.</p>\n<p><img src=\"/images/k8s-taller-3-2-6.png\" alt=\"Descripción de la imagen\"></p>\n<h3 id=\"ejercicio-3-despliegue-de-la-aplicación-guestbook\"><a class=\"markdownIt-Anchor\" href=\"#ejercicio-3-despliegue-de-la-aplicación-guestbook\">#</a> Ejercicio 3: Despliegue de la aplicación GuestBook</h3>\n<p>guestbook-deployment.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: guestbook\n  labels:\n    app: guestbook\n    tier: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: frontend\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: contenedor-guestbook\n        image: iesgn/guestbook\n        ports:\n          - name: http-server\n            containerPort: 5000\n\n</code></pre>\n<p>redis-deployment.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis\n  labels:\n    app: redis\n    tier: backend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: redis\n      tier: backend\n  template:\n    metadata:\n      labels:\n        app: redis\n        tier: backend\n    spec:\n      containers:\n        - name: contenedor-redis\n          image: redis\n          ports:\n            - name: redis-server\n              containerPort: 6379\n</code></pre>\n<p>Creamos el escenario ejecutando los siguientes comandos:</p>\n<p><code>kubectl apply -f guestbook-deployment.yaml</code></p>\n<p><code>kubectl apply -f redis-deployment.yaml</code></p>\n<p>Tenemos dos deploys, uno con guestbook y otro con redis. Para acceder a la aplicación de guestbook, debemos hacer un port-forward al servicio de guestbook. Para ello, ejecutamos el siguiente comando:</p>\n<p><code>kubectl port-forward deployment/guestbook 8082:5000</code></p>\n<p>Podemos ver que los recursos están creados con el siguiente comando:</p>\n<p><code>kubectl get all</code> ,  <code>kubectl get all -o wide</code>  o bien  <code>kubectl get deploy,rs,pod</code></p>\n<p><img src=\"/images/k8s-taller-3-3-1.png\" alt=\"Descripción de la imagen\"></p>\n<p>Lo que ocurre es que no conecta a la base de datos porque los dos deployments no están relacionados entre sí.</p>\n<p><img src=\"/images/k8s-taller-3-3-2.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"taller-4-trabajando-con-services\"><a class=\"markdownIt-Anchor\" href=\"#taller-4-trabajando-con-services\">#</a> Taller 4: Trabajando con Services</h2>\n<h3 id=\"ejercicio-1-despliegue-y-acceso-de-la-aplicación-guestbook\"><a class=\"markdownIt-Anchor\" href=\"#ejercicio-1-despliegue-y-acceso-de-la-aplicación-guestbook\">#</a> Ejercicio 1: Despliegue y acceso de la aplicación GuestBook</h3>\n<ol>\n<li>Pantallazo donde se vea el acceso desde un navegador web a la aplicación cuando sólo tenemos el servicio para acceder a la aplicación (tiene que aparecer el mensaje de error).</li>\n</ol>\n<p><img src=\"/images/k8s-taller-4-1.png\" alt=\"Descripción de la imagen\"></p>\n<ol start=\"2\">\n<li>Pantallazo donde se vea el acceso desde un navegador web a la aplicación usando la ip del nodo master y el puerto asignado al Service.</li>\n</ol>\n<p><img src=\"/images/k8s-taller-4-2.png\" alt=\"Descripción de la imagen\"></p>\n<ol start=\"3\">\n<li>Pantallazo donde se vea el acceso desde un navegador web a la aplicación usando el nombre que hemos configurado en el recurso Ingress.</li>\n</ol>\n<p>Para crear el recurso ingress debemos tener el siguiente yaml:</p>\n<p>nano ingress.yaml</p>\n<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: nginx\nspec:\n  rules:\n  - host: www.antonio.org\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: guestbook\n            port:\n              number: 80\n\n</code></pre>\n<p><img src=\"/images/k8s-taller-4-3.png\" alt=\"Descripción de la imagen\"></p>\n<h3 id=\"ejercicio-2-despliegue-y-acceso-de-la-aplicación-lets-chat\"><a class=\"markdownIt-Anchor\" href=\"#ejercicio-2-despliegue-y-acceso-de-la-aplicación-lets-chat\">#</a> Ejercicio 2: Despliegue y acceso de la Aplicación Lets-Chat</h3>\n<ol>\n<li>Los ficheros yaml que has creado.</li>\n</ol>\n<p>He creado varios yaml, voy a ordenarlos en sentido de conexión desde el frontend al backend:</p>\n<p>ingress.yaml</p>\n<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: nginx\nspec:\n  rules:\n  - host: www.chat-antonio.org\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: letschat\n            port:\n              number: 8080\n\n</code></pre>\n<p>letschat-service.yaml</p>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: letschat\n  labels:\n    app: letschat\n    tier: frontend\nspec:\n  type: NodePort\n  ports: \n  - port: 8080\n    targetPort: letschat-server\n  selector:\n    app: letschat\n    tier: frontend\n</code></pre>\n<p>letschat-deployment.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: letschat\n  labels:\n    app: letschat\n    tier: frontend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: letschat\n      tier: frontend\n  template:\n    metadata:\n      labels:\n        app: letschat\n        tier: frontend\n    spec:\n      containers:\n      - name: contenedor-letschat\n        image: sdelements/lets-chat\n        ports:\n          - name: letschat-server\n            containerPort: 8080\n</code></pre>\n<p>mongo-srv.yaml</p>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: mongo\n  labels:\n    app: mongo\n    tier: backend\nspec:\n  type: ClusterIP\n  ports: \n  - port: 27017\n    targetPort: mongo-server\n  selector:\n    app: mongo\n    tier: backend\n</code></pre>\n<p>mongo-deployment.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mongo\n  labels:\n    app: mongo\n    tier: backend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mongo\n      tier: backend\n  template:\n    metadata:\n      labels:\n        app: mongo\n        tier: backend\n    spec:\n      containers:\n        - name: contenedor-mongo\n          image: mongo:4\n          ports:\n            - name: mongo-server\n              containerPort: 27017\n</code></pre>\n<p>A través de este esquema podemos ver como los diferentes deploys y pods se conectan entre sí para ofrecer el servicio:</p>\n<p><img src=\"/images/letschat-minikube-esquema.png\" alt=\"Descripción de la imagen\"></p>\n<ol start=\"2\">\n<li>Un pantallazo donde se vea el acceso desde un navegador web a la aplicación usando la ip del nodo master y el puerto asignado al Service.</li>\n</ol>\n<p>Si usamos el comando  <code>minikube service letschat</code>  nos abre el navegador con la aplicación.</p>\n<p><img src=\"/images/k8s-taller-4-4.png\" alt=\"Descripción de la imagen\"></p>\n<ol start=\"3\">\n<li>Un pantallazo donde se vea el acceso desde un navegador web a la aplicación usando el nombre que hemos configurado en el recurso Ingress.</li>\n</ol>\n<p><img src=\"/images/k8s-taller-4-5.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"taller-5-trabajando-con-configmaps\"><a class=\"markdownIt-Anchor\" href=\"#taller-5-trabajando-con-configmaps\">#</a> Taller 5: Trabajando con ConfigMaps</h2>\n<h3 id=\"ejercicio-1-configurando-nuestra-aplicación-temperaturas\"><a class=\"markdownIt-Anchor\" href=\"#ejercicio-1-configurando-nuestra-aplicación-temperaturas\">#</a> Ejercicio 1: Configurando nuestra aplicación Temperaturas</h3>\n<p>Con el siguiente comando estaremos creando una variable de entorno en el cual indica el nombre SERVIDOR_TEMPERATURAS y el valor servidor-temperaturas:5000</p>\n<pre><code>kubectl create cm tempcm --from-literal=SERVIDOR_TEMPERATURAS=servidor-temperaturas:5000 -o yaml --dry-run=client &gt; temperaturas_configmap.yaml\n</code></pre>\n<p>UNa vez ejecutado se crea un fichero que contiene en data el nombre y la clave de la variable de entorno:</p>\n<p>temperaturas_configmap.yaml</p>\n<pre><code>apiVersion: v1\ndata:\n  SERVIDOR_TEMPERATURAS: servidor-temperaturas:5000\nkind: ConfigMap\nmetadata:\n  creationTimestamp: null\n  name: tempcm\n\n</code></pre>\n<p>El nombre lo debemos especificar en el deployment, y la key el nombre que va a llevar la variable de entorno, en nuestro caso tempcm y SERVIDOR_TEMPERATURAS respectivamente:</p>\n<p>Entonces en nuestro fichero yaml de nuestro deployment, quedaría de la siguiente manera:</p>\n<p>tempers-deployment.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: temperaturas-frontend\n  labels:\n    app: temperaturas\n    tier: frontend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: temperaturas\n      tier: frontend\n  template:\n    metadata:\n      labels:\n        app: temperaturas\n        tier: frontend\n    spec:\n      containers:\n      - name: contenedor-temperaturas\n        image: iesgn/temperaturas_frontend\n        ports:\n          - name: http-server\n            containerPort: 3000\n        env:\n          - name: TEMP_SERVER\n            valueFrom:\n              configMapKeyRef:\n                name: tempcm\n                key: SERVIDOR_TEMPERATURAS\n</code></pre>\n<p>Ahora vamos a crear el servicio para el frontend por el cual vamos a ver que se puede acceder a la aplicación a través de un puerto aleatorio:</p>\n<p>temperaturas-srv.yaml</p>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: temperaturas\n  labels:\n    app: temperaturas\n    tier: frontend\nspec:\n  type: NodePort\n  ports: \n  - port: 3000\n    targetPort: http-server\n  selector:\n    app: temperaturas\n    tier: frontend\n</code></pre>\n<p>Tomará el puerto 3000 y hará un proxy para que lo veamos a través de un puerto aleatorio, pero a través del port y el targetPort crearemos un ingress para que se pueda acceder a través de un dominio, que será <a href=\"http://www.antonio.org\">www.antonio.org</a></p>\n<p>ingress.yaml</p>\n<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: acceso-frontend\nspec:\n  rules:\n  - host: www.antonio.org\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: temperaturas\n            port:\n              number: 3000\n\n</code></pre>\n<p>Dentro del confimap que hemos mencionado más arriba hace referencia al backend-srv.yaml, que toma el nombre de TEMP_SERVER y coge el valor de la key SERVIDOR_TEMPERATURAS, que es el la clave del valor servidor-temperaturas:5000, que se halla en el tempeaturas-deployment.yaml, tomado del configmap tempcm.</p>\n<p>backend-srv.yaml</p>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: servidor-temperaturas\n  labels:\n    app: temperaturas\n    tier: backend\nspec:\n  type: ClusterIP\n  ports:\n  - port: 5000\n    targetPort: api-server\n  selector:\n    app: temperaturas\n    tier: backend\n\n</code></pre>\n<p>Pantallazo donde se vea la definición del recurso ConfigMap.</p>\n<p><img src=\"/images/k8s-taller-5-1.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se vea la modificación del fichero frontend-deployment.yaml.</p>\n<p><img src=\"/images/k8s-taller-5-2.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se vea la modificación del fichero backend-srv.yaml.</p>\n<p><img src=\"/images/k8s-taller-5-3.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se compruebe que la aplicación está funcionando.</p>\n<p><img src=\"/images/k8s-taller-5-4.png\" alt=\"Descripción de la imagen\"></p>\n<h3 id=\"ejercicio-2-despliegue-y-acceso-de-la-aplicación-nextcloud\"><a class=\"markdownIt-Anchor\" href=\"#ejercicio-2-despliegue-y-acceso-de-la-aplicación-nextcloud\">#</a> Ejercicio 2: Despliegue y acceso de la aplicación Nextcloud</h3>\n<p>Primero vamos a generar las claves para que la base de datos mariadb pueda cambiar los valores por defecto del usuario:</p>\n<p>En el configmap cambiaremos:</p>\n<ul>\n<li>nombre de usuario</li>\n<li>nombre de la base de datos</li>\n<li>nombre del host mariadb</li>\n</ul>\n<p>En el secret que lo utilizaremos para convertir a base64 las contraseñas:</p>\n<ul>\n<li>contraseña de usuario</li>\n</ul>\n<pre><code>kubectl create cm bd-datos --from-literal=bd_user=antonio \\\n                           --from-literal=bd_dbname=nextcloud \\\n                           --from-literal=bd_host=mariadb-service \\\n                           -o yaml --dry-run=client &gt; bd_datos_configmap.yaml\n\n\n\nkubectl create secret generic bd-passwords --from-literal=bd_password=antonio \\\n                                           --from-literal=bd_rootpassword=root1234 \\\n                                           -o yaml --dry-run=client &gt; bd_passwords_secret.yaml\n</code></pre>\n<p>Seguidamente, tanto el deploy de nextcloud como el de mariadb van a tomar cada uno de estos datos para poder crear la base de datos y el usuario, y nextcloud va a tomar el usuario y la contraseña para poder conectarse a la base de datos.</p>\n<p>nextcloud-deployment.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nextcloud-deployment\n  labels:\n    app: nextcloud\n    type: frontend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nextcloud\n      type: frontend\n  template:\n    metadata:\n      labels:\n        app: nextcloud\n        type: frontend\n    spec:\n      containers:\n        - name: contenedor-nextcloud\n          image: nextcloud\n          ports:\n            - containerPort: 80\n              name: http-port\n            - containerPort: 443\n              name: https-port\n          env:\n            - name: MYSQL_USER\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_user\n            - name: MYSQL_DATABASE\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_dbname\n            - name: MYSQL_HOST\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_host\n            - name: MYSQL_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_password\n</code></pre>\n<p>mariadb-deployment.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mariadb-deployment\n  labels:\n    app: nextcloud\n    type: database\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nextcloud\n      type: database\n  template:\n    metadata:\n      labels:\n        app: nextcloud\n        type: database\n    spec:\n      containers:\n        - name: contenedor-mariadb\n          image: mariadb:10.5\n          ports:\n            - containerPort: 3306\n              name: db-port\n          env:\n            - name: MYSQL_USER\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_user\n            - name: MYSQL_DATABASE\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_dbname\n            - name: MYSQL_HOST\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_host\n            - name: MYSQL_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_password\n            - name: MYSQL_ROOT_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_rootpassword\n</code></pre>\n<p>Como podemos ver en el valor env tanto en nextcloud como en mariadb, se toman los valores de los configmaps y los secrets que hemos creado anteriormente, teniendo como ‘- name:’ el valor que la aplicación toma por defecto.</p>\n<p>maradb-srv.yaml</p>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: mariadb-service\n  labels:\n    app: nextcloud\n    type: database\nspec:\n  selector:\n    app: nextcloud\n    type: database\n  ports:\n  - port: 3306\n    targetPort: db-port\n  type: ClusterIP\n</code></pre>\n<p>nextclod-srv.yaml</p>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: nextcloud\n  labels:\n    app: nextcloud\n    type: frontend\nspec:\n  selector:\n    app: nextcloud\n    type: frontend\n  ports:\n  - name: http-sv-port\n    port: 80\n    targetPort: http-port\n  type: NodePort\n</code></pre>\n<p>Pantallazo donde se vea el contenido del fichero de despliegue de NextCloud.</p>\n<p><img src=\"/images/k8s-taller-5-5.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se vean los recursos que se han creado.</p>\n<p><img src=\"/images/k8s-taller-5-6.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se compruebe que la aplicación está funcionando.</p>\n<p><img src=\"/images/k8s-taller-5-7.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"taller-6-almacenamiento-en-kubernetes\"><a class=\"markdownIt-Anchor\" href=\"#taller-6-almacenamiento-en-kubernetes\">#</a> Taller 6: Almacenamiento en Kubernetes</h2>\n<h3 id=\"ejercicio-1-desplegando-un-servidor-web-persistente\"><a class=\"markdownIt-Anchor\" href=\"#ejercicio-1-desplegando-un-servidor-web-persistente\">#</a> Ejercicio 1: Desplegando un servidor web persistente</h3>\n<p>Para empezar debemos pedir el recurso de almacenamiento que vamos a utilizar, en este caso vamos a utilizar un recurso de tipo persistent volume claim, que es un recurso que nos permite pedir un recurso de almacenamiento, en este caso un disco duro, y que nos lo asigne a un nodo.</p>\n<p>cat apache-pvc.yaml</p>\n<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n    name: pvc-webserver\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 2Gi\n\n</code></pre>\n<p>Como podemos ver, pide un recurso de almacenamiento de 2Gi</p>\n<p>cat apache-deployment.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: apache-taller6\n  labels:\n    app: apache\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: apache\n  template:\n    metadata:\n      labels:\n        app: apache\n    spec:\n      volumes:\n        - name: pvc-webserver\n          persistentVolumeClaim:\n            claimName: pvc-webserver\n      containers:\n        - name: contenedor-apache\n          image: php:7.4-apache\n          ports:\n            - name: http-server\n              containerPort: 80\n          volumeMounts:\n            - mountPath: &quot;/var/www/html&quot;\n              name: pvc-webserver\n</code></pre>\n<p>En el apartado spec nombra el volumen y lo monta en VolumeMounts.</p>\n<p>Ahora vamos a crear el servicio nodeport por el cual vamos a entrar en la web:</p>\n<p>cat apache-srv.yaml</p>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: apache\nspec:\n  type: NodePort\n  ports:\n  - name: service-http\n    port: 80\n    targetPort: http-server\n  selector:\n    app: apache\n</code></pre>\n<p>Tras esto vamos a ejecutar un comando que es un info.php por bash y lo va a poner en /var/www/html que es donde está el recurso solicitado montado:</p>\n<pre><code>kubectl exec pod/apache-taller6-5f78fbb47d-7rlzd -- bash -c &quot;echo '&lt;?php phpinfo(); ?&gt;' &gt; /var/www/html/info.php&quot;\n</code></pre>\n<p>Pantallazo con la definición del recurso PersistentVolumenClaim.</p>\n<p><img src=\"/images/k8s-taller-6-1.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se visualice los recursos pv y pvc que se han creado.</p>\n<p><img src=\"/images/k8s-taller-6-2.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se vea el fichero yaml para el despliegue.</p>\n<p><img src=\"/images/k8s-taller-6-3.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se vea el acceso a info.php.</p>\n<p><img src=\"/images/k8s-taller-6-4.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se vea que se ha eliminado y se ha vuelto a crear el despliegue y se sigue sirviendo el fichero info.php.</p>\n<p>Adjunto en una sola imagen la destrucción,creación y comprobación de que sigue funcionando a través de un curl:</p>\n<p><img src=\"/images/k8s-taller-6-5.png\" alt=\"Descripción de la imagen\"></p>\n<h3 id=\"ejercicio-2-haciendo-persistente-la-aplicación-guestbook\"><a class=\"markdownIt-Anchor\" href=\"#ejercicio-2-haciendo-persistente-la-aplicación-guestbook\">#</a> Ejercicio 2: Haciendo persistente la aplicación GuestBook</h3>\n<p>Vamos a modificar el recurso de despliegue de guestbook para que se pueda hacer persistente, a través de hacer una copia d ela base de datos redis en /data:</p>\n<p>redis-deployment.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis\n  labels:\n    app: redis\n    tier: backend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: redis\n      tier: backend\n  template:\n    metadata:\n      labels:\n        app: redis\n        tier: backend\n    spec:\n      volumes:\n        - name: volumen-redis\n          persistentVolumeClaim:\n            claimName: pvc-guestbook\n      containers:\n        - name: contenedor-redis\n          image: redis\n          command: [&quot;redis-server&quot;]\n          args: [&quot;--appendonly&quot;, &quot;yes&quot;]\n          ports:\n            - name: redis-server\n              containerPort: 6379\n          volumeMounts:\n            - mountPath: /data\n              name: volumen-redis\n</code></pre>\n<p>Y este sería el guestbook-pvc.yaml</p>\n<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n    name: pvc-guestbook\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 3Gi\n</code></pre>\n<p>Pantallazo con la definición del recurso PersistentVolumenClaim.</p>\n<p>Mostrado arriba.</p>\n<p>Pantallazo donde se visualicen los recursos pv y pvc que se han creado.</p>\n<p><img src=\"/images/k8s-taller-6-6.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se vea el fichero yaml modificado para el despliegue de redis.</p>\n<p>Mostrado arriba.</p>\n<p>Pantallazo donde se vea el acceso a la aplicación con los mensajes escritos.</p>\n<p><img src=\"/images/k8s-taller-6-7.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se vea que se ha eliminado y se ha vuelto a crear el despliegue de redis y que se sigue sirviendo la aplicación con los mensajes.</p>\n<p><img src=\"/images/k8s-taller-6-8.gif\" alt=\"Descripción de la imagen\"></p>\n<h3 id=\"ejercicio-3-haciendo-persistente-la-aplicación-nextcloud\"><a class=\"markdownIt-Anchor\" href=\"#ejercicio-3-haciendo-persistente-la-aplicación-nextcloud\">#</a> Ejercicio 3: Haciendo persistente la aplicación Nextcloud</h3>\n<p>Vamos a utilizar los ficheros que anteriormente creamos en nextcloud, lo que haremos será proporcionar almacenamiento tanto en nextcloud como mariadb, para ello vamos a modificar los ficheros de despliegue en relación a los pvc:</p>\n<p>nextcloud-pvc.yaml</p>\n<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n    name: nextcloud-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 4Gi\n</code></pre>\n<p>nextcloud-deployment.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nextcloud-deployment\n  labels:\n    app: nextcloud\n    type: frontend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nextcloud\n      type: frontend\n  template:\n    metadata:\n      labels:\n        app: nextcloud\n        type: frontend\n    spec:\n      volumes:\n        - name: nextcloud-pvc\n          persistentVolumeClaim:\n            claimName: nextcloud-pvc\n      containers:\n        - name: contenedor-nextcloud\n          image: nextcloud\n          volumeMounts:\n            - mountPath: /var/www/html/\n              name: nextcloud-pvc\n          ports:\n            - containerPort: 80\n              name: http-port\n            - containerPort: 443\n              name: https-port\n          env:\n            - name: MYSQL_USER\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_user\n            - name: MYSQL_DATABASE\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_dbname\n            - name: MYSQL_HOST\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_host\n            - name: MYSQL_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_password\n</code></pre>\n<p>Ahora vamos con mariadb:</p>\n<p>mariadb-pvc.yaml</p>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: mariadb-service\n  labels:\n    app: nextcloud\n    type: database\nspec:\n  selector:\n    app: nextcloud\n    type: database\n  ports:\n  - port: 3306\n    targetPort: db-port\n  type: ClusterIP\n</code></pre>\n<p>cat mariadb-deployment.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mariadb-deployment\n  labels:\n    app: nextcloud\n    type: database\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nextcloud\n      type: database\n  template:\n    metadata:\n      labels:\n        app: nextcloud\n        type: database\n    spec:\n      volumes:\n        - name: mariadb-pvc\n          persistentVolumeClaim:\n            claimName: mariadb-pvc\n      containers:\n        - name: contenedor-mariadb\n          image: mariadb:10.5\n          ports:\n            - containerPort: 3306\n              name: db-port\n          volumeMounts:\n            - mountPath: &quot;/var/lib/mysql&quot;\n              name: mariadb-pvc\n          env:\n            - name: MYSQL_USER\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_user\n            - name: MYSQL_DATABASE\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_dbname\n            - name: MYSQL_HOST\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_host\n            - name: MYSQL_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_password\n            - name: MYSQL_ROOT_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_rootpassword\n\n</code></pre>\n<p>Pantallazo donde se vean los ficheros yaml modificados para los despliegues.</p>\n<p>Se muestra arriba.</p>\n<p>Pantallazo donde se vea el acceso a la aplicación con el fichero que has subido.</p>\n<p><img src=\"/images/k8s-taller-6-8.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se vea que se han eliminado y se han vuelto a crear los despliegues y que la aplicación sigue sirviendo el fichero que habíamos subido.</p>\n<p><img src=\"/images/k8s-taller-6-9.gif\" alt=\"Descripción de la imagen\"></p>\n","site":{"data":{}},"length":18691,"excerpt":"","more":"<p><img src=\"/images/k8s-logo.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"taller-1-trabajando-con-pods\"><a class=\"markdownIt-Anchor\" href=\"#taller-1-trabajando-con-pods\">#</a> Taller 1: Trabajando con Pods</h2>\n<p>Trabajar con pods nos permite crear contenedores que se ejecutan en un mismo nodo. Los pods son la unidad mínima de despliegue en Kubernetes.</p>\n<ol>\n<li>Pantallazo del fichero yaml que has creado con la definición del Pod.</li>\n</ol>\n<p><img src=\"/images/k8s-taller-1-1.png\" alt=\"Descripción de la imagen\"></p>\n<ol start=\"2\">\n<li>Pantallazo donde se comprueba que el Pod ha sido creado.</li>\n</ol>\n<p>kubectl get pods</p>\n<p><img src=\"/images/k8s-taller-1-2.png\" alt=\"Descripción de la imagen\"></p>\n<ol start=\"3\">\n<li>Pantallazo donde se ve la información detallada del Pod.</li>\n</ol>\n<p>Podemos ver la información detallada del pod con  <code>kubectl describe pod pod-nginx</code></p>\n<p><img src=\"/images/k8s-taller-1-3.png\" alt=\"Descripción de la imagen\"></p>\n<ol start=\"4\">\n<li>Pantallazo donde se ve el fichero index.html del DocumentRoot.</li>\n</ol>\n<p>Podemos acceder al interior del pod con  <code>kubectl exec -it pod-nginx -- /bin/bash</code></p>\n<p><img src=\"/images/k8s-taller-1-4.png\" alt=\"Descripción de la imagen\"></p>\n<ol start=\"5\">\n<li>Pantallazo del navegador accediendo a la aplicación con el port-forward.</li>\n</ol>\n<p>Para poder acceder a través de un navegador, tenemos que hacer un port-forward al puerto 80 del pod.</p>\n<p><code>kubectl port-forward pod-nginx 8080:80</code></p>\n<p><img src=\"/images/k8s-taller-1-5.png\" alt=\"Descripción de la imagen\"></p>\n<ol start=\"6\">\n<li>Pantallazo donde se ve los logs de acceso del Pod.</li>\n</ol>\n<p><code>kubectl logs pod-nginx</code></p>\n<p><img src=\"/images/k8s-taller-1-6.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"taller-2-trabajando-con-replicasets\"><a class=\"markdownIt-Anchor\" href=\"#taller-2-trabajando-con-replicasets\">#</a> Taller 2: Trabajando con ReplicaSets</h2>\n<p>Trabajar con ReplicaSets nos permite crear réplicas de un mismo pod.</p>\n<p>iesgn/test_web:latest</p>\n<pre><code>apiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: iesgn-web\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n        - image: iesgn/test_web:latest\n          name: contenedor-nginx\n</code></pre>\n<p><img src=\"/images/k8s-taller-2-1.png\" alt=\"Descripción de la imagen\"></p>\n<p>Una vez creado el replicaset podemos crearlo con  <code>kubectl apply -f iesgn.yaml</code></p>\n<p>También podemos crearlo con  <code>kubectl create -f iesgn.yaml</code>  pero en este caso no se puede modificar el replicaset una vez creado.</p>\n<p>Para borrarlo emplearemos  <code>kubectl delete -f iesgn.yaml</code></p>\n<p><img src=\"/images/k8s-taller-2-2.png\" alt=\"Descripción de la imagen\"></p>\n<p>Para ver los replicaset creados emplearemos   <code>kubectl get rs,pods</code></p>\n<pre><code>╭─antonio@debian ~/Documentos/k8s/replicasets  \n╰─➤  kubectl get rs,pods\nNAME                        DESIRED   CURRENT   READY   AGE\nreplicaset.apps/iesgn-web   3         3         3       55s\n\nNAME                      READY   STATUS    RESTARTS      AGE\npod/iesgn-web-g6s5g       1/1     Running   0             55s\npod/iesgn-web-sls5g       1/1     Running   0             55s\npod/iesgn-web-tnsff       1/1     Running   0             55s\n\n</code></pre>\n<p>Para ver la información detallada de un replicaset podemos emplear  <code>kubectl describe rs iesgn-web</code></p>\n<p><img src=\"/images/k8s-taller-2-3.png\" alt=\"Descripción de la imagen\"></p>\n<p>POdemos ver la tolerancia a fallos borrando un pod con  <code>kubectl delete pod iesgn-web-vjckt</code></p>\n<p><img src=\"/images/k8s-taller-2-4.png\" alt=\"Descripción de la imagen\"></p>\n<p>Kubernetes nos ofrece escalabilidad horizontal, es decir, podemos aumentar o disminuir el número de réplicas de un replicaset. Para ello emplearemos  <code>kubectl scale --replicas=6 rs iesgn-web</code></p>\n<p><img src=\"/images/k8s-taller-2-5.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"taller-3-trabajando-con-deployments\"><a class=\"markdownIt-Anchor\" href=\"#taller-3-trabajando-con-deployments\">#</a> Taller 3: Trabajando con Deployments</h2>\n<h3 id=\"ejercicio-1-trabajando-con-deployments\"><a class=\"markdownIt-Anchor\" href=\"#ejercicio-1-trabajando-con-deployments\">#</a> Ejercicio 1: Trabajando con Deployments</h3>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: deployment-iesgn\n  labels:\n    app: nginx\nspec:\n  revisionHistoryLimit: 2\n  strategy:\n    type: RollingUpdate\n  replicas: 2\n  selector:\n    matchLabels:\n      app: iesgn\n  template:\n    metadata:\n      labels:\n        app: iesgn\n    spec:\n      containers:\n      - image: iesgn/test_web:latest\n        name: iesgn\n        ports:\n        - name: http\n          containerPort: 80\n</code></pre>\n<p>Pantallazo del fichero yaml que has creado con la definición del Deployment.</p>\n<p><img src=\"/images/k8s-taller-3-1.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se comprueba los recursos que se han creado.</p>\n<p><code>kubectl get deploy,rs,pod</code></p>\n<p><img src=\"/images/k8s-taller-3-2.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se ve la información detallada del Deployment.</p>\n<p><code>kubectl describe deployment/deployment-nginx</code></p>\n<p><img src=\"/images/k8s-taller-3-3.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se vea el acceso desde un navegador web a la aplicación usando el port-forward.</p>\n<p><code>kubectl port-forward deployment/deployment-iesgn 8080:80</code></p>\n<p><img src=\"/images/k8s-taller-3-4.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se vea los logs del despliegue después del acceso.</p>\n<p><code>kubectl logs deployment/deployment-iesgn</code></p>\n<p><img src=\"/images/k8s-taller-3-5.png\" alt=\"Descripción de la imagen\"></p>\n<h3 id=\"ejercicio-2-actualización-y-desactualización-de-nuestra-aplicación\"><a class=\"markdownIt-Anchor\" href=\"#ejercicio-2-actualización-y-desactualización-de-nuestra-aplicación\">#</a> Ejercicio 2: Actualización y desactualización de nuestra aplicación</h3>\n<p>Pantallazo donde se vea el acceso desde un navegador web a la version 1 de la aplicación aplicación.</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: deployment-iesgn-v1\n  labels:\n    app: contendor-iesgn\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: contenedor-iesgn\n  template:\n    metadata:\n      labels:\n        app: contenedor-iesgn\n    spec:\n      containers:\n      - name: contenedor-iesgn\n        image: iesgn/test_web:version1\n        ports:\n        - containerPort: 80\n</code></pre>\n<pre><code>kubectl annotate deployment/deployment-iesgn-v1 kubernetes.io/change-cause=&quot;Primer despliegue de iesgn&quot;\n</code></pre>\n<p><img src=\"/images/k8s-taller-3-2-1.png\" alt=\"Descripción de la imagen\"></p>\n<pre><code>kubectl port-forward deployment/deployment-iesgn-v1 8081:80\n</code></pre>\n<p>Pantallazo donde se vea el acceso desde un navegador web a la version 2 de la aplicación aplicación.</p>\n<pre><code>kubectl apply -f deployment-iesgn-v1.yaml\n</code></pre>\n<p><img src=\"/images/k8s-taller-3-2-2.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se visualice el historial de actualización del despliegue después de actualizar a la versión 2.</p>\n<p><img src=\"/images/k8s-taller-3-2-3.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se vea el acceso desde un navegador web a la version 3 de la aplicación (¡¡¡No se visualiza bien la<br>\nhoja de estilos!!!).</p>\n<p><img src=\"/images/k8s-taller-3-2-4.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se visualice el historial de actualización después de realizar el rollback del despliegue.</p>\n<p><code>kubectl rollout undo deployment/deployment-iesgn-v1</code></p>\n<p><img src=\"/images/k8s-taller-3-2-5.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se vea el acceso desde un navegador web a la version de la aplicación que queda después de hacer el rollout.</p>\n<p><img src=\"/images/k8s-taller-3-2-6.png\" alt=\"Descripción de la imagen\"></p>\n<h3 id=\"ejercicio-3-despliegue-de-la-aplicación-guestbook\"><a class=\"markdownIt-Anchor\" href=\"#ejercicio-3-despliegue-de-la-aplicación-guestbook\">#</a> Ejercicio 3: Despliegue de la aplicación GuestBook</h3>\n<p>guestbook-deployment.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: guestbook\n  labels:\n    app: guestbook\n    tier: frontend\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: guestbook\n      tier: frontend\n  template:\n    metadata:\n      labels:\n        app: guestbook\n        tier: frontend\n    spec:\n      containers:\n      - name: contenedor-guestbook\n        image: iesgn/guestbook\n        ports:\n          - name: http-server\n            containerPort: 5000\n\n</code></pre>\n<p>redis-deployment.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis\n  labels:\n    app: redis\n    tier: backend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: redis\n      tier: backend\n  template:\n    metadata:\n      labels:\n        app: redis\n        tier: backend\n    spec:\n      containers:\n        - name: contenedor-redis\n          image: redis\n          ports:\n            - name: redis-server\n              containerPort: 6379\n</code></pre>\n<p>Creamos el escenario ejecutando los siguientes comandos:</p>\n<p><code>kubectl apply -f guestbook-deployment.yaml</code></p>\n<p><code>kubectl apply -f redis-deployment.yaml</code></p>\n<p>Tenemos dos deploys, uno con guestbook y otro con redis. Para acceder a la aplicación de guestbook, debemos hacer un port-forward al servicio de guestbook. Para ello, ejecutamos el siguiente comando:</p>\n<p><code>kubectl port-forward deployment/guestbook 8082:5000</code></p>\n<p>Podemos ver que los recursos están creados con el siguiente comando:</p>\n<p><code>kubectl get all</code> ,  <code>kubectl get all -o wide</code>  o bien  <code>kubectl get deploy,rs,pod</code></p>\n<p><img src=\"/images/k8s-taller-3-3-1.png\" alt=\"Descripción de la imagen\"></p>\n<p>Lo que ocurre es que no conecta a la base de datos porque los dos deployments no están relacionados entre sí.</p>\n<p><img src=\"/images/k8s-taller-3-3-2.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"taller-4-trabajando-con-services\"><a class=\"markdownIt-Anchor\" href=\"#taller-4-trabajando-con-services\">#</a> Taller 4: Trabajando con Services</h2>\n<h3 id=\"ejercicio-1-despliegue-y-acceso-de-la-aplicación-guestbook\"><a class=\"markdownIt-Anchor\" href=\"#ejercicio-1-despliegue-y-acceso-de-la-aplicación-guestbook\">#</a> Ejercicio 1: Despliegue y acceso de la aplicación GuestBook</h3>\n<ol>\n<li>Pantallazo donde se vea el acceso desde un navegador web a la aplicación cuando sólo tenemos el servicio para acceder a la aplicación (tiene que aparecer el mensaje de error).</li>\n</ol>\n<p><img src=\"/images/k8s-taller-4-1.png\" alt=\"Descripción de la imagen\"></p>\n<ol start=\"2\">\n<li>Pantallazo donde se vea el acceso desde un navegador web a la aplicación usando la ip del nodo master y el puerto asignado al Service.</li>\n</ol>\n<p><img src=\"/images/k8s-taller-4-2.png\" alt=\"Descripción de la imagen\"></p>\n<ol start=\"3\">\n<li>Pantallazo donde se vea el acceso desde un navegador web a la aplicación usando el nombre que hemos configurado en el recurso Ingress.</li>\n</ol>\n<p>Para crear el recurso ingress debemos tener el siguiente yaml:</p>\n<p>nano ingress.yaml</p>\n<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: nginx\nspec:\n  rules:\n  - host: www.antonio.org\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: guestbook\n            port:\n              number: 80\n\n</code></pre>\n<p><img src=\"/images/k8s-taller-4-3.png\" alt=\"Descripción de la imagen\"></p>\n<h3 id=\"ejercicio-2-despliegue-y-acceso-de-la-aplicación-lets-chat\"><a class=\"markdownIt-Anchor\" href=\"#ejercicio-2-despliegue-y-acceso-de-la-aplicación-lets-chat\">#</a> Ejercicio 2: Despliegue y acceso de la Aplicación Lets-Chat</h3>\n<ol>\n<li>Los ficheros yaml que has creado.</li>\n</ol>\n<p>He creado varios yaml, voy a ordenarlos en sentido de conexión desde el frontend al backend:</p>\n<p>ingress.yaml</p>\n<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: nginx\nspec:\n  rules:\n  - host: www.chat-antonio.org\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: letschat\n            port:\n              number: 8080\n\n</code></pre>\n<p>letschat-service.yaml</p>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: letschat\n  labels:\n    app: letschat\n    tier: frontend\nspec:\n  type: NodePort\n  ports: \n  - port: 8080\n    targetPort: letschat-server\n  selector:\n    app: letschat\n    tier: frontend\n</code></pre>\n<p>letschat-deployment.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: letschat\n  labels:\n    app: letschat\n    tier: frontend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: letschat\n      tier: frontend\n  template:\n    metadata:\n      labels:\n        app: letschat\n        tier: frontend\n    spec:\n      containers:\n      - name: contenedor-letschat\n        image: sdelements/lets-chat\n        ports:\n          - name: letschat-server\n            containerPort: 8080\n</code></pre>\n<p>mongo-srv.yaml</p>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: mongo\n  labels:\n    app: mongo\n    tier: backend\nspec:\n  type: ClusterIP\n  ports: \n  - port: 27017\n    targetPort: mongo-server\n  selector:\n    app: mongo\n    tier: backend\n</code></pre>\n<p>mongo-deployment.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mongo\n  labels:\n    app: mongo\n    tier: backend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mongo\n      tier: backend\n  template:\n    metadata:\n      labels:\n        app: mongo\n        tier: backend\n    spec:\n      containers:\n        - name: contenedor-mongo\n          image: mongo:4\n          ports:\n            - name: mongo-server\n              containerPort: 27017\n</code></pre>\n<p>A través de este esquema podemos ver como los diferentes deploys y pods se conectan entre sí para ofrecer el servicio:</p>\n<p><img src=\"/images/letschat-minikube-esquema.png\" alt=\"Descripción de la imagen\"></p>\n<ol start=\"2\">\n<li>Un pantallazo donde se vea el acceso desde un navegador web a la aplicación usando la ip del nodo master y el puerto asignado al Service.</li>\n</ol>\n<p>Si usamos el comando  <code>minikube service letschat</code>  nos abre el navegador con la aplicación.</p>\n<p><img src=\"/images/k8s-taller-4-4.png\" alt=\"Descripción de la imagen\"></p>\n<ol start=\"3\">\n<li>Un pantallazo donde se vea el acceso desde un navegador web a la aplicación usando el nombre que hemos configurado en el recurso Ingress.</li>\n</ol>\n<p><img src=\"/images/k8s-taller-4-5.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"taller-5-trabajando-con-configmaps\"><a class=\"markdownIt-Anchor\" href=\"#taller-5-trabajando-con-configmaps\">#</a> Taller 5: Trabajando con ConfigMaps</h2>\n<h3 id=\"ejercicio-1-configurando-nuestra-aplicación-temperaturas\"><a class=\"markdownIt-Anchor\" href=\"#ejercicio-1-configurando-nuestra-aplicación-temperaturas\">#</a> Ejercicio 1: Configurando nuestra aplicación Temperaturas</h3>\n<p>Con el siguiente comando estaremos creando una variable de entorno en el cual indica el nombre SERVIDOR_TEMPERATURAS y el valor servidor-temperaturas:5000</p>\n<pre><code>kubectl create cm tempcm --from-literal=SERVIDOR_TEMPERATURAS=servidor-temperaturas:5000 -o yaml --dry-run=client &gt; temperaturas_configmap.yaml\n</code></pre>\n<p>UNa vez ejecutado se crea un fichero que contiene en data el nombre y la clave de la variable de entorno:</p>\n<p>temperaturas_configmap.yaml</p>\n<pre><code>apiVersion: v1\ndata:\n  SERVIDOR_TEMPERATURAS: servidor-temperaturas:5000\nkind: ConfigMap\nmetadata:\n  creationTimestamp: null\n  name: tempcm\n\n</code></pre>\n<p>El nombre lo debemos especificar en el deployment, y la key el nombre que va a llevar la variable de entorno, en nuestro caso tempcm y SERVIDOR_TEMPERATURAS respectivamente:</p>\n<p>Entonces en nuestro fichero yaml de nuestro deployment, quedaría de la siguiente manera:</p>\n<p>tempers-deployment.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: temperaturas-frontend\n  labels:\n    app: temperaturas\n    tier: frontend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: temperaturas\n      tier: frontend\n  template:\n    metadata:\n      labels:\n        app: temperaturas\n        tier: frontend\n    spec:\n      containers:\n      - name: contenedor-temperaturas\n        image: iesgn/temperaturas_frontend\n        ports:\n          - name: http-server\n            containerPort: 3000\n        env:\n          - name: TEMP_SERVER\n            valueFrom:\n              configMapKeyRef:\n                name: tempcm\n                key: SERVIDOR_TEMPERATURAS\n</code></pre>\n<p>Ahora vamos a crear el servicio para el frontend por el cual vamos a ver que se puede acceder a la aplicación a través de un puerto aleatorio:</p>\n<p>temperaturas-srv.yaml</p>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: temperaturas\n  labels:\n    app: temperaturas\n    tier: frontend\nspec:\n  type: NodePort\n  ports: \n  - port: 3000\n    targetPort: http-server\n  selector:\n    app: temperaturas\n    tier: frontend\n</code></pre>\n<p>Tomará el puerto 3000 y hará un proxy para que lo veamos a través de un puerto aleatorio, pero a través del port y el targetPort crearemos un ingress para que se pueda acceder a través de un dominio, que será <a href=\"http://www.antonio.org\">www.antonio.org</a></p>\n<p>ingress.yaml</p>\n<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: acceso-frontend\nspec:\n  rules:\n  - host: www.antonio.org\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: temperaturas\n            port:\n              number: 3000\n\n</code></pre>\n<p>Dentro del confimap que hemos mencionado más arriba hace referencia al backend-srv.yaml, que toma el nombre de TEMP_SERVER y coge el valor de la key SERVIDOR_TEMPERATURAS, que es el la clave del valor servidor-temperaturas:5000, que se halla en el tempeaturas-deployment.yaml, tomado del configmap tempcm.</p>\n<p>backend-srv.yaml</p>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: servidor-temperaturas\n  labels:\n    app: temperaturas\n    tier: backend\nspec:\n  type: ClusterIP\n  ports:\n  - port: 5000\n    targetPort: api-server\n  selector:\n    app: temperaturas\n    tier: backend\n\n</code></pre>\n<p>Pantallazo donde se vea la definición del recurso ConfigMap.</p>\n<p><img src=\"/images/k8s-taller-5-1.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se vea la modificación del fichero frontend-deployment.yaml.</p>\n<p><img src=\"/images/k8s-taller-5-2.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se vea la modificación del fichero backend-srv.yaml.</p>\n<p><img src=\"/images/k8s-taller-5-3.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se compruebe que la aplicación está funcionando.</p>\n<p><img src=\"/images/k8s-taller-5-4.png\" alt=\"Descripción de la imagen\"></p>\n<h3 id=\"ejercicio-2-despliegue-y-acceso-de-la-aplicación-nextcloud\"><a class=\"markdownIt-Anchor\" href=\"#ejercicio-2-despliegue-y-acceso-de-la-aplicación-nextcloud\">#</a> Ejercicio 2: Despliegue y acceso de la aplicación Nextcloud</h3>\n<p>Primero vamos a generar las claves para que la base de datos mariadb pueda cambiar los valores por defecto del usuario:</p>\n<p>En el configmap cambiaremos:</p>\n<ul>\n<li>nombre de usuario</li>\n<li>nombre de la base de datos</li>\n<li>nombre del host mariadb</li>\n</ul>\n<p>En el secret que lo utilizaremos para convertir a base64 las contraseñas:</p>\n<ul>\n<li>contraseña de usuario</li>\n</ul>\n<pre><code>kubectl create cm bd-datos --from-literal=bd_user=antonio \\\n                           --from-literal=bd_dbname=nextcloud \\\n                           --from-literal=bd_host=mariadb-service \\\n                           -o yaml --dry-run=client &gt; bd_datos_configmap.yaml\n\n\n\nkubectl create secret generic bd-passwords --from-literal=bd_password=antonio \\\n                                           --from-literal=bd_rootpassword=root1234 \\\n                                           -o yaml --dry-run=client &gt; bd_passwords_secret.yaml\n</code></pre>\n<p>Seguidamente, tanto el deploy de nextcloud como el de mariadb van a tomar cada uno de estos datos para poder crear la base de datos y el usuario, y nextcloud va a tomar el usuario y la contraseña para poder conectarse a la base de datos.</p>\n<p>nextcloud-deployment.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nextcloud-deployment\n  labels:\n    app: nextcloud\n    type: frontend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nextcloud\n      type: frontend\n  template:\n    metadata:\n      labels:\n        app: nextcloud\n        type: frontend\n    spec:\n      containers:\n        - name: contenedor-nextcloud\n          image: nextcloud\n          ports:\n            - containerPort: 80\n              name: http-port\n            - containerPort: 443\n              name: https-port\n          env:\n            - name: MYSQL_USER\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_user\n            - name: MYSQL_DATABASE\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_dbname\n            - name: MYSQL_HOST\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_host\n            - name: MYSQL_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_password\n</code></pre>\n<p>mariadb-deployment.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mariadb-deployment\n  labels:\n    app: nextcloud\n    type: database\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nextcloud\n      type: database\n  template:\n    metadata:\n      labels:\n        app: nextcloud\n        type: database\n    spec:\n      containers:\n        - name: contenedor-mariadb\n          image: mariadb:10.5\n          ports:\n            - containerPort: 3306\n              name: db-port\n          env:\n            - name: MYSQL_USER\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_user\n            - name: MYSQL_DATABASE\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_dbname\n            - name: MYSQL_HOST\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_host\n            - name: MYSQL_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_password\n            - name: MYSQL_ROOT_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_rootpassword\n</code></pre>\n<p>Como podemos ver en el valor env tanto en nextcloud como en mariadb, se toman los valores de los configmaps y los secrets que hemos creado anteriormente, teniendo como ‘- name:’ el valor que la aplicación toma por defecto.</p>\n<p>maradb-srv.yaml</p>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: mariadb-service\n  labels:\n    app: nextcloud\n    type: database\nspec:\n  selector:\n    app: nextcloud\n    type: database\n  ports:\n  - port: 3306\n    targetPort: db-port\n  type: ClusterIP\n</code></pre>\n<p>nextclod-srv.yaml</p>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: nextcloud\n  labels:\n    app: nextcloud\n    type: frontend\nspec:\n  selector:\n    app: nextcloud\n    type: frontend\n  ports:\n  - name: http-sv-port\n    port: 80\n    targetPort: http-port\n  type: NodePort\n</code></pre>\n<p>Pantallazo donde se vea el contenido del fichero de despliegue de NextCloud.</p>\n<p><img src=\"/images/k8s-taller-5-5.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se vean los recursos que se han creado.</p>\n<p><img src=\"/images/k8s-taller-5-6.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se compruebe que la aplicación está funcionando.</p>\n<p><img src=\"/images/k8s-taller-5-7.png\" alt=\"Descripción de la imagen\"></p>\n<h2 id=\"taller-6-almacenamiento-en-kubernetes\"><a class=\"markdownIt-Anchor\" href=\"#taller-6-almacenamiento-en-kubernetes\">#</a> Taller 6: Almacenamiento en Kubernetes</h2>\n<h3 id=\"ejercicio-1-desplegando-un-servidor-web-persistente\"><a class=\"markdownIt-Anchor\" href=\"#ejercicio-1-desplegando-un-servidor-web-persistente\">#</a> Ejercicio 1: Desplegando un servidor web persistente</h3>\n<p>Para empezar debemos pedir el recurso de almacenamiento que vamos a utilizar, en este caso vamos a utilizar un recurso de tipo persistent volume claim, que es un recurso que nos permite pedir un recurso de almacenamiento, en este caso un disco duro, y que nos lo asigne a un nodo.</p>\n<p>cat apache-pvc.yaml</p>\n<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n    name: pvc-webserver\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 2Gi\n\n</code></pre>\n<p>Como podemos ver, pide un recurso de almacenamiento de 2Gi</p>\n<p>cat apache-deployment.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: apache-taller6\n  labels:\n    app: apache\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: apache\n  template:\n    metadata:\n      labels:\n        app: apache\n    spec:\n      volumes:\n        - name: pvc-webserver\n          persistentVolumeClaim:\n            claimName: pvc-webserver\n      containers:\n        - name: contenedor-apache\n          image: php:7.4-apache\n          ports:\n            - name: http-server\n              containerPort: 80\n          volumeMounts:\n            - mountPath: &quot;/var/www/html&quot;\n              name: pvc-webserver\n</code></pre>\n<p>En el apartado spec nombra el volumen y lo monta en VolumeMounts.</p>\n<p>Ahora vamos a crear el servicio nodeport por el cual vamos a entrar en la web:</p>\n<p>cat apache-srv.yaml</p>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: apache\nspec:\n  type: NodePort\n  ports:\n  - name: service-http\n    port: 80\n    targetPort: http-server\n  selector:\n    app: apache\n</code></pre>\n<p>Tras esto vamos a ejecutar un comando que es un info.php por bash y lo va a poner en /var/www/html que es donde está el recurso solicitado montado:</p>\n<pre><code>kubectl exec pod/apache-taller6-5f78fbb47d-7rlzd -- bash -c &quot;echo '&lt;?php phpinfo(); ?&gt;' &gt; /var/www/html/info.php&quot;\n</code></pre>\n<p>Pantallazo con la definición del recurso PersistentVolumenClaim.</p>\n<p><img src=\"/images/k8s-taller-6-1.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se visualice los recursos pv y pvc que se han creado.</p>\n<p><img src=\"/images/k8s-taller-6-2.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se vea el fichero yaml para el despliegue.</p>\n<p><img src=\"/images/k8s-taller-6-3.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se vea el acceso a info.php.</p>\n<p><img src=\"/images/k8s-taller-6-4.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se vea que se ha eliminado y se ha vuelto a crear el despliegue y se sigue sirviendo el fichero info.php.</p>\n<p>Adjunto en una sola imagen la destrucción,creación y comprobación de que sigue funcionando a través de un curl:</p>\n<p><img src=\"/images/k8s-taller-6-5.png\" alt=\"Descripción de la imagen\"></p>\n<h3 id=\"ejercicio-2-haciendo-persistente-la-aplicación-guestbook\"><a class=\"markdownIt-Anchor\" href=\"#ejercicio-2-haciendo-persistente-la-aplicación-guestbook\">#</a> Ejercicio 2: Haciendo persistente la aplicación GuestBook</h3>\n<p>Vamos a modificar el recurso de despliegue de guestbook para que se pueda hacer persistente, a través de hacer una copia d ela base de datos redis en /data:</p>\n<p>redis-deployment.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: redis\n  labels:\n    app: redis\n    tier: backend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: redis\n      tier: backend\n  template:\n    metadata:\n      labels:\n        app: redis\n        tier: backend\n    spec:\n      volumes:\n        - name: volumen-redis\n          persistentVolumeClaim:\n            claimName: pvc-guestbook\n      containers:\n        - name: contenedor-redis\n          image: redis\n          command: [&quot;redis-server&quot;]\n          args: [&quot;--appendonly&quot;, &quot;yes&quot;]\n          ports:\n            - name: redis-server\n              containerPort: 6379\n          volumeMounts:\n            - mountPath: /data\n              name: volumen-redis\n</code></pre>\n<p>Y este sería el guestbook-pvc.yaml</p>\n<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n    name: pvc-guestbook\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 3Gi\n</code></pre>\n<p>Pantallazo con la definición del recurso PersistentVolumenClaim.</p>\n<p>Mostrado arriba.</p>\n<p>Pantallazo donde se visualicen los recursos pv y pvc que se han creado.</p>\n<p><img src=\"/images/k8s-taller-6-6.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se vea el fichero yaml modificado para el despliegue de redis.</p>\n<p>Mostrado arriba.</p>\n<p>Pantallazo donde se vea el acceso a la aplicación con los mensajes escritos.</p>\n<p><img src=\"/images/k8s-taller-6-7.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se vea que se ha eliminado y se ha vuelto a crear el despliegue de redis y que se sigue sirviendo la aplicación con los mensajes.</p>\n<p><img src=\"/images/k8s-taller-6-8.gif\" alt=\"Descripción de la imagen\"></p>\n<h3 id=\"ejercicio-3-haciendo-persistente-la-aplicación-nextcloud\"><a class=\"markdownIt-Anchor\" href=\"#ejercicio-3-haciendo-persistente-la-aplicación-nextcloud\">#</a> Ejercicio 3: Haciendo persistente la aplicación Nextcloud</h3>\n<p>Vamos a utilizar los ficheros que anteriormente creamos en nextcloud, lo que haremos será proporcionar almacenamiento tanto en nextcloud como mariadb, para ello vamos a modificar los ficheros de despliegue en relación a los pvc:</p>\n<p>nextcloud-pvc.yaml</p>\n<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n    name: nextcloud-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 4Gi\n</code></pre>\n<p>nextcloud-deployment.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nextcloud-deployment\n  labels:\n    app: nextcloud\n    type: frontend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nextcloud\n      type: frontend\n  template:\n    metadata:\n      labels:\n        app: nextcloud\n        type: frontend\n    spec:\n      volumes:\n        - name: nextcloud-pvc\n          persistentVolumeClaim:\n            claimName: nextcloud-pvc\n      containers:\n        - name: contenedor-nextcloud\n          image: nextcloud\n          volumeMounts:\n            - mountPath: /var/www/html/\n              name: nextcloud-pvc\n          ports:\n            - containerPort: 80\n              name: http-port\n            - containerPort: 443\n              name: https-port\n          env:\n            - name: MYSQL_USER\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_user\n            - name: MYSQL_DATABASE\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_dbname\n            - name: MYSQL_HOST\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_host\n            - name: MYSQL_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_password\n</code></pre>\n<p>Ahora vamos con mariadb:</p>\n<p>mariadb-pvc.yaml</p>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: mariadb-service\n  labels:\n    app: nextcloud\n    type: database\nspec:\n  selector:\n    app: nextcloud\n    type: database\n  ports:\n  - port: 3306\n    targetPort: db-port\n  type: ClusterIP\n</code></pre>\n<p>cat mariadb-deployment.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mariadb-deployment\n  labels:\n    app: nextcloud\n    type: database\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nextcloud\n      type: database\n  template:\n    metadata:\n      labels:\n        app: nextcloud\n        type: database\n    spec:\n      volumes:\n        - name: mariadb-pvc\n          persistentVolumeClaim:\n            claimName: mariadb-pvc\n      containers:\n        - name: contenedor-mariadb\n          image: mariadb:10.5\n          ports:\n            - containerPort: 3306\n              name: db-port\n          volumeMounts:\n            - mountPath: &quot;/var/lib/mysql&quot;\n              name: mariadb-pvc\n          env:\n            - name: MYSQL_USER\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_user\n            - name: MYSQL_DATABASE\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_dbname\n            - name: MYSQL_HOST\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_host\n            - name: MYSQL_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_password\n            - name: MYSQL_ROOT_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_rootpassword\n\n</code></pre>\n<p>Pantallazo donde se vean los ficheros yaml modificados para los despliegues.</p>\n<p>Se muestra arriba.</p>\n<p>Pantallazo donde se vea el acceso a la aplicación con el fichero que has subido.</p>\n<p><img src=\"/images/k8s-taller-6-8.png\" alt=\"Descripción de la imagen\"></p>\n<p>Pantallazo donde se vea que se han eliminado y se han vuelto a crear los despliegues y que la aplicación sigue sirviendo el fichero que habíamos subido.</p>\n<p><img src=\"/images/k8s-taller-6-9.gif\" alt=\"Descripción de la imagen\"></p>\n"},{"title":"Introducción a Docker","_content":"\n![imagen](/images/docker-logo.png)\n\n# Introducción a Docker\n\n## ¿Qué es Docker?\n\nDocker es una plataforma de código abierto que permite crear, probar y desplegar aplicaciones de forma rápida y sencilla. Docker permite crear contenedores que contienen todo lo necesario para ejecutar una aplicación, incluyendo el sistema operativo, herramientas, librerías y código. Los contenedores son independientes entre sí y se pueden ejecutar en cualquier máquina que tenga Docker instalado.\n\n\n## Usando volumen\n\nCrearemos un volumen que se almacenará en /var/lib/docker/volumes/\n\nInstrucción para crear el volumen docker.\n\n`docker volume create miweb`\n\nInstrucción para crear el contenedor.\n\n`docker run -d --name apache -v miweb:/var/www/html -p 8081:80 php:7.4-apache`\n\nPodemos ver una imagen accediendo a la página web.\n\n![imagen](/images/docker-taller-1-1.png)\n\n\nInstrucción para borrar el contenedor.\n\n`docker rm -f apache`\n\nInstrucción para crear de nuevo el contenedor con el volumen y pantallazo accediendo de nuevo a la página.\n\n`docker run -d --name apache -v miweb:/var/www/html -p 8081:80 php:7.4-apache`\n\n\n\n## Usando bind\n\nUsando bind podemos elegir una ruta de nuestro host para montarla en el contenedor y así preservar los datos que se quieran guardar.\n\nInstrucción para crear el contenedor.\n\n`docker run -d --name apache -v /home/antonio/directorio:/var/www/html -p 8080:80 php:7.4-apache`\nPantallazo accediendo a la página web.\n\n![imagen](/images/docker-taller1-2.png)\n\nPantallazo accediendo a la página web, después de cambiar el fichero index.html en tu host.\n\n\n![imagen](/images/docker-taller1-3.png)\n\nRedes\n\nInstrucción para crear la red\n\n`docker network create rednextcloud`\n\nInstrucción para crear el contenedor de base de datos.\n```\ndocker run -d --name servidor_mysql \\\n                --network rednextcloud \\\n                -v /home/antonio/nextcloud-mariadb:/var/lib/mysql \\\n                -e MYSQL_DATABASE=nextcloud \\\n                -e MYSQL_USER=nextcloud \\\n                -e MYSQL_PASSWORD=antonio \\\n                -e MYSQL_ROOT_PASSWORD=hola \\\n                mariadb\n```\nInstrucción para crear el contenedor de nextcloud.\n\n```\ndocker run -d --name nexcloud \\\n                --network rednextcloud \\\n                -v /home/antonio/nextcloud:/var/www/html \\\n                -e MYSQL_DATABASE=nextcloud \\\n                -e MYSQL_USER=nextcloud \\\n                -e MYSQL_PASSWORD=antonio \\\n                -e MYSQL_HOST=servidor_mysql \\\n                -p 8080:80 \\\n                nextcloud\n```\n\nPantallazos accediendo a nextcloud para comprobar que funciona de manera correcta.\n\n![imagen](/images/docker-taller1-4.png)\n\n\n## Escenarios multicontenedor en Docker (Docker compose)\n\nInstalamos docker compose con el siguiente comando:\n\n`sudo apt install docker-compose`\n\nCreamos el fichero docker-compose.yml\n\n```\nversion: '3.1'\nservices:\n  nc:\n    container_name: servidor_nc\n    image: nextcloud\n    restart: always\n    environment:\n      MYSQL_DATABASE: bd_nc\n      MYSQL_USER: user_nc\n      MYSQL_PASSWORD: asdasd\n      MYSQL_HOST: servidor_mysql\n    ports:\n      - 8085:80\n    volumes:\n      - nextcloud:/var/www/html\n    depends_on:\n      - db\n  db:\n    container_name: servidor_mysql\n    image: mariadb:10.5\n    restart: always\n    environment:\n      MYSQL_DATABASE: bd_nc\n      MYSQL_USER: user_nc\n      MYSQL_PASSWORD: asdasd\n      MYSQL_ROOT_PASSWORD: asdasd\n    volumes:\n      - /opt/mysql_wp:/var/lib/mysql\n\nnetworks:\n  mi_red:\n    driver: bridge\n    driver_opts:\n      com.docker.network.driver.mtu: 1420\n\nvolumes:\n    nextcloud:\n```\n\n\nLo levantamos con `docker-compose up -d` estando dentro del directorio en el que se halle el docker-compose.yml\n\n\nComo podemos apreciar ya está corriendo el contenedor de nextcloud y el de la base de datos:\n\n![imagen](/images/docker-taller2-1.png)\n\n\n\nAhora con docker `docker volume ls` podemos apreciar los volúmenes docker que han sido creados (No los creados por bind):\n\n![imagen](/images/docker-taller2-2.png)\n\n\nTambién podemos ver la red creada en el docker compose con el comando `docker network ls`\n\n![imagen](/images/docker-taller2-3.png)\n\n\nPara borrar un docker-compose podemos usar el comando `docker-compose down -v`, también borrará el volumen creado si no es por bind mount.\n\n![imagen](/images/docker-taller2-4.png)\n\n\n## Creación de una imagen a partir de un Dockerfile\n\n\nPantallazo donde se vea el contenido del fichero Dockerfile.\n\n![imagen](/images/docker-taller3-1.png)\n\nPantallazo donde se vea el comando que crea la nueva imagen.\n\n`docker build -t evanticks/mi_servidor_web:v1 .`\n\n![imagen](/images/docker-taller3-2.png)\n\nPantallazo donde se vea el acceso a la página web primera versión.\n\n![imagen](/images/docker-taller3-3.png)\n\nPantallazo donde se vean las dos imágenes subidas a tu cuenta de Docker Hub.\n\n![imagen](/images/docker-taller3-4.png)\n\nPantallazo donde se vea el acceso a la página web segunda versión.\n\n`docker run -d -p 8086:80 --name entrebytes evanticks/mi_servidor_web:v2`\n\n![imagen](/images/docker-taller3-5.png)\n\n\n## Comandos de Docker compose\n\nOtros comandos de Docker compose:\n\n`docker-compose up`: Crear los contenedores (servicios) que están descritos en el docker-compose.yml.\n`docker-compose up -d`: Crear en modo detach los contenedores (servicios) que están descritos en el docker-compose.yml. Eso significa que no muestran mensajes de log en el terminal y que se nos vuelve a mostrar un prompt.\n`docker-compose stop`: Detiene los contenedores que previamente se han lanzado con docker-compose up.\n`docker-compose rm`: Borra los contenedores parados del escenario. Con las opción -f elimina también los contenedores en ejecución.\n`docker-compose run`: Inicia los contenedores descritos en el docker-compose.yml que estén parados.\n`docker-compose pause`: Pausa los contenedores que previamente se han lanzado con docker-compose up.\n`docker-compose unpause`: Reanuda los contenedores que previamente se han pausado.\n`docker-compose restart`: Reinicia los contenedores. Orden ideal para reiniciar servicios con nuevas configuraciones.\n`docker-compose down`: Para los contenedores, los borra y también borra las redes que se han creado con docker-compose up (en caso de haberse creado).\n`docker-compose down -v`: Para los contenedores y borra contenedores, redes y volúmenes.\ndocker-compose logs: Muestra los logs de todos los servicios del escenario. Con el parámetro -fpodremos ir viendo los logs en \"vivo\".\n`docker-compose logs servicio1:` Muestra los logs del servicio llamado servicio1 que estaba descrito en el docker-compose.yml.\n`docker-compose exec servicio1` /bin/bash: Ejecuta una orden, en este caso /bin/bash en un contenedor llamado servicio1 que estaba descrito en el docker-compose.yml\n`docker-compose build`: Ejecuta, si está indicado, el proceso de construcción de una imagen que va a ser usado en el docker-compose.yml a partir de los ficheros Dockerfile que se indican.\n`docker-compose top`: Muestra los procesos que están ejecutándose en cada uno de los contenedores de los servicios.\n\n\n\n\n","source":"_posts/docker-introduccion.md","raw":"---\ntitle: \"Introducción a Docker\"\ncategories: Contenedores\n---\n\n![imagen](/images/docker-logo.png)\n\n# Introducción a Docker\n\n## ¿Qué es Docker?\n\nDocker es una plataforma de código abierto que permite crear, probar y desplegar aplicaciones de forma rápida y sencilla. Docker permite crear contenedores que contienen todo lo necesario para ejecutar una aplicación, incluyendo el sistema operativo, herramientas, librerías y código. Los contenedores son independientes entre sí y se pueden ejecutar en cualquier máquina que tenga Docker instalado.\n\n\n## Usando volumen\n\nCrearemos un volumen que se almacenará en /var/lib/docker/volumes/\n\nInstrucción para crear el volumen docker.\n\n`docker volume create miweb`\n\nInstrucción para crear el contenedor.\n\n`docker run -d --name apache -v miweb:/var/www/html -p 8081:80 php:7.4-apache`\n\nPodemos ver una imagen accediendo a la página web.\n\n![imagen](/images/docker-taller-1-1.png)\n\n\nInstrucción para borrar el contenedor.\n\n`docker rm -f apache`\n\nInstrucción para crear de nuevo el contenedor con el volumen y pantallazo accediendo de nuevo a la página.\n\n`docker run -d --name apache -v miweb:/var/www/html -p 8081:80 php:7.4-apache`\n\n\n\n## Usando bind\n\nUsando bind podemos elegir una ruta de nuestro host para montarla en el contenedor y así preservar los datos que se quieran guardar.\n\nInstrucción para crear el contenedor.\n\n`docker run -d --name apache -v /home/antonio/directorio:/var/www/html -p 8080:80 php:7.4-apache`\nPantallazo accediendo a la página web.\n\n![imagen](/images/docker-taller1-2.png)\n\nPantallazo accediendo a la página web, después de cambiar el fichero index.html en tu host.\n\n\n![imagen](/images/docker-taller1-3.png)\n\nRedes\n\nInstrucción para crear la red\n\n`docker network create rednextcloud`\n\nInstrucción para crear el contenedor de base de datos.\n```\ndocker run -d --name servidor_mysql \\\n                --network rednextcloud \\\n                -v /home/antonio/nextcloud-mariadb:/var/lib/mysql \\\n                -e MYSQL_DATABASE=nextcloud \\\n                -e MYSQL_USER=nextcloud \\\n                -e MYSQL_PASSWORD=antonio \\\n                -e MYSQL_ROOT_PASSWORD=hola \\\n                mariadb\n```\nInstrucción para crear el contenedor de nextcloud.\n\n```\ndocker run -d --name nexcloud \\\n                --network rednextcloud \\\n                -v /home/antonio/nextcloud:/var/www/html \\\n                -e MYSQL_DATABASE=nextcloud \\\n                -e MYSQL_USER=nextcloud \\\n                -e MYSQL_PASSWORD=antonio \\\n                -e MYSQL_HOST=servidor_mysql \\\n                -p 8080:80 \\\n                nextcloud\n```\n\nPantallazos accediendo a nextcloud para comprobar que funciona de manera correcta.\n\n![imagen](/images/docker-taller1-4.png)\n\n\n## Escenarios multicontenedor en Docker (Docker compose)\n\nInstalamos docker compose con el siguiente comando:\n\n`sudo apt install docker-compose`\n\nCreamos el fichero docker-compose.yml\n\n```\nversion: '3.1'\nservices:\n  nc:\n    container_name: servidor_nc\n    image: nextcloud\n    restart: always\n    environment:\n      MYSQL_DATABASE: bd_nc\n      MYSQL_USER: user_nc\n      MYSQL_PASSWORD: asdasd\n      MYSQL_HOST: servidor_mysql\n    ports:\n      - 8085:80\n    volumes:\n      - nextcloud:/var/www/html\n    depends_on:\n      - db\n  db:\n    container_name: servidor_mysql\n    image: mariadb:10.5\n    restart: always\n    environment:\n      MYSQL_DATABASE: bd_nc\n      MYSQL_USER: user_nc\n      MYSQL_PASSWORD: asdasd\n      MYSQL_ROOT_PASSWORD: asdasd\n    volumes:\n      - /opt/mysql_wp:/var/lib/mysql\n\nnetworks:\n  mi_red:\n    driver: bridge\n    driver_opts:\n      com.docker.network.driver.mtu: 1420\n\nvolumes:\n    nextcloud:\n```\n\n\nLo levantamos con `docker-compose up -d` estando dentro del directorio en el que se halle el docker-compose.yml\n\n\nComo podemos apreciar ya está corriendo el contenedor de nextcloud y el de la base de datos:\n\n![imagen](/images/docker-taller2-1.png)\n\n\n\nAhora con docker `docker volume ls` podemos apreciar los volúmenes docker que han sido creados (No los creados por bind):\n\n![imagen](/images/docker-taller2-2.png)\n\n\nTambién podemos ver la red creada en el docker compose con el comando `docker network ls`\n\n![imagen](/images/docker-taller2-3.png)\n\n\nPara borrar un docker-compose podemos usar el comando `docker-compose down -v`, también borrará el volumen creado si no es por bind mount.\n\n![imagen](/images/docker-taller2-4.png)\n\n\n## Creación de una imagen a partir de un Dockerfile\n\n\nPantallazo donde se vea el contenido del fichero Dockerfile.\n\n![imagen](/images/docker-taller3-1.png)\n\nPantallazo donde se vea el comando que crea la nueva imagen.\n\n`docker build -t evanticks/mi_servidor_web:v1 .`\n\n![imagen](/images/docker-taller3-2.png)\n\nPantallazo donde se vea el acceso a la página web primera versión.\n\n![imagen](/images/docker-taller3-3.png)\n\nPantallazo donde se vean las dos imágenes subidas a tu cuenta de Docker Hub.\n\n![imagen](/images/docker-taller3-4.png)\n\nPantallazo donde se vea el acceso a la página web segunda versión.\n\n`docker run -d -p 8086:80 --name entrebytes evanticks/mi_servidor_web:v2`\n\n![imagen](/images/docker-taller3-5.png)\n\n\n## Comandos de Docker compose\n\nOtros comandos de Docker compose:\n\n`docker-compose up`: Crear los contenedores (servicios) que están descritos en el docker-compose.yml.\n`docker-compose up -d`: Crear en modo detach los contenedores (servicios) que están descritos en el docker-compose.yml. Eso significa que no muestran mensajes de log en el terminal y que se nos vuelve a mostrar un prompt.\n`docker-compose stop`: Detiene los contenedores que previamente se han lanzado con docker-compose up.\n`docker-compose rm`: Borra los contenedores parados del escenario. Con las opción -f elimina también los contenedores en ejecución.\n`docker-compose run`: Inicia los contenedores descritos en el docker-compose.yml que estén parados.\n`docker-compose pause`: Pausa los contenedores que previamente se han lanzado con docker-compose up.\n`docker-compose unpause`: Reanuda los contenedores que previamente se han pausado.\n`docker-compose restart`: Reinicia los contenedores. Orden ideal para reiniciar servicios con nuevas configuraciones.\n`docker-compose down`: Para los contenedores, los borra y también borra las redes que se han creado con docker-compose up (en caso de haberse creado).\n`docker-compose down -v`: Para los contenedores y borra contenedores, redes y volúmenes.\ndocker-compose logs: Muestra los logs de todos los servicios del escenario. Con el parámetro -fpodremos ir viendo los logs en \"vivo\".\n`docker-compose logs servicio1:` Muestra los logs del servicio llamado servicio1 que estaba descrito en el docker-compose.yml.\n`docker-compose exec servicio1` /bin/bash: Ejecuta una orden, en este caso /bin/bash en un contenedor llamado servicio1 que estaba descrito en el docker-compose.yml\n`docker-compose build`: Ejecuta, si está indicado, el proceso de construcción de una imagen que va a ser usado en el docker-compose.yml a partir de los ficheros Dockerfile que se indican.\n`docker-compose top`: Muestra los procesos que están ejecutándose en cada uno de los contenedores de los servicios.\n\n\n\n\n","slug":"docker-introduccion","published":1,"date":"2023-02-02T11:16:21.203Z","updated":"2023-02-10T07:30:22.704Z","_id":"cldn18mbc00004qi5fptd4r6q","comments":1,"layout":"post","photos":[],"link":"","content":"<p><img src=\"/images/docker-logo.png\" alt=\"imagen\"></p>\n<h1 id=\"introducción-a-docker\"><a class=\"markdownIt-Anchor\" href=\"#introducción-a-docker\">#</a> Introducción a Docker</h1>\n<h2 id=\"qué-es-docker\"><a class=\"markdownIt-Anchor\" href=\"#qué-es-docker\">#</a> ¿Qué es Docker?</h2>\n<p>Docker es una plataforma de código abierto que permite crear, probar y desplegar aplicaciones de forma rápida y sencilla. Docker permite crear contenedores que contienen todo lo necesario para ejecutar una aplicación, incluyendo el sistema operativo, herramientas, librerías y código. Los contenedores son independientes entre sí y se pueden ejecutar en cualquier máquina que tenga Docker instalado.</p>\n<h2 id=\"usando-volumen\"><a class=\"markdownIt-Anchor\" href=\"#usando-volumen\">#</a> Usando volumen</h2>\n<p>Crearemos un volumen que se almacenará en /var/lib/docker/volumes/</p>\n<p>Instrucción para crear el volumen docker.</p>\n<p><code>docker volume create miweb</code></p>\n<p>Instrucción para crear el contenedor.</p>\n<p><code>docker run -d --name apache -v miweb:/var/www/html -p 8081:80 php:7.4-apache</code></p>\n<p>Podemos ver una imagen accediendo a la página web.</p>\n<p><img src=\"/images/docker-taller-1-1.png\" alt=\"imagen\"></p>\n<p>Instrucción para borrar el contenedor.</p>\n<p><code>docker rm -f apache</code></p>\n<p>Instrucción para crear de nuevo el contenedor con el volumen y pantallazo accediendo de nuevo a la página.</p>\n<p><code>docker run -d --name apache -v miweb:/var/www/html -p 8081:80 php:7.4-apache</code></p>\n<h2 id=\"usando-bind\"><a class=\"markdownIt-Anchor\" href=\"#usando-bind\">#</a> Usando bind</h2>\n<p>Usando bind podemos elegir una ruta de nuestro host para montarla en el contenedor y así preservar los datos que se quieran guardar.</p>\n<p>Instrucción para crear el contenedor.</p>\n<p><code>docker run -d --name apache -v /home/antonio/directorio:/var/www/html -p 8080:80 php:7.4-apache</code> <br>\nPantallazo accediendo a la página web.</p>\n<p><img src=\"/images/docker-taller1-2.png\" alt=\"imagen\"></p>\n<p>Pantallazo accediendo a la página web, después de cambiar el fichero index.html en tu host.</p>\n<p><img src=\"/images/docker-taller1-3.png\" alt=\"imagen\"></p>\n<p>Redes</p>\n<p>Instrucción para crear la red</p>\n<p><code>docker network create rednextcloud</code></p>\n<p>Instrucción para crear el contenedor de base de datos.</p>\n<pre><code>docker run -d --name servidor_mysql \\\n                --network rednextcloud \\\n                -v /home/antonio/nextcloud-mariadb:/var/lib/mysql \\\n                -e MYSQL_DATABASE=nextcloud \\\n                -e MYSQL_USER=nextcloud \\\n                -e MYSQL_PASSWORD=antonio \\\n                -e MYSQL_ROOT_PASSWORD=hola \\\n                mariadb\n</code></pre>\n<p>Instrucción para crear el contenedor de nextcloud.</p>\n<pre><code>docker run -d --name nexcloud \\\n                --network rednextcloud \\\n                -v /home/antonio/nextcloud:/var/www/html \\\n                -e MYSQL_DATABASE=nextcloud \\\n                -e MYSQL_USER=nextcloud \\\n                -e MYSQL_PASSWORD=antonio \\\n                -e MYSQL_HOST=servidor_mysql \\\n                -p 8080:80 \\\n                nextcloud\n</code></pre>\n<p>Pantallazos accediendo a nextcloud para comprobar que funciona de manera correcta.</p>\n<p><img src=\"/images/docker-taller1-4.png\" alt=\"imagen\"></p>\n<h2 id=\"escenarios-multicontenedor-en-docker-docker-compose\"><a class=\"markdownIt-Anchor\" href=\"#escenarios-multicontenedor-en-docker-docker-compose\">#</a> Escenarios multicontenedor en Docker (Docker compose)</h2>\n<p>Instalamos docker compose con el siguiente comando:</p>\n<p><code>sudo apt install docker-compose</code></p>\n<p>Creamos el fichero docker-compose.yml</p>\n<pre><code>version: '3.1'\nservices:\n  nc:\n    container_name: servidor_nc\n    image: nextcloud\n    restart: always\n    environment:\n      MYSQL_DATABASE: bd_nc\n      MYSQL_USER: user_nc\n      MYSQL_PASSWORD: asdasd\n      MYSQL_HOST: servidor_mysql\n    ports:\n      - 8085:80\n    volumes:\n      - nextcloud:/var/www/html\n    depends_on:\n      - db\n  db:\n    container_name: servidor_mysql\n    image: mariadb:10.5\n    restart: always\n    environment:\n      MYSQL_DATABASE: bd_nc\n      MYSQL_USER: user_nc\n      MYSQL_PASSWORD: asdasd\n      MYSQL_ROOT_PASSWORD: asdasd\n    volumes:\n      - /opt/mysql_wp:/var/lib/mysql\n\nnetworks:\n  mi_red:\n    driver: bridge\n    driver_opts:\n      com.docker.network.driver.mtu: 1420\n\nvolumes:\n    nextcloud:\n</code></pre>\n<p>Lo levantamos con  <code>docker-compose up -d</code>  estando dentro del directorio en el que se halle el docker-compose.yml</p>\n<p>Como podemos apreciar ya está corriendo el contenedor de nextcloud y el de la base de datos:</p>\n<p><img src=\"/images/docker-taller2-1.png\" alt=\"imagen\"></p>\n<p>Ahora con docker  <code>docker volume ls</code>  podemos apreciar los volúmenes docker que han sido creados (No los creados por bind):</p>\n<p><img src=\"/images/docker-taller2-2.png\" alt=\"imagen\"></p>\n<p>También podemos ver la red creada en el docker compose con el comando  <code>docker network ls</code></p>\n<p><img src=\"/images/docker-taller2-3.png\" alt=\"imagen\"></p>\n<p>Para borrar un docker-compose podemos usar el comando  <code>docker-compose down -v</code> , también borrará el volumen creado si no es por bind mount.</p>\n<p><img src=\"/images/docker-taller2-4.png\" alt=\"imagen\"></p>\n<h2 id=\"creación-de-una-imagen-a-partir-de-un-dockerfile\"><a class=\"markdownIt-Anchor\" href=\"#creación-de-una-imagen-a-partir-de-un-dockerfile\">#</a> Creación de una imagen a partir de un Dockerfile</h2>\n<p>Pantallazo donde se vea el contenido del fichero Dockerfile.</p>\n<p><img src=\"/images/docker-taller3-1.png\" alt=\"imagen\"></p>\n<p>Pantallazo donde se vea el comando que crea la nueva imagen.</p>\n<p><code>docker build -t evanticks/mi_servidor_web:v1 .</code></p>\n<p><img src=\"/images/docker-taller3-2.png\" alt=\"imagen\"></p>\n<p>Pantallazo donde se vea el acceso a la página web primera versión.</p>\n<p><img src=\"/images/docker-taller3-3.png\" alt=\"imagen\"></p>\n<p>Pantallazo donde se vean las dos imágenes subidas a tu cuenta de Docker Hub.</p>\n<p><img src=\"/images/docker-taller3-4.png\" alt=\"imagen\"></p>\n<p>Pantallazo donde se vea el acceso a la página web segunda versión.</p>\n<p><code>docker run -d -p 8086:80 --name entrebytes evanticks/mi_servidor_web:v2</code></p>\n<p><img src=\"/images/docker-taller3-5.png\" alt=\"imagen\"></p>\n<h2 id=\"comandos-de-docker-compose\"><a class=\"markdownIt-Anchor\" href=\"#comandos-de-docker-compose\">#</a> Comandos de Docker compose</h2>\n<p>Otros comandos de Docker compose:</p>\n<p><code>docker-compose up</code> : Crear los contenedores (servicios) que están descritos en el docker-compose.yml.<br>\n <code>docker-compose up -d</code> : Crear en modo detach los contenedores (servicios) que están descritos en el docker-compose.yml. Eso significa que no muestran mensajes de log en el terminal y que se nos vuelve a mostrar un prompt.<br>\n <code>docker-compose stop</code> : Detiene los contenedores que previamente se han lanzado con docker-compose up.<br>\n <code>docker-compose rm</code> : Borra los contenedores parados del escenario. Con las opción -f elimina también los contenedores en ejecución.<br>\n <code>docker-compose run</code> : Inicia los contenedores descritos en el docker-compose.yml que estén parados.<br>\n <code>docker-compose pause</code> : Pausa los contenedores que previamente se han lanzado con docker-compose up.<br>\n <code>docker-compose unpause</code> : Reanuda los contenedores que previamente se han pausado.<br>\n <code>docker-compose restart</code> : Reinicia los contenedores. Orden ideal para reiniciar servicios con nuevas configuraciones.<br>\n <code>docker-compose down</code> : Para los contenedores, los borra y también borra las redes que se han creado con docker-compose up (en caso de haberse creado).<br>\n <code>docker-compose down -v</code> : Para los contenedores y borra contenedores, redes y volúmenes.<br>\ndocker-compose logs: Muestra los logs de todos los servicios del escenario. Con el parámetro -fpodremos ir viendo los logs en “vivo”.<br>\n <code>docker-compose logs servicio1:</code>  Muestra los logs del servicio llamado servicio1 que estaba descrito en el docker-compose.yml.<br>\n <code>docker-compose exec servicio1</code>  /bin/bash: Ejecuta una orden, en este caso /bin/bash en un contenedor llamado servicio1 que estaba descrito en el docker-compose.yml<br>\n <code>docker-compose build</code> : Ejecuta, si está indicado, el proceso de construcción de una imagen que va a ser usado en el docker-compose.yml a partir de los ficheros Dockerfile que se indican.<br>\n <code>docker-compose top</code> : Muestra los procesos que están ejecutándose en cada uno de los contenedores de los servicios.</p>\n","site":{"data":{}},"length":5099,"excerpt":"","more":"<p><img src=\"/images/docker-logo.png\" alt=\"imagen\"></p>\n<h1 id=\"introducción-a-docker\"><a class=\"markdownIt-Anchor\" href=\"#introducción-a-docker\">#</a> Introducción a Docker</h1>\n<h2 id=\"qué-es-docker\"><a class=\"markdownIt-Anchor\" href=\"#qué-es-docker\">#</a> ¿Qué es Docker?</h2>\n<p>Docker es una plataforma de código abierto que permite crear, probar y desplegar aplicaciones de forma rápida y sencilla. Docker permite crear contenedores que contienen todo lo necesario para ejecutar una aplicación, incluyendo el sistema operativo, herramientas, librerías y código. Los contenedores son independientes entre sí y se pueden ejecutar en cualquier máquina que tenga Docker instalado.</p>\n<h2 id=\"usando-volumen\"><a class=\"markdownIt-Anchor\" href=\"#usando-volumen\">#</a> Usando volumen</h2>\n<p>Crearemos un volumen que se almacenará en /var/lib/docker/volumes/</p>\n<p>Instrucción para crear el volumen docker.</p>\n<p><code>docker volume create miweb</code></p>\n<p>Instrucción para crear el contenedor.</p>\n<p><code>docker run -d --name apache -v miweb:/var/www/html -p 8081:80 php:7.4-apache</code></p>\n<p>Podemos ver una imagen accediendo a la página web.</p>\n<p><img src=\"/images/docker-taller-1-1.png\" alt=\"imagen\"></p>\n<p>Instrucción para borrar el contenedor.</p>\n<p><code>docker rm -f apache</code></p>\n<p>Instrucción para crear de nuevo el contenedor con el volumen y pantallazo accediendo de nuevo a la página.</p>\n<p><code>docker run -d --name apache -v miweb:/var/www/html -p 8081:80 php:7.4-apache</code></p>\n<h2 id=\"usando-bind\"><a class=\"markdownIt-Anchor\" href=\"#usando-bind\">#</a> Usando bind</h2>\n<p>Usando bind podemos elegir una ruta de nuestro host para montarla en el contenedor y así preservar los datos que se quieran guardar.</p>\n<p>Instrucción para crear el contenedor.</p>\n<p><code>docker run -d --name apache -v /home/antonio/directorio:/var/www/html -p 8080:80 php:7.4-apache</code> <br>\nPantallazo accediendo a la página web.</p>\n<p><img src=\"/images/docker-taller1-2.png\" alt=\"imagen\"></p>\n<p>Pantallazo accediendo a la página web, después de cambiar el fichero index.html en tu host.</p>\n<p><img src=\"/images/docker-taller1-3.png\" alt=\"imagen\"></p>\n<p>Redes</p>\n<p>Instrucción para crear la red</p>\n<p><code>docker network create rednextcloud</code></p>\n<p>Instrucción para crear el contenedor de base de datos.</p>\n<pre><code>docker run -d --name servidor_mysql \\\n                --network rednextcloud \\\n                -v /home/antonio/nextcloud-mariadb:/var/lib/mysql \\\n                -e MYSQL_DATABASE=nextcloud \\\n                -e MYSQL_USER=nextcloud \\\n                -e MYSQL_PASSWORD=antonio \\\n                -e MYSQL_ROOT_PASSWORD=hola \\\n                mariadb\n</code></pre>\n<p>Instrucción para crear el contenedor de nextcloud.</p>\n<pre><code>docker run -d --name nexcloud \\\n                --network rednextcloud \\\n                -v /home/antonio/nextcloud:/var/www/html \\\n                -e MYSQL_DATABASE=nextcloud \\\n                -e MYSQL_USER=nextcloud \\\n                -e MYSQL_PASSWORD=antonio \\\n                -e MYSQL_HOST=servidor_mysql \\\n                -p 8080:80 \\\n                nextcloud\n</code></pre>\n<p>Pantallazos accediendo a nextcloud para comprobar que funciona de manera correcta.</p>\n<p><img src=\"/images/docker-taller1-4.png\" alt=\"imagen\"></p>\n<h2 id=\"escenarios-multicontenedor-en-docker-docker-compose\"><a class=\"markdownIt-Anchor\" href=\"#escenarios-multicontenedor-en-docker-docker-compose\">#</a> Escenarios multicontenedor en Docker (Docker compose)</h2>\n<p>Instalamos docker compose con el siguiente comando:</p>\n<p><code>sudo apt install docker-compose</code></p>\n<p>Creamos el fichero docker-compose.yml</p>\n<pre><code>version: '3.1'\nservices:\n  nc:\n    container_name: servidor_nc\n    image: nextcloud\n    restart: always\n    environment:\n      MYSQL_DATABASE: bd_nc\n      MYSQL_USER: user_nc\n      MYSQL_PASSWORD: asdasd\n      MYSQL_HOST: servidor_mysql\n    ports:\n      - 8085:80\n    volumes:\n      - nextcloud:/var/www/html\n    depends_on:\n      - db\n  db:\n    container_name: servidor_mysql\n    image: mariadb:10.5\n    restart: always\n    environment:\n      MYSQL_DATABASE: bd_nc\n      MYSQL_USER: user_nc\n      MYSQL_PASSWORD: asdasd\n      MYSQL_ROOT_PASSWORD: asdasd\n    volumes:\n      - /opt/mysql_wp:/var/lib/mysql\n\nnetworks:\n  mi_red:\n    driver: bridge\n    driver_opts:\n      com.docker.network.driver.mtu: 1420\n\nvolumes:\n    nextcloud:\n</code></pre>\n<p>Lo levantamos con  <code>docker-compose up -d</code>  estando dentro del directorio en el que se halle el docker-compose.yml</p>\n<p>Como podemos apreciar ya está corriendo el contenedor de nextcloud y el de la base de datos:</p>\n<p><img src=\"/images/docker-taller2-1.png\" alt=\"imagen\"></p>\n<p>Ahora con docker  <code>docker volume ls</code>  podemos apreciar los volúmenes docker que han sido creados (No los creados por bind):</p>\n<p><img src=\"/images/docker-taller2-2.png\" alt=\"imagen\"></p>\n<p>También podemos ver la red creada en el docker compose con el comando  <code>docker network ls</code></p>\n<p><img src=\"/images/docker-taller2-3.png\" alt=\"imagen\"></p>\n<p>Para borrar un docker-compose podemos usar el comando  <code>docker-compose down -v</code> , también borrará el volumen creado si no es por bind mount.</p>\n<p><img src=\"/images/docker-taller2-4.png\" alt=\"imagen\"></p>\n<h2 id=\"creación-de-una-imagen-a-partir-de-un-dockerfile\"><a class=\"markdownIt-Anchor\" href=\"#creación-de-una-imagen-a-partir-de-un-dockerfile\">#</a> Creación de una imagen a partir de un Dockerfile</h2>\n<p>Pantallazo donde se vea el contenido del fichero Dockerfile.</p>\n<p><img src=\"/images/docker-taller3-1.png\" alt=\"imagen\"></p>\n<p>Pantallazo donde se vea el comando que crea la nueva imagen.</p>\n<p><code>docker build -t evanticks/mi_servidor_web:v1 .</code></p>\n<p><img src=\"/images/docker-taller3-2.png\" alt=\"imagen\"></p>\n<p>Pantallazo donde se vea el acceso a la página web primera versión.</p>\n<p><img src=\"/images/docker-taller3-3.png\" alt=\"imagen\"></p>\n<p>Pantallazo donde se vean las dos imágenes subidas a tu cuenta de Docker Hub.</p>\n<p><img src=\"/images/docker-taller3-4.png\" alt=\"imagen\"></p>\n<p>Pantallazo donde se vea el acceso a la página web segunda versión.</p>\n<p><code>docker run -d -p 8086:80 --name entrebytes evanticks/mi_servidor_web:v2</code></p>\n<p><img src=\"/images/docker-taller3-5.png\" alt=\"imagen\"></p>\n<h2 id=\"comandos-de-docker-compose\"><a class=\"markdownIt-Anchor\" href=\"#comandos-de-docker-compose\">#</a> Comandos de Docker compose</h2>\n<p>Otros comandos de Docker compose:</p>\n<p><code>docker-compose up</code> : Crear los contenedores (servicios) que están descritos en el docker-compose.yml.<br>\n <code>docker-compose up -d</code> : Crear en modo detach los contenedores (servicios) que están descritos en el docker-compose.yml. Eso significa que no muestran mensajes de log en el terminal y que se nos vuelve a mostrar un prompt.<br>\n <code>docker-compose stop</code> : Detiene los contenedores que previamente se han lanzado con docker-compose up.<br>\n <code>docker-compose rm</code> : Borra los contenedores parados del escenario. Con las opción -f elimina también los contenedores en ejecución.<br>\n <code>docker-compose run</code> : Inicia los contenedores descritos en el docker-compose.yml que estén parados.<br>\n <code>docker-compose pause</code> : Pausa los contenedores que previamente se han lanzado con docker-compose up.<br>\n <code>docker-compose unpause</code> : Reanuda los contenedores que previamente se han pausado.<br>\n <code>docker-compose restart</code> : Reinicia los contenedores. Orden ideal para reiniciar servicios con nuevas configuraciones.<br>\n <code>docker-compose down</code> : Para los contenedores, los borra y también borra las redes que se han creado con docker-compose up (en caso de haberse creado).<br>\n <code>docker-compose down -v</code> : Para los contenedores y borra contenedores, redes y volúmenes.<br>\ndocker-compose logs: Muestra los logs de todos los servicios del escenario. Con el parámetro -fpodremos ir viendo los logs en “vivo”.<br>\n <code>docker-compose logs servicio1:</code>  Muestra los logs del servicio llamado servicio1 que estaba descrito en el docker-compose.yml.<br>\n <code>docker-compose exec servicio1</code>  /bin/bash: Ejecuta una orden, en este caso /bin/bash en un contenedor llamado servicio1 que estaba descrito en el docker-compose.yml<br>\n <code>docker-compose build</code> : Ejecuta, si está indicado, el proceso de construcción de una imagen que va a ser usado en el docker-compose.yml a partir de los ficheros Dockerfile que se indican.<br>\n <code>docker-compose top</code> : Muestra los procesos que están ejecutándose en cada uno de los contenedores de los servicios.</p>\n"},{"title":"DRBD","_content":"\n![imagen](/images/drbd-logo.png)\n\n\n\n# 1. La salida del comando drbdadm status wwwdata.\n\nEn el nodo 1 instalamos:\n\n`apt install drbd-utils`\n\nAhora vamos a crear el recurso en /etc/drbd.d/wwwdata.res\n\n```\nresource wwwdata {\n protocol C;\n meta-disk internal;\n device /dev/drbd1;\n syncer {\n  verify-alg sha1;\n }\n net {\n  allow-two-primaries;\n }\n on nodo1 {\n    disk /dev/vdb;\n    address 10.1.1.101:7789;\n }\n on nodo2 {\n    disk /dev/vdb;\n    address 10.1.1.102:7789;\n }\n\n```\n\nDebemos crear el mismo recurso de manera simétrica en el nodo2 para que funcionen correctamente.\n\n\n```\ndrbdadm create-md wwwdata\ndrbdadm up wwwdata\ndrbdadm primary --force wwwdata\napt install xfsprogs\nmkfs.xfs /dev/drbd1\nmount /dev/drbd1 /mnt\necho \"<h1>Hola soy Antonio</h1>\" > /mnt/index.html\n```\n\n\n\n`drbdadm status wwwdata`\n\n```\nwwwdata role:Primary\n  disk:UpToDate\n  peer role:Secondary\n    replication:Established peer-disk:UpToDate\n```\n\n# 2. Prueba de funcionamiento del modo Single-primary.\n\n\nAcabo de desmontar /mnt del nodo1 que funcionaba con normalidad, habiendo creado un fichero index.html.\n\nA continuación vamos a hacerlo al reverso, siendo el nodo 2 el nodo primario y el nodo 1 secundrio, para eso ejecutamos en el nodo 1:\n\ndbdadm secundary wwwdata\n\nY en el nodo 2:\n\ndbdadm primary --force wwwdata\n\nacto seguido comprobamos que funciona:\n\n![imagen](/images/drbd-1.png)\n\nY si montamos el recurso podemos leer el fichero:\n\n```\nroot@nodo2:/home/vagrant# mount /dev/drbd1 /mnt\nroot@nodo2:/home/vagrant# cat /mnt/index.html\n<h1>Hola soy Antonio</h1>\n```\n\n\n## OCFS2\n\nOCFS2 es un sistema de ficheros el cual nos permitirá leer y escribir de manera simultánea en un mismo disco. Para ello, se utiliza un sistema de ficheros distribuido, que permite que varios nodos puedan acceder al mismo disco, y que los cambios que se realicen en un nodo se reflejen en el resto de nodos.\n\npara instalar OCFS2 en ambos nodos ejecutamos:\n\n`apt install ocfs2-tools`\n\nAhora vamos a crear el recurso en /etc/drbd.d/dbdata.res en ambos nodos:\n\n```\nresource dbdata {\n  protocol C;\n  meta-disk internal;\n  device /dev/drbd2;\n  syncer {\n    verify-alg sha1;\n  }\n  net {\n    allow-two-primaries;\n  }\n  on nodo1 {\n    disk /dev/vdc;\n    address 10.1.1.101:7790;\n  }\n  on nodo2 {\n    disk /dev/vdc;\n    address 10.1.1.102:7790;\n  }\n}\n```\n\n```\ndrbdadm create-md dbdata \n\ndrbdadm up dbdata\n\ndrbdadm primary --force dbdata\n```\n\nAhora en el nodo1:\n\n`o2cb add-cluster micluster`\n\nseguidamente ingresamos estos parámetros:\n\n```\no2cb add-node micluster nodo1 --ip 10.1.1.101\no2cb add-node micluster nodo2 --ip 10.1.1.102\n```\n\nejecutando `o2cb list-cluster micluster` podemos ver que se ha añadido correctamente.\ncopiamos el contenido de /etc/ocfs2/cluster.conf en el nodo2 en el mismo directorio.\n```\nnode:\n\tnumber = 0\n\tname = nodo1\n\tip_address = 10.1.1.101\n\tip_port = 7777\n\tcluster = micluster\n\nnode:\n\tnumber = 1\n\tname = nodo2\n\tip_address = 10.1.1.102\n\tip_port = 7777\n\tcluster = micluster\n\ncluster:\n\tnode_count = 2\n\theartbeat_mode = local\n\tname = micluster\n```\n\nEn el nodo 2 vamos a /etc/default/o2cb y establecemos los siguientes parámetros:\n\n```\n# O2CB_ENABLED: 'true' means to load the driver on boot.\nO2CB_ENABLED=true\n\n# O2CB_BOOTCLUSTER: If not empty, the name of a cluster to start.\nO2CB_BOOTCLUSTER=micluster  # Cambiamos el valor de este parámetro por el nombre de nuestro cluster.\n```\n\ningresamos en /etc/sysctl.conf  y añadimos la siguiente línea:\n\n```\nkernel.panic = 30\nkernel.panic_on_oops = 1\n```\n\nsysctl -p\n\nejecutamos lo siguiente en ambos nodos:\n\n```\no2cb register-cluster micluster\n```\n\nEn nodo1 ejecutamos:\n\n```\nmkfs.ocfs2 --cluster-stack=o2cb --cluster-name=micluster /dev/drbd2\nmount /dev/drbd2 /mnt\n```\n\nsi ejecutamos el siguiente comando en nodo1:\n\n```\nfor ((;;)) do date >> /mnt/fecha_nodo1.txt;sleep 1; done\n```\n\nPodemos ver en nodo2 con:\n\n```\nwatch tail fecha_nodo1.txt\n```\n\n\n# 3. La salida del comando drbdadm status dbdata.\n\n```\nroot@nodo1:~# drbdadm status dbdata\ndbdata role:Primary\n  disk:UpToDate\n  peer role:Primary\n    replication:Established peer-disk:UpToDate\n```\n\n\n\n# 4. Prueba de funcionamiento del modo Dual-primary.\n\n![imagen](/images/peek.gif)\n\n# 5. Muestra al profesor el funcionamiento del modo Dual-primary.\n\n\nAl reiniciar los dos nodos deberemos de ejecutar el siguiente comando para que sincronice los datos:\n\n`drbdadm up dbdata`\n`drbdadm primary --force dbdata`\n\nSi no es capaz de unirse al grupo de cluster:\n`o2cb register-cluster micluster`","source":"_posts/drbd.md","raw":"---\ntitle: \"DRBD\"\ncategories: almacenamiento\n---\n\n![imagen](/images/drbd-logo.png)\n\n\n\n# 1. La salida del comando drbdadm status wwwdata.\n\nEn el nodo 1 instalamos:\n\n`apt install drbd-utils`\n\nAhora vamos a crear el recurso en /etc/drbd.d/wwwdata.res\n\n```\nresource wwwdata {\n protocol C;\n meta-disk internal;\n device /dev/drbd1;\n syncer {\n  verify-alg sha1;\n }\n net {\n  allow-two-primaries;\n }\n on nodo1 {\n    disk /dev/vdb;\n    address 10.1.1.101:7789;\n }\n on nodo2 {\n    disk /dev/vdb;\n    address 10.1.1.102:7789;\n }\n\n```\n\nDebemos crear el mismo recurso de manera simétrica en el nodo2 para que funcionen correctamente.\n\n\n```\ndrbdadm create-md wwwdata\ndrbdadm up wwwdata\ndrbdadm primary --force wwwdata\napt install xfsprogs\nmkfs.xfs /dev/drbd1\nmount /dev/drbd1 /mnt\necho \"<h1>Hola soy Antonio</h1>\" > /mnt/index.html\n```\n\n\n\n`drbdadm status wwwdata`\n\n```\nwwwdata role:Primary\n  disk:UpToDate\n  peer role:Secondary\n    replication:Established peer-disk:UpToDate\n```\n\n# 2. Prueba de funcionamiento del modo Single-primary.\n\n\nAcabo de desmontar /mnt del nodo1 que funcionaba con normalidad, habiendo creado un fichero index.html.\n\nA continuación vamos a hacerlo al reverso, siendo el nodo 2 el nodo primario y el nodo 1 secundrio, para eso ejecutamos en el nodo 1:\n\ndbdadm secundary wwwdata\n\nY en el nodo 2:\n\ndbdadm primary --force wwwdata\n\nacto seguido comprobamos que funciona:\n\n![imagen](/images/drbd-1.png)\n\nY si montamos el recurso podemos leer el fichero:\n\n```\nroot@nodo2:/home/vagrant# mount /dev/drbd1 /mnt\nroot@nodo2:/home/vagrant# cat /mnt/index.html\n<h1>Hola soy Antonio</h1>\n```\n\n\n## OCFS2\n\nOCFS2 es un sistema de ficheros el cual nos permitirá leer y escribir de manera simultánea en un mismo disco. Para ello, se utiliza un sistema de ficheros distribuido, que permite que varios nodos puedan acceder al mismo disco, y que los cambios que se realicen en un nodo se reflejen en el resto de nodos.\n\npara instalar OCFS2 en ambos nodos ejecutamos:\n\n`apt install ocfs2-tools`\n\nAhora vamos a crear el recurso en /etc/drbd.d/dbdata.res en ambos nodos:\n\n```\nresource dbdata {\n  protocol C;\n  meta-disk internal;\n  device /dev/drbd2;\n  syncer {\n    verify-alg sha1;\n  }\n  net {\n    allow-two-primaries;\n  }\n  on nodo1 {\n    disk /dev/vdc;\n    address 10.1.1.101:7790;\n  }\n  on nodo2 {\n    disk /dev/vdc;\n    address 10.1.1.102:7790;\n  }\n}\n```\n\n```\ndrbdadm create-md dbdata \n\ndrbdadm up dbdata\n\ndrbdadm primary --force dbdata\n```\n\nAhora en el nodo1:\n\n`o2cb add-cluster micluster`\n\nseguidamente ingresamos estos parámetros:\n\n```\no2cb add-node micluster nodo1 --ip 10.1.1.101\no2cb add-node micluster nodo2 --ip 10.1.1.102\n```\n\nejecutando `o2cb list-cluster micluster` podemos ver que se ha añadido correctamente.\ncopiamos el contenido de /etc/ocfs2/cluster.conf en el nodo2 en el mismo directorio.\n```\nnode:\n\tnumber = 0\n\tname = nodo1\n\tip_address = 10.1.1.101\n\tip_port = 7777\n\tcluster = micluster\n\nnode:\n\tnumber = 1\n\tname = nodo2\n\tip_address = 10.1.1.102\n\tip_port = 7777\n\tcluster = micluster\n\ncluster:\n\tnode_count = 2\n\theartbeat_mode = local\n\tname = micluster\n```\n\nEn el nodo 2 vamos a /etc/default/o2cb y establecemos los siguientes parámetros:\n\n```\n# O2CB_ENABLED: 'true' means to load the driver on boot.\nO2CB_ENABLED=true\n\n# O2CB_BOOTCLUSTER: If not empty, the name of a cluster to start.\nO2CB_BOOTCLUSTER=micluster  # Cambiamos el valor de este parámetro por el nombre de nuestro cluster.\n```\n\ningresamos en /etc/sysctl.conf  y añadimos la siguiente línea:\n\n```\nkernel.panic = 30\nkernel.panic_on_oops = 1\n```\n\nsysctl -p\n\nejecutamos lo siguiente en ambos nodos:\n\n```\no2cb register-cluster micluster\n```\n\nEn nodo1 ejecutamos:\n\n```\nmkfs.ocfs2 --cluster-stack=o2cb --cluster-name=micluster /dev/drbd2\nmount /dev/drbd2 /mnt\n```\n\nsi ejecutamos el siguiente comando en nodo1:\n\n```\nfor ((;;)) do date >> /mnt/fecha_nodo1.txt;sleep 1; done\n```\n\nPodemos ver en nodo2 con:\n\n```\nwatch tail fecha_nodo1.txt\n```\n\n\n# 3. La salida del comando drbdadm status dbdata.\n\n```\nroot@nodo1:~# drbdadm status dbdata\ndbdata role:Primary\n  disk:UpToDate\n  peer role:Primary\n    replication:Established peer-disk:UpToDate\n```\n\n\n\n# 4. Prueba de funcionamiento del modo Dual-primary.\n\n![imagen](/images/peek.gif)\n\n# 5. Muestra al profesor el funcionamiento del modo Dual-primary.\n\n\nAl reiniciar los dos nodos deberemos de ejecutar el siguiente comando para que sincronice los datos:\n\n`drbdadm up dbdata`\n`drbdadm primary --force dbdata`\n\nSi no es capaz de unirse al grupo de cluster:\n`o2cb register-cluster micluster`","slug":"drbd","published":1,"date":"2023-02-05T17:17:37.596Z","updated":"2023-02-06T08:21:36.840Z","_id":"cldrq0zqd0000v4i5720cdi7e","comments":1,"layout":"post","photos":[],"link":"","content":"<p><img src=\"/images/drbd-logo.png\" alt=\"imagen\"></p>\n<h1 id=\"1-La-salida-del-comando-drbdadm-status-wwwdata\"><a href=\"#1-La-salida-del-comando-drbdadm-status-wwwdata\" class=\"headerlink\" title=\"1. La salida del comando drbdadm status wwwdata.\"></a>1. La salida del comando drbdadm status wwwdata.</h1><p>En el nodo 1 instalamos:</p>\n<p><code>apt install drbd-utils</code></p>\n<p>Ahora vamos a crear el recurso en &#x2F;etc&#x2F;drbd.d&#x2F;wwwdata.res</p>\n<pre><code>resource wwwdata &#123;\n protocol C;\n meta-disk internal;\n device /dev/drbd1;\n syncer &#123;\n  verify-alg sha1;\n &#125;\n net &#123;\n  allow-two-primaries;\n &#125;\n on nodo1 &#123;\n    disk /dev/vdb;\n    address 10.1.1.101:7789;\n &#125;\n on nodo2 &#123;\n    disk /dev/vdb;\n    address 10.1.1.102:7789;\n &#125;\n</code></pre>\n<p>Debemos crear el mismo recurso de manera simétrica en el nodo2 para que funcionen correctamente.</p>\n<pre><code>drbdadm create-md wwwdata\ndrbdadm up wwwdata\ndrbdadm primary --force wwwdata\napt install xfsprogs\nmkfs.xfs /dev/drbd1\nmount /dev/drbd1 /mnt\necho &quot;&lt;h1&gt;Hola soy Antonio&lt;/h1&gt;&quot; &gt; /mnt/index.html\n</code></pre>\n<p><code>drbdadm status wwwdata</code></p>\n<pre><code>wwwdata role:Primary\n  disk:UpToDate\n  peer role:Secondary\n    replication:Established peer-disk:UpToDate\n</code></pre>\n<h1 id=\"2-Prueba-de-funcionamiento-del-modo-Single-primary\"><a href=\"#2-Prueba-de-funcionamiento-del-modo-Single-primary\" class=\"headerlink\" title=\"2. Prueba de funcionamiento del modo Single-primary.\"></a>2. Prueba de funcionamiento del modo Single-primary.</h1><p>Acabo de desmontar &#x2F;mnt del nodo1 que funcionaba con normalidad, habiendo creado un fichero index.html.</p>\n<p>A continuación vamos a hacerlo al reverso, siendo el nodo 2 el nodo primario y el nodo 1 secundrio, para eso ejecutamos en el nodo 1:</p>\n<p>dbdadm secundary wwwdata</p>\n<p>Y en el nodo 2:</p>\n<p>dbdadm primary –force wwwdata</p>\n<p>acto seguido comprobamos que funciona:</p>\n<p><img src=\"/images/drbd-1.png\" alt=\"imagen\"></p>\n<p>Y si montamos el recurso podemos leer el fichero:</p>\n<pre><code>root@nodo2:/home/vagrant# mount /dev/drbd1 /mnt\nroot@nodo2:/home/vagrant# cat /mnt/index.html\n&lt;h1&gt;Hola soy Antonio&lt;/h1&gt;\n</code></pre>\n<h2 id=\"OCFS2\"><a href=\"#OCFS2\" class=\"headerlink\" title=\"OCFS2\"></a>OCFS2</h2><p>OCFS2 es un sistema de ficheros el cual nos permitirá leer y escribir de manera simultánea en un mismo disco. Para ello, se utiliza un sistema de ficheros distribuido, que permite que varios nodos puedan acceder al mismo disco, y que los cambios que se realicen en un nodo se reflejen en el resto de nodos.</p>\n<p>para instalar OCFS2 en ambos nodos ejecutamos:</p>\n<p><code>apt install ocfs2-tools</code></p>\n<p>Ahora vamos a crear el recurso en &#x2F;etc&#x2F;drbd.d&#x2F;dbdata.res en ambos nodos:</p>\n<pre><code>resource dbdata &#123;\n  protocol C;\n  meta-disk internal;\n  device /dev/drbd2;\n  syncer &#123;\n    verify-alg sha1;\n  &#125;\n  net &#123;\n    allow-two-primaries;\n  &#125;\n  on nodo1 &#123;\n    disk /dev/vdc;\n    address 10.1.1.101:7790;\n  &#125;\n  on nodo2 &#123;\n    disk /dev/vdc;\n    address 10.1.1.102:7790;\n  &#125;\n&#125;\n</code></pre>\n<pre><code>drbdadm create-md dbdata \n\ndrbdadm up dbdata\n\ndrbdadm primary --force dbdata\n</code></pre>\n<p>Ahora en el nodo1:</p>\n<p><code>o2cb add-cluster micluster</code></p>\n<p>seguidamente ingresamos estos parámetros:</p>\n<pre><code>o2cb add-node micluster nodo1 --ip 10.1.1.101\no2cb add-node micluster nodo2 --ip 10.1.1.102\n</code></pre>\n<p>ejecutando <code>o2cb list-cluster micluster</code> podemos ver que se ha añadido correctamente.<br>copiamos el contenido de &#x2F;etc&#x2F;ocfs2&#x2F;cluster.conf en el nodo2 en el mismo directorio.</p>\n<pre><code>node:\n    number = 0\n    name = nodo1\n    ip_address = 10.1.1.101\n    ip_port = 7777\n    cluster = micluster\n\nnode:\n    number = 1\n    name = nodo2\n    ip_address = 10.1.1.102\n    ip_port = 7777\n    cluster = micluster\n\ncluster:\n    node_count = 2\n    heartbeat_mode = local\n    name = micluster\n</code></pre>\n<p>En el nodo 2 vamos a &#x2F;etc&#x2F;default&#x2F;o2cb y establecemos los siguientes parámetros:</p>\n<pre><code># O2CB_ENABLED: &#39;true&#39; means to load the driver on boot.\nO2CB_ENABLED=true\n\n# O2CB_BOOTCLUSTER: If not empty, the name of a cluster to start.\nO2CB_BOOTCLUSTER=micluster  # Cambiamos el valor de este parámetro por el nombre de nuestro cluster.\n</code></pre>\n<p>ingresamos en &#x2F;etc&#x2F;sysctl.conf  y añadimos la siguiente línea:</p>\n<pre><code>kernel.panic = 30\nkernel.panic_on_oops = 1\n</code></pre>\n<p>sysctl -p</p>\n<p>ejecutamos lo siguiente en ambos nodos:</p>\n<pre><code>o2cb register-cluster micluster\n</code></pre>\n<p>En nodo1 ejecutamos:</p>\n<pre><code>mkfs.ocfs2 --cluster-stack=o2cb --cluster-name=micluster /dev/drbd2\nmount /dev/drbd2 /mnt\n</code></pre>\n<p>si ejecutamos el siguiente comando en nodo1:</p>\n<pre><code>for ((;;)) do date &gt;&gt; /mnt/fecha_nodo1.txt;sleep 1; done\n</code></pre>\n<p>Podemos ver en nodo2 con:</p>\n<pre><code>watch tail fecha_nodo1.txt\n</code></pre>\n<h1 id=\"3-La-salida-del-comando-drbdadm-status-dbdata\"><a href=\"#3-La-salida-del-comando-drbdadm-status-dbdata\" class=\"headerlink\" title=\"3. La salida del comando drbdadm status dbdata.\"></a>3. La salida del comando drbdadm status dbdata.</h1><pre><code>root@nodo1:~# drbdadm status dbdata\ndbdata role:Primary\n  disk:UpToDate\n  peer role:Primary\n    replication:Established peer-disk:UpToDate\n</code></pre>\n<h1 id=\"4-Prueba-de-funcionamiento-del-modo-Dual-primary\"><a href=\"#4-Prueba-de-funcionamiento-del-modo-Dual-primary\" class=\"headerlink\" title=\"4. Prueba de funcionamiento del modo Dual-primary.\"></a>4. Prueba de funcionamiento del modo Dual-primary.</h1><p><img src=\"/images/peek.gif\" alt=\"imagen\"></p>\n<h1 id=\"5-Muestra-al-profesor-el-funcionamiento-del-modo-Dual-primary\"><a href=\"#5-Muestra-al-profesor-el-funcionamiento-del-modo-Dual-primary\" class=\"headerlink\" title=\"5. Muestra al profesor el funcionamiento del modo Dual-primary.\"></a>5. Muestra al profesor el funcionamiento del modo Dual-primary.</h1><p>Al reiniciar los dos nodos deberemos de ejecutar el siguiente comando para que sincronice los datos:</p>\n<p><code>drbdadm up dbdata</code><br><code>drbdadm primary --force dbdata</code></p>\n<p>Si no es capaz de unirse al grupo de cluster:<br><code>o2cb register-cluster micluster</code></p>\n","site":{"data":{}},"length":3662,"excerpt":"","more":"<p><img src=\"/images/drbd-logo.png\" alt=\"imagen\"></p>\n<h1 id=\"1-La-salida-del-comando-drbdadm-status-wwwdata\"><a href=\"#1-La-salida-del-comando-drbdadm-status-wwwdata\" class=\"headerlink\" title=\"1. La salida del comando drbdadm status wwwdata.\"></a>1. La salida del comando drbdadm status wwwdata.</h1><p>En el nodo 1 instalamos:</p>\n<p><code>apt install drbd-utils</code></p>\n<p>Ahora vamos a crear el recurso en &#x2F;etc&#x2F;drbd.d&#x2F;wwwdata.res</p>\n<pre><code>resource wwwdata &#123;\n protocol C;\n meta-disk internal;\n device /dev/drbd1;\n syncer &#123;\n  verify-alg sha1;\n &#125;\n net &#123;\n  allow-two-primaries;\n &#125;\n on nodo1 &#123;\n    disk /dev/vdb;\n    address 10.1.1.101:7789;\n &#125;\n on nodo2 &#123;\n    disk /dev/vdb;\n    address 10.1.1.102:7789;\n &#125;\n</code></pre>\n<p>Debemos crear el mismo recurso de manera simétrica en el nodo2 para que funcionen correctamente.</p>\n<pre><code>drbdadm create-md wwwdata\ndrbdadm up wwwdata\ndrbdadm primary --force wwwdata\napt install xfsprogs\nmkfs.xfs /dev/drbd1\nmount /dev/drbd1 /mnt\necho &quot;&lt;h1&gt;Hola soy Antonio&lt;/h1&gt;&quot; &gt; /mnt/index.html\n</code></pre>\n<p><code>drbdadm status wwwdata</code></p>\n<pre><code>wwwdata role:Primary\n  disk:UpToDate\n  peer role:Secondary\n    replication:Established peer-disk:UpToDate\n</code></pre>\n<h1 id=\"2-Prueba-de-funcionamiento-del-modo-Single-primary\"><a href=\"#2-Prueba-de-funcionamiento-del-modo-Single-primary\" class=\"headerlink\" title=\"2. Prueba de funcionamiento del modo Single-primary.\"></a>2. Prueba de funcionamiento del modo Single-primary.</h1><p>Acabo de desmontar &#x2F;mnt del nodo1 que funcionaba con normalidad, habiendo creado un fichero index.html.</p>\n<p>A continuación vamos a hacerlo al reverso, siendo el nodo 2 el nodo primario y el nodo 1 secundrio, para eso ejecutamos en el nodo 1:</p>\n<p>dbdadm secundary wwwdata</p>\n<p>Y en el nodo 2:</p>\n<p>dbdadm primary –force wwwdata</p>\n<p>acto seguido comprobamos que funciona:</p>\n<p><img src=\"/images/drbd-1.png\" alt=\"imagen\"></p>\n<p>Y si montamos el recurso podemos leer el fichero:</p>\n<pre><code>root@nodo2:/home/vagrant# mount /dev/drbd1 /mnt\nroot@nodo2:/home/vagrant# cat /mnt/index.html\n&lt;h1&gt;Hola soy Antonio&lt;/h1&gt;\n</code></pre>\n<h2 id=\"OCFS2\"><a href=\"#OCFS2\" class=\"headerlink\" title=\"OCFS2\"></a>OCFS2</h2><p>OCFS2 es un sistema de ficheros el cual nos permitirá leer y escribir de manera simultánea en un mismo disco. Para ello, se utiliza un sistema de ficheros distribuido, que permite que varios nodos puedan acceder al mismo disco, y que los cambios que se realicen en un nodo se reflejen en el resto de nodos.</p>\n<p>para instalar OCFS2 en ambos nodos ejecutamos:</p>\n<p><code>apt install ocfs2-tools</code></p>\n<p>Ahora vamos a crear el recurso en &#x2F;etc&#x2F;drbd.d&#x2F;dbdata.res en ambos nodos:</p>\n<pre><code>resource dbdata &#123;\n  protocol C;\n  meta-disk internal;\n  device /dev/drbd2;\n  syncer &#123;\n    verify-alg sha1;\n  &#125;\n  net &#123;\n    allow-two-primaries;\n  &#125;\n  on nodo1 &#123;\n    disk /dev/vdc;\n    address 10.1.1.101:7790;\n  &#125;\n  on nodo2 &#123;\n    disk /dev/vdc;\n    address 10.1.1.102:7790;\n  &#125;\n&#125;\n</code></pre>\n<pre><code>drbdadm create-md dbdata \n\ndrbdadm up dbdata\n\ndrbdadm primary --force dbdata\n</code></pre>\n<p>Ahora en el nodo1:</p>\n<p><code>o2cb add-cluster micluster</code></p>\n<p>seguidamente ingresamos estos parámetros:</p>\n<pre><code>o2cb add-node micluster nodo1 --ip 10.1.1.101\no2cb add-node micluster nodo2 --ip 10.1.1.102\n</code></pre>\n<p>ejecutando <code>o2cb list-cluster micluster</code> podemos ver que se ha añadido correctamente.<br>copiamos el contenido de &#x2F;etc&#x2F;ocfs2&#x2F;cluster.conf en el nodo2 en el mismo directorio.</p>\n<pre><code>node:\n    number = 0\n    name = nodo1\n    ip_address = 10.1.1.101\n    ip_port = 7777\n    cluster = micluster\n\nnode:\n    number = 1\n    name = nodo2\n    ip_address = 10.1.1.102\n    ip_port = 7777\n    cluster = micluster\n\ncluster:\n    node_count = 2\n    heartbeat_mode = local\n    name = micluster\n</code></pre>\n<p>En el nodo 2 vamos a &#x2F;etc&#x2F;default&#x2F;o2cb y establecemos los siguientes parámetros:</p>\n<pre><code># O2CB_ENABLED: &#39;true&#39; means to load the driver on boot.\nO2CB_ENABLED=true\n\n# O2CB_BOOTCLUSTER: If not empty, the name of a cluster to start.\nO2CB_BOOTCLUSTER=micluster  # Cambiamos el valor de este parámetro por el nombre de nuestro cluster.\n</code></pre>\n<p>ingresamos en &#x2F;etc&#x2F;sysctl.conf  y añadimos la siguiente línea:</p>\n<pre><code>kernel.panic = 30\nkernel.panic_on_oops = 1\n</code></pre>\n<p>sysctl -p</p>\n<p>ejecutamos lo siguiente en ambos nodos:</p>\n<pre><code>o2cb register-cluster micluster\n</code></pre>\n<p>En nodo1 ejecutamos:</p>\n<pre><code>mkfs.ocfs2 --cluster-stack=o2cb --cluster-name=micluster /dev/drbd2\nmount /dev/drbd2 /mnt\n</code></pre>\n<p>si ejecutamos el siguiente comando en nodo1:</p>\n<pre><code>for ((;;)) do date &gt;&gt; /mnt/fecha_nodo1.txt;sleep 1; done\n</code></pre>\n<p>Podemos ver en nodo2 con:</p>\n<pre><code>watch tail fecha_nodo1.txt\n</code></pre>\n<h1 id=\"3-La-salida-del-comando-drbdadm-status-dbdata\"><a href=\"#3-La-salida-del-comando-drbdadm-status-dbdata\" class=\"headerlink\" title=\"3. La salida del comando drbdadm status dbdata.\"></a>3. La salida del comando drbdadm status dbdata.</h1><pre><code>root@nodo1:~# drbdadm status dbdata\ndbdata role:Primary\n  disk:UpToDate\n  peer role:Primary\n    replication:Established peer-disk:UpToDate\n</code></pre>\n<h1 id=\"4-Prueba-de-funcionamiento-del-modo-Dual-primary\"><a href=\"#4-Prueba-de-funcionamiento-del-modo-Dual-primary\" class=\"headerlink\" title=\"4. Prueba de funcionamiento del modo Dual-primary.\"></a>4. Prueba de funcionamiento del modo Dual-primary.</h1><p><img src=\"/images/peek.gif\" alt=\"imagen\"></p>\n<h1 id=\"5-Muestra-al-profesor-el-funcionamiento-del-modo-Dual-primary\"><a href=\"#5-Muestra-al-profesor-el-funcionamiento-del-modo-Dual-primary\" class=\"headerlink\" title=\"5. Muestra al profesor el funcionamiento del modo Dual-primary.\"></a>5. Muestra al profesor el funcionamiento del modo Dual-primary.</h1><p>Al reiniciar los dos nodos deberemos de ejecutar el siguiente comando para que sincronice los datos:</p>\n<p><code>drbdadm up dbdata</code><br><code>drbdadm primary --force dbdata</code></p>\n<p>Si no es capaz de unirse al grupo de cluster:<br><code>o2cb register-cluster micluster</code></p>\n"},{"_content":"\n![imagen](/images/forense-logo.png)\n\nLa informática forense es el conjunto de técnicas que nos permite obtener la máxima información posible tras un incidente o delito informático.\n\nEn esta práctica, realizarás la fase de toma de evidencias y análisis de las mismas sobre una máquina Linux y otra Windows. Supondremos que pillamos al delincuente in fraganti y las máquinas se encontraban encendidas. Opcionalmente, podéis realizar el análisis de un dispositivo Android.\n\nSobre cada una de las máquinas debes realizar un volcado de memoria y otro de disco duro, tomando las medidas necesarias para certificar posteriormente la cadena de custodia.\n\nDebes tratar de obtener las siguientes informaciones:\n\n# Apartado A) Máquina Windows.\n\nPor comandos:\n\n## 1. Procesos en ejecución.\n\nEn la máquina linux, tras haber instalado volatility, ejecutamos el comando sobre el volcado de memoria de la máquina windows:\n\n`python3 vol.py -f /home/vagrant/memwin7.mem windows.pslist`\n\n![imagen](/images/forense-1.png)\n\n## 2. Servicios en ejecución.\n\n`python3 vol.py -f /home/vagrant/memwin7.mem windows.getservicesids.GetServiceSIDs`\n\n![imagen](/images/forense-2.png)\n\n## 3. Puertos abiertos.\n\n`python3 vol.py -f /home/vagrant/memwin7.mem windows.netscan`\n\n![imagen](/images/forense-3.png)\n\n\n## 4. Conexiones establecidas por la máquina.\n\n\n\n## 5. Sesiones de usuario establecidas remotamente.\n\n`python3 vol.py -f /home/vagrant/memwin7.mem windows.sessions.Sessions`\n\n![imagen](/images/forense-5.png)\n\n## 6. Ficheros transferidos recientemente por NetBios.\n\n\n\n## 7. Contenido de la caché DNS.\n\n\n\n## 8. Variables de entorno.\n\n`python3 vol.py -f /home/vagrant/memwin7.mem envars`\n\n![imagen](/images/forense-8.png)\n\n\nAnalizando el Registro de Windows:\n\n## 9. Dispositivos USB conectados\n\n![imagen](/images/forense-9.png)\n\n## 10. Redes wifi utilizadas recientemente.\n\nPara mostrar las conexiones realizadas recientemente, vamos al registro a la ruta /Network/Connections y veremos la información en formato hexadecimal:\n\n![imagen](/images/forense-10.png)\n\n\n\n## 11. Configuración del firewall de nodo.\n\n![imagen](/images/forense-11.png)\n\n## 12. Programas que se ejecutan en el Inicio.\n\n\n## 13. Asociación de extensiones de ficheros y aplicaciones.\n\n![imagen](/images/forense-13.png)\n\n## 14. Aplicaciones usadas recientemente.\n\nSi nos vamos a el spartado run programs podemos ver los primeros los que se han ejecutado recientemente.\n\n![imagen](/images/forense-14.png)\n\n## 15. Ficheros abiertos recientemente.\n\n![imagen](/images/forense-15.png)\n\n## 16. Software Instalado.\n\nNos vamos a installed programs y podemos ver una lista con los programas instalados.\n\n![imagen](/images/forense-16.png)\n\n## 17. Contraseñas guardadas.\n\n\n![imagen](/images/forense-17-1.png)\n\n\n## 18. Cuentas de Usuario\n\n![imagen](/images/forense-18.png)\n\n## 19. Historial de navegación y descargas. Cookies.\n\n![imagen](/images/forense-19-2.png)\n![imagen](/images/forense-19-3.png)\n![imagen](/images/forense-19-4.png)\n\n\n## 20. Volúmenes cifrados\n\n![imagen](/images/forense-20.png)\n\nSobre la imagen del disco:\n\n## 21. Archivos con extensión cambiada.\n\nPonemos el tipo de archivo en la herramientas de búsqueda por atributos.\n\n![imagen](/images/forense-21.png)\n\n\n## 22. Archivos eliminados.\n\nEn el programa en el apartado de archivos eliminados podemos encontrar el fichero con contraseña que borré de la máquina.\n\n![imagen](/images/forense-22.png)\n\n## 23. Archivos Ocultos.\n\n![imagen](/images/forense-23.png)\n\n\n## 24. Archivos que contienen una cadena determinada.\n\nHe buscado por palabras clave y he encontrado el ficher oculto.\n\n![imagen](/images/forense-24.png)\n\n## 25. Búsqueda de imágenes por ubicación.\n\n![imagen](/images/forense-25.jpg)\n\n\n## 26. Búsqueda de archivos por autor.\n\n\n\n# Apartado B) Máquina Linux.\n\nIntenta realizar las mismas operaciones en una máquina Linux para aquellos apartados que tengan sentido y no se realicen de manera idéntica a Windows.\n\n\n## 1. Procesos en ejecución.\n\nEn la máquina linux, tras haber instalado volatility, ejecutamos el comando sobre el volcado de memoria de la máquina windows:\n\n`python3 vol.py -f /home/vagrant/memwin7.mem windows.pslist`\n\n![imagen](/images/forense-1.png)\n\n## 2. Servicios en ejecución.\n\n`python3 vol.py -f /home/vagrant/memwin7.mem windows.getservicesids.GetServiceSIDs`\n\n![imagen](/images/forense-2.png)\n\n## 3. Puertos abiertos.\n\n`python3 vol.py -f /home/vagrant/memwin7.mem windows.netscan`\n\n![imagen](/images/forense-3.png)\n\n\n## 4. Conexiones establecidas por la máquina.\n\nEn el mismo comando como el anterior podemos ver las conexiones establecidas por la máquina.\n\n## 5. Sesiones de usuario establecidas remotamente.\n\n`python3 vol.py -f /home/vagrant/memwin7.mem windows.sessions.Sessions`\n\n![imagen](/images/forense-5.png)\n\n## 6. Ficheros transferidos recientemente por NetBios.\n\n\n\n## 7. Contenido de la caché DNS.\n\n\n\n## 8. Variables de entorno.\n\n\n![imagen](/images/forense-linux-8.png)\n\n## 9. Dispositivos USB conectados\n\n`lsusb`\n\n![imagen](/images/forense-linux-9.png)\n\n## 10. Redes wifi utilizadas recientemente.\n\ncat /etc/NetworkManager/system-connections/* | egrep id\n\n![imagen](/images/forense-linux-10.png)\n\n## 11. Configuración del firewall de nodo.\n\n`iptables -L`\n\n![imagen](/images/forense-linux-11.png)\n\n\n## 12. Programas que se ejecutan en el Inicio.\n\nsystemctl list-unit-files | egrep \"enabled\"\n\n![imagen](/images/forense-linux-12.png)\n\n## 13. Asociación de extensiones de ficheros y aplicaciones.\n\n![imagen](/images/forense-linux-13.png)\n\n## 14. Aplicaciones usadas recientemente.\n\n\n\n## 15. Ficheros abiertos recientemente.\n\n`ls /* -Artls | tail -10`\n\n![imagen](/images/forense-linux-15.png)\n\n\n## 16. Software Instalado.\n\n`apt list --installed`\n\n![imagen](/images/forense-linux-16.png)\n\n## 17. Contraseñas guardadas.\n\n`cat /etc/shadow`\n\n![imagen](/images/forense-17.png)\n\n## 18. Cuentas de Usuario\nComo vemos que múltiples cuentas que no son de usuarios reales, sino que son de programas que contienen permisos para ejecutar comandos como root, podemos filtrar por el shell que en mi caso será zsh.\n\ncat /etc/passwd | egrep zsh\n\n![imagen](/images/forense-linux-18.png)\n\n\n## 19. Historial de navegación y descargas. Cookies.\n\n![imagen](/images/forense-linux-19-1.png)\n![imagen](/images/forense-linux-19-2.png)\n\n\n## 20. Volúmenes cifrados\n\n![imagen](/images/forense-linux-20.png)\n\nSobre la imagen del disco:\n\n## 21. Archivos con extensión cambiada.\n\nPonemos el tipo de archivo en la herramientas de búsqueda por atributos.\n\n![imagen](/images/forense-linux-21.png)\n\n\n## 22. Archivos eliminados.\n\nEn el programa en el apartado de archivos eliminados podemos encontrar el fichero con contraseña que borré de la máquina.\n\n![imagen](/images/forense-linux-22.png)\n\n## 23. Archivos Ocultos.\n\n![imagen](/images/forense-linux-23.png)\n\n\n## 24. Archivos que contienen una cadena determinada.\n\nHe buscado por palabras clave y he encontrado el ficher oculto.\n\n![imagen](/images/forense-linux-24.png)\n\n## 25. Búsqueda de imágenes por ubicación.\n\n![imagen](/images/forense-linux-25.png)\n\n\n## 26. Búsqueda de archivos por autor.\n\n\n# Apartado C) Android\n\nEn un dispositivo Android, trata de hacer un volcado de memoria y recuperar información de ubicación, llamadas, mensajes, aplicaciones de mensajería, perfiles en redes sociales, etc...\n\nAl hacer el volcado de memoria con Andriller, podemos ver como muestra las cuentas que utiliza el usuario del teléfono:\n\n![imagen](/images/forense-Android-1.png)\n\nSi entramos dentro de la carpeta generada llamada Apps, podemos ver las diferentes aplicaciones activas en el momento del volcado de memoria:\n\n![imagen](/images/forense-Android-3.png)\n\nSi nos vamos por ejemplo dentro de la siguiente carpeta, podemos ver metainformación del emulador que estuvo usando Macarena antes del volcado de memoria:\n\n![imagen](/images/forense-Android-2.png)\n\n\nHe utilizado el teléfono de mi chica porque yo utilizo un Samsung S21, el cual tiene un sistema de seguridad llamado Knox que impide el volcado de memoria del dispositivo.","source":"_posts/forense.md","raw":"\n![imagen](/images/forense-logo.png)\n\nLa informática forense es el conjunto de técnicas que nos permite obtener la máxima información posible tras un incidente o delito informático.\n\nEn esta práctica, realizarás la fase de toma de evidencias y análisis de las mismas sobre una máquina Linux y otra Windows. Supondremos que pillamos al delincuente in fraganti y las máquinas se encontraban encendidas. Opcionalmente, podéis realizar el análisis de un dispositivo Android.\n\nSobre cada una de las máquinas debes realizar un volcado de memoria y otro de disco duro, tomando las medidas necesarias para certificar posteriormente la cadena de custodia.\n\nDebes tratar de obtener las siguientes informaciones:\n\n# Apartado A) Máquina Windows.\n\nPor comandos:\n\n## 1. Procesos en ejecución.\n\nEn la máquina linux, tras haber instalado volatility, ejecutamos el comando sobre el volcado de memoria de la máquina windows:\n\n`python3 vol.py -f /home/vagrant/memwin7.mem windows.pslist`\n\n![imagen](/images/forense-1.png)\n\n## 2. Servicios en ejecución.\n\n`python3 vol.py -f /home/vagrant/memwin7.mem windows.getservicesids.GetServiceSIDs`\n\n![imagen](/images/forense-2.png)\n\n## 3. Puertos abiertos.\n\n`python3 vol.py -f /home/vagrant/memwin7.mem windows.netscan`\n\n![imagen](/images/forense-3.png)\n\n\n## 4. Conexiones establecidas por la máquina.\n\n\n\n## 5. Sesiones de usuario establecidas remotamente.\n\n`python3 vol.py -f /home/vagrant/memwin7.mem windows.sessions.Sessions`\n\n![imagen](/images/forense-5.png)\n\n## 6. Ficheros transferidos recientemente por NetBios.\n\n\n\n## 7. Contenido de la caché DNS.\n\n\n\n## 8. Variables de entorno.\n\n`python3 vol.py -f /home/vagrant/memwin7.mem envars`\n\n![imagen](/images/forense-8.png)\n\n\nAnalizando el Registro de Windows:\n\n## 9. Dispositivos USB conectados\n\n![imagen](/images/forense-9.png)\n\n## 10. Redes wifi utilizadas recientemente.\n\nPara mostrar las conexiones realizadas recientemente, vamos al registro a la ruta /Network/Connections y veremos la información en formato hexadecimal:\n\n![imagen](/images/forense-10.png)\n\n\n\n## 11. Configuración del firewall de nodo.\n\n![imagen](/images/forense-11.png)\n\n## 12. Programas que se ejecutan en el Inicio.\n\n\n## 13. Asociación de extensiones de ficheros y aplicaciones.\n\n![imagen](/images/forense-13.png)\n\n## 14. Aplicaciones usadas recientemente.\n\nSi nos vamos a el spartado run programs podemos ver los primeros los que se han ejecutado recientemente.\n\n![imagen](/images/forense-14.png)\n\n## 15. Ficheros abiertos recientemente.\n\n![imagen](/images/forense-15.png)\n\n## 16. Software Instalado.\n\nNos vamos a installed programs y podemos ver una lista con los programas instalados.\n\n![imagen](/images/forense-16.png)\n\n## 17. Contraseñas guardadas.\n\n\n![imagen](/images/forense-17-1.png)\n\n\n## 18. Cuentas de Usuario\n\n![imagen](/images/forense-18.png)\n\n## 19. Historial de navegación y descargas. Cookies.\n\n![imagen](/images/forense-19-2.png)\n![imagen](/images/forense-19-3.png)\n![imagen](/images/forense-19-4.png)\n\n\n## 20. Volúmenes cifrados\n\n![imagen](/images/forense-20.png)\n\nSobre la imagen del disco:\n\n## 21. Archivos con extensión cambiada.\n\nPonemos el tipo de archivo en la herramientas de búsqueda por atributos.\n\n![imagen](/images/forense-21.png)\n\n\n## 22. Archivos eliminados.\n\nEn el programa en el apartado de archivos eliminados podemos encontrar el fichero con contraseña que borré de la máquina.\n\n![imagen](/images/forense-22.png)\n\n## 23. Archivos Ocultos.\n\n![imagen](/images/forense-23.png)\n\n\n## 24. Archivos que contienen una cadena determinada.\n\nHe buscado por palabras clave y he encontrado el ficher oculto.\n\n![imagen](/images/forense-24.png)\n\n## 25. Búsqueda de imágenes por ubicación.\n\n![imagen](/images/forense-25.jpg)\n\n\n## 26. Búsqueda de archivos por autor.\n\n\n\n# Apartado B) Máquina Linux.\n\nIntenta realizar las mismas operaciones en una máquina Linux para aquellos apartados que tengan sentido y no se realicen de manera idéntica a Windows.\n\n\n## 1. Procesos en ejecución.\n\nEn la máquina linux, tras haber instalado volatility, ejecutamos el comando sobre el volcado de memoria de la máquina windows:\n\n`python3 vol.py -f /home/vagrant/memwin7.mem windows.pslist`\n\n![imagen](/images/forense-1.png)\n\n## 2. Servicios en ejecución.\n\n`python3 vol.py -f /home/vagrant/memwin7.mem windows.getservicesids.GetServiceSIDs`\n\n![imagen](/images/forense-2.png)\n\n## 3. Puertos abiertos.\n\n`python3 vol.py -f /home/vagrant/memwin7.mem windows.netscan`\n\n![imagen](/images/forense-3.png)\n\n\n## 4. Conexiones establecidas por la máquina.\n\nEn el mismo comando como el anterior podemos ver las conexiones establecidas por la máquina.\n\n## 5. Sesiones de usuario establecidas remotamente.\n\n`python3 vol.py -f /home/vagrant/memwin7.mem windows.sessions.Sessions`\n\n![imagen](/images/forense-5.png)\n\n## 6. Ficheros transferidos recientemente por NetBios.\n\n\n\n## 7. Contenido de la caché DNS.\n\n\n\n## 8. Variables de entorno.\n\n\n![imagen](/images/forense-linux-8.png)\n\n## 9. Dispositivos USB conectados\n\n`lsusb`\n\n![imagen](/images/forense-linux-9.png)\n\n## 10. Redes wifi utilizadas recientemente.\n\ncat /etc/NetworkManager/system-connections/* | egrep id\n\n![imagen](/images/forense-linux-10.png)\n\n## 11. Configuración del firewall de nodo.\n\n`iptables -L`\n\n![imagen](/images/forense-linux-11.png)\n\n\n## 12. Programas que se ejecutan en el Inicio.\n\nsystemctl list-unit-files | egrep \"enabled\"\n\n![imagen](/images/forense-linux-12.png)\n\n## 13. Asociación de extensiones de ficheros y aplicaciones.\n\n![imagen](/images/forense-linux-13.png)\n\n## 14. Aplicaciones usadas recientemente.\n\n\n\n## 15. Ficheros abiertos recientemente.\n\n`ls /* -Artls | tail -10`\n\n![imagen](/images/forense-linux-15.png)\n\n\n## 16. Software Instalado.\n\n`apt list --installed`\n\n![imagen](/images/forense-linux-16.png)\n\n## 17. Contraseñas guardadas.\n\n`cat /etc/shadow`\n\n![imagen](/images/forense-17.png)\n\n## 18. Cuentas de Usuario\nComo vemos que múltiples cuentas que no son de usuarios reales, sino que son de programas que contienen permisos para ejecutar comandos como root, podemos filtrar por el shell que en mi caso será zsh.\n\ncat /etc/passwd | egrep zsh\n\n![imagen](/images/forense-linux-18.png)\n\n\n## 19. Historial de navegación y descargas. Cookies.\n\n![imagen](/images/forense-linux-19-1.png)\n![imagen](/images/forense-linux-19-2.png)\n\n\n## 20. Volúmenes cifrados\n\n![imagen](/images/forense-linux-20.png)\n\nSobre la imagen del disco:\n\n## 21. Archivos con extensión cambiada.\n\nPonemos el tipo de archivo en la herramientas de búsqueda por atributos.\n\n![imagen](/images/forense-linux-21.png)\n\n\n## 22. Archivos eliminados.\n\nEn el programa en el apartado de archivos eliminados podemos encontrar el fichero con contraseña que borré de la máquina.\n\n![imagen](/images/forense-linux-22.png)\n\n## 23. Archivos Ocultos.\n\n![imagen](/images/forense-linux-23.png)\n\n\n## 24. Archivos que contienen una cadena determinada.\n\nHe buscado por palabras clave y he encontrado el ficher oculto.\n\n![imagen](/images/forense-linux-24.png)\n\n## 25. Búsqueda de imágenes por ubicación.\n\n![imagen](/images/forense-linux-25.png)\n\n\n## 26. Búsqueda de archivos por autor.\n\n\n# Apartado C) Android\n\nEn un dispositivo Android, trata de hacer un volcado de memoria y recuperar información de ubicación, llamadas, mensajes, aplicaciones de mensajería, perfiles en redes sociales, etc...\n\nAl hacer el volcado de memoria con Andriller, podemos ver como muestra las cuentas que utiliza el usuario del teléfono:\n\n![imagen](/images/forense-Android-1.png)\n\nSi entramos dentro de la carpeta generada llamada Apps, podemos ver las diferentes aplicaciones activas en el momento del volcado de memoria:\n\n![imagen](/images/forense-Android-3.png)\n\nSi nos vamos por ejemplo dentro de la siguiente carpeta, podemos ver metainformación del emulador que estuvo usando Macarena antes del volcado de memoria:\n\n![imagen](/images/forense-Android-2.png)\n\n\nHe utilizado el teléfono de mi chica porque yo utilizo un Samsung S21, el cual tiene un sistema de seguridad llamado Knox que impide el volcado de memoria del dispositivo.","slug":"forense","published":1,"date":"2023-02-08T01:35:51.808Z","updated":"2023-02-12T16:04:02.172Z","_id":"cldy7hqzy0000hdi506ppe27n","title":"","comments":1,"layout":"post","photos":[],"link":"","content":"<p><img src=\"/images/forense-logo.png\" alt=\"imagen\"></p>\n<p>La informática forense es el conjunto de técnicas que nos permite obtener la máxima información posible tras un incidente o delito informático.</p>\n<p>En esta práctica, realizarás la fase de toma de evidencias y análisis de las mismas sobre una máquina Linux y otra Windows. Supondremos que pillamos al delincuente in fraganti y las máquinas se encontraban encendidas. Opcionalmente, podéis realizar el análisis de un dispositivo Android.</p>\n<p>Sobre cada una de las máquinas debes realizar un volcado de memoria y otro de disco duro, tomando las medidas necesarias para certificar posteriormente la cadena de custodia.</p>\n<p>Debes tratar de obtener las siguientes informaciones:</p>\n<h1 id=\"apartado-a-máquina-windows\"><a class=\"markdownIt-Anchor\" href=\"#apartado-a-máquina-windows\">#</a> Apartado A) Máquina Windows.</h1>\n<p>Por comandos:</p>\n<h2 id=\"1-procesos-en-ejecución\"><a class=\"markdownIt-Anchor\" href=\"#1-procesos-en-ejecución\">#</a> 1. Procesos en ejecución.</h2>\n<p>En la máquina linux, tras haber instalado volatility, ejecutamos el comando sobre el volcado de memoria de la máquina windows:</p>\n<p><code>python3 vol.py -f /home/vagrant/memwin7.mem windows.pslist</code></p>\n<p><img src=\"/images/forense-1.png\" alt=\"imagen\"></p>\n<h2 id=\"2-servicios-en-ejecución\"><a class=\"markdownIt-Anchor\" href=\"#2-servicios-en-ejecución\">#</a> 2. Servicios en ejecución.</h2>\n<p><code>python3 vol.py -f /home/vagrant/memwin7.mem windows.getservicesids.GetServiceSIDs</code></p>\n<p><img src=\"/images/forense-2.png\" alt=\"imagen\"></p>\n<h2 id=\"3-puertos-abiertos\"><a class=\"markdownIt-Anchor\" href=\"#3-puertos-abiertos\">#</a> 3. Puertos abiertos.</h2>\n<p><code>python3 vol.py -f /home/vagrant/memwin7.mem windows.netscan</code></p>\n<p><img src=\"/images/forense-3.png\" alt=\"imagen\"></p>\n<h2 id=\"4-conexiones-establecidas-por-la-máquina\"><a class=\"markdownIt-Anchor\" href=\"#4-conexiones-establecidas-por-la-máquina\">#</a> 4. Conexiones establecidas por la máquina.</h2>\n<h2 id=\"5-sesiones-de-usuario-establecidas-remotamente\"><a class=\"markdownIt-Anchor\" href=\"#5-sesiones-de-usuario-establecidas-remotamente\">#</a> 5. Sesiones de usuario establecidas remotamente.</h2>\n<p><code>python3 vol.py -f /home/vagrant/memwin7.mem windows.sessions.Sessions</code></p>\n<p><img src=\"/images/forense-5.png\" alt=\"imagen\"></p>\n<h2 id=\"6-ficheros-transferidos-recientemente-por-netbios\"><a class=\"markdownIt-Anchor\" href=\"#6-ficheros-transferidos-recientemente-por-netbios\">#</a> 6. Ficheros transferidos recientemente por NetBios.</h2>\n<h2 id=\"7-contenido-de-la-caché-dns\"><a class=\"markdownIt-Anchor\" href=\"#7-contenido-de-la-caché-dns\">#</a> 7. Contenido de la caché DNS.</h2>\n<h2 id=\"8-variables-de-entorno\"><a class=\"markdownIt-Anchor\" href=\"#8-variables-de-entorno\">#</a> 8. Variables de entorno.</h2>\n<p><code>python3 vol.py -f /home/vagrant/memwin7.mem envars</code></p>\n<p><img src=\"/images/forense-8.png\" alt=\"imagen\"></p>\n<p>Analizando el Registro de Windows:</p>\n<h2 id=\"9-dispositivos-usb-conectados\"><a class=\"markdownIt-Anchor\" href=\"#9-dispositivos-usb-conectados\">#</a> 9. Dispositivos USB conectados</h2>\n<p><img src=\"/images/forense-9.png\" alt=\"imagen\"></p>\n<h2 id=\"10-redes-wifi-utilizadas-recientemente\"><a class=\"markdownIt-Anchor\" href=\"#10-redes-wifi-utilizadas-recientemente\">#</a> 10. Redes wifi utilizadas recientemente.</h2>\n<p>Para mostrar las conexiones realizadas recientemente, vamos al registro a la ruta /Network/Connections y veremos la información en formato hexadecimal:</p>\n<p><img src=\"/images/forense-10.png\" alt=\"imagen\"></p>\n<h2 id=\"11-configuración-del-firewall-de-nodo\"><a class=\"markdownIt-Anchor\" href=\"#11-configuración-del-firewall-de-nodo\">#</a> 11. Configuración del firewall de nodo.</h2>\n<p><img src=\"/images/forense-11.png\" alt=\"imagen\"></p>\n<h2 id=\"12-programas-que-se-ejecutan-en-el-inicio\"><a class=\"markdownIt-Anchor\" href=\"#12-programas-que-se-ejecutan-en-el-inicio\">#</a> 12. Programas que se ejecutan en el Inicio.</h2>\n<h2 id=\"13-asociación-de-extensiones-de-ficheros-y-aplicaciones\"><a class=\"markdownIt-Anchor\" href=\"#13-asociación-de-extensiones-de-ficheros-y-aplicaciones\">#</a> 13. Asociación de extensiones de ficheros y aplicaciones.</h2>\n<p><img src=\"/images/forense-13.png\" alt=\"imagen\"></p>\n<h2 id=\"14-aplicaciones-usadas-recientemente\"><a class=\"markdownIt-Anchor\" href=\"#14-aplicaciones-usadas-recientemente\">#</a> 14. Aplicaciones usadas recientemente.</h2>\n<p>Si nos vamos a el spartado run programs podemos ver los primeros los que se han ejecutado recientemente.</p>\n<p><img src=\"/images/forense-14.png\" alt=\"imagen\"></p>\n<h2 id=\"15-ficheros-abiertos-recientemente\"><a class=\"markdownIt-Anchor\" href=\"#15-ficheros-abiertos-recientemente\">#</a> 15. Ficheros abiertos recientemente.</h2>\n<p><img src=\"/images/forense-15.png\" alt=\"imagen\"></p>\n<h2 id=\"16-software-instalado\"><a class=\"markdownIt-Anchor\" href=\"#16-software-instalado\">#</a> 16. Software Instalado.</h2>\n<p>Nos vamos a installed programs y podemos ver una lista con los programas instalados.</p>\n<p><img src=\"/images/forense-16.png\" alt=\"imagen\"></p>\n<h2 id=\"17-contraseñas-guardadas\"><a class=\"markdownIt-Anchor\" href=\"#17-contraseñas-guardadas\">#</a> 17. Contraseñas guardadas.</h2>\n<p><img src=\"/images/forense-17-1.png\" alt=\"imagen\"></p>\n<h2 id=\"18-cuentas-de-usuario\"><a class=\"markdownIt-Anchor\" href=\"#18-cuentas-de-usuario\">#</a> 18. Cuentas de Usuario</h2>\n<p><img src=\"/images/forense-18.png\" alt=\"imagen\"></p>\n<h2 id=\"19-historial-de-navegación-y-descargas-cookies\"><a class=\"markdownIt-Anchor\" href=\"#19-historial-de-navegación-y-descargas-cookies\">#</a> 19. Historial de navegación y descargas. Cookies.</h2>\n<p><img src=\"/images/forense-19-2.png\" alt=\"imagen\"><br>\n<img src=\"/images/forense-19-3.png\" alt=\"imagen\"><br>\n<img src=\"/images/forense-19-4.png\" alt=\"imagen\"></p>\n<h2 id=\"20-volúmenes-cifrados\"><a class=\"markdownIt-Anchor\" href=\"#20-volúmenes-cifrados\">#</a> 20. Volúmenes cifrados</h2>\n<p><img src=\"/images/forense-20.png\" alt=\"imagen\"></p>\n<p>Sobre la imagen del disco:</p>\n<h2 id=\"21-archivos-con-extensión-cambiada\"><a class=\"markdownIt-Anchor\" href=\"#21-archivos-con-extensión-cambiada\">#</a> 21. Archivos con extensión cambiada.</h2>\n<p>Ponemos el tipo de archivo en la herramientas de búsqueda por atributos.</p>\n<p><img src=\"/images/forense-21.png\" alt=\"imagen\"></p>\n<h2 id=\"22-archivos-eliminados\"><a class=\"markdownIt-Anchor\" href=\"#22-archivos-eliminados\">#</a> 22. Archivos eliminados.</h2>\n<p>En el programa en el apartado de archivos eliminados podemos encontrar el fichero con contraseña que borré de la máquina.</p>\n<p><img src=\"/images/forense-22.png\" alt=\"imagen\"></p>\n<h2 id=\"23-archivos-ocultos\"><a class=\"markdownIt-Anchor\" href=\"#23-archivos-ocultos\">#</a> 23. Archivos Ocultos.</h2>\n<p><img src=\"/images/forense-23.png\" alt=\"imagen\"></p>\n<h2 id=\"24-archivos-que-contienen-una-cadena-determinada\"><a class=\"markdownIt-Anchor\" href=\"#24-archivos-que-contienen-una-cadena-determinada\">#</a> 24. Archivos que contienen una cadena determinada.</h2>\n<p>He buscado por palabras clave y he encontrado el ficher oculto.</p>\n<p><img src=\"/images/forense-24.png\" alt=\"imagen\"></p>\n<h2 id=\"25-búsqueda-de-imágenes-por-ubicación\"><a class=\"markdownIt-Anchor\" href=\"#25-búsqueda-de-imágenes-por-ubicación\">#</a> 25. Búsqueda de imágenes por ubicación.</h2>\n<p><img src=\"/images/forense-25.jpg\" alt=\"imagen\"></p>\n<h2 id=\"26-búsqueda-de-archivos-por-autor\"><a class=\"markdownIt-Anchor\" href=\"#26-búsqueda-de-archivos-por-autor\">#</a> 26. Búsqueda de archivos por autor.</h2>\n<h1 id=\"apartado-b-máquina-linux\"><a class=\"markdownIt-Anchor\" href=\"#apartado-b-máquina-linux\">#</a> Apartado B) Máquina Linux.</h1>\n<p>Intenta realizar las mismas operaciones en una máquina Linux para aquellos apartados que tengan sentido y no se realicen de manera idéntica a Windows.</p>\n<h2 id=\"1-procesos-en-ejecución-2\"><a class=\"markdownIt-Anchor\" href=\"#1-procesos-en-ejecución-2\">#</a> 1. Procesos en ejecución.</h2>\n<p>En la máquina linux, tras haber instalado volatility, ejecutamos el comando sobre el volcado de memoria de la máquina windows:</p>\n<p><code>python3 vol.py -f /home/vagrant/memwin7.mem windows.pslist</code></p>\n<p><img src=\"/images/forense-1.png\" alt=\"imagen\"></p>\n<h2 id=\"2-servicios-en-ejecución-2\"><a class=\"markdownIt-Anchor\" href=\"#2-servicios-en-ejecución-2\">#</a> 2. Servicios en ejecución.</h2>\n<p><code>python3 vol.py -f /home/vagrant/memwin7.mem windows.getservicesids.GetServiceSIDs</code></p>\n<p><img src=\"/images/forense-2.png\" alt=\"imagen\"></p>\n<h2 id=\"3-puertos-abiertos-2\"><a class=\"markdownIt-Anchor\" href=\"#3-puertos-abiertos-2\">#</a> 3. Puertos abiertos.</h2>\n<p><code>python3 vol.py -f /home/vagrant/memwin7.mem windows.netscan</code></p>\n<p><img src=\"/images/forense-3.png\" alt=\"imagen\"></p>\n<h2 id=\"4-conexiones-establecidas-por-la-máquina-2\"><a class=\"markdownIt-Anchor\" href=\"#4-conexiones-establecidas-por-la-máquina-2\">#</a> 4. Conexiones establecidas por la máquina.</h2>\n<p>En el mismo comando como el anterior podemos ver las conexiones establecidas por la máquina.</p>\n<h2 id=\"5-sesiones-de-usuario-establecidas-remotamente-2\"><a class=\"markdownIt-Anchor\" href=\"#5-sesiones-de-usuario-establecidas-remotamente-2\">#</a> 5. Sesiones de usuario establecidas remotamente.</h2>\n<p><code>python3 vol.py -f /home/vagrant/memwin7.mem windows.sessions.Sessions</code></p>\n<p><img src=\"/images/forense-5.png\" alt=\"imagen\"></p>\n<h2 id=\"6-ficheros-transferidos-recientemente-por-netbios-2\"><a class=\"markdownIt-Anchor\" href=\"#6-ficheros-transferidos-recientemente-por-netbios-2\">#</a> 6. Ficheros transferidos recientemente por NetBios.</h2>\n<h2 id=\"7-contenido-de-la-caché-dns-2\"><a class=\"markdownIt-Anchor\" href=\"#7-contenido-de-la-caché-dns-2\">#</a> 7. Contenido de la caché DNS.</h2>\n<h2 id=\"8-variables-de-entorno-2\"><a class=\"markdownIt-Anchor\" href=\"#8-variables-de-entorno-2\">#</a> 8. Variables de entorno.</h2>\n<p><img src=\"/images/forense-linux-8.png\" alt=\"imagen\"></p>\n<h2 id=\"9-dispositivos-usb-conectados-2\"><a class=\"markdownIt-Anchor\" href=\"#9-dispositivos-usb-conectados-2\">#</a> 9. Dispositivos USB conectados</h2>\n<p><code>lsusb</code></p>\n<p><img src=\"/images/forense-linux-9.png\" alt=\"imagen\"></p>\n<h2 id=\"10-redes-wifi-utilizadas-recientemente-2\"><a class=\"markdownIt-Anchor\" href=\"#10-redes-wifi-utilizadas-recientemente-2\">#</a> 10. Redes wifi utilizadas recientemente.</h2>\n<p>cat /etc/NetworkManager/system-connections/* | egrep id</p>\n<p><img src=\"/images/forense-linux-10.png\" alt=\"imagen\"></p>\n<h2 id=\"11-configuración-del-firewall-de-nodo-2\"><a class=\"markdownIt-Anchor\" href=\"#11-configuración-del-firewall-de-nodo-2\">#</a> 11. Configuración del firewall de nodo.</h2>\n<p><code>iptables -L</code></p>\n<p><img src=\"/images/forense-linux-11.png\" alt=\"imagen\"></p>\n<h2 id=\"12-programas-que-se-ejecutan-en-el-inicio-2\"><a class=\"markdownIt-Anchor\" href=\"#12-programas-que-se-ejecutan-en-el-inicio-2\">#</a> 12. Programas que se ejecutan en el Inicio.</h2>\n<p>systemctl list-unit-files | egrep “enabled”</p>\n<p><img src=\"/images/forense-linux-12.png\" alt=\"imagen\"></p>\n<h2 id=\"13-asociación-de-extensiones-de-ficheros-y-aplicaciones-2\"><a class=\"markdownIt-Anchor\" href=\"#13-asociación-de-extensiones-de-ficheros-y-aplicaciones-2\">#</a> 13. Asociación de extensiones de ficheros y aplicaciones.</h2>\n<p><img src=\"/images/forense-linux-13.png\" alt=\"imagen\"></p>\n<h2 id=\"14-aplicaciones-usadas-recientemente-2\"><a class=\"markdownIt-Anchor\" href=\"#14-aplicaciones-usadas-recientemente-2\">#</a> 14. Aplicaciones usadas recientemente.</h2>\n<h2 id=\"15-ficheros-abiertos-recientemente-2\"><a class=\"markdownIt-Anchor\" href=\"#15-ficheros-abiertos-recientemente-2\">#</a> 15. Ficheros abiertos recientemente.</h2>\n<p><code>ls /* -Artls | tail -10</code></p>\n<p><img src=\"/images/forense-linux-15.png\" alt=\"imagen\"></p>\n<h2 id=\"16-software-instalado-2\"><a class=\"markdownIt-Anchor\" href=\"#16-software-instalado-2\">#</a> 16. Software Instalado.</h2>\n<p><code>apt list --installed</code></p>\n<p><img src=\"/images/forense-linux-16.png\" alt=\"imagen\"></p>\n<h2 id=\"17-contraseñas-guardadas-2\"><a class=\"markdownIt-Anchor\" href=\"#17-contraseñas-guardadas-2\">#</a> 17. Contraseñas guardadas.</h2>\n<p><code>cat /etc/shadow</code></p>\n<p><img src=\"/images/forense-17.png\" alt=\"imagen\"></p>\n<h2 id=\"18-cuentas-de-usuario-2\"><a class=\"markdownIt-Anchor\" href=\"#18-cuentas-de-usuario-2\">#</a> 18. Cuentas de Usuario</h2>\n<p>Como vemos que múltiples cuentas que no son de usuarios reales, sino que son de programas que contienen permisos para ejecutar comandos como root, podemos filtrar por el shell que en mi caso será zsh.</p>\n<p>cat /etc/passwd | egrep zsh</p>\n<p><img src=\"/images/forense-linux-18.png\" alt=\"imagen\"></p>\n<h2 id=\"19-historial-de-navegación-y-descargas-cookies-2\"><a class=\"markdownIt-Anchor\" href=\"#19-historial-de-navegación-y-descargas-cookies-2\">#</a> 19. Historial de navegación y descargas. Cookies.</h2>\n<p><img src=\"/images/forense-linux-19-1.png\" alt=\"imagen\"><br>\n<img src=\"/images/forense-linux-19-2.png\" alt=\"imagen\"></p>\n<h2 id=\"20-volúmenes-cifrados-2\"><a class=\"markdownIt-Anchor\" href=\"#20-volúmenes-cifrados-2\">#</a> 20. Volúmenes cifrados</h2>\n<p><img src=\"/images/forense-linux-20.png\" alt=\"imagen\"></p>\n<p>Sobre la imagen del disco:</p>\n<h2 id=\"21-archivos-con-extensión-cambiada-2\"><a class=\"markdownIt-Anchor\" href=\"#21-archivos-con-extensión-cambiada-2\">#</a> 21. Archivos con extensión cambiada.</h2>\n<p>Ponemos el tipo de archivo en la herramientas de búsqueda por atributos.</p>\n<p><img src=\"/images/forense-linux-21.png\" alt=\"imagen\"></p>\n<h2 id=\"22-archivos-eliminados-2\"><a class=\"markdownIt-Anchor\" href=\"#22-archivos-eliminados-2\">#</a> 22. Archivos eliminados.</h2>\n<p>En el programa en el apartado de archivos eliminados podemos encontrar el fichero con contraseña que borré de la máquina.</p>\n<p><img src=\"/images/forense-linux-22.png\" alt=\"imagen\"></p>\n<h2 id=\"23-archivos-ocultos-2\"><a class=\"markdownIt-Anchor\" href=\"#23-archivos-ocultos-2\">#</a> 23. Archivos Ocultos.</h2>\n<p><img src=\"/images/forense-linux-23.png\" alt=\"imagen\"></p>\n<h2 id=\"24-archivos-que-contienen-una-cadena-determinada-2\"><a class=\"markdownIt-Anchor\" href=\"#24-archivos-que-contienen-una-cadena-determinada-2\">#</a> 24. Archivos que contienen una cadena determinada.</h2>\n<p>He buscado por palabras clave y he encontrado el ficher oculto.</p>\n<p><img src=\"/images/forense-linux-24.png\" alt=\"imagen\"></p>\n<h2 id=\"25-búsqueda-de-imágenes-por-ubicación-2\"><a class=\"markdownIt-Anchor\" href=\"#25-búsqueda-de-imágenes-por-ubicación-2\">#</a> 25. Búsqueda de imágenes por ubicación.</h2>\n<p><img src=\"/images/forense-linux-25.png\" alt=\"imagen\"></p>\n<h2 id=\"26-búsqueda-de-archivos-por-autor-2\"><a class=\"markdownIt-Anchor\" href=\"#26-búsqueda-de-archivos-por-autor-2\">#</a> 26. Búsqueda de archivos por autor.</h2>\n<h1 id=\"apartado-c-android\"><a class=\"markdownIt-Anchor\" href=\"#apartado-c-android\">#</a> Apartado C) Android</h1>\n<p>En un dispositivo Android, trata de hacer un volcado de memoria y recuperar información de ubicación, llamadas, mensajes, aplicaciones de mensajería, perfiles en redes sociales, etc…</p>\n<p>Al hacer el volcado de memoria con Andriller, podemos ver como muestra las cuentas que utiliza el usuario del teléfono:</p>\n<p><img src=\"/images/forense-Android-1.png\" alt=\"imagen\"></p>\n<p>Si entramos dentro de la carpeta generada llamada Apps, podemos ver las diferentes aplicaciones activas en el momento del volcado de memoria:</p>\n<p><img src=\"/images/forense-Android-3.png\" alt=\"imagen\"></p>\n<p>Si nos vamos por ejemplo dentro de la siguiente carpeta, podemos ver metainformación del emulador que estuvo usando Macarena antes del volcado de memoria:</p>\n<p><img src=\"/images/forense-Android-2.png\" alt=\"imagen\"></p>\n<p>He utilizado el teléfono de mi chica porque yo utilizo un Samsung S21, el cual tiene un sistema de seguridad llamado Knox que impide el volcado de memoria del dispositivo.</p>\n","site":{"data":{}},"length":5035,"excerpt":"","more":"<p><img src=\"/images/forense-logo.png\" alt=\"imagen\"></p>\n<p>La informática forense es el conjunto de técnicas que nos permite obtener la máxima información posible tras un incidente o delito informático.</p>\n<p>En esta práctica, realizarás la fase de toma de evidencias y análisis de las mismas sobre una máquina Linux y otra Windows. Supondremos que pillamos al delincuente in fraganti y las máquinas se encontraban encendidas. Opcionalmente, podéis realizar el análisis de un dispositivo Android.</p>\n<p>Sobre cada una de las máquinas debes realizar un volcado de memoria y otro de disco duro, tomando las medidas necesarias para certificar posteriormente la cadena de custodia.</p>\n<p>Debes tratar de obtener las siguientes informaciones:</p>\n<h1 id=\"apartado-a-máquina-windows\"><a class=\"markdownIt-Anchor\" href=\"#apartado-a-máquina-windows\">#</a> Apartado A) Máquina Windows.</h1>\n<p>Por comandos:</p>\n<h2 id=\"1-procesos-en-ejecución\"><a class=\"markdownIt-Anchor\" href=\"#1-procesos-en-ejecución\">#</a> 1. Procesos en ejecución.</h2>\n<p>En la máquina linux, tras haber instalado volatility, ejecutamos el comando sobre el volcado de memoria de la máquina windows:</p>\n<p><code>python3 vol.py -f /home/vagrant/memwin7.mem windows.pslist</code></p>\n<p><img src=\"/images/forense-1.png\" alt=\"imagen\"></p>\n<h2 id=\"2-servicios-en-ejecución\"><a class=\"markdownIt-Anchor\" href=\"#2-servicios-en-ejecución\">#</a> 2. Servicios en ejecución.</h2>\n<p><code>python3 vol.py -f /home/vagrant/memwin7.mem windows.getservicesids.GetServiceSIDs</code></p>\n<p><img src=\"/images/forense-2.png\" alt=\"imagen\"></p>\n<h2 id=\"3-puertos-abiertos\"><a class=\"markdownIt-Anchor\" href=\"#3-puertos-abiertos\">#</a> 3. Puertos abiertos.</h2>\n<p><code>python3 vol.py -f /home/vagrant/memwin7.mem windows.netscan</code></p>\n<p><img src=\"/images/forense-3.png\" alt=\"imagen\"></p>\n<h2 id=\"4-conexiones-establecidas-por-la-máquina\"><a class=\"markdownIt-Anchor\" href=\"#4-conexiones-establecidas-por-la-máquina\">#</a> 4. Conexiones establecidas por la máquina.</h2>\n<h2 id=\"5-sesiones-de-usuario-establecidas-remotamente\"><a class=\"markdownIt-Anchor\" href=\"#5-sesiones-de-usuario-establecidas-remotamente\">#</a> 5. Sesiones de usuario establecidas remotamente.</h2>\n<p><code>python3 vol.py -f /home/vagrant/memwin7.mem windows.sessions.Sessions</code></p>\n<p><img src=\"/images/forense-5.png\" alt=\"imagen\"></p>\n<h2 id=\"6-ficheros-transferidos-recientemente-por-netbios\"><a class=\"markdownIt-Anchor\" href=\"#6-ficheros-transferidos-recientemente-por-netbios\">#</a> 6. Ficheros transferidos recientemente por NetBios.</h2>\n<h2 id=\"7-contenido-de-la-caché-dns\"><a class=\"markdownIt-Anchor\" href=\"#7-contenido-de-la-caché-dns\">#</a> 7. Contenido de la caché DNS.</h2>\n<h2 id=\"8-variables-de-entorno\"><a class=\"markdownIt-Anchor\" href=\"#8-variables-de-entorno\">#</a> 8. Variables de entorno.</h2>\n<p><code>python3 vol.py -f /home/vagrant/memwin7.mem envars</code></p>\n<p><img src=\"/images/forense-8.png\" alt=\"imagen\"></p>\n<p>Analizando el Registro de Windows:</p>\n<h2 id=\"9-dispositivos-usb-conectados\"><a class=\"markdownIt-Anchor\" href=\"#9-dispositivos-usb-conectados\">#</a> 9. Dispositivos USB conectados</h2>\n<p><img src=\"/images/forense-9.png\" alt=\"imagen\"></p>\n<h2 id=\"10-redes-wifi-utilizadas-recientemente\"><a class=\"markdownIt-Anchor\" href=\"#10-redes-wifi-utilizadas-recientemente\">#</a> 10. Redes wifi utilizadas recientemente.</h2>\n<p>Para mostrar las conexiones realizadas recientemente, vamos al registro a la ruta /Network/Connections y veremos la información en formato hexadecimal:</p>\n<p><img src=\"/images/forense-10.png\" alt=\"imagen\"></p>\n<h2 id=\"11-configuración-del-firewall-de-nodo\"><a class=\"markdownIt-Anchor\" href=\"#11-configuración-del-firewall-de-nodo\">#</a> 11. Configuración del firewall de nodo.</h2>\n<p><img src=\"/images/forense-11.png\" alt=\"imagen\"></p>\n<h2 id=\"12-programas-que-se-ejecutan-en-el-inicio\"><a class=\"markdownIt-Anchor\" href=\"#12-programas-que-se-ejecutan-en-el-inicio\">#</a> 12. Programas que se ejecutan en el Inicio.</h2>\n<h2 id=\"13-asociación-de-extensiones-de-ficheros-y-aplicaciones\"><a class=\"markdownIt-Anchor\" href=\"#13-asociación-de-extensiones-de-ficheros-y-aplicaciones\">#</a> 13. Asociación de extensiones de ficheros y aplicaciones.</h2>\n<p><img src=\"/images/forense-13.png\" alt=\"imagen\"></p>\n<h2 id=\"14-aplicaciones-usadas-recientemente\"><a class=\"markdownIt-Anchor\" href=\"#14-aplicaciones-usadas-recientemente\">#</a> 14. Aplicaciones usadas recientemente.</h2>\n<p>Si nos vamos a el spartado run programs podemos ver los primeros los que se han ejecutado recientemente.</p>\n<p><img src=\"/images/forense-14.png\" alt=\"imagen\"></p>\n<h2 id=\"15-ficheros-abiertos-recientemente\"><a class=\"markdownIt-Anchor\" href=\"#15-ficheros-abiertos-recientemente\">#</a> 15. Ficheros abiertos recientemente.</h2>\n<p><img src=\"/images/forense-15.png\" alt=\"imagen\"></p>\n<h2 id=\"16-software-instalado\"><a class=\"markdownIt-Anchor\" href=\"#16-software-instalado\">#</a> 16. Software Instalado.</h2>\n<p>Nos vamos a installed programs y podemos ver una lista con los programas instalados.</p>\n<p><img src=\"/images/forense-16.png\" alt=\"imagen\"></p>\n<h2 id=\"17-contraseñas-guardadas\"><a class=\"markdownIt-Anchor\" href=\"#17-contraseñas-guardadas\">#</a> 17. Contraseñas guardadas.</h2>\n<p><img src=\"/images/forense-17-1.png\" alt=\"imagen\"></p>\n<h2 id=\"18-cuentas-de-usuario\"><a class=\"markdownIt-Anchor\" href=\"#18-cuentas-de-usuario\">#</a> 18. Cuentas de Usuario</h2>\n<p><img src=\"/images/forense-18.png\" alt=\"imagen\"></p>\n<h2 id=\"19-historial-de-navegación-y-descargas-cookies\"><a class=\"markdownIt-Anchor\" href=\"#19-historial-de-navegación-y-descargas-cookies\">#</a> 19. Historial de navegación y descargas. Cookies.</h2>\n<p><img src=\"/images/forense-19-2.png\" alt=\"imagen\"><br>\n<img src=\"/images/forense-19-3.png\" alt=\"imagen\"><br>\n<img src=\"/images/forense-19-4.png\" alt=\"imagen\"></p>\n<h2 id=\"20-volúmenes-cifrados\"><a class=\"markdownIt-Anchor\" href=\"#20-volúmenes-cifrados\">#</a> 20. Volúmenes cifrados</h2>\n<p><img src=\"/images/forense-20.png\" alt=\"imagen\"></p>\n<p>Sobre la imagen del disco:</p>\n<h2 id=\"21-archivos-con-extensión-cambiada\"><a class=\"markdownIt-Anchor\" href=\"#21-archivos-con-extensión-cambiada\">#</a> 21. Archivos con extensión cambiada.</h2>\n<p>Ponemos el tipo de archivo en la herramientas de búsqueda por atributos.</p>\n<p><img src=\"/images/forense-21.png\" alt=\"imagen\"></p>\n<h2 id=\"22-archivos-eliminados\"><a class=\"markdownIt-Anchor\" href=\"#22-archivos-eliminados\">#</a> 22. Archivos eliminados.</h2>\n<p>En el programa en el apartado de archivos eliminados podemos encontrar el fichero con contraseña que borré de la máquina.</p>\n<p><img src=\"/images/forense-22.png\" alt=\"imagen\"></p>\n<h2 id=\"23-archivos-ocultos\"><a class=\"markdownIt-Anchor\" href=\"#23-archivos-ocultos\">#</a> 23. Archivos Ocultos.</h2>\n<p><img src=\"/images/forense-23.png\" alt=\"imagen\"></p>\n<h2 id=\"24-archivos-que-contienen-una-cadena-determinada\"><a class=\"markdownIt-Anchor\" href=\"#24-archivos-que-contienen-una-cadena-determinada\">#</a> 24. Archivos que contienen una cadena determinada.</h2>\n<p>He buscado por palabras clave y he encontrado el ficher oculto.</p>\n<p><img src=\"/images/forense-24.png\" alt=\"imagen\"></p>\n<h2 id=\"25-búsqueda-de-imágenes-por-ubicación\"><a class=\"markdownIt-Anchor\" href=\"#25-búsqueda-de-imágenes-por-ubicación\">#</a> 25. Búsqueda de imágenes por ubicación.</h2>\n<p><img src=\"/images/forense-25.jpg\" alt=\"imagen\"></p>\n<h2 id=\"26-búsqueda-de-archivos-por-autor\"><a class=\"markdownIt-Anchor\" href=\"#26-búsqueda-de-archivos-por-autor\">#</a> 26. Búsqueda de archivos por autor.</h2>\n<h1 id=\"apartado-b-máquina-linux\"><a class=\"markdownIt-Anchor\" href=\"#apartado-b-máquina-linux\">#</a> Apartado B) Máquina Linux.</h1>\n<p>Intenta realizar las mismas operaciones en una máquina Linux para aquellos apartados que tengan sentido y no se realicen de manera idéntica a Windows.</p>\n<h2 id=\"1-procesos-en-ejecución-2\"><a class=\"markdownIt-Anchor\" href=\"#1-procesos-en-ejecución-2\">#</a> 1. Procesos en ejecución.</h2>\n<p>En la máquina linux, tras haber instalado volatility, ejecutamos el comando sobre el volcado de memoria de la máquina windows:</p>\n<p><code>python3 vol.py -f /home/vagrant/memwin7.mem windows.pslist</code></p>\n<p><img src=\"/images/forense-1.png\" alt=\"imagen\"></p>\n<h2 id=\"2-servicios-en-ejecución-2\"><a class=\"markdownIt-Anchor\" href=\"#2-servicios-en-ejecución-2\">#</a> 2. Servicios en ejecución.</h2>\n<p><code>python3 vol.py -f /home/vagrant/memwin7.mem windows.getservicesids.GetServiceSIDs</code></p>\n<p><img src=\"/images/forense-2.png\" alt=\"imagen\"></p>\n<h2 id=\"3-puertos-abiertos-2\"><a class=\"markdownIt-Anchor\" href=\"#3-puertos-abiertos-2\">#</a> 3. Puertos abiertos.</h2>\n<p><code>python3 vol.py -f /home/vagrant/memwin7.mem windows.netscan</code></p>\n<p><img src=\"/images/forense-3.png\" alt=\"imagen\"></p>\n<h2 id=\"4-conexiones-establecidas-por-la-máquina-2\"><a class=\"markdownIt-Anchor\" href=\"#4-conexiones-establecidas-por-la-máquina-2\">#</a> 4. Conexiones establecidas por la máquina.</h2>\n<p>En el mismo comando como el anterior podemos ver las conexiones establecidas por la máquina.</p>\n<h2 id=\"5-sesiones-de-usuario-establecidas-remotamente-2\"><a class=\"markdownIt-Anchor\" href=\"#5-sesiones-de-usuario-establecidas-remotamente-2\">#</a> 5. Sesiones de usuario establecidas remotamente.</h2>\n<p><code>python3 vol.py -f /home/vagrant/memwin7.mem windows.sessions.Sessions</code></p>\n<p><img src=\"/images/forense-5.png\" alt=\"imagen\"></p>\n<h2 id=\"6-ficheros-transferidos-recientemente-por-netbios-2\"><a class=\"markdownIt-Anchor\" href=\"#6-ficheros-transferidos-recientemente-por-netbios-2\">#</a> 6. Ficheros transferidos recientemente por NetBios.</h2>\n<h2 id=\"7-contenido-de-la-caché-dns-2\"><a class=\"markdownIt-Anchor\" href=\"#7-contenido-de-la-caché-dns-2\">#</a> 7. Contenido de la caché DNS.</h2>\n<h2 id=\"8-variables-de-entorno-2\"><a class=\"markdownIt-Anchor\" href=\"#8-variables-de-entorno-2\">#</a> 8. Variables de entorno.</h2>\n<p><img src=\"/images/forense-linux-8.png\" alt=\"imagen\"></p>\n<h2 id=\"9-dispositivos-usb-conectados-2\"><a class=\"markdownIt-Anchor\" href=\"#9-dispositivos-usb-conectados-2\">#</a> 9. Dispositivos USB conectados</h2>\n<p><code>lsusb</code></p>\n<p><img src=\"/images/forense-linux-9.png\" alt=\"imagen\"></p>\n<h2 id=\"10-redes-wifi-utilizadas-recientemente-2\"><a class=\"markdownIt-Anchor\" href=\"#10-redes-wifi-utilizadas-recientemente-2\">#</a> 10. Redes wifi utilizadas recientemente.</h2>\n<p>cat /etc/NetworkManager/system-connections/* | egrep id</p>\n<p><img src=\"/images/forense-linux-10.png\" alt=\"imagen\"></p>\n<h2 id=\"11-configuración-del-firewall-de-nodo-2\"><a class=\"markdownIt-Anchor\" href=\"#11-configuración-del-firewall-de-nodo-2\">#</a> 11. Configuración del firewall de nodo.</h2>\n<p><code>iptables -L</code></p>\n<p><img src=\"/images/forense-linux-11.png\" alt=\"imagen\"></p>\n<h2 id=\"12-programas-que-se-ejecutan-en-el-inicio-2\"><a class=\"markdownIt-Anchor\" href=\"#12-programas-que-se-ejecutan-en-el-inicio-2\">#</a> 12. Programas que se ejecutan en el Inicio.</h2>\n<p>systemctl list-unit-files | egrep “enabled”</p>\n<p><img src=\"/images/forense-linux-12.png\" alt=\"imagen\"></p>\n<h2 id=\"13-asociación-de-extensiones-de-ficheros-y-aplicaciones-2\"><a class=\"markdownIt-Anchor\" href=\"#13-asociación-de-extensiones-de-ficheros-y-aplicaciones-2\">#</a> 13. Asociación de extensiones de ficheros y aplicaciones.</h2>\n<p><img src=\"/images/forense-linux-13.png\" alt=\"imagen\"></p>\n<h2 id=\"14-aplicaciones-usadas-recientemente-2\"><a class=\"markdownIt-Anchor\" href=\"#14-aplicaciones-usadas-recientemente-2\">#</a> 14. Aplicaciones usadas recientemente.</h2>\n<h2 id=\"15-ficheros-abiertos-recientemente-2\"><a class=\"markdownIt-Anchor\" href=\"#15-ficheros-abiertos-recientemente-2\">#</a> 15. Ficheros abiertos recientemente.</h2>\n<p><code>ls /* -Artls | tail -10</code></p>\n<p><img src=\"/images/forense-linux-15.png\" alt=\"imagen\"></p>\n<h2 id=\"16-software-instalado-2\"><a class=\"markdownIt-Anchor\" href=\"#16-software-instalado-2\">#</a> 16. Software Instalado.</h2>\n<p><code>apt list --installed</code></p>\n<p><img src=\"/images/forense-linux-16.png\" alt=\"imagen\"></p>\n<h2 id=\"17-contraseñas-guardadas-2\"><a class=\"markdownIt-Anchor\" href=\"#17-contraseñas-guardadas-2\">#</a> 17. Contraseñas guardadas.</h2>\n<p><code>cat /etc/shadow</code></p>\n<p><img src=\"/images/forense-17.png\" alt=\"imagen\"></p>\n<h2 id=\"18-cuentas-de-usuario-2\"><a class=\"markdownIt-Anchor\" href=\"#18-cuentas-de-usuario-2\">#</a> 18. Cuentas de Usuario</h2>\n<p>Como vemos que múltiples cuentas que no son de usuarios reales, sino que son de programas que contienen permisos para ejecutar comandos como root, podemos filtrar por el shell que en mi caso será zsh.</p>\n<p>cat /etc/passwd | egrep zsh</p>\n<p><img src=\"/images/forense-linux-18.png\" alt=\"imagen\"></p>\n<h2 id=\"19-historial-de-navegación-y-descargas-cookies-2\"><a class=\"markdownIt-Anchor\" href=\"#19-historial-de-navegación-y-descargas-cookies-2\">#</a> 19. Historial de navegación y descargas. Cookies.</h2>\n<p><img src=\"/images/forense-linux-19-1.png\" alt=\"imagen\"><br>\n<img src=\"/images/forense-linux-19-2.png\" alt=\"imagen\"></p>\n<h2 id=\"20-volúmenes-cifrados-2\"><a class=\"markdownIt-Anchor\" href=\"#20-volúmenes-cifrados-2\">#</a> 20. Volúmenes cifrados</h2>\n<p><img src=\"/images/forense-linux-20.png\" alt=\"imagen\"></p>\n<p>Sobre la imagen del disco:</p>\n<h2 id=\"21-archivos-con-extensión-cambiada-2\"><a class=\"markdownIt-Anchor\" href=\"#21-archivos-con-extensión-cambiada-2\">#</a> 21. Archivos con extensión cambiada.</h2>\n<p>Ponemos el tipo de archivo en la herramientas de búsqueda por atributos.</p>\n<p><img src=\"/images/forense-linux-21.png\" alt=\"imagen\"></p>\n<h2 id=\"22-archivos-eliminados-2\"><a class=\"markdownIt-Anchor\" href=\"#22-archivos-eliminados-2\">#</a> 22. Archivos eliminados.</h2>\n<p>En el programa en el apartado de archivos eliminados podemos encontrar el fichero con contraseña que borré de la máquina.</p>\n<p><img src=\"/images/forense-linux-22.png\" alt=\"imagen\"></p>\n<h2 id=\"23-archivos-ocultos-2\"><a class=\"markdownIt-Anchor\" href=\"#23-archivos-ocultos-2\">#</a> 23. Archivos Ocultos.</h2>\n<p><img src=\"/images/forense-linux-23.png\" alt=\"imagen\"></p>\n<h2 id=\"24-archivos-que-contienen-una-cadena-determinada-2\"><a class=\"markdownIt-Anchor\" href=\"#24-archivos-que-contienen-una-cadena-determinada-2\">#</a> 24. Archivos que contienen una cadena determinada.</h2>\n<p>He buscado por palabras clave y he encontrado el ficher oculto.</p>\n<p><img src=\"/images/forense-linux-24.png\" alt=\"imagen\"></p>\n<h2 id=\"25-búsqueda-de-imágenes-por-ubicación-2\"><a class=\"markdownIt-Anchor\" href=\"#25-búsqueda-de-imágenes-por-ubicación-2\">#</a> 25. Búsqueda de imágenes por ubicación.</h2>\n<p><img src=\"/images/forense-linux-25.png\" alt=\"imagen\"></p>\n<h2 id=\"26-búsqueda-de-archivos-por-autor-2\"><a class=\"markdownIt-Anchor\" href=\"#26-búsqueda-de-archivos-por-autor-2\">#</a> 26. Búsqueda de archivos por autor.</h2>\n<h1 id=\"apartado-c-android\"><a class=\"markdownIt-Anchor\" href=\"#apartado-c-android\">#</a> Apartado C) Android</h1>\n<p>En un dispositivo Android, trata de hacer un volcado de memoria y recuperar información de ubicación, llamadas, mensajes, aplicaciones de mensajería, perfiles en redes sociales, etc…</p>\n<p>Al hacer el volcado de memoria con Andriller, podemos ver como muestra las cuentas que utiliza el usuario del teléfono:</p>\n<p><img src=\"/images/forense-Android-1.png\" alt=\"imagen\"></p>\n<p>Si entramos dentro de la carpeta generada llamada Apps, podemos ver las diferentes aplicaciones activas en el momento del volcado de memoria:</p>\n<p><img src=\"/images/forense-Android-3.png\" alt=\"imagen\"></p>\n<p>Si nos vamos por ejemplo dentro de la siguiente carpeta, podemos ver metainformación del emulador que estuvo usando Macarena antes del volcado de memoria:</p>\n<p><img src=\"/images/forense-Android-2.png\" alt=\"imagen\"></p>\n<p>He utilizado el teléfono de mi chica porque yo utilizo un Samsung S21, el cual tiene un sistema de seguridad llamado Knox que impide el volcado de memoria del dispositivo.</p>\n"},{"title":"Journalctl","_content":"\n![imagen](/images/jurnal-logo.png)\n\n# Centralizar journalctl en alfa.\n\n\nPara ello primero debemos actualizar los sistemas y e instalar el siguiente paquete en todo el entorno:\n\n`sudo apt update && sudo apt install systemd-journal-remote -y`\n\nEn rocky:\n\n`sudo dnf update && sudo dnf install systemd-journal-remote -y`\n\nTras esto debemos de iniciar en alfa los servicios de journalctl:\n\n\n```\nsystemctl enable --now systemd-journal-remote.socket\n\nsystemctl enable systemd-journal-remote.service\n```\n\nY en los clientes debemos de activar el servicio de journalctl:\n\n`systemctl enable systemd-journal-upload.service`\n\nAhora vamos a editar el fichero `/etc/systemd/system/systemd-journal-remote.service`\nDe forma que funcione a través de http y no de https ya que estamos dentro de un escenario cerrado.\n\n\n```\n\n[Unit]\nDescription=Journal Remote Sink Service\nDocumentation=man:systemd-journal-remote(8) man:journal-remote.conf(5)\nRequires=systemd-journal-remote.socket\n\n[Service]\nExecStart=/lib/systemd/systemd-journal-remote --listen-http=-3 --output=/var/log/journal/remote/\nUser=systemd-journal-remote\nGroup=systemd-journal-remote\nPrivateTmp=yes\nPrivateDevices=yes\nPrivateNetwork=yes\nWatchdogSec=3min\n\n[Install]\nAlso=systemd-journal-remote.socket\n```\n\n\nAhora vamos a crear la carpeta donde vamos a recopilar los logs de los clientes y darle permisos al usuario systemd-journal-remote:\n\n```\nmkdir /var/log/journal/remote\nchown systemd-journal-remote /var/log/journal/remote\n```\n\nAhora reiniciamos sudo systemctl daemon-reload: esta orden nos permite recargar todos los servicios de nuevo, muy útil por si modificamos varios de ellos, de esta forma, podremos hacerlo de forma global con todos.\n\n`systemctl daemon-reload`\n\nAhora iniciamos el servicio de recolección de logs en alfa:\n\n`systemctl start systemd-journal-remote.service`\n\nDebemos de crear el uduario systemd-journal-upload en todos los clientes para que se encargue de recopilar los logs y enviarlos a alfa:\n\n```\n#En Debian/Ubuntu\nadduser --system --home /run/systemd --no-create-home --disabled-login --group systemd-journal-upload \n\n#En Rocky\nadduser --system --home /run/systemd --no-create-home --user-group systemd-journal-upload\n```\n\nTras esto debemos de editar el fichero de journal-upload.conf para que se conecten a alfa:\n\n```\nnano /etc/systemd/journal-upload.conf\n\n[Upload]\nURL=http://alfa.antonio.gonzalonazareno.org:19532\n```\n\nY por último reiniciamos el servicio de journal-upload en todos los clientes:\n\n\n`systemctl restart systemd-journal-upload.service`\n\n\nPara comprobar que todo funciona correctamente, podemos ver en el directorio /var/log/journal/remote/ los logs de los clientes:\n\n![imagen](/images/journal-1.png)\n\nPara ver los logs de los clientes, podemos usar el comando journalctl para cada uno de los logs de los clientes:\n\ncharlie:\n`journalctl --file=/var/log/journal/remote/remote-192.168.0.2.journal`\n![imagen](/images/journal-2.png)\n\ndelta:\n`journalctl --file=/var/log/journal/remote/remote-192.168.0.2.journal`\n![imagen](/images/journal-3.png)\n\nbravo:\n\n`journalctl --file=/var/log/journal/remote/remote-172.16.0.200.journal`\n![imagen](/images/journal-4.png)\n\nDebemos realizarlo con este comando y no con un cat ya que lo que se encuentra en la carpeta es un fichero binario, lo cual no está en texto plano.","source":"_posts/journal.md","raw":"---\ntitle: Journalctl\n---\n\n![imagen](/images/jurnal-logo.png)\n\n# Centralizar journalctl en alfa.\n\n\nPara ello primero debemos actualizar los sistemas y e instalar el siguiente paquete en todo el entorno:\n\n`sudo apt update && sudo apt install systemd-journal-remote -y`\n\nEn rocky:\n\n`sudo dnf update && sudo dnf install systemd-journal-remote -y`\n\nTras esto debemos de iniciar en alfa los servicios de journalctl:\n\n\n```\nsystemctl enable --now systemd-journal-remote.socket\n\nsystemctl enable systemd-journal-remote.service\n```\n\nY en los clientes debemos de activar el servicio de journalctl:\n\n`systemctl enable systemd-journal-upload.service`\n\nAhora vamos a editar el fichero `/etc/systemd/system/systemd-journal-remote.service`\nDe forma que funcione a través de http y no de https ya que estamos dentro de un escenario cerrado.\n\n\n```\n\n[Unit]\nDescription=Journal Remote Sink Service\nDocumentation=man:systemd-journal-remote(8) man:journal-remote.conf(5)\nRequires=systemd-journal-remote.socket\n\n[Service]\nExecStart=/lib/systemd/systemd-journal-remote --listen-http=-3 --output=/var/log/journal/remote/\nUser=systemd-journal-remote\nGroup=systemd-journal-remote\nPrivateTmp=yes\nPrivateDevices=yes\nPrivateNetwork=yes\nWatchdogSec=3min\n\n[Install]\nAlso=systemd-journal-remote.socket\n```\n\n\nAhora vamos a crear la carpeta donde vamos a recopilar los logs de los clientes y darle permisos al usuario systemd-journal-remote:\n\n```\nmkdir /var/log/journal/remote\nchown systemd-journal-remote /var/log/journal/remote\n```\n\nAhora reiniciamos sudo systemctl daemon-reload: esta orden nos permite recargar todos los servicios de nuevo, muy útil por si modificamos varios de ellos, de esta forma, podremos hacerlo de forma global con todos.\n\n`systemctl daemon-reload`\n\nAhora iniciamos el servicio de recolección de logs en alfa:\n\n`systemctl start systemd-journal-remote.service`\n\nDebemos de crear el uduario systemd-journal-upload en todos los clientes para que se encargue de recopilar los logs y enviarlos a alfa:\n\n```\n#En Debian/Ubuntu\nadduser --system --home /run/systemd --no-create-home --disabled-login --group systemd-journal-upload \n\n#En Rocky\nadduser --system --home /run/systemd --no-create-home --user-group systemd-journal-upload\n```\n\nTras esto debemos de editar el fichero de journal-upload.conf para que se conecten a alfa:\n\n```\nnano /etc/systemd/journal-upload.conf\n\n[Upload]\nURL=http://alfa.antonio.gonzalonazareno.org:19532\n```\n\nY por último reiniciamos el servicio de journal-upload en todos los clientes:\n\n\n`systemctl restart systemd-journal-upload.service`\n\n\nPara comprobar que todo funciona correctamente, podemos ver en el directorio /var/log/journal/remote/ los logs de los clientes:\n\n![imagen](/images/journal-1.png)\n\nPara ver los logs de los clientes, podemos usar el comando journalctl para cada uno de los logs de los clientes:\n\ncharlie:\n`journalctl --file=/var/log/journal/remote/remote-192.168.0.2.journal`\n![imagen](/images/journal-2.png)\n\ndelta:\n`journalctl --file=/var/log/journal/remote/remote-192.168.0.2.journal`\n![imagen](/images/journal-3.png)\n\nbravo:\n\n`journalctl --file=/var/log/journal/remote/remote-172.16.0.200.journal`\n![imagen](/images/journal-4.png)\n\nDebemos realizarlo con este comando y no con un cat ya que lo que se encuentra en la carpeta es un fichero binario, lo cual no está en texto plano.","slug":"journal","published":1,"date":"2023-02-13T00:51:02.168Z","updated":"2023-02-13T01:17:22.884Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cle24lxoc0000j4i5a8vfe3gz","content":"<p><img src=\"/images/jurnal-logo.png\" alt=\"imagen\"></p>\n<h1 id=\"centralizar-journalctl-en-alfa\"><a class=\"markdownIt-Anchor\" href=\"#centralizar-journalctl-en-alfa\">#</a> Centralizar journalctl en alfa.</h1>\n<p>Para ello primero debemos actualizar los sistemas y e instalar el siguiente paquete en todo el entorno:</p>\n<p><code>sudo apt update &amp;&amp; sudo apt install systemd-journal-remote -y</code></p>\n<p>En rocky:</p>\n<p><code>sudo dnf update &amp;&amp; sudo dnf install systemd-journal-remote -y</code></p>\n<p>Tras esto debemos de iniciar en alfa los servicios de journalctl:</p>\n<pre><code>systemctl enable --now systemd-journal-remote.socket\n\nsystemctl enable systemd-journal-remote.service\n</code></pre>\n<p>Y en los clientes debemos de activar el servicio de journalctl:</p>\n<p><code>systemctl enable systemd-journal-upload.service</code></p>\n<p>Ahora vamos a editar el fichero  <code>/etc/systemd/system/systemd-journal-remote.service</code> <br>\nDe forma que funcione a través de http y no de https ya que estamos dentro de un escenario cerrado.</p>\n<pre><code>\n[Unit]\nDescription=Journal Remote Sink Service\nDocumentation=man:systemd-journal-remote(8) man:journal-remote.conf(5)\nRequires=systemd-journal-remote.socket\n\n[Service]\nExecStart=/lib/systemd/systemd-journal-remote --listen-http=-3 --output=/var/log/journal/remote/\nUser=systemd-journal-remote\nGroup=systemd-journal-remote\nPrivateTmp=yes\nPrivateDevices=yes\nPrivateNetwork=yes\nWatchdogSec=3min\n\n[Install]\nAlso=systemd-journal-remote.socket\n</code></pre>\n<p>Ahora vamos a crear la carpeta donde vamos a recopilar los logs de los clientes y darle permisos al usuario systemd-journal-remote:</p>\n<pre><code>mkdir /var/log/journal/remote\nchown systemd-journal-remote /var/log/journal/remote\n</code></pre>\n<p>Ahora reiniciamos sudo systemctl daemon-reload: esta orden nos permite recargar todos los servicios de nuevo, muy útil por si modificamos varios de ellos, de esta forma, podremos hacerlo de forma global con todos.</p>\n<p><code>systemctl daemon-reload</code></p>\n<p>Ahora iniciamos el servicio de recolección de logs en alfa:</p>\n<p><code>systemctl start systemd-journal-remote.service</code></p>\n<p>Debemos de crear el uduario systemd-journal-upload en todos los clientes para que se encargue de recopilar los logs y enviarlos a alfa:</p>\n<pre><code>#En Debian/Ubuntu\nadduser --system --home /run/systemd --no-create-home --disabled-login --group systemd-journal-upload \n\n#En Rocky\nadduser --system --home /run/systemd --no-create-home --user-group systemd-journal-upload\n</code></pre>\n<p>Tras esto debemos de editar el fichero de journal-upload.conf para que se conecten a alfa:</p>\n<pre><code>nano /etc/systemd/journal-upload.conf\n\n[Upload]\nURL=http://alfa.antonio.gonzalonazareno.org:19532\n</code></pre>\n<p>Y por último reiniciamos el servicio de journal-upload en todos los clientes:</p>\n<p><code>systemctl restart systemd-journal-upload.service</code></p>\n<p>Para comprobar que todo funciona correctamente, podemos ver en el directorio /var/log/journal/remote/ los logs de los clientes:</p>\n<p><img src=\"/images/journal-1.png\" alt=\"imagen\"></p>\n<p>Para ver los logs de los clientes, podemos usar el comando journalctl para cada uno de los logs de los clientes:</p>\n<p>charlie:<br>\n <code>journalctl --file=/var/log/journal/remote/remote-192.168.0.2.journal</code> <br>\n<img src=\"/images/journal-2.png\" alt=\"imagen\"></p>\n<p>delta:<br>\n <code>journalctl --file=/var/log/journal/remote/remote-192.168.0.2.journal</code> <br>\n<img src=\"/images/journal-3.png\" alt=\"imagen\"></p>\n<p>bravo:</p>\n<p><code>journalctl --file=/var/log/journal/remote/remote-172.16.0.200.journal</code> <br>\n<img src=\"/images/journal-4.png\" alt=\"imagen\"></p>\n<p>Debemos realizarlo con este comando y no con un cat ya que lo que se encuentra en la carpeta es un fichero binario, lo cual no está en texto plano.</p>\n","site":{"data":{}},"length":2690,"excerpt":"","more":"<p><img src=\"/images/jurnal-logo.png\" alt=\"imagen\"></p>\n<h1 id=\"centralizar-journalctl-en-alfa\"><a class=\"markdownIt-Anchor\" href=\"#centralizar-journalctl-en-alfa\">#</a> Centralizar journalctl en alfa.</h1>\n<p>Para ello primero debemos actualizar los sistemas y e instalar el siguiente paquete en todo el entorno:</p>\n<p><code>sudo apt update &amp;&amp; sudo apt install systemd-journal-remote -y</code></p>\n<p>En rocky:</p>\n<p><code>sudo dnf update &amp;&amp; sudo dnf install systemd-journal-remote -y</code></p>\n<p>Tras esto debemos de iniciar en alfa los servicios de journalctl:</p>\n<pre><code>systemctl enable --now systemd-journal-remote.socket\n\nsystemctl enable systemd-journal-remote.service\n</code></pre>\n<p>Y en los clientes debemos de activar el servicio de journalctl:</p>\n<p><code>systemctl enable systemd-journal-upload.service</code></p>\n<p>Ahora vamos a editar el fichero  <code>/etc/systemd/system/systemd-journal-remote.service</code> <br>\nDe forma que funcione a través de http y no de https ya que estamos dentro de un escenario cerrado.</p>\n<pre><code>\n[Unit]\nDescription=Journal Remote Sink Service\nDocumentation=man:systemd-journal-remote(8) man:journal-remote.conf(5)\nRequires=systemd-journal-remote.socket\n\n[Service]\nExecStart=/lib/systemd/systemd-journal-remote --listen-http=-3 --output=/var/log/journal/remote/\nUser=systemd-journal-remote\nGroup=systemd-journal-remote\nPrivateTmp=yes\nPrivateDevices=yes\nPrivateNetwork=yes\nWatchdogSec=3min\n\n[Install]\nAlso=systemd-journal-remote.socket\n</code></pre>\n<p>Ahora vamos a crear la carpeta donde vamos a recopilar los logs de los clientes y darle permisos al usuario systemd-journal-remote:</p>\n<pre><code>mkdir /var/log/journal/remote\nchown systemd-journal-remote /var/log/journal/remote\n</code></pre>\n<p>Ahora reiniciamos sudo systemctl daemon-reload: esta orden nos permite recargar todos los servicios de nuevo, muy útil por si modificamos varios de ellos, de esta forma, podremos hacerlo de forma global con todos.</p>\n<p><code>systemctl daemon-reload</code></p>\n<p>Ahora iniciamos el servicio de recolección de logs en alfa:</p>\n<p><code>systemctl start systemd-journal-remote.service</code></p>\n<p>Debemos de crear el uduario systemd-journal-upload en todos los clientes para que se encargue de recopilar los logs y enviarlos a alfa:</p>\n<pre><code>#En Debian/Ubuntu\nadduser --system --home /run/systemd --no-create-home --disabled-login --group systemd-journal-upload \n\n#En Rocky\nadduser --system --home /run/systemd --no-create-home --user-group systemd-journal-upload\n</code></pre>\n<p>Tras esto debemos de editar el fichero de journal-upload.conf para que se conecten a alfa:</p>\n<pre><code>nano /etc/systemd/journal-upload.conf\n\n[Upload]\nURL=http://alfa.antonio.gonzalonazareno.org:19532\n</code></pre>\n<p>Y por último reiniciamos el servicio de journal-upload en todos los clientes:</p>\n<p><code>systemctl restart systemd-journal-upload.service</code></p>\n<p>Para comprobar que todo funciona correctamente, podemos ver en el directorio /var/log/journal/remote/ los logs de los clientes:</p>\n<p><img src=\"/images/journal-1.png\" alt=\"imagen\"></p>\n<p>Para ver los logs de los clientes, podemos usar el comando journalctl para cada uno de los logs de los clientes:</p>\n<p>charlie:<br>\n <code>journalctl --file=/var/log/journal/remote/remote-192.168.0.2.journal</code> <br>\n<img src=\"/images/journal-2.png\" alt=\"imagen\"></p>\n<p>delta:<br>\n <code>journalctl --file=/var/log/journal/remote/remote-192.168.0.2.journal</code> <br>\n<img src=\"/images/journal-3.png\" alt=\"imagen\"></p>\n<p>bravo:</p>\n<p><code>journalctl --file=/var/log/journal/remote/remote-172.16.0.200.journal</code> <br>\n<img src=\"/images/journal-4.png\" alt=\"imagen\"></p>\n<p>Debemos realizarlo con este comando y no con un cat ya que lo que se encuentra en la carpeta es un fichero binario, lo cual no está en texto plano.</p>\n"},{"title":"Firewall 1","Categories":"firewall","_content":"\n![ssh](/images/firewall1-logo.png)\n\n\nEjecutaremos primero las reglas de entrada y salida para poder hacer conexiones ssh a la propia máquina.\n\n```\niptables -A INPUT -s 172.22.0.0/16 -p tcp --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A OUTPUT -d 172.22.0.0/16 -p tcp --sport 22 -m state --state ESTABLISHED -j ACCEPT\n\niptables -A INPUT -s 172.29.0.0/16 -p tcp --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A OUTPUT -d 172.29.0.0/16 -p tcp --sport 22 -m state --state ESTABLISHED -j ACCEPT\n```\n\n![ssh](/images/fw1-1.png)\n\nPonemos como política por defecto una lista blanca, con lo cual rechazaremos todas las conexiones:\n\n```\niptables -P INPUT DROP\niptables -P OUTPUT DROP\n```\n\nSi hacemos un ping a la ip de la máquina, no nos responde, ya que no hemos permitido el acceso a la ip de la máquina de ninguna forma, solo a través de ssh.\n\n![ssh](/images/fw1-2.png)\n\n\nAhora dentro de la máquina permitiremos el ping del localhost:\n\n```\niptables -A INPUT -i lo -p icmp -j ACCEPT\niptables -A OUTPUT -o lo -p icmp -j ACCEPT\n```\n\n![ssh](/images/fw1-3.png)\n\nAhora vamos a permitir el ping tanto de entrada como de salida de la máquina, para ello haremos un ping a una ip pública:\n\n```\niptables -A INPUT -i ens3 -p icmp --icmp-type echo-reply -j ACCEPT\niptables -A OUTPUT -o ens3 -p icmp --icmp-type echo-request -j ACCEPT\n```\n\n![ssh](/images/fw1-4.png)\n\n\nAhora vamos a permitir las consultas DNS de entrada y salida de la máquina al exterior:\n\n```\niptables -A OUTPUT -o ens3 -p udp --dport 53 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A INPUT -i ens3 -p udp --sport 53 -m state --state ESTABLISHED -j ACCEPT\n```\n\n![ssh](/images/fw1-5.png)\n\n\nA continuación permitiremos el tráfico web de entrada y salida de la máquina al exterior por http y https:\n\n```\niptables -A OUTPUT -o ens3 -p tcp --match multiport --dports 80,443 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A INPUT -i ens3 -p tcp --match multiport --sports 80,443 -m state --state ESTABLISHED -j ACCEPT\n```\n\nMuestro la prueba de que puedo navegar al puerto 80 y a mi web que es a través de https:\n\n![ssh](/images/fw1-6.png)\n\n\n\nAhora vamos a permitir el tráfico hacia el servidor apache instalado:\n\n```\niptables -A INPUT -i ens3 -p tcp --dport 80 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A OUTPUT -o ens3 -p tcp --sport 80 -m state --state ESTABLISHED -j ACCEPT\n```\n\n\n![ssh](/images/fw1-7.png)\n\n# Ejercicios\n\n## Permite poder hacer conexiones ssh al exterior.\n\n```\niptables -A INPUT -i ens3 -p tcp --sport 22 -m state --state ESTABLISHED -j ACCEPT\niptables -A OUTPUT -o ens3 -p tcp --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPT\n```\n\nNos conectamos a otra máquina que tenemos en la red de Openstack\n\n![ssh](/images/fw1-8.png)\n\n## Deniega el acceso a tu servidor web desde una ip concreta.\n\nVamos a denegar el acceso web a mi máquina local, con lo cual vamos a bloquear la ip de la vpn:\n\n```\niptables -A INPUT ! -s 172.29.0.14 -p tcp --dport 80 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A OUTPUT ! -d 172.29.0.14 -p tcp --sport 80 -m state --state ESTABLISHED -j ACCEPT\n```\n\n![ssh](/images/fw1-9.png)\n\n\n## Permite hacer consultas DNS sólo al servidor 192.168.202.2. Comprueba que no puedes hacer un dig @1.1.1.1.\n\n\nPrimero vamos a borrar las reglas que permite el acceso a todos los DNS:\n\n```\niptables -L --line-numbers\n```\n\n\n```\niptables -D INPUT 6\niptables -D OUTPUT 6\n```\n\n\n```\niptables -A INPUT -s 192.168.202.2 -p udp --sport 53 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A OUTPUT -d 192.168.202.2 -p udp --dport 53 -m state --state NEW,ESTABLISHED -j ACCEPT\n```\n\n\n![ssh](/images/fw1-10.png)\n\n\n## No permitir el acceso al servidor web de www.josedomingo.org (Tienes que utilizar la ip). ¿Puedes acceder a fp.josedomingo.org?\n\n```\ndig www.josedomingo.org\n\n37.187.119.60\n```\n\nAhora vamos a establecer una regla por encima a la de permitir todas las conexiones al puerto 80, porque cuando lee esa regla, ignora la del bloqueo que podamos ponerle, entonces establecemos la regla por encima de la que permite todas las conexiones al puerto 80:\n\nPrimero averiguamos la posición de la regla con iptaules -L --line-numbers\n\n![ssh](/images/fw1-11.png)\n\nVemos que se encuentra en la posición 6, entonces vamos a insertar la regla en la posición 5:\n\n```\niptables -I OUTPUT 6 -d 37.187.119.60 -p tcp --dport 80 -m state --state NEW,ESTABLISHED -j DROP\n```\n\nAhora vemos que la regla queda por encima:\n\n![ssh](/images/fw1-12.png)\n\n\nPodemos acceder a mi web, pero no a la de www.josedomingo.org ni a la de fp.josedomingo.org ya que se encuentran bajo la misma ip\n\n![ssh](/images/fw1-13.png)\n\n## Permite mandar un correo usando nuestro servidor de correo: babuino-smtp. Para probarlo ejecuta un telnet bubuino-smtp.gonzalonazareno.org 25.\n\napt update && apt install telnet -y\n\ndig babuino-smtp.gonzalonazareno.org\n\n```\niptables -A INPUT -s 192.168.203.3 -p tcp --sport 25 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A OUTPUT -d 192.168.203.3 -p tcp --dport 25 -m state --state NEW,ESTABLISHED -j ACCEPT\n```\n\nAhora podemos comprobar que podemos mandar un correo a babuino-smtp.gonzalonazareno.org por el puerto 25:\n\n![ssh](/images/fw1-14.png)\n\n\n## Instala un servidor mariadb, y permite los accesos desde la ip de tu cliente. Comprueba que desde otro cliente no se puede acceder.\n\nInstalamos el servidor mariadb:\n\n```\napt install mariadb-server -y\n```\n\nLuego vamos al archivo de configuración de mariadb:\n\n```\nnano /etc/mysql/mariadb.conf.d/50-server.cnf\n```\n\ny ponemos el bind-address:\n\n```\nbind-address            = 0.0.0.0\n```\n\nLuego establecemos las reglas dando paso a la ip de mi cliente:\n\n```\niptables -A INPUT -s 10.0.0.112 -p tcp --dport 3306 -j ACCEPT\niptables -A OUTPUT -d 10.0.0.112 -p tcp --sport 3306 -j ACCEPT\n```\n\nEn la izquierda vemos que la máquina cliente puede acceder al servidor mariadb, pero en la derecha no, ya que no le hemos dado paso a delta de nuestro escenario:\n\n![ssh](/images/fw1-15.png)\n\n\nPero si le damos permiso a delta:\n\nPara ello debemos darle permiso a la ip pública del escenario, que sería alfa:\n\n```\niptables -A INPUT -s 10.0.0.175 -p tcp --dport 3306 -j ACCEPT\niptables -A OUTPUT -d 10.0.0.175 -p tcp --sport 3306 -j ACCEPT\n```\n\nAhora podemos ver como delta puede conectar con el servidor mariadb:\n\n![ssh](/images/fw1-16.png)","source":"_posts/fw1.md","raw":"---\ntitle: Firewall 1\nCategories: firewall\n---\n\n![ssh](/images/firewall1-logo.png)\n\n\nEjecutaremos primero las reglas de entrada y salida para poder hacer conexiones ssh a la propia máquina.\n\n```\niptables -A INPUT -s 172.22.0.0/16 -p tcp --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A OUTPUT -d 172.22.0.0/16 -p tcp --sport 22 -m state --state ESTABLISHED -j ACCEPT\n\niptables -A INPUT -s 172.29.0.0/16 -p tcp --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A OUTPUT -d 172.29.0.0/16 -p tcp --sport 22 -m state --state ESTABLISHED -j ACCEPT\n```\n\n![ssh](/images/fw1-1.png)\n\nPonemos como política por defecto una lista blanca, con lo cual rechazaremos todas las conexiones:\n\n```\niptables -P INPUT DROP\niptables -P OUTPUT DROP\n```\n\nSi hacemos un ping a la ip de la máquina, no nos responde, ya que no hemos permitido el acceso a la ip de la máquina de ninguna forma, solo a través de ssh.\n\n![ssh](/images/fw1-2.png)\n\n\nAhora dentro de la máquina permitiremos el ping del localhost:\n\n```\niptables -A INPUT -i lo -p icmp -j ACCEPT\niptables -A OUTPUT -o lo -p icmp -j ACCEPT\n```\n\n![ssh](/images/fw1-3.png)\n\nAhora vamos a permitir el ping tanto de entrada como de salida de la máquina, para ello haremos un ping a una ip pública:\n\n```\niptables -A INPUT -i ens3 -p icmp --icmp-type echo-reply -j ACCEPT\niptables -A OUTPUT -o ens3 -p icmp --icmp-type echo-request -j ACCEPT\n```\n\n![ssh](/images/fw1-4.png)\n\n\nAhora vamos a permitir las consultas DNS de entrada y salida de la máquina al exterior:\n\n```\niptables -A OUTPUT -o ens3 -p udp --dport 53 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A INPUT -i ens3 -p udp --sport 53 -m state --state ESTABLISHED -j ACCEPT\n```\n\n![ssh](/images/fw1-5.png)\n\n\nA continuación permitiremos el tráfico web de entrada y salida de la máquina al exterior por http y https:\n\n```\niptables -A OUTPUT -o ens3 -p tcp --match multiport --dports 80,443 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A INPUT -i ens3 -p tcp --match multiport --sports 80,443 -m state --state ESTABLISHED -j ACCEPT\n```\n\nMuestro la prueba de que puedo navegar al puerto 80 y a mi web que es a través de https:\n\n![ssh](/images/fw1-6.png)\n\n\n\nAhora vamos a permitir el tráfico hacia el servidor apache instalado:\n\n```\niptables -A INPUT -i ens3 -p tcp --dport 80 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A OUTPUT -o ens3 -p tcp --sport 80 -m state --state ESTABLISHED -j ACCEPT\n```\n\n\n![ssh](/images/fw1-7.png)\n\n# Ejercicios\n\n## Permite poder hacer conexiones ssh al exterior.\n\n```\niptables -A INPUT -i ens3 -p tcp --sport 22 -m state --state ESTABLISHED -j ACCEPT\niptables -A OUTPUT -o ens3 -p tcp --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPT\n```\n\nNos conectamos a otra máquina que tenemos en la red de Openstack\n\n![ssh](/images/fw1-8.png)\n\n## Deniega el acceso a tu servidor web desde una ip concreta.\n\nVamos a denegar el acceso web a mi máquina local, con lo cual vamos a bloquear la ip de la vpn:\n\n```\niptables -A INPUT ! -s 172.29.0.14 -p tcp --dport 80 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A OUTPUT ! -d 172.29.0.14 -p tcp --sport 80 -m state --state ESTABLISHED -j ACCEPT\n```\n\n![ssh](/images/fw1-9.png)\n\n\n## Permite hacer consultas DNS sólo al servidor 192.168.202.2. Comprueba que no puedes hacer un dig @1.1.1.1.\n\n\nPrimero vamos a borrar las reglas que permite el acceso a todos los DNS:\n\n```\niptables -L --line-numbers\n```\n\n\n```\niptables -D INPUT 6\niptables -D OUTPUT 6\n```\n\n\n```\niptables -A INPUT -s 192.168.202.2 -p udp --sport 53 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A OUTPUT -d 192.168.202.2 -p udp --dport 53 -m state --state NEW,ESTABLISHED -j ACCEPT\n```\n\n\n![ssh](/images/fw1-10.png)\n\n\n## No permitir el acceso al servidor web de www.josedomingo.org (Tienes que utilizar la ip). ¿Puedes acceder a fp.josedomingo.org?\n\n```\ndig www.josedomingo.org\n\n37.187.119.60\n```\n\nAhora vamos a establecer una regla por encima a la de permitir todas las conexiones al puerto 80, porque cuando lee esa regla, ignora la del bloqueo que podamos ponerle, entonces establecemos la regla por encima de la que permite todas las conexiones al puerto 80:\n\nPrimero averiguamos la posición de la regla con iptaules -L --line-numbers\n\n![ssh](/images/fw1-11.png)\n\nVemos que se encuentra en la posición 6, entonces vamos a insertar la regla en la posición 5:\n\n```\niptables -I OUTPUT 6 -d 37.187.119.60 -p tcp --dport 80 -m state --state NEW,ESTABLISHED -j DROP\n```\n\nAhora vemos que la regla queda por encima:\n\n![ssh](/images/fw1-12.png)\n\n\nPodemos acceder a mi web, pero no a la de www.josedomingo.org ni a la de fp.josedomingo.org ya que se encuentran bajo la misma ip\n\n![ssh](/images/fw1-13.png)\n\n## Permite mandar un correo usando nuestro servidor de correo: babuino-smtp. Para probarlo ejecuta un telnet bubuino-smtp.gonzalonazareno.org 25.\n\napt update && apt install telnet -y\n\ndig babuino-smtp.gonzalonazareno.org\n\n```\niptables -A INPUT -s 192.168.203.3 -p tcp --sport 25 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A OUTPUT -d 192.168.203.3 -p tcp --dport 25 -m state --state NEW,ESTABLISHED -j ACCEPT\n```\n\nAhora podemos comprobar que podemos mandar un correo a babuino-smtp.gonzalonazareno.org por el puerto 25:\n\n![ssh](/images/fw1-14.png)\n\n\n## Instala un servidor mariadb, y permite los accesos desde la ip de tu cliente. Comprueba que desde otro cliente no se puede acceder.\n\nInstalamos el servidor mariadb:\n\n```\napt install mariadb-server -y\n```\n\nLuego vamos al archivo de configuración de mariadb:\n\n```\nnano /etc/mysql/mariadb.conf.d/50-server.cnf\n```\n\ny ponemos el bind-address:\n\n```\nbind-address            = 0.0.0.0\n```\n\nLuego establecemos las reglas dando paso a la ip de mi cliente:\n\n```\niptables -A INPUT -s 10.0.0.112 -p tcp --dport 3306 -j ACCEPT\niptables -A OUTPUT -d 10.0.0.112 -p tcp --sport 3306 -j ACCEPT\n```\n\nEn la izquierda vemos que la máquina cliente puede acceder al servidor mariadb, pero en la derecha no, ya que no le hemos dado paso a delta de nuestro escenario:\n\n![ssh](/images/fw1-15.png)\n\n\nPero si le damos permiso a delta:\n\nPara ello debemos darle permiso a la ip pública del escenario, que sería alfa:\n\n```\niptables -A INPUT -s 10.0.0.175 -p tcp --dport 3306 -j ACCEPT\niptables -A OUTPUT -d 10.0.0.175 -p tcp --sport 3306 -j ACCEPT\n```\n\nAhora podemos ver como delta puede conectar con el servidor mariadb:\n\n![ssh](/images/fw1-16.png)","slug":"fw1","published":1,"date":"2023-02-15T13:27:19.594Z","updated":"2023-02-20T21:01:54.628Z","_id":"cle6jfkny0000dwi54jvk4ltq","comments":1,"layout":"post","photos":[],"link":"","content":"<p><img src=\"/images/firewall1-logo.png\" alt=\"ssh\"></p>\n<p>Ejecutaremos primero las reglas de entrada y salida para poder hacer conexiones ssh a la propia máquina.</p>\n<pre><code>iptables -A INPUT -s 172.22.0.0/16 -p tcp --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A OUTPUT -d 172.22.0.0/16 -p tcp --sport 22 -m state --state ESTABLISHED -j ACCEPT\n\niptables -A INPUT -s 172.29.0.0/16 -p tcp --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A OUTPUT -d 172.29.0.0/16 -p tcp --sport 22 -m state --state ESTABLISHED -j ACCEPT\n</code></pre>\n<p><img src=\"/images/fw1-1.png\" alt=\"ssh\"></p>\n<p>Ponemos como política por defecto una lista blanca, con lo cual rechazaremos todas las conexiones:</p>\n<pre><code>iptables -P INPUT DROP\niptables -P OUTPUT DROP\n</code></pre>\n<p>Si hacemos un ping a la ip de la máquina, no nos responde, ya que no hemos permitido el acceso a la ip de la máquina de ninguna forma, solo a través de ssh.</p>\n<p><img src=\"/images/fw1-2.png\" alt=\"ssh\"></p>\n<p>Ahora dentro de la máquina permitiremos el ping del localhost:</p>\n<pre><code>iptables -A INPUT -i lo -p icmp -j ACCEPT\niptables -A OUTPUT -o lo -p icmp -j ACCEPT\n</code></pre>\n<p><img src=\"/images/fw1-3.png\" alt=\"ssh\"></p>\n<p>Ahora vamos a permitir el ping tanto de entrada como de salida de la máquina, para ello haremos un ping a una ip pública:</p>\n<pre><code>iptables -A INPUT -i ens3 -p icmp --icmp-type echo-reply -j ACCEPT\niptables -A OUTPUT -o ens3 -p icmp --icmp-type echo-request -j ACCEPT\n</code></pre>\n<p><img src=\"/images/fw1-4.png\" alt=\"ssh\"></p>\n<p>Ahora vamos a permitir las consultas DNS de entrada y salida de la máquina al exterior:</p>\n<pre><code>iptables -A OUTPUT -o ens3 -p udp --dport 53 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A INPUT -i ens3 -p udp --sport 53 -m state --state ESTABLISHED -j ACCEPT\n</code></pre>\n<p><img src=\"/images/fw1-5.png\" alt=\"ssh\"></p>\n<p>A continuación permitiremos el tráfico web de entrada y salida de la máquina al exterior por http y https:</p>\n<pre><code>iptables -A OUTPUT -o ens3 -p tcp --match multiport --dports 80,443 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A INPUT -i ens3 -p tcp --match multiport --sports 80,443 -m state --state ESTABLISHED -j ACCEPT\n</code></pre>\n<p>Muestro la prueba de que puedo navegar al puerto 80 y a mi web que es a través de https:</p>\n<p><img src=\"/images/fw1-6.png\" alt=\"ssh\"></p>\n<p>Ahora vamos a permitir el tráfico hacia el servidor apache instalado:</p>\n<pre><code>iptables -A INPUT -i ens3 -p tcp --dport 80 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A OUTPUT -o ens3 -p tcp --sport 80 -m state --state ESTABLISHED -j ACCEPT\n</code></pre>\n<p><img src=\"/images/fw1-7.png\" alt=\"ssh\"></p>\n<h1 id=\"ejercicios\"><a class=\"markdownIt-Anchor\" href=\"#ejercicios\">#</a> Ejercicios</h1>\n<h2 id=\"permite-poder-hacer-conexiones-ssh-al-exterior\"><a class=\"markdownIt-Anchor\" href=\"#permite-poder-hacer-conexiones-ssh-al-exterior\">#</a> Permite poder hacer conexiones ssh al exterior.</h2>\n<pre><code>iptables -A INPUT -i ens3 -p tcp --sport 22 -m state --state ESTABLISHED -j ACCEPT\niptables -A OUTPUT -o ens3 -p tcp --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPT\n</code></pre>\n<p>Nos conectamos a otra máquina que tenemos en la red de Openstack</p>\n<p><img src=\"/images/fw1-8.png\" alt=\"ssh\"></p>\n<h2 id=\"deniega-el-acceso-a-tu-servidor-web-desde-una-ip-concreta\"><a class=\"markdownIt-Anchor\" href=\"#deniega-el-acceso-a-tu-servidor-web-desde-una-ip-concreta\">#</a> Deniega el acceso a tu servidor web desde una ip concreta.</h2>\n<p>Vamos a denegar el acceso web a mi máquina local, con lo cual vamos a bloquear la ip de la vpn:</p>\n<pre><code>iptables -A INPUT ! -s 172.29.0.14 -p tcp --dport 80 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A OUTPUT ! -d 172.29.0.14 -p tcp --sport 80 -m state --state ESTABLISHED -j ACCEPT\n</code></pre>\n<p><img src=\"/images/fw1-9.png\" alt=\"ssh\"></p>\n<h2 id=\"permite-hacer-consultas-dns-sólo-al-servidor-1921682022-comprueba-que-no-puedes-hacer-un-dig-1111\"><a class=\"markdownIt-Anchor\" href=\"#permite-hacer-consultas-dns-sólo-al-servidor-1921682022-comprueba-que-no-puedes-hacer-un-dig-1111\">#</a> Permite hacer consultas DNS sólo al servidor 192.168.202.2. Comprueba que no puedes hacer un dig @1.1.1.1.</h2>\n<p>Primero vamos a borrar las reglas que permite el acceso a todos los DNS:</p>\n<pre><code>iptables -L --line-numbers\n</code></pre>\n<pre><code>iptables -D INPUT 6\niptables -D OUTPUT 6\n</code></pre>\n<pre><code>iptables -A INPUT -s 192.168.202.2 -p udp --sport 53 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A OUTPUT -d 192.168.202.2 -p udp --dport 53 -m state --state NEW,ESTABLISHED -j ACCEPT\n</code></pre>\n<p><img src=\"/images/fw1-10.png\" alt=\"ssh\"></p>\n<h2 id=\"no-permitir-el-acceso-al-servidor-web-de-wwwjosedomingoorg-tienes-que-utilizar-la-ip-puedes-acceder-a-fpjosedomingoorg\"><a class=\"markdownIt-Anchor\" href=\"#no-permitir-el-acceso-al-servidor-web-de-wwwjosedomingoorg-tienes-que-utilizar-la-ip-puedes-acceder-a-fpjosedomingoorg\">#</a> No permitir el acceso al servidor web de <a href=\"http://www.josedomingo.org\">www.josedomingo.org</a> (Tienes que utilizar la ip). ¿Puedes acceder a <a href=\"http://fp.josedomingo.org\">fp.josedomingo.org</a>?</h2>\n<pre><code>dig www.josedomingo.org\n\n37.187.119.60\n</code></pre>\n<p>Ahora vamos a establecer una regla por encima a la de permitir todas las conexiones al puerto 80, porque cuando lee esa regla, ignora la del bloqueo que podamos ponerle, entonces establecemos la regla por encima de la que permite todas las conexiones al puerto 80:</p>\n<p>Primero averiguamos la posición de la regla con iptaules -L --line-numbers</p>\n<p><img src=\"/images/fw1-11.png\" alt=\"ssh\"></p>\n<p>Vemos que se encuentra en la posición 6, entonces vamos a insertar la regla en la posición 5:</p>\n<pre><code>iptables -I OUTPUT 6 -d 37.187.119.60 -p tcp --dport 80 -m state --state NEW,ESTABLISHED -j DROP\n</code></pre>\n<p>Ahora vemos que la regla queda por encima:</p>\n<p><img src=\"/images/fw1-12.png\" alt=\"ssh\"></p>\n<p>Podemos acceder a mi web, pero no a la de <a href=\"http://www.josedomingo.org\">www.josedomingo.org</a> ni a la de <a href=\"http://fp.josedomingo.org\">fp.josedomingo.org</a> ya que se encuentran bajo la misma ip</p>\n<p><img src=\"/images/fw1-13.png\" alt=\"ssh\"></p>\n<h2 id=\"permite-mandar-un-correo-usando-nuestro-servidor-de-correo-babuino-smtp-para-probarlo-ejecuta-un-telnet-bubuino-smtpgonzalonazarenoorg-25\"><a class=\"markdownIt-Anchor\" href=\"#permite-mandar-un-correo-usando-nuestro-servidor-de-correo-babuino-smtp-para-probarlo-ejecuta-un-telnet-bubuino-smtpgonzalonazarenoorg-25\">#</a> Permite mandar un correo usando nuestro servidor de correo: babuino-smtp. Para probarlo ejecuta un telnet <a href=\"http://bubuino-smtp.gonzalonazareno.org\">bubuino-smtp.gonzalonazareno.org</a> 25.</h2>\n<p>apt update &amp;&amp; apt install telnet -y</p>\n<p>dig <a href=\"http://babuino-smtp.gonzalonazareno.org\">babuino-smtp.gonzalonazareno.org</a></p>\n<pre><code>iptables -A INPUT -s 192.168.203.3 -p tcp --sport 25 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A OUTPUT -d 192.168.203.3 -p tcp --dport 25 -m state --state NEW,ESTABLISHED -j ACCEPT\n</code></pre>\n<p>Ahora podemos comprobar que podemos mandar un correo a <a href=\"http://babuino-smtp.gonzalonazareno.org\">babuino-smtp.gonzalonazareno.org</a> por el puerto 25:</p>\n<p><img src=\"/images/fw1-14.png\" alt=\"ssh\"></p>\n<h2 id=\"instala-un-servidor-mariadb-y-permite-los-accesos-desde-la-ip-de-tu-cliente-comprueba-que-desde-otro-cliente-no-se-puede-acceder\"><a class=\"markdownIt-Anchor\" href=\"#instala-un-servidor-mariadb-y-permite-los-accesos-desde-la-ip-de-tu-cliente-comprueba-que-desde-otro-cliente-no-se-puede-acceder\">#</a> Instala un servidor mariadb, y permite los accesos desde la ip de tu cliente. Comprueba que desde otro cliente no se puede acceder.</h2>\n<p>Instalamos el servidor mariadb:</p>\n<pre><code>apt install mariadb-server -y\n</code></pre>\n<p>Luego vamos al archivo de configuración de mariadb:</p>\n<pre><code>nano /etc/mysql/mariadb.conf.d/50-server.cnf\n</code></pre>\n<p>y ponemos el bind-address:</p>\n<pre><code>bind-address            = 0.0.0.0\n</code></pre>\n<p>Luego establecemos las reglas dando paso a la ip de mi cliente:</p>\n<pre><code>iptables -A INPUT -s 10.0.0.112 -p tcp --dport 3306 -j ACCEPT\niptables -A OUTPUT -d 10.0.0.112 -p tcp --sport 3306 -j ACCEPT\n</code></pre>\n<p>En la izquierda vemos que la máquina cliente puede acceder al servidor mariadb, pero en la derecha no, ya que no le hemos dado paso a delta de nuestro escenario:</p>\n<p><img src=\"/images/fw1-15.png\" alt=\"ssh\"></p>\n<p>Pero si le damos permiso a delta:</p>\n<p>Para ello debemos darle permiso a la ip pública del escenario, que sería alfa:</p>\n<pre><code>iptables -A INPUT -s 10.0.0.175 -p tcp --dport 3306 -j ACCEPT\niptables -A OUTPUT -d 10.0.0.175 -p tcp --sport 3306 -j ACCEPT\n</code></pre>\n<p>Ahora podemos ver como delta puede conectar con el servidor mariadb:</p>\n<p><img src=\"/images/fw1-16.png\" alt=\"ssh\"></p>\n","site":{"data":{}},"length":4652,"excerpt":"","more":"<p><img src=\"/images/firewall1-logo.png\" alt=\"ssh\"></p>\n<p>Ejecutaremos primero las reglas de entrada y salida para poder hacer conexiones ssh a la propia máquina.</p>\n<pre><code>iptables -A INPUT -s 172.22.0.0/16 -p tcp --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A OUTPUT -d 172.22.0.0/16 -p tcp --sport 22 -m state --state ESTABLISHED -j ACCEPT\n\niptables -A INPUT -s 172.29.0.0/16 -p tcp --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A OUTPUT -d 172.29.0.0/16 -p tcp --sport 22 -m state --state ESTABLISHED -j ACCEPT\n</code></pre>\n<p><img src=\"/images/fw1-1.png\" alt=\"ssh\"></p>\n<p>Ponemos como política por defecto una lista blanca, con lo cual rechazaremos todas las conexiones:</p>\n<pre><code>iptables -P INPUT DROP\niptables -P OUTPUT DROP\n</code></pre>\n<p>Si hacemos un ping a la ip de la máquina, no nos responde, ya que no hemos permitido el acceso a la ip de la máquina de ninguna forma, solo a través de ssh.</p>\n<p><img src=\"/images/fw1-2.png\" alt=\"ssh\"></p>\n<p>Ahora dentro de la máquina permitiremos el ping del localhost:</p>\n<pre><code>iptables -A INPUT -i lo -p icmp -j ACCEPT\niptables -A OUTPUT -o lo -p icmp -j ACCEPT\n</code></pre>\n<p><img src=\"/images/fw1-3.png\" alt=\"ssh\"></p>\n<p>Ahora vamos a permitir el ping tanto de entrada como de salida de la máquina, para ello haremos un ping a una ip pública:</p>\n<pre><code>iptables -A INPUT -i ens3 -p icmp --icmp-type echo-reply -j ACCEPT\niptables -A OUTPUT -o ens3 -p icmp --icmp-type echo-request -j ACCEPT\n</code></pre>\n<p><img src=\"/images/fw1-4.png\" alt=\"ssh\"></p>\n<p>Ahora vamos a permitir las consultas DNS de entrada y salida de la máquina al exterior:</p>\n<pre><code>iptables -A OUTPUT -o ens3 -p udp --dport 53 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A INPUT -i ens3 -p udp --sport 53 -m state --state ESTABLISHED -j ACCEPT\n</code></pre>\n<p><img src=\"/images/fw1-5.png\" alt=\"ssh\"></p>\n<p>A continuación permitiremos el tráfico web de entrada y salida de la máquina al exterior por http y https:</p>\n<pre><code>iptables -A OUTPUT -o ens3 -p tcp --match multiport --dports 80,443 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A INPUT -i ens3 -p tcp --match multiport --sports 80,443 -m state --state ESTABLISHED -j ACCEPT\n</code></pre>\n<p>Muestro la prueba de que puedo navegar al puerto 80 y a mi web que es a través de https:</p>\n<p><img src=\"/images/fw1-6.png\" alt=\"ssh\"></p>\n<p>Ahora vamos a permitir el tráfico hacia el servidor apache instalado:</p>\n<pre><code>iptables -A INPUT -i ens3 -p tcp --dport 80 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A OUTPUT -o ens3 -p tcp --sport 80 -m state --state ESTABLISHED -j ACCEPT\n</code></pre>\n<p><img src=\"/images/fw1-7.png\" alt=\"ssh\"></p>\n<h1 id=\"ejercicios\"><a class=\"markdownIt-Anchor\" href=\"#ejercicios\">#</a> Ejercicios</h1>\n<h2 id=\"permite-poder-hacer-conexiones-ssh-al-exterior\"><a class=\"markdownIt-Anchor\" href=\"#permite-poder-hacer-conexiones-ssh-al-exterior\">#</a> Permite poder hacer conexiones ssh al exterior.</h2>\n<pre><code>iptables -A INPUT -i ens3 -p tcp --sport 22 -m state --state ESTABLISHED -j ACCEPT\niptables -A OUTPUT -o ens3 -p tcp --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPT\n</code></pre>\n<p>Nos conectamos a otra máquina que tenemos en la red de Openstack</p>\n<p><img src=\"/images/fw1-8.png\" alt=\"ssh\"></p>\n<h2 id=\"deniega-el-acceso-a-tu-servidor-web-desde-una-ip-concreta\"><a class=\"markdownIt-Anchor\" href=\"#deniega-el-acceso-a-tu-servidor-web-desde-una-ip-concreta\">#</a> Deniega el acceso a tu servidor web desde una ip concreta.</h2>\n<p>Vamos a denegar el acceso web a mi máquina local, con lo cual vamos a bloquear la ip de la vpn:</p>\n<pre><code>iptables -A INPUT ! -s 172.29.0.14 -p tcp --dport 80 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A OUTPUT ! -d 172.29.0.14 -p tcp --sport 80 -m state --state ESTABLISHED -j ACCEPT\n</code></pre>\n<p><img src=\"/images/fw1-9.png\" alt=\"ssh\"></p>\n<h2 id=\"permite-hacer-consultas-dns-sólo-al-servidor-1921682022-comprueba-que-no-puedes-hacer-un-dig-1111\"><a class=\"markdownIt-Anchor\" href=\"#permite-hacer-consultas-dns-sólo-al-servidor-1921682022-comprueba-que-no-puedes-hacer-un-dig-1111\">#</a> Permite hacer consultas DNS sólo al servidor 192.168.202.2. Comprueba que no puedes hacer un dig @1.1.1.1.</h2>\n<p>Primero vamos a borrar las reglas que permite el acceso a todos los DNS:</p>\n<pre><code>iptables -L --line-numbers\n</code></pre>\n<pre><code>iptables -D INPUT 6\niptables -D OUTPUT 6\n</code></pre>\n<pre><code>iptables -A INPUT -s 192.168.202.2 -p udp --sport 53 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A OUTPUT -d 192.168.202.2 -p udp --dport 53 -m state --state NEW,ESTABLISHED -j ACCEPT\n</code></pre>\n<p><img src=\"/images/fw1-10.png\" alt=\"ssh\"></p>\n<h2 id=\"no-permitir-el-acceso-al-servidor-web-de-wwwjosedomingoorg-tienes-que-utilizar-la-ip-puedes-acceder-a-fpjosedomingoorg\"><a class=\"markdownIt-Anchor\" href=\"#no-permitir-el-acceso-al-servidor-web-de-wwwjosedomingoorg-tienes-que-utilizar-la-ip-puedes-acceder-a-fpjosedomingoorg\">#</a> No permitir el acceso al servidor web de <a href=\"http://www.josedomingo.org\">www.josedomingo.org</a> (Tienes que utilizar la ip). ¿Puedes acceder a <a href=\"http://fp.josedomingo.org\">fp.josedomingo.org</a>?</h2>\n<pre><code>dig www.josedomingo.org\n\n37.187.119.60\n</code></pre>\n<p>Ahora vamos a establecer una regla por encima a la de permitir todas las conexiones al puerto 80, porque cuando lee esa regla, ignora la del bloqueo que podamos ponerle, entonces establecemos la regla por encima de la que permite todas las conexiones al puerto 80:</p>\n<p>Primero averiguamos la posición de la regla con iptaules -L --line-numbers</p>\n<p><img src=\"/images/fw1-11.png\" alt=\"ssh\"></p>\n<p>Vemos que se encuentra en la posición 6, entonces vamos a insertar la regla en la posición 5:</p>\n<pre><code>iptables -I OUTPUT 6 -d 37.187.119.60 -p tcp --dport 80 -m state --state NEW,ESTABLISHED -j DROP\n</code></pre>\n<p>Ahora vemos que la regla queda por encima:</p>\n<p><img src=\"/images/fw1-12.png\" alt=\"ssh\"></p>\n<p>Podemos acceder a mi web, pero no a la de <a href=\"http://www.josedomingo.org\">www.josedomingo.org</a> ni a la de <a href=\"http://fp.josedomingo.org\">fp.josedomingo.org</a> ya que se encuentran bajo la misma ip</p>\n<p><img src=\"/images/fw1-13.png\" alt=\"ssh\"></p>\n<h2 id=\"permite-mandar-un-correo-usando-nuestro-servidor-de-correo-babuino-smtp-para-probarlo-ejecuta-un-telnet-bubuino-smtpgonzalonazarenoorg-25\"><a class=\"markdownIt-Anchor\" href=\"#permite-mandar-un-correo-usando-nuestro-servidor-de-correo-babuino-smtp-para-probarlo-ejecuta-un-telnet-bubuino-smtpgonzalonazarenoorg-25\">#</a> Permite mandar un correo usando nuestro servidor de correo: babuino-smtp. Para probarlo ejecuta un telnet <a href=\"http://bubuino-smtp.gonzalonazareno.org\">bubuino-smtp.gonzalonazareno.org</a> 25.</h2>\n<p>apt update &amp;&amp; apt install telnet -y</p>\n<p>dig <a href=\"http://babuino-smtp.gonzalonazareno.org\">babuino-smtp.gonzalonazareno.org</a></p>\n<pre><code>iptables -A INPUT -s 192.168.203.3 -p tcp --sport 25 -m state --state NEW,ESTABLISHED -j ACCEPT\niptables -A OUTPUT -d 192.168.203.3 -p tcp --dport 25 -m state --state NEW,ESTABLISHED -j ACCEPT\n</code></pre>\n<p>Ahora podemos comprobar que podemos mandar un correo a <a href=\"http://babuino-smtp.gonzalonazareno.org\">babuino-smtp.gonzalonazareno.org</a> por el puerto 25:</p>\n<p><img src=\"/images/fw1-14.png\" alt=\"ssh\"></p>\n<h2 id=\"instala-un-servidor-mariadb-y-permite-los-accesos-desde-la-ip-de-tu-cliente-comprueba-que-desde-otro-cliente-no-se-puede-acceder\"><a class=\"markdownIt-Anchor\" href=\"#instala-un-servidor-mariadb-y-permite-los-accesos-desde-la-ip-de-tu-cliente-comprueba-que-desde-otro-cliente-no-se-puede-acceder\">#</a> Instala un servidor mariadb, y permite los accesos desde la ip de tu cliente. Comprueba que desde otro cliente no se puede acceder.</h2>\n<p>Instalamos el servidor mariadb:</p>\n<pre><code>apt install mariadb-server -y\n</code></pre>\n<p>Luego vamos al archivo de configuración de mariadb:</p>\n<pre><code>nano /etc/mysql/mariadb.conf.d/50-server.cnf\n</code></pre>\n<p>y ponemos el bind-address:</p>\n<pre><code>bind-address            = 0.0.0.0\n</code></pre>\n<p>Luego establecemos las reglas dando paso a la ip de mi cliente:</p>\n<pre><code>iptables -A INPUT -s 10.0.0.112 -p tcp --dport 3306 -j ACCEPT\niptables -A OUTPUT -d 10.0.0.112 -p tcp --sport 3306 -j ACCEPT\n</code></pre>\n<p>En la izquierda vemos que la máquina cliente puede acceder al servidor mariadb, pero en la derecha no, ya que no le hemos dado paso a delta de nuestro escenario:</p>\n<p><img src=\"/images/fw1-15.png\" alt=\"ssh\"></p>\n<p>Pero si le damos permiso a delta:</p>\n<p>Para ello debemos darle permiso a la ip pública del escenario, que sería alfa:</p>\n<pre><code>iptables -A INPUT -s 10.0.0.175 -p tcp --dport 3306 -j ACCEPT\niptables -A OUTPUT -d 10.0.0.175 -p tcp --sport 3306 -j ACCEPT\n</code></pre>\n<p>Ahora podemos ver como delta puede conectar con el servidor mariadb:</p>\n<p><img src=\"/images/fw1-16.png\" alt=\"ssh\"></p>\n"},{"title":"Poblando un directorio LDAP con datos CSV","Categoria":"Administración de sistemas","_content":"\n![ldap.png](/images/ldap-csv-logo.png)\n\n# Poblando un directorio LDAP con datos CSV\n\nComenzaremos conectándonos a alfa y establecer un fichero csv que es simplemente un fichero separado por comas:\n\n```\nBelen,Nazareth,belennazareth@gmail.com,antonio,ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQC73j7AidXdLgiu5wJw7YgJuvOHyb6U8c04MuQyehYnMknMR8mTnWZr20npVHJ8VHYHDy8RlgbkMMBFgeVCgXJ+Im3A6Efp6HC4yj2SM+73hr1EKCLdRPzCzdtDSUtkqU9k+x2RdF3T6qD6H4Cg/nT8Sg3Qenqds4XORfDWOvntxFja2D0OhZv1MLPUD9pEj+a8D4erfiPx/gKW/Rtu89une+uiwVgK60B5CxnC8XXnXmPO3NhrgyQhVgzQZ658cUbLooxQURVlo1gnOmcqX5h+svUKN1SDbzTyy7HKSk7bbLHEhk7qDh7jSzcf80GLU0li8vXc2to8NpC00EOQ9POPivESz23gMNY8ooDtNU3Ll/xYvhtvXrJNTbuBiuVLzuopMvrQi6LVsQEWmPJzBiJ2qt8JW1KRLcnWRL4AezbxAPXuRYVnYBS3it6L0J4AZjZg63BkIIrfU7GYzrKb+z5mqUgDJhIZ4d5av+OAxPSSzNeVnyWEnWrI0k9kf9qmqhU= nazare@ThousandSunny \nRoberto,Rodriguez,roberroberto@gmail.com,antonio,ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDV+kKxQNDAQzjU+v5vKBdDBryGRZVx8isCL+VIyZM44qVELXgSA8ZAKfv6YqOwF669WIGD7LKUAZ9PpNk0kWJCiDkHUMW1KmAgaqzo0NAAux0cdoMDfHDpREvlDwS5Ryr64H08oJsNh3IAqefrAU0rszFAkK2ycCLI4Dl0bqO4zNMAqkbDdrhk61jB3nZEAvDTvxZ/3c+mX4RlWBeCARPR9Hq0AuGcR5JAdQf74AySk6mbu0h8mw3DRnU9dxdrCkkhEuPlAVo7uh6i81NDfFLxkddjv46P9aDDvQxxhmv2jCFjx7PUuDvGb0MoCDXV+C4oZyJ0HzUkwX2YuqRTVcE8wvTIxjeQ/ABRgMBfYMr7qvwPV8v2lrylfmHw4A3vxDHmS3kQojnFUxc9lWTWRtT8Ab+3PIPPU+a09Mw7N9dEdusljhviLMZ83ni7qTtfd4IBpS3oVS9JbgkpxOxNJw9bQlFqm+hwKH2sRmjgZft3QcOy1JAwGTViI8eW1mCyl3U= roberto@portatil\n```\n\n\nCrearemos un fichero ldif que será el que se encargue de poblar el directorio:\n\n\n```\ndn: cn=openssh-lpk,cn=schema,cn=config\nobjectClass: olcSchemaConfig\ncn: openssh-lpk\nolcAttributeTypes: ( 1.3.6.1.4.1.24552.500.1.1.1.13 NAME 'sshPublicKey'\n  DESC 'MANDATORY: OpenSSH Public key'\n  EQUALITY octetStringMatch\n  SYNTAX 1.3.6.1.4.1.1466.115.121.1.40 )\nolcObjectClasses: ( 1.3.6.1.4.1.24552.500.1.1.2.0 NAME 'ldapPublicKey' SUP top AUXILIARY\n  DESC 'MANDATORY: OpenSSH LPK objectclass'\n  MAY ( sshPublicKey $ uid )\n  )\n```\n\nImportaremos la nueva configuración con el siguiente comando:\n\n```\nldapadd -Y EXTERNAL -H ldapi:/// -f openssh-lpk.ldif\n```\n\n![img](/images/ldap-2-1.png)\n\nAhora crearemos un programa en python en el cual podremos leer el fichero csv y crear un fichero ldif que será el que se encargue de poblar el directorio:\n\nPara ello instalaremos python y crearemos el entorno virtual:\n\n```\napt install python3-venv -y\n\npython3 -m venv ldap-csv\n\nsource ldap-csv/bin/activate\n```\n\n\nSeguidamente crearemos el programa en python:\n\n```\n#!/usr/bin/env python\n\nimport ldap3\nfrom ldap3 import Connection, ALL\nfrom getpass import getpass\nfrom sys import exit\n\n### VARIABLES\n\n# Shell que se le asigna a los usuarios\nshell = '/bin/bash'\n\n# Ruta absoluta del directorio que contiene los directorios personales de los usuarios. Terminado en \"/\"\nhome_dir = '/home/ldap/'\n\n# El valor inicial para los UID que se asignan al insertar usuarios. \nuid_number = 10000\n\n# El GID que se le asigna a los usuarios. Si no se manda al anadir el usuario da error.\ngid = 10000\n\n### VARIABLES\n\n# Leemos el fichero .csv de los usuarios y guardamos cada linea en una lista.\nwith open('usuarios.csv', 'r') as usuarios:\n  usuarios = usuarios.readlines()\n\n\n### Parametros para la conexion\nldap_ip = 'ldap://alfa.antonio.gonzalonazareno.org:389'\ndominio_base = 'dc=antonio,dc=gonzalonazareno,dc=org'\nuser_admin = 'admin' \ncontrasena = getpass('Contrasena: ')\n\n# Intenta realizar la conexion.\nconn = Connection(ldap_ip, 'cn={},{}'.format(user_admin, dominio_base),contrasena)\n\n# conn.bind() devuelve \"True\" si se ha establecido la conexion y \"False\" en caso contrario.\n\n# Si no se establece la conexion imprime por pantalla un error de conexion.\nif not conn.bind():\n  print('No se ha podido conectar con ldap') \n  if conn.result['description'] == 'invalidCredentials':\n    print('Credenciales no validas.')\n  # Termina el script.\n  exit(0)\n\n# Recorre la lista de usuarios\nfor user in usuarios:\n  # Separa los valores del usuario usando como delimitador \",\", y asigna cada valor a la variable correspondiente.\n  user = user.split(',')\n  cn = user[0]\n  sn = user[1]\n  mail = user[2]\n  uid = user[3]\n  ssh = user[4]\n\n  #Anade el usuario.\n  conn.add(\n    'uid={},ou=Personas,{}'.format(uid, dominio_base),\n    object_class = \n      [\n      'inetOrgPerson',\n      'posixAccount', \n      'ldapPublicKey'\n      ],\n    attributes =\n      {\n      'cn': cn,\n      'sn': sn,\n      'mail': mail,\n      'uid': uid,\n      'uidNumber': str(uid_number),\n      'gidNumber': str(gid),\n      'homeDirectory': '{}{}'.format(home_dir,uid),\n      'loginShell': shell,\n      'sshPublicKey': str(ssh)\n      })\n\n  if conn.result['description'] == 'entryAlreadyExists':\n    print('El usuario {} ya existe.'.format(uid))\n\n  # Aumenta el contador para asignar un UID diferente a cada usuario (cada vez que ejecutemos el script debemos asegurarnos de ante mano que no existe dicho uid en el directorio ldap, o se solaparian los datos)\n  uid_number += 1\n\n#Cierra la conexion.\nconn.unbind()\n\n```\n\nLo ejecutaremos:\n\n```\npython3 poblarusuarios-csv.py\n```\n\n![img](/images/ldap-2-2.png)\n\n```\nldapsearch -x -D \"cn=admin,dc=antonio,dc=gonzalonazareno,dc=org\" -b \"dc=antonio,dc=gonzalonazareno,dc=org\" -W\n```\n\nRoberto:\n\n![img](/images/ldap-2-3.png)\n\nNazareth:\n\n![img](/images/ldap-2-4.png)\n\nnano /etc/ldap/ldap.conf\n\n```\nBASE dc=antonio,dc=gonzalonazareno,dc=org\nURI ldap://alfa.antonio.gonzalonazareno.org\n```\n\n\nY hacemos esto para que cuando un usuario entre puedan crearse sus respectivos directorios:\n\n```\necho \"session    required        pam_mkhomedir.so\" >> /etc/pam.d/common-session\n```\n\n\nAhora vamos a hacer un script que luego adjuntaremos en el servicio de sshd config para que encuentre las claves públicas de los usuarios:\n\nnano /opt/buscarclave.sh\n\n```\n#!/bin/bash\nldapsearch -x -u -LLL -o ldif-wrap=no '(&(objectClass=posixAccount)(uid='\"$1\"'))' 'sshPublicKey' | sed -n 's/^[ \\t]*sshPublicKey::[ \\t]*\\(.*\\)>\n```\n\nLe damos permisos de ejecución:\n\n```\nchmod u + x /opt/buscarclave.sh \n```\n\n\nVemos que el programa se ejecuta correctamente:\n\n![img](/images/ldap-2-5.png)\n\n\nnano /etc/ssh/sshd_config\n\n```\nAuthorizedKeysCommand /opt/buscarclave.sh\nAuthorizedKeysCommandUser nobody\n```\n\nY por último reiniciamos el servicio ssh:\n\n```\nsystemctl restart sshd\n```\n\n\n\nAquí comprobamos que Nazareth puede conectarse a alfa:\n\n![img](/images/nazareth1.jpeg)\n\n\nY comprobamos que Roberto puede conectarse:\n\n![img](/images/rober1.jpeg)","source":"_posts/ldap-csv.md","raw":"---\ntitle: Poblando un directorio LDAP con datos CSV\nCategoria: Administración de sistemas\n---\n\n![ldap.png](/images/ldap-csv-logo.png)\n\n# Poblando un directorio LDAP con datos CSV\n\nComenzaremos conectándonos a alfa y establecer un fichero csv que es simplemente un fichero separado por comas:\n\n```\nBelen,Nazareth,belennazareth@gmail.com,antonio,ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQC73j7AidXdLgiu5wJw7YgJuvOHyb6U8c04MuQyehYnMknMR8mTnWZr20npVHJ8VHYHDy8RlgbkMMBFgeVCgXJ+Im3A6Efp6HC4yj2SM+73hr1EKCLdRPzCzdtDSUtkqU9k+x2RdF3T6qD6H4Cg/nT8Sg3Qenqds4XORfDWOvntxFja2D0OhZv1MLPUD9pEj+a8D4erfiPx/gKW/Rtu89une+uiwVgK60B5CxnC8XXnXmPO3NhrgyQhVgzQZ658cUbLooxQURVlo1gnOmcqX5h+svUKN1SDbzTyy7HKSk7bbLHEhk7qDh7jSzcf80GLU0li8vXc2to8NpC00EOQ9POPivESz23gMNY8ooDtNU3Ll/xYvhtvXrJNTbuBiuVLzuopMvrQi6LVsQEWmPJzBiJ2qt8JW1KRLcnWRL4AezbxAPXuRYVnYBS3it6L0J4AZjZg63BkIIrfU7GYzrKb+z5mqUgDJhIZ4d5av+OAxPSSzNeVnyWEnWrI0k9kf9qmqhU= nazare@ThousandSunny \nRoberto,Rodriguez,roberroberto@gmail.com,antonio,ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDV+kKxQNDAQzjU+v5vKBdDBryGRZVx8isCL+VIyZM44qVELXgSA8ZAKfv6YqOwF669WIGD7LKUAZ9PpNk0kWJCiDkHUMW1KmAgaqzo0NAAux0cdoMDfHDpREvlDwS5Ryr64H08oJsNh3IAqefrAU0rszFAkK2ycCLI4Dl0bqO4zNMAqkbDdrhk61jB3nZEAvDTvxZ/3c+mX4RlWBeCARPR9Hq0AuGcR5JAdQf74AySk6mbu0h8mw3DRnU9dxdrCkkhEuPlAVo7uh6i81NDfFLxkddjv46P9aDDvQxxhmv2jCFjx7PUuDvGb0MoCDXV+C4oZyJ0HzUkwX2YuqRTVcE8wvTIxjeQ/ABRgMBfYMr7qvwPV8v2lrylfmHw4A3vxDHmS3kQojnFUxc9lWTWRtT8Ab+3PIPPU+a09Mw7N9dEdusljhviLMZ83ni7qTtfd4IBpS3oVS9JbgkpxOxNJw9bQlFqm+hwKH2sRmjgZft3QcOy1JAwGTViI8eW1mCyl3U= roberto@portatil\n```\n\n\nCrearemos un fichero ldif que será el que se encargue de poblar el directorio:\n\n\n```\ndn: cn=openssh-lpk,cn=schema,cn=config\nobjectClass: olcSchemaConfig\ncn: openssh-lpk\nolcAttributeTypes: ( 1.3.6.1.4.1.24552.500.1.1.1.13 NAME 'sshPublicKey'\n  DESC 'MANDATORY: OpenSSH Public key'\n  EQUALITY octetStringMatch\n  SYNTAX 1.3.6.1.4.1.1466.115.121.1.40 )\nolcObjectClasses: ( 1.3.6.1.4.1.24552.500.1.1.2.0 NAME 'ldapPublicKey' SUP top AUXILIARY\n  DESC 'MANDATORY: OpenSSH LPK objectclass'\n  MAY ( sshPublicKey $ uid )\n  )\n```\n\nImportaremos la nueva configuración con el siguiente comando:\n\n```\nldapadd -Y EXTERNAL -H ldapi:/// -f openssh-lpk.ldif\n```\n\n![img](/images/ldap-2-1.png)\n\nAhora crearemos un programa en python en el cual podremos leer el fichero csv y crear un fichero ldif que será el que se encargue de poblar el directorio:\n\nPara ello instalaremos python y crearemos el entorno virtual:\n\n```\napt install python3-venv -y\n\npython3 -m venv ldap-csv\n\nsource ldap-csv/bin/activate\n```\n\n\nSeguidamente crearemos el programa en python:\n\n```\n#!/usr/bin/env python\n\nimport ldap3\nfrom ldap3 import Connection, ALL\nfrom getpass import getpass\nfrom sys import exit\n\n### VARIABLES\n\n# Shell que se le asigna a los usuarios\nshell = '/bin/bash'\n\n# Ruta absoluta del directorio que contiene los directorios personales de los usuarios. Terminado en \"/\"\nhome_dir = '/home/ldap/'\n\n# El valor inicial para los UID que se asignan al insertar usuarios. \nuid_number = 10000\n\n# El GID que se le asigna a los usuarios. Si no se manda al anadir el usuario da error.\ngid = 10000\n\n### VARIABLES\n\n# Leemos el fichero .csv de los usuarios y guardamos cada linea en una lista.\nwith open('usuarios.csv', 'r') as usuarios:\n  usuarios = usuarios.readlines()\n\n\n### Parametros para la conexion\nldap_ip = 'ldap://alfa.antonio.gonzalonazareno.org:389'\ndominio_base = 'dc=antonio,dc=gonzalonazareno,dc=org'\nuser_admin = 'admin' \ncontrasena = getpass('Contrasena: ')\n\n# Intenta realizar la conexion.\nconn = Connection(ldap_ip, 'cn={},{}'.format(user_admin, dominio_base),contrasena)\n\n# conn.bind() devuelve \"True\" si se ha establecido la conexion y \"False\" en caso contrario.\n\n# Si no se establece la conexion imprime por pantalla un error de conexion.\nif not conn.bind():\n  print('No se ha podido conectar con ldap') \n  if conn.result['description'] == 'invalidCredentials':\n    print('Credenciales no validas.')\n  # Termina el script.\n  exit(0)\n\n# Recorre la lista de usuarios\nfor user in usuarios:\n  # Separa los valores del usuario usando como delimitador \",\", y asigna cada valor a la variable correspondiente.\n  user = user.split(',')\n  cn = user[0]\n  sn = user[1]\n  mail = user[2]\n  uid = user[3]\n  ssh = user[4]\n\n  #Anade el usuario.\n  conn.add(\n    'uid={},ou=Personas,{}'.format(uid, dominio_base),\n    object_class = \n      [\n      'inetOrgPerson',\n      'posixAccount', \n      'ldapPublicKey'\n      ],\n    attributes =\n      {\n      'cn': cn,\n      'sn': sn,\n      'mail': mail,\n      'uid': uid,\n      'uidNumber': str(uid_number),\n      'gidNumber': str(gid),\n      'homeDirectory': '{}{}'.format(home_dir,uid),\n      'loginShell': shell,\n      'sshPublicKey': str(ssh)\n      })\n\n  if conn.result['description'] == 'entryAlreadyExists':\n    print('El usuario {} ya existe.'.format(uid))\n\n  # Aumenta el contador para asignar un UID diferente a cada usuario (cada vez que ejecutemos el script debemos asegurarnos de ante mano que no existe dicho uid en el directorio ldap, o se solaparian los datos)\n  uid_number += 1\n\n#Cierra la conexion.\nconn.unbind()\n\n```\n\nLo ejecutaremos:\n\n```\npython3 poblarusuarios-csv.py\n```\n\n![img](/images/ldap-2-2.png)\n\n```\nldapsearch -x -D \"cn=admin,dc=antonio,dc=gonzalonazareno,dc=org\" -b \"dc=antonio,dc=gonzalonazareno,dc=org\" -W\n```\n\nRoberto:\n\n![img](/images/ldap-2-3.png)\n\nNazareth:\n\n![img](/images/ldap-2-4.png)\n\nnano /etc/ldap/ldap.conf\n\n```\nBASE dc=antonio,dc=gonzalonazareno,dc=org\nURI ldap://alfa.antonio.gonzalonazareno.org\n```\n\n\nY hacemos esto para que cuando un usuario entre puedan crearse sus respectivos directorios:\n\n```\necho \"session    required        pam_mkhomedir.so\" >> /etc/pam.d/common-session\n```\n\n\nAhora vamos a hacer un script que luego adjuntaremos en el servicio de sshd config para que encuentre las claves públicas de los usuarios:\n\nnano /opt/buscarclave.sh\n\n```\n#!/bin/bash\nldapsearch -x -u -LLL -o ldif-wrap=no '(&(objectClass=posixAccount)(uid='\"$1\"'))' 'sshPublicKey' | sed -n 's/^[ \\t]*sshPublicKey::[ \\t]*\\(.*\\)>\n```\n\nLe damos permisos de ejecución:\n\n```\nchmod u + x /opt/buscarclave.sh \n```\n\n\nVemos que el programa se ejecuta correctamente:\n\n![img](/images/ldap-2-5.png)\n\n\nnano /etc/ssh/sshd_config\n\n```\nAuthorizedKeysCommand /opt/buscarclave.sh\nAuthorizedKeysCommandUser nobody\n```\n\nY por último reiniciamos el servicio ssh:\n\n```\nsystemctl restart sshd\n```\n\n\n\nAquí comprobamos que Nazareth puede conectarse a alfa:\n\n![img](/images/nazareth1.jpeg)\n\n\nY comprobamos que Roberto puede conectarse:\n\n![img](/images/rober1.jpeg)","slug":"ldap-csv","published":1,"date":"2023-02-17T02:01:26.020Z","updated":"2023-02-21T08:29:08.967Z","_id":"cle9yc9fv0000dhi553w33cpr","comments":1,"layout":"post","photos":[],"link":"","content":"<p><img src=\"/images/ldap-csv-logo.png\" alt=\"ldap.png\"></p>\n<h1 id=\"poblando-un-directorio-ldap-con-datos-csv\"><a class=\"markdownIt-Anchor\" href=\"#poblando-un-directorio-ldap-con-datos-csv\">#</a> Poblando un directorio LDAP con datos CSV</h1>\n<p>Comenzaremos conectándonos a alfa y establecer un fichero csv que es simplemente un fichero separado por comas:</p>\n<pre><code>Belen,Nazareth,belennazareth@gmail.com,antonio,ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQC73j7AidXdLgiu5wJw7YgJuvOHyb6U8c04MuQyehYnMknMR8mTnWZr20npVHJ8VHYHDy8RlgbkMMBFgeVCgXJ+Im3A6Efp6HC4yj2SM+73hr1EKCLdRPzCzdtDSUtkqU9k+x2RdF3T6qD6H4Cg/nT8Sg3Qenqds4XORfDWOvntxFja2D0OhZv1MLPUD9pEj+a8D4erfiPx/gKW/Rtu89une+uiwVgK60B5CxnC8XXnXmPO3NhrgyQhVgzQZ658cUbLooxQURVlo1gnOmcqX5h+svUKN1SDbzTyy7HKSk7bbLHEhk7qDh7jSzcf80GLU0li8vXc2to8NpC00EOQ9POPivESz23gMNY8ooDtNU3Ll/xYvhtvXrJNTbuBiuVLzuopMvrQi6LVsQEWmPJzBiJ2qt8JW1KRLcnWRL4AezbxAPXuRYVnYBS3it6L0J4AZjZg63BkIIrfU7GYzrKb+z5mqUgDJhIZ4d5av+OAxPSSzNeVnyWEnWrI0k9kf9qmqhU= nazare@ThousandSunny \nRoberto,Rodriguez,roberroberto@gmail.com,antonio,ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDV+kKxQNDAQzjU+v5vKBdDBryGRZVx8isCL+VIyZM44qVELXgSA8ZAKfv6YqOwF669WIGD7LKUAZ9PpNk0kWJCiDkHUMW1KmAgaqzo0NAAux0cdoMDfHDpREvlDwS5Ryr64H08oJsNh3IAqefrAU0rszFAkK2ycCLI4Dl0bqO4zNMAqkbDdrhk61jB3nZEAvDTvxZ/3c+mX4RlWBeCARPR9Hq0AuGcR5JAdQf74AySk6mbu0h8mw3DRnU9dxdrCkkhEuPlAVo7uh6i81NDfFLxkddjv46P9aDDvQxxhmv2jCFjx7PUuDvGb0MoCDXV+C4oZyJ0HzUkwX2YuqRTVcE8wvTIxjeQ/ABRgMBfYMr7qvwPV8v2lrylfmHw4A3vxDHmS3kQojnFUxc9lWTWRtT8Ab+3PIPPU+a09Mw7N9dEdusljhviLMZ83ni7qTtfd4IBpS3oVS9JbgkpxOxNJw9bQlFqm+hwKH2sRmjgZft3QcOy1JAwGTViI8eW1mCyl3U= roberto@portatil\n</code></pre>\n<p>Crearemos un fichero ldif que será el que se encargue de poblar el directorio:</p>\n<pre><code>dn: cn=openssh-lpk,cn=schema,cn=config\nobjectClass: olcSchemaConfig\ncn: openssh-lpk\nolcAttributeTypes: ( 1.3.6.1.4.1.24552.500.1.1.1.13 NAME 'sshPublicKey'\n  DESC 'MANDATORY: OpenSSH Public key'\n  EQUALITY octetStringMatch\n  SYNTAX 1.3.6.1.4.1.1466.115.121.1.40 )\nolcObjectClasses: ( 1.3.6.1.4.1.24552.500.1.1.2.0 NAME 'ldapPublicKey' SUP top AUXILIARY\n  DESC 'MANDATORY: OpenSSH LPK objectclass'\n  MAY ( sshPublicKey $ uid )\n  )\n</code></pre>\n<p>Importaremos la nueva configuración con el siguiente comando:</p>\n<pre><code>ldapadd -Y EXTERNAL -H ldapi:/// -f openssh-lpk.ldif\n</code></pre>\n<p><img src=\"/images/ldap-2-1.png\" alt=\"img\"></p>\n<p>Ahora crearemos un programa en python en el cual podremos leer el fichero csv y crear un fichero ldif que será el que se encargue de poblar el directorio:</p>\n<p>Para ello instalaremos python y crearemos el entorno virtual:</p>\n<pre><code>apt install python3-venv -y\n\npython3 -m venv ldap-csv\n\nsource ldap-csv/bin/activate\n</code></pre>\n<p>Seguidamente crearemos el programa en python:</p>\n<pre><code>#!/usr/bin/env python\n\nimport ldap3\nfrom ldap3 import Connection, ALL\nfrom getpass import getpass\nfrom sys import exit\n\n### VARIABLES\n\n# Shell que se le asigna a los usuarios\nshell = '/bin/bash'\n\n# Ruta absoluta del directorio que contiene los directorios personales de los usuarios. Terminado en &quot;/&quot;\nhome_dir = '/home/ldap/'\n\n# El valor inicial para los UID que se asignan al insertar usuarios. \nuid_number = 10000\n\n# El GID que se le asigna a los usuarios. Si no se manda al anadir el usuario da error.\ngid = 10000\n\n### VARIABLES\n\n# Leemos el fichero .csv de los usuarios y guardamos cada linea en una lista.\nwith open('usuarios.csv', 'r') as usuarios:\n  usuarios = usuarios.readlines()\n\n\n### Parametros para la conexion\nldap_ip = 'ldap://alfa.antonio.gonzalonazareno.org:389'\ndominio_base = 'dc=antonio,dc=gonzalonazareno,dc=org'\nuser_admin = 'admin' \ncontrasena = getpass('Contrasena: ')\n\n# Intenta realizar la conexion.\nconn = Connection(ldap_ip, 'cn=&#123;&#125;,&#123;&#125;'.format(user_admin, dominio_base),contrasena)\n\n# conn.bind() devuelve &quot;True&quot; si se ha establecido la conexion y &quot;False&quot; en caso contrario.\n\n# Si no se establece la conexion imprime por pantalla un error de conexion.\nif not conn.bind():\n  print('No se ha podido conectar con ldap') \n  if conn.result['description'] == 'invalidCredentials':\n    print('Credenciales no validas.')\n  # Termina el script.\n  exit(0)\n\n# Recorre la lista de usuarios\nfor user in usuarios:\n  # Separa los valores del usuario usando como delimitador &quot;,&quot;, y asigna cada valor a la variable correspondiente.\n  user = user.split(',')\n  cn = user[0]\n  sn = user[1]\n  mail = user[2]\n  uid = user[3]\n  ssh = user[4]\n\n  #Anade el usuario.\n  conn.add(\n    'uid=&#123;&#125;,ou=Personas,&#123;&#125;'.format(uid, dominio_base),\n    object_class = \n      [\n      'inetOrgPerson',\n      'posixAccount', \n      'ldapPublicKey'\n      ],\n    attributes =\n      &#123;\n      'cn': cn,\n      'sn': sn,\n      'mail': mail,\n      'uid': uid,\n      'uidNumber': str(uid_number),\n      'gidNumber': str(gid),\n      'homeDirectory': '&#123;&#125;&#123;&#125;'.format(home_dir,uid),\n      'loginShell': shell,\n      'sshPublicKey': str(ssh)\n      &#125;)\n\n  if conn.result['description'] == 'entryAlreadyExists':\n    print('El usuario &#123;&#125; ya existe.'.format(uid))\n\n  # Aumenta el contador para asignar un UID diferente a cada usuario (cada vez que ejecutemos el script debemos asegurarnos de ante mano que no existe dicho uid en el directorio ldap, o se solaparian los datos)\n  uid_number += 1\n\n#Cierra la conexion.\nconn.unbind()\n\n</code></pre>\n<p>Lo ejecutaremos:</p>\n<pre><code>python3 poblarusuarios-csv.py\n</code></pre>\n<p><img src=\"/images/ldap-2-2.png\" alt=\"img\"></p>\n<pre><code>ldapsearch -x -D &quot;cn=admin,dc=antonio,dc=gonzalonazareno,dc=org&quot; -b &quot;dc=antonio,dc=gonzalonazareno,dc=org&quot; -W\n</code></pre>\n<p>Roberto:</p>\n<p><img src=\"/images/ldap-2-3.png\" alt=\"img\"></p>\n<p>Nazareth:</p>\n<p><img src=\"/images/ldap-2-4.png\" alt=\"img\"></p>\n<p>nano /etc/ldap/ldap.conf</p>\n<pre><code>BASE dc=antonio,dc=gonzalonazareno,dc=org\nURI ldap://alfa.antonio.gonzalonazareno.org\n</code></pre>\n<p>Y hacemos esto para que cuando un usuario entre puedan crearse sus respectivos directorios:</p>\n<pre><code>echo &quot;session    required        pam_mkhomedir.so&quot; &gt;&gt; /etc/pam.d/common-session\n</code></pre>\n<p>Ahora vamos a hacer un script que luego adjuntaremos en el servicio de sshd config para que encuentre las claves públicas de los usuarios:</p>\n<p>nano /opt/buscarclave.sh</p>\n<pre><code>#!/bin/bash\nldapsearch -x -u -LLL -o ldif-wrap=no '(&amp;(objectClass=posixAccount)(uid='&quot;$1&quot;'))' 'sshPublicKey' | sed -n 's/^[ \\t]*sshPublicKey::[ \\t]*\\(.*\\)&gt;\n</code></pre>\n<p>Le damos permisos de ejecución:</p>\n<pre><code>chmod u + x /opt/buscarclave.sh \n</code></pre>\n<p>Vemos que el programa se ejecuta correctamente:</p>\n<p><img src=\"/images/ldap-2-5.png\" alt=\"img\"></p>\n<p>nano /etc/ssh/sshd_config</p>\n<pre><code>AuthorizedKeysCommand /opt/buscarclave.sh\nAuthorizedKeysCommandUser nobody\n</code></pre>\n<p>Y por último reiniciamos el servicio ssh:</p>\n<pre><code>systemctl restart sshd\n</code></pre>\n<p>Aquí comprobamos que Nazareth puede conectarse a alfa:</p>\n<p><img src=\"/images/nazareth1.jpeg\" alt=\"img\"></p>\n<p>Y comprobamos que Roberto puede conectarse:</p>\n<p><img src=\"/images/rober1.jpeg\" alt=\"img\"></p>\n","site":{"data":{}},"length":5382,"excerpt":"","more":"<p><img src=\"/images/ldap-csv-logo.png\" alt=\"ldap.png\"></p>\n<h1 id=\"poblando-un-directorio-ldap-con-datos-csv\"><a class=\"markdownIt-Anchor\" href=\"#poblando-un-directorio-ldap-con-datos-csv\">#</a> Poblando un directorio LDAP con datos CSV</h1>\n<p>Comenzaremos conectándonos a alfa y establecer un fichero csv que es simplemente un fichero separado por comas:</p>\n<pre><code>Belen,Nazareth,belennazareth@gmail.com,antonio,ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQC73j7AidXdLgiu5wJw7YgJuvOHyb6U8c04MuQyehYnMknMR8mTnWZr20npVHJ8VHYHDy8RlgbkMMBFgeVCgXJ+Im3A6Efp6HC4yj2SM+73hr1EKCLdRPzCzdtDSUtkqU9k+x2RdF3T6qD6H4Cg/nT8Sg3Qenqds4XORfDWOvntxFja2D0OhZv1MLPUD9pEj+a8D4erfiPx/gKW/Rtu89une+uiwVgK60B5CxnC8XXnXmPO3NhrgyQhVgzQZ658cUbLooxQURVlo1gnOmcqX5h+svUKN1SDbzTyy7HKSk7bbLHEhk7qDh7jSzcf80GLU0li8vXc2to8NpC00EOQ9POPivESz23gMNY8ooDtNU3Ll/xYvhtvXrJNTbuBiuVLzuopMvrQi6LVsQEWmPJzBiJ2qt8JW1KRLcnWRL4AezbxAPXuRYVnYBS3it6L0J4AZjZg63BkIIrfU7GYzrKb+z5mqUgDJhIZ4d5av+OAxPSSzNeVnyWEnWrI0k9kf9qmqhU= nazare@ThousandSunny \nRoberto,Rodriguez,roberroberto@gmail.com,antonio,ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDV+kKxQNDAQzjU+v5vKBdDBryGRZVx8isCL+VIyZM44qVELXgSA8ZAKfv6YqOwF669WIGD7LKUAZ9PpNk0kWJCiDkHUMW1KmAgaqzo0NAAux0cdoMDfHDpREvlDwS5Ryr64H08oJsNh3IAqefrAU0rszFAkK2ycCLI4Dl0bqO4zNMAqkbDdrhk61jB3nZEAvDTvxZ/3c+mX4RlWBeCARPR9Hq0AuGcR5JAdQf74AySk6mbu0h8mw3DRnU9dxdrCkkhEuPlAVo7uh6i81NDfFLxkddjv46P9aDDvQxxhmv2jCFjx7PUuDvGb0MoCDXV+C4oZyJ0HzUkwX2YuqRTVcE8wvTIxjeQ/ABRgMBfYMr7qvwPV8v2lrylfmHw4A3vxDHmS3kQojnFUxc9lWTWRtT8Ab+3PIPPU+a09Mw7N9dEdusljhviLMZ83ni7qTtfd4IBpS3oVS9JbgkpxOxNJw9bQlFqm+hwKH2sRmjgZft3QcOy1JAwGTViI8eW1mCyl3U= roberto@portatil\n</code></pre>\n<p>Crearemos un fichero ldif que será el que se encargue de poblar el directorio:</p>\n<pre><code>dn: cn=openssh-lpk,cn=schema,cn=config\nobjectClass: olcSchemaConfig\ncn: openssh-lpk\nolcAttributeTypes: ( 1.3.6.1.4.1.24552.500.1.1.1.13 NAME 'sshPublicKey'\n  DESC 'MANDATORY: OpenSSH Public key'\n  EQUALITY octetStringMatch\n  SYNTAX 1.3.6.1.4.1.1466.115.121.1.40 )\nolcObjectClasses: ( 1.3.6.1.4.1.24552.500.1.1.2.0 NAME 'ldapPublicKey' SUP top AUXILIARY\n  DESC 'MANDATORY: OpenSSH LPK objectclass'\n  MAY ( sshPublicKey $ uid )\n  )\n</code></pre>\n<p>Importaremos la nueva configuración con el siguiente comando:</p>\n<pre><code>ldapadd -Y EXTERNAL -H ldapi:/// -f openssh-lpk.ldif\n</code></pre>\n<p><img src=\"/images/ldap-2-1.png\" alt=\"img\"></p>\n<p>Ahora crearemos un programa en python en el cual podremos leer el fichero csv y crear un fichero ldif que será el que se encargue de poblar el directorio:</p>\n<p>Para ello instalaremos python y crearemos el entorno virtual:</p>\n<pre><code>apt install python3-venv -y\n\npython3 -m venv ldap-csv\n\nsource ldap-csv/bin/activate\n</code></pre>\n<p>Seguidamente crearemos el programa en python:</p>\n<pre><code>#!/usr/bin/env python\n\nimport ldap3\nfrom ldap3 import Connection, ALL\nfrom getpass import getpass\nfrom sys import exit\n\n### VARIABLES\n\n# Shell que se le asigna a los usuarios\nshell = '/bin/bash'\n\n# Ruta absoluta del directorio que contiene los directorios personales de los usuarios. Terminado en &quot;/&quot;\nhome_dir = '/home/ldap/'\n\n# El valor inicial para los UID que se asignan al insertar usuarios. \nuid_number = 10000\n\n# El GID que se le asigna a los usuarios. Si no se manda al anadir el usuario da error.\ngid = 10000\n\n### VARIABLES\n\n# Leemos el fichero .csv de los usuarios y guardamos cada linea en una lista.\nwith open('usuarios.csv', 'r') as usuarios:\n  usuarios = usuarios.readlines()\n\n\n### Parametros para la conexion\nldap_ip = 'ldap://alfa.antonio.gonzalonazareno.org:389'\ndominio_base = 'dc=antonio,dc=gonzalonazareno,dc=org'\nuser_admin = 'admin' \ncontrasena = getpass('Contrasena: ')\n\n# Intenta realizar la conexion.\nconn = Connection(ldap_ip, 'cn=&#123;&#125;,&#123;&#125;'.format(user_admin, dominio_base),contrasena)\n\n# conn.bind() devuelve &quot;True&quot; si se ha establecido la conexion y &quot;False&quot; en caso contrario.\n\n# Si no se establece la conexion imprime por pantalla un error de conexion.\nif not conn.bind():\n  print('No se ha podido conectar con ldap') \n  if conn.result['description'] == 'invalidCredentials':\n    print('Credenciales no validas.')\n  # Termina el script.\n  exit(0)\n\n# Recorre la lista de usuarios\nfor user in usuarios:\n  # Separa los valores del usuario usando como delimitador &quot;,&quot;, y asigna cada valor a la variable correspondiente.\n  user = user.split(',')\n  cn = user[0]\n  sn = user[1]\n  mail = user[2]\n  uid = user[3]\n  ssh = user[4]\n\n  #Anade el usuario.\n  conn.add(\n    'uid=&#123;&#125;,ou=Personas,&#123;&#125;'.format(uid, dominio_base),\n    object_class = \n      [\n      'inetOrgPerson',\n      'posixAccount', \n      'ldapPublicKey'\n      ],\n    attributes =\n      &#123;\n      'cn': cn,\n      'sn': sn,\n      'mail': mail,\n      'uid': uid,\n      'uidNumber': str(uid_number),\n      'gidNumber': str(gid),\n      'homeDirectory': '&#123;&#125;&#123;&#125;'.format(home_dir,uid),\n      'loginShell': shell,\n      'sshPublicKey': str(ssh)\n      &#125;)\n\n  if conn.result['description'] == 'entryAlreadyExists':\n    print('El usuario &#123;&#125; ya existe.'.format(uid))\n\n  # Aumenta el contador para asignar un UID diferente a cada usuario (cada vez que ejecutemos el script debemos asegurarnos de ante mano que no existe dicho uid en el directorio ldap, o se solaparian los datos)\n  uid_number += 1\n\n#Cierra la conexion.\nconn.unbind()\n\n</code></pre>\n<p>Lo ejecutaremos:</p>\n<pre><code>python3 poblarusuarios-csv.py\n</code></pre>\n<p><img src=\"/images/ldap-2-2.png\" alt=\"img\"></p>\n<pre><code>ldapsearch -x -D &quot;cn=admin,dc=antonio,dc=gonzalonazareno,dc=org&quot; -b &quot;dc=antonio,dc=gonzalonazareno,dc=org&quot; -W\n</code></pre>\n<p>Roberto:</p>\n<p><img src=\"/images/ldap-2-3.png\" alt=\"img\"></p>\n<p>Nazareth:</p>\n<p><img src=\"/images/ldap-2-4.png\" alt=\"img\"></p>\n<p>nano /etc/ldap/ldap.conf</p>\n<pre><code>BASE dc=antonio,dc=gonzalonazareno,dc=org\nURI ldap://alfa.antonio.gonzalonazareno.org\n</code></pre>\n<p>Y hacemos esto para que cuando un usuario entre puedan crearse sus respectivos directorios:</p>\n<pre><code>echo &quot;session    required        pam_mkhomedir.so&quot; &gt;&gt; /etc/pam.d/common-session\n</code></pre>\n<p>Ahora vamos a hacer un script que luego adjuntaremos en el servicio de sshd config para que encuentre las claves públicas de los usuarios:</p>\n<p>nano /opt/buscarclave.sh</p>\n<pre><code>#!/bin/bash\nldapsearch -x -u -LLL -o ldif-wrap=no '(&amp;(objectClass=posixAccount)(uid='&quot;$1&quot;'))' 'sshPublicKey' | sed -n 's/^[ \\t]*sshPublicKey::[ \\t]*\\(.*\\)&gt;\n</code></pre>\n<p>Le damos permisos de ejecución:</p>\n<pre><code>chmod u + x /opt/buscarclave.sh \n</code></pre>\n<p>Vemos que el programa se ejecuta correctamente:</p>\n<p><img src=\"/images/ldap-2-5.png\" alt=\"img\"></p>\n<p>nano /etc/ssh/sshd_config</p>\n<pre><code>AuthorizedKeysCommand /opt/buscarclave.sh\nAuthorizedKeysCommandUser nobody\n</code></pre>\n<p>Y por último reiniciamos el servicio ssh:</p>\n<pre><code>systemctl restart sshd\n</code></pre>\n<p>Aquí comprobamos que Nazareth puede conectarse a alfa:</p>\n<p><img src=\"/images/nazareth1.jpeg\" alt=\"img\"></p>\n<p>Y comprobamos que Roberto puede conectarse:</p>\n<p><img src=\"/images/rober1.jpeg\" alt=\"img\"></p>\n"},{"title":"Auditoría","categoria":"Bases de datos","_content":"\n![image](/images/audit-logo.png)\n\n## 1. Activa desde SQL*Plus la auditoría de los intentos de acceso exitosos al sistema. Comprueba su funcionamiento.\n\nVemos si tenemos activado el registro de auditoría:\n\n\n```\nSELECT name, value FROM v$parameter WHERE name = 'audit_trail';\n```\n\nTambién podemos emplear la siguiente sentencia:\n\n```\nSHOW PARAMETER AUDIT\n```\n\n![image](/images/audit-1.png)\n\nEmplearemos la siguiente sentencia para activar la auditoría:\n\n```\nAUDIT CREATE SESSION WHENEVER SUCCESSFUL;\n```\n\nAhora nos desconectamos del susuario administrador y entraremos con el de antonio:\n\n![image](/images/audit-2.png)\n\n```\nSELECT OS_USERNAME, USERNAME, EXTENDED_TIMESTAMP, ACTION_NAME FROM DBA_AUDIT_SESSION WHERE USERNAME = 'ANTONIO';\n```\n\n![image](/images/audit-3.png)\n\n\nComo podemos ver el usuario ha quedado registrado en la tabla DBA_AUDIT_SESSION.\n\n\n\n## 2. Realiza un procedimiento en PL/SQL que te muestre los accesos fallidos junto con el motivo de los mismos, transformando el código de error almacenado en un mensaje de texto comprensible. Contempla todos los motivos posibles para que un acceso sea fallido.\n\n\n```\nCREATE OR REPLACE PROCEDURE AUDIT_ACCESOS\nIS\ncursor c_conexion is SELECT OS_USERNAME,TIMESTAMP, USERNAME, RETURNCODE FROM DBA_AUDIT_SESSION;\nBEGIN\nfor v_conexion in c_conexion loop\n    Dbms_Output.Put_Line(v_conexion.OS_USERNAME);\n    Dbms_Output.Put_Line(v_conexion.USERNAME);\n    Dbms_Output.Put_Line(v_conexion.TIMESTAMP);\n    MOSTRAR_DEF_ERROR(v_conexion.RETURNCODE);\nend loop;\nEND;\n/\n\nCREATE OR REPLACE PROCEDURE MOSTRAR_DEF_ERROR (p_codigo NUMBER)\nIS\nBEGIN\nIF p_codigo = 1017 THEN\n    dbms_Output.Put_Line('Error ' || p_codigo || ' El usuario o la contraseña no existe');\nELSIF p_codigo = 2391 THEN\n    dbms_Output.Put_Line('Error ' || p_codigo || ' Excedidas las conexiones simultáneas permitidas');\nELSIF p_codigo = 1045 THEN\n    dbms_Output.Put_Line('Error ' || p_codigo || ' El usuario no tiene permisos de creación de sesión');\nELSIF p_codigo = 28001 THEN\n    dbms_Output.Put_Line('Error ' || p_codigo || ' La contraseña del usuario ha caducado');\nELSIF p_codigo = 28009 THEN\n    dbms_Output.Put_Line('Error ' || p_codigo || ' La conexión debe ser a través de SYS o SYSOPER');\nELSIF p_codigo = 1034 THEN\n    dbms_Output.Put_Line('Error ' || p_codigo || ' La base de datos no está levantada');\nEND IF;\nEND;\n/\n```\n\n![image](/images/audit-4.png)\n\n## 3. Activa la auditoría de las operaciones DML realizadas por SCOTT. Comprueba su funcionamiento.\n\n```\nAUDIT INSERT TABLE, UPDATE TABLE, DELETE TABLE BY SCOTT BY ACCESS;\n```\n\n\n\nAhora vamos a rellenar con diferentes cambios para registrarlo en la auditoría:\n\n\n![image](/images/audit-5.png)\n\nY con la siguiente sentencia podemos ver los cambios que se han realizado desde el usuario sys:\n\n```\nSELECT OS_USERNAME, USERNAME, TIMESTAMP, ACTION_NAME FROM DBA_AUDIT_OBJECT WHERE USERNAME = 'SCOTT';\n```\n\n![image](/images/audit-6.png)\n\n## 4. Realiza una auditoría de grano fino para almacenar información sobre la inserción de empleados con sueldo superior a 2000 en la tabla emp de scott.\n\n¿Qué es una auditoría de grano fino?\n\nUna auditoría de grano fino es una auditoría más detallada que no solo contempla el hecho de inserción de filas y columnas sino que también pueden auditarse qué datos han cambiado para así tener un major control sobre la base de datos.\n\nAsí que con el objeto DBMS_FGA.ADD_POLICY podemos crear una auditoría de grano fino para la tabla emp de scott:\n\n```\nBEGIN\n    DBMS_FGA.ADD_POLICY (\n        object_schema      =>  'SCOTT',\n        object_name        =>  'EMP',\n        policy_name        =>  'AUDIT_EMP_SAL',\n        audit_condition    =>  'SAL > 2000',\n        statement_types    =>  'INSERT'\n    );\nEND;\n/\n```\n\n![image](/images/audit-7.png)\n\nAhora vamos a insertar un empleado con un salario superior a 2000 con el usuario SCOTT:\n\n![image](/images/audit-8.png)\n\nY entramos en como administrador de nuevo y comprobamos que se ha registrado el insert que contiene el salario mayor a 2000:\n\n```\nSELECT DB_USER, OBJECT_NAME, SQL_TEXT, TIMESTAMP FROM DBA_FGA_AUDIT_TRAIL WHERE POLICY_NAME='AUDIT_EMP_SAL';\n```\n\n![image](/images/audit-9.png)\n\n\nAlternativamente podríamos hacer nosotros nuestra auditoría con un trigger, como veremos en los siguientes casos, pero viendo que la utilidad de DBMS_FGA es más sencilla y rápida, es la que hemos empleado en este caso.\n\n## 5. Explica la diferencia entre auditar una operación by access o by session ilustrándolo con ejemplos.\n\nLa auditoría by access registra cada acceso a los objetos de la base de datos, mientras que la auditoría by session registra la actividad del usuario solo una vez, lo que evita recursividad. La elección de qué tipo de auditoría utilizar dependerá de los objetivos de la auditoría y del nivel de detalle necesario para cumplirlos, siendo así más detallado el hecho de la auditoría by access.\n\nComo ejemplos podemos tomar de ejercicios anteriores la auditoría de accesos exitosos:\n\n![image](/images/audit-3.png)\n\nY la auditoría by session:\n\n![image](/images/audit-6.png)\n\n\n\n\n## 6. Documenta las diferencias entre los valores db y db, extended del parámetro audit_trail de ORACLE. Demuéstralas poniendo un ejemplo de la información sobre una operación concreta recopilada con cada uno de ellos.\n\nLos valores que alberga el parámetro deb y db extended son los mismos, exceptos en varias columnas, que es SQLBIND y SQLTEXT:\n\nSi añadimor SQLBIND a nuestra consulta podemos ver que no logra encontrar el campo SQLBIND:\n\n```\nSELECT DB_USER, OBJECT_NAME, SQL_TEXT, TIMESTAMP FROM DBA_FGA_AUDIT_TRAIL WHERE POLICY_NAME='AUDIT_EMP_SAL';\n```\n\n![image](/images/audit-10.png)\n\nCon esto podemos ver el parámetro audit_trail como vimos en el ejercicio 1:\n\n```\nSHOW PARAMETER AUDIT\n```\n\n![image](/images/audit-1.png)\n\n\nEntonces, si queremos cambiar el valor de audit_trail a db extended, debemos hacer lo siguiente:\n\n```\nALTER SYSTEM SET audit_trail = DB,EXTENDED SCOPE=SPFILE;\n```\n\nY seguidamente reiniciar la base de datos:\n\n```\nshutdown\nstartup\n```\n\nAhora podemos comprobar que se encuentra de manera extendida:\n\n![image](/images/audit-11.png)\n\n\nY al entrar en la base de datos con el usuario SCOTT y hacer un insert en la tabla emp, podemos ver que ahora si se encuentra el campo SQLBIND y SQLTEXT:\n\n```\nSELECT USERNAME,ACTION_NAME,TIMESTAMP, OBJ_NAME, SQL_TEXT, SQL_BIND from DBA_AUDIT_OBJECT where USERNAME='SCOTT';\n```\n\n![image](/images/audit-12.png)\n\n## 7. Averigua si en Postgres se pueden realizar los cuatro primeros apartados. Si es así, documenta el proceso adecuadamente.\n\nEn postgres podemos ver gracias a la ruta `/var/log/postgresql/postgresql-13-main.log` los logs de intentos fallidos al sistema:\n\n![image](/images/audit-13.png)\n\nA parte de esto, Postgres no contempla las auditorías, para ello debemos descargar una herramienta de terceros llamada audit trigger 91 plus que nos permitirá realizar auditorías en la base de datos.\n\nSeguidamente importaremos el esquema de base de datos a nuestro sistema gestor de base de datos:\n\n```\n\\i audit.sql\n```\n\nComo podemos contemplar en la imagen se ha creado diferentes funciones, tablas y disparadores que nos permitirán realizar auditorías en la base de datos:\n\n![image](/images/audit-14.png)\n\nVamos a activar la auditoría de la tabla personaje:\n\n```\nSELECT audit.audit_table('personaje');\n```\n\n![image](/images/audit-16.png)\n\n\nAHora vamos a insertar un nuevo registro en la tabla personaje:\n\n![image](/images/audit-15.png)\n\n\nSeguidamente vamos a comprobar que funciona la auditoría:\n\n```\nselect session_user_name, action, table_name, action_tstamp_clk, client_query \nfrom audit.logged_actions;\n```\n![image](/images/audit-17.png)\n\nNota: para poder realizar la auditoría de manera correcta, la importación del esquema debe hacerse dentro de la base de datos con la que se va a trabajar, de manera que si queremos que se audite la tabla personaje de la base de datos souls, deberemos importar el esquema dentro de esta base de datos.\n\nAhora vamos a resolver el ejercicio 4 que consiste en crear una política de auditoría que registre los accesos a la tabla EMP de SCOTT que tengan un salario superior a 2000, por defecto no tiene una funcionalidad bd como pudiese tenerlo Oracle, pero sí que podemos crear un trigger que nos permita realizar esta auditoría.\n\n\nPrimero crearemos la tabla auditoria_emp:\n\n```\nCREATE TABLE auditoria_emp (\n  id SERIAL PRIMARY KEY,\n  EMPNO INT NOT NULL,\n  ACCION VARCHAR(10) NOT NULL,\n  SALARIO DECIMAL(7, 2) NOT NULL,\n  FECHA_HORA TIMESTAMP NOT NULL DEFAULT NOW()\n);\n```\n\nVamos a explicar esta tabla:\n- id: es un campo autoincremental que nos permitirá identificar cada registro de la tabla.\n- EMPNO: es el número de empleado.\n- ACCION: es el salario del empleado.\n- SALARIO: es el salario del empleado.\n- FECHA_HORA: es la fecha y hora en la que se ha realizado la acción.\n\n\n```\nCREATE OR REPLACE FUNCTION insert_auditoria_emp()\nRETURNS TRIGGER AS $$\nBEGIN\n  INSERT INTO auditoria_emp (EMPNO, SALARIO, ACCION)\n  VALUES (NEW.EMPNO, NEW.SAL, 'INSERT');\n  RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER tr_insert_emp\nAFTER INSERT ON EMP\nFOR EACH ROW\nWHEN (NEW.SAL > 2000)\nEXECUTE FUNCTION insert_auditoria_emp();\n```\n\n```\nCREATE OR REPLACE FUNCTION update_auditoria_emp()\nRETURNS TRIGGER AS $$\nBEGIN\n  INSERT INTO auditoria_emp (EMPNO, SALARIO, ACCION)\n  VALUES (NEW.EMPNO, NEW.SAL, 'UPDATE');\n  RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER tr_update_emp\nAFTER UPDATE ON EMP\nFOR EACH ROW\nWHEN (NEW.SAL > 2000)\nEXECUTE FUNCTION update_auditoria_emp();\n```\n\nAhora vamos a insertar un registro y seguidamente actualizar otro para comprobar que funciona correctamente:\n\n```\nINSERT INTO EMP VALUES(7909, 'JAMES', 'CLERK', 7698, '1981-12-03', 2950, NULL, 30);\nUPDATE EMP SET SAL = 4000 WHERE EMPNO = 7369;\n```\n\n![image](/images/audit-22.png)\n\n## 8. Averigua si en MySQL se pueden realizar los apartados 1, 3 y 4. Si es así, documenta el proceso adecuadamente.\n\n\nPrimero para activar la auditoría en Maríadb, que es la alternativa más a MySQL, debemos modificar el archivo de configuración que se encuentra en `/etc/mysql/mariadb.conf.d/50-server.cnf` y descomentar las líneas que vemos en la siguiente imagen:\n\n![image](/images/audit-18.png)\n\nSeguidamente necesitamos que el usuario mysql tenga permisos para poder escribir en el fichero que hemos descomentado en la línea de configuración `log_error`:\n\n\n`chown -R mysql: /var/log/mysql`\n\nseguidamente reiniciamos el servicio:\n\n`systemctl restart mysql`\n\nSi intentamos acceder a través de mysql -u root -p y fallamos la contraseña se mantendrá registrado en el log:\n\n![image](/images/audit-19.png)\n\nAhora nos conectaremos con el usuario SCOTT, crearemos la tabla personaje del anterior ejercicio de postgres y haremos varios inserts:\n\n```\nCREATE TABLE personaje (\ncodpersonaje varchar (3),\nnombre varchar (15),\naltura decimal (3,2),\npeso decimal (3),\nraza varchar (10) DEFAULT ('Humano'),\nCONSTRAINT pk_codpersonaje PRIMARY KEY (codpersonaje),\nCONSTRAINT ck_codpersonaje CHECK (codpersonaje REGEXP '^1.*'),\nconstraint ck_nombre CHECK (nombre REGEXP '^[A-Z][a-z]*')\n);\n\n\n\ninsert into personaje values ('101','Solaire',1.70,80,'humano');\ninsert into personaje values ('102','Artorias',1.90,90,'hueco');\ninsert into personaje values ('103','Gargola',3.10,680,'Gárgola');\n```\n\nAl terminar, nos vamos al fichero de log `cat /var/log/mysql/mysql.log` y podemos ver cada uno de las acciones que hemos realizado:\n\n![image](/images/audit-20.png)\n\nAhora vamos a realizar el ejercicio 4 de manera que solo audite cada vez que el usuario inserte o actualice el salario de un empleado que sea mayor de 2000:\n\n```\nCREATE TABLE auditoria_emp (\n  id INT NOT NULL AUTO_INCREMENT,\n  EMPNO INT NOT NULL,\n  SALARIO DECIMAL(7, 2) NOT NULL,\n  ACCION VARCHAR(10) NOT NULL,\n  FECHA_HORA TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  PRIMARY KEY (id)\n);\n```\n\nVamos a explicar esta tabla:\n\n- La tabla contiene un id que es autoincremental, lo cual nos permitirá identificar cada uno de los registros de la tabla aunque se repitan datos, la cual haremos primary key.\n- el código del empleado el cual nos servirá para identificar el empleado que ha sufrido el cambio.\n- el salario que será mayor de 2000 para que se pueda auditar.\n- La fecha y hora del sistema en ese momento.\n\n\nAhora vamos a crear el disparador bastante sencillo que nos permitirá auditar cada vez que el salario de un empleado sea mayor de 2000:\n\n```\nDELIMITER //\n\nCREATE TRIGGER tr_insert_emp\nAFTER INSERT ON EMP\nFOR EACH ROW\nBEGIN\n  IF NEW.SAL > 2000 THEN\n    INSERT INTO auditoria_emp (EMPNO, SALARIO, ACCION) VALUES (NEW.EMPNO, NEW.SAL, 'INSERT');\n  END IF;\nEND //\n\nDELIMITER ;\n```\n\n```\nDELIMITER //\n\nCREATE TRIGGER tr_update_emp\nAFTER UPDATE ON EMP\nFOR EACH ROW\nBEGIN\n  IF NEW.SAL > 2000 THEN\n    INSERT INTO auditoria_emp (EMPNO, SALARIO, ACCION) VALUES (NEW.EMPNO, NEW.SAL, 'UPDATE');\n  END IF;\nEND //\n\nDELIMITER ;\n```\n\nInsertamos y actualizamos registros:\n\n```\nINSERT INTO EMP VALUES(7911, 'JAMES', 'CLERK', 7698,'1981-12-03', 2950, NULL, 30);\nUPDATE EMP SET SAL = 3000 WHERE EMPNO = 7369;\n```\n\n\n\nY aquí el resultado junto con la acción de insertar o actualizar un salario a más de 2000:\n\n![image](/images/audit-21.png)\n\n## 9.  Averigua las posibilidades que ofrece MongoDB para auditar los cambios que va sufriendo un documento. Demuestra su funcionamiento.\n\nLas posibilidades que ofrece MongoDB para auditar los cambios que va sufriendo un documento son las siguientes:\n\n\n\nPodemos activar las auditorías en un fichero JSON desde el fichero de configuración:\n`nano /etc/mongod.conf`\n\n\n```\nauditLog:\n  destination: file\n  format: JSON\n  path: /var/log/mongodb/auditLog.json\n```\n\nTambién podremos activar las auditorías en el syslog desde el fichero de configuración:\nnano /etc/mongod.conf\n\n```\nauditLog:\n  destination: syslog\n```\n\nTambién podemos habilitar las auditorías en un fichero BSON desde el fichero de configuración:\nnano /etc/mongod.conf\n\n```\nauditLog:\n  destination: file\n  format: BSON\n  path: /var/log/mongodb/auditLog.bson\n```\n\nHabilitar las auditorías en la consola desde el fichero de configuración:\nnano /etc/mongod.conf\n\n```\nauditLog:\n  destination: console\n```\n\n\n\nVamos a empezar a crear el usuario en la base de datos, la cual más tarde importará unos 140 documentos que poseo.\n\n```\ndb.createUser(\n   {\n     user: \"admin\", \n     pwd: \"admin\", \n     roles: [ { role: \"dbOwner\", db: \"souls\" } ]\n   }\n )\n```\n\n\nEn la documentación oficial de mongo especifica que recomienda la auditoría en formato BSON, ya que los JSON degradan la eficiencia de la auditoría.\n\n![image](/images/audit-25.png)\n\nPor ende elijo mostrar la auditoría en formato BSON:\n\n```\nnano /etc/mongod.conf\n\nauditLog:\n  destination: file\n  format: BSON\n  path: /var/log/mongodb/auditLog.bson\n```\n\nATENCIÓN: mongodb trabaja con ficheros bson, el cual es un lenguaje interpretado por la máquina específicamente creado por mongodb, por lo que no podremos visualizarlo con el comando `cat` o `less` como normalmente se hace con con los ficheros de texto plano, para ello utilizaremos el comando `bsondump` que nos permite visualizar el contenido de un fichero BSON y lo transforma a JSON.\n\n```\nbsondump /var/log/mongodb/auditLog.bson | jq\n```\n\nEntonces... por qué no he elegido el formato JSON si al final lo transformo a JSON? Pues porque al elegir el JSON directamente haces que lmongo sea la que traduzca directamente el BSON a JSON, lo cual hace que la base de datos tenga que hacer un trabajo extra que no es necesario, por lo que es mejor que la base de datos realice la auditoría con BSON y nosotros con la computación de la máquina del cliente lo transformemos a JSON cuando queramos visualizarlo.\n\nEn nuestro caso con 140 documentos es una diferencia mínima, pero si tuviéramos millones de documentos, la diferencia sería notable.\n\nAhora vamos a proceder a importar los documentos a la base de datos souls:\n\n\n```\nmongoimport --db souls --type=json --file DarkSoulsWeapons.json --jsonArray\n```\n\n![image](/images/audit-24.png)\n\nAhora vamos a comprobar que se ha registrado la importación en el fichero de auditoría:\n\n![image](/images/audit-26.png)\n\n\nComo podemos ver se ha realizado la acción de mongoimport y ha actuado sobre la base de datos y colección souls/soulsweapons.\n\nHan pasado varios días, me levanto una mañana y descubro que alguien ha borrado todos los documentos de la colección soulsweapons, por lo que voy a proceder a realizar una auditoría de la base de datos para descubrir quien ha sido el culpable:\n\nResulta que un usuario con un nick un tanto sospechoso ha entrado en la base de datos souls, lo podemos ver a través del ActionType y user,db:\n\n![image](/images/audit-27.png)\n\nPero esto no dice nada sobre lo que el usuario ha podido hacer, debemos indagar un poco más de su actividad una vez logueado en la base de datos, por lo que podemos filtrar ahora que conocemos los valores que hay que observar:\n\n```\nbsondump /var/log/mongodb/auditLog.bson | jq | egrep 'user|atype|ns''\n```\n\nOJO!! Este usuario ha hecho un drop de la colección soulsweapons, ahora sí que podemos decir que esta persona ha sido la culpable.\n\n![image](/images/audit-29.png)\n\n\n\n## 10. Averigua si en MongoDB se pueden auditar los accesos a una colección concreta. Demuestra su funcionamiento.\n\nComo buenos administradores de sistemas tenemos la copia de la información guardada, entonces vamos a comenzar auditando la colección soulsweapons:\n\nEn el ejercicio anterior entre los valores que hemos filtrado se encuentra el campo ns, este es el campo del namespace, el cual es \"nombrebasededatos.coleccion\" así que vamos a establecer un filtro en el archivo de configuración de mongo para que comience a auditar la colección soulsweapons:\n\n\nEntramos como administrador en la base de datos admin y ejecutamos el siguiente comando:\n\n```\nuse souls\ndb.setProfilingLevel(2)\n```\n\nA partir de ahora todas las acciones que se realicen sobre la colección, podrán ser auditadas de manera que sabremos incluso qué se está insertando:\n\n\n```\ndb.system.profile.find({\n   \"ns\": \"souls.DarkSoulsWeapons\",\n   \"op\": {\n      \"$in\": [\n         \"insert\",\n         \"update\",\n         \"delete\"\n      ]\n   }\n})\n```\n\n![image](/images/audit-31.png)\n\n\nComo podemos ver, el usuario admin ha insertado un documento en la colección soulsweapons.\n\n","source":"_posts/auditoria.md","raw":"---\ntitle: Auditoría\ncategoria: Bases de datos\n---\n\n![image](/images/audit-logo.png)\n\n## 1. Activa desde SQL*Plus la auditoría de los intentos de acceso exitosos al sistema. Comprueba su funcionamiento.\n\nVemos si tenemos activado el registro de auditoría:\n\n\n```\nSELECT name, value FROM v$parameter WHERE name = 'audit_trail';\n```\n\nTambién podemos emplear la siguiente sentencia:\n\n```\nSHOW PARAMETER AUDIT\n```\n\n![image](/images/audit-1.png)\n\nEmplearemos la siguiente sentencia para activar la auditoría:\n\n```\nAUDIT CREATE SESSION WHENEVER SUCCESSFUL;\n```\n\nAhora nos desconectamos del susuario administrador y entraremos con el de antonio:\n\n![image](/images/audit-2.png)\n\n```\nSELECT OS_USERNAME, USERNAME, EXTENDED_TIMESTAMP, ACTION_NAME FROM DBA_AUDIT_SESSION WHERE USERNAME = 'ANTONIO';\n```\n\n![image](/images/audit-3.png)\n\n\nComo podemos ver el usuario ha quedado registrado en la tabla DBA_AUDIT_SESSION.\n\n\n\n## 2. Realiza un procedimiento en PL/SQL que te muestre los accesos fallidos junto con el motivo de los mismos, transformando el código de error almacenado en un mensaje de texto comprensible. Contempla todos los motivos posibles para que un acceso sea fallido.\n\n\n```\nCREATE OR REPLACE PROCEDURE AUDIT_ACCESOS\nIS\ncursor c_conexion is SELECT OS_USERNAME,TIMESTAMP, USERNAME, RETURNCODE FROM DBA_AUDIT_SESSION;\nBEGIN\nfor v_conexion in c_conexion loop\n    Dbms_Output.Put_Line(v_conexion.OS_USERNAME);\n    Dbms_Output.Put_Line(v_conexion.USERNAME);\n    Dbms_Output.Put_Line(v_conexion.TIMESTAMP);\n    MOSTRAR_DEF_ERROR(v_conexion.RETURNCODE);\nend loop;\nEND;\n/\n\nCREATE OR REPLACE PROCEDURE MOSTRAR_DEF_ERROR (p_codigo NUMBER)\nIS\nBEGIN\nIF p_codigo = 1017 THEN\n    dbms_Output.Put_Line('Error ' || p_codigo || ' El usuario o la contraseña no existe');\nELSIF p_codigo = 2391 THEN\n    dbms_Output.Put_Line('Error ' || p_codigo || ' Excedidas las conexiones simultáneas permitidas');\nELSIF p_codigo = 1045 THEN\n    dbms_Output.Put_Line('Error ' || p_codigo || ' El usuario no tiene permisos de creación de sesión');\nELSIF p_codigo = 28001 THEN\n    dbms_Output.Put_Line('Error ' || p_codigo || ' La contraseña del usuario ha caducado');\nELSIF p_codigo = 28009 THEN\n    dbms_Output.Put_Line('Error ' || p_codigo || ' La conexión debe ser a través de SYS o SYSOPER');\nELSIF p_codigo = 1034 THEN\n    dbms_Output.Put_Line('Error ' || p_codigo || ' La base de datos no está levantada');\nEND IF;\nEND;\n/\n```\n\n![image](/images/audit-4.png)\n\n## 3. Activa la auditoría de las operaciones DML realizadas por SCOTT. Comprueba su funcionamiento.\n\n```\nAUDIT INSERT TABLE, UPDATE TABLE, DELETE TABLE BY SCOTT BY ACCESS;\n```\n\n\n\nAhora vamos a rellenar con diferentes cambios para registrarlo en la auditoría:\n\n\n![image](/images/audit-5.png)\n\nY con la siguiente sentencia podemos ver los cambios que se han realizado desde el usuario sys:\n\n```\nSELECT OS_USERNAME, USERNAME, TIMESTAMP, ACTION_NAME FROM DBA_AUDIT_OBJECT WHERE USERNAME = 'SCOTT';\n```\n\n![image](/images/audit-6.png)\n\n## 4. Realiza una auditoría de grano fino para almacenar información sobre la inserción de empleados con sueldo superior a 2000 en la tabla emp de scott.\n\n¿Qué es una auditoría de grano fino?\n\nUna auditoría de grano fino es una auditoría más detallada que no solo contempla el hecho de inserción de filas y columnas sino que también pueden auditarse qué datos han cambiado para así tener un major control sobre la base de datos.\n\nAsí que con el objeto DBMS_FGA.ADD_POLICY podemos crear una auditoría de grano fino para la tabla emp de scott:\n\n```\nBEGIN\n    DBMS_FGA.ADD_POLICY (\n        object_schema      =>  'SCOTT',\n        object_name        =>  'EMP',\n        policy_name        =>  'AUDIT_EMP_SAL',\n        audit_condition    =>  'SAL > 2000',\n        statement_types    =>  'INSERT'\n    );\nEND;\n/\n```\n\n![image](/images/audit-7.png)\n\nAhora vamos a insertar un empleado con un salario superior a 2000 con el usuario SCOTT:\n\n![image](/images/audit-8.png)\n\nY entramos en como administrador de nuevo y comprobamos que se ha registrado el insert que contiene el salario mayor a 2000:\n\n```\nSELECT DB_USER, OBJECT_NAME, SQL_TEXT, TIMESTAMP FROM DBA_FGA_AUDIT_TRAIL WHERE POLICY_NAME='AUDIT_EMP_SAL';\n```\n\n![image](/images/audit-9.png)\n\n\nAlternativamente podríamos hacer nosotros nuestra auditoría con un trigger, como veremos en los siguientes casos, pero viendo que la utilidad de DBMS_FGA es más sencilla y rápida, es la que hemos empleado en este caso.\n\n## 5. Explica la diferencia entre auditar una operación by access o by session ilustrándolo con ejemplos.\n\nLa auditoría by access registra cada acceso a los objetos de la base de datos, mientras que la auditoría by session registra la actividad del usuario solo una vez, lo que evita recursividad. La elección de qué tipo de auditoría utilizar dependerá de los objetivos de la auditoría y del nivel de detalle necesario para cumplirlos, siendo así más detallado el hecho de la auditoría by access.\n\nComo ejemplos podemos tomar de ejercicios anteriores la auditoría de accesos exitosos:\n\n![image](/images/audit-3.png)\n\nY la auditoría by session:\n\n![image](/images/audit-6.png)\n\n\n\n\n## 6. Documenta las diferencias entre los valores db y db, extended del parámetro audit_trail de ORACLE. Demuéstralas poniendo un ejemplo de la información sobre una operación concreta recopilada con cada uno de ellos.\n\nLos valores que alberga el parámetro deb y db extended son los mismos, exceptos en varias columnas, que es SQLBIND y SQLTEXT:\n\nSi añadimor SQLBIND a nuestra consulta podemos ver que no logra encontrar el campo SQLBIND:\n\n```\nSELECT DB_USER, OBJECT_NAME, SQL_TEXT, TIMESTAMP FROM DBA_FGA_AUDIT_TRAIL WHERE POLICY_NAME='AUDIT_EMP_SAL';\n```\n\n![image](/images/audit-10.png)\n\nCon esto podemos ver el parámetro audit_trail como vimos en el ejercicio 1:\n\n```\nSHOW PARAMETER AUDIT\n```\n\n![image](/images/audit-1.png)\n\n\nEntonces, si queremos cambiar el valor de audit_trail a db extended, debemos hacer lo siguiente:\n\n```\nALTER SYSTEM SET audit_trail = DB,EXTENDED SCOPE=SPFILE;\n```\n\nY seguidamente reiniciar la base de datos:\n\n```\nshutdown\nstartup\n```\n\nAhora podemos comprobar que se encuentra de manera extendida:\n\n![image](/images/audit-11.png)\n\n\nY al entrar en la base de datos con el usuario SCOTT y hacer un insert en la tabla emp, podemos ver que ahora si se encuentra el campo SQLBIND y SQLTEXT:\n\n```\nSELECT USERNAME,ACTION_NAME,TIMESTAMP, OBJ_NAME, SQL_TEXT, SQL_BIND from DBA_AUDIT_OBJECT where USERNAME='SCOTT';\n```\n\n![image](/images/audit-12.png)\n\n## 7. Averigua si en Postgres se pueden realizar los cuatro primeros apartados. Si es así, documenta el proceso adecuadamente.\n\nEn postgres podemos ver gracias a la ruta `/var/log/postgresql/postgresql-13-main.log` los logs de intentos fallidos al sistema:\n\n![image](/images/audit-13.png)\n\nA parte de esto, Postgres no contempla las auditorías, para ello debemos descargar una herramienta de terceros llamada audit trigger 91 plus que nos permitirá realizar auditorías en la base de datos.\n\nSeguidamente importaremos el esquema de base de datos a nuestro sistema gestor de base de datos:\n\n```\n\\i audit.sql\n```\n\nComo podemos contemplar en la imagen se ha creado diferentes funciones, tablas y disparadores que nos permitirán realizar auditorías en la base de datos:\n\n![image](/images/audit-14.png)\n\nVamos a activar la auditoría de la tabla personaje:\n\n```\nSELECT audit.audit_table('personaje');\n```\n\n![image](/images/audit-16.png)\n\n\nAHora vamos a insertar un nuevo registro en la tabla personaje:\n\n![image](/images/audit-15.png)\n\n\nSeguidamente vamos a comprobar que funciona la auditoría:\n\n```\nselect session_user_name, action, table_name, action_tstamp_clk, client_query \nfrom audit.logged_actions;\n```\n![image](/images/audit-17.png)\n\nNota: para poder realizar la auditoría de manera correcta, la importación del esquema debe hacerse dentro de la base de datos con la que se va a trabajar, de manera que si queremos que se audite la tabla personaje de la base de datos souls, deberemos importar el esquema dentro de esta base de datos.\n\nAhora vamos a resolver el ejercicio 4 que consiste en crear una política de auditoría que registre los accesos a la tabla EMP de SCOTT que tengan un salario superior a 2000, por defecto no tiene una funcionalidad bd como pudiese tenerlo Oracle, pero sí que podemos crear un trigger que nos permita realizar esta auditoría.\n\n\nPrimero crearemos la tabla auditoria_emp:\n\n```\nCREATE TABLE auditoria_emp (\n  id SERIAL PRIMARY KEY,\n  EMPNO INT NOT NULL,\n  ACCION VARCHAR(10) NOT NULL,\n  SALARIO DECIMAL(7, 2) NOT NULL,\n  FECHA_HORA TIMESTAMP NOT NULL DEFAULT NOW()\n);\n```\n\nVamos a explicar esta tabla:\n- id: es un campo autoincremental que nos permitirá identificar cada registro de la tabla.\n- EMPNO: es el número de empleado.\n- ACCION: es el salario del empleado.\n- SALARIO: es el salario del empleado.\n- FECHA_HORA: es la fecha y hora en la que se ha realizado la acción.\n\n\n```\nCREATE OR REPLACE FUNCTION insert_auditoria_emp()\nRETURNS TRIGGER AS $$\nBEGIN\n  INSERT INTO auditoria_emp (EMPNO, SALARIO, ACCION)\n  VALUES (NEW.EMPNO, NEW.SAL, 'INSERT');\n  RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER tr_insert_emp\nAFTER INSERT ON EMP\nFOR EACH ROW\nWHEN (NEW.SAL > 2000)\nEXECUTE FUNCTION insert_auditoria_emp();\n```\n\n```\nCREATE OR REPLACE FUNCTION update_auditoria_emp()\nRETURNS TRIGGER AS $$\nBEGIN\n  INSERT INTO auditoria_emp (EMPNO, SALARIO, ACCION)\n  VALUES (NEW.EMPNO, NEW.SAL, 'UPDATE');\n  RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER tr_update_emp\nAFTER UPDATE ON EMP\nFOR EACH ROW\nWHEN (NEW.SAL > 2000)\nEXECUTE FUNCTION update_auditoria_emp();\n```\n\nAhora vamos a insertar un registro y seguidamente actualizar otro para comprobar que funciona correctamente:\n\n```\nINSERT INTO EMP VALUES(7909, 'JAMES', 'CLERK', 7698, '1981-12-03', 2950, NULL, 30);\nUPDATE EMP SET SAL = 4000 WHERE EMPNO = 7369;\n```\n\n![image](/images/audit-22.png)\n\n## 8. Averigua si en MySQL se pueden realizar los apartados 1, 3 y 4. Si es así, documenta el proceso adecuadamente.\n\n\nPrimero para activar la auditoría en Maríadb, que es la alternativa más a MySQL, debemos modificar el archivo de configuración que se encuentra en `/etc/mysql/mariadb.conf.d/50-server.cnf` y descomentar las líneas que vemos en la siguiente imagen:\n\n![image](/images/audit-18.png)\n\nSeguidamente necesitamos que el usuario mysql tenga permisos para poder escribir en el fichero que hemos descomentado en la línea de configuración `log_error`:\n\n\n`chown -R mysql: /var/log/mysql`\n\nseguidamente reiniciamos el servicio:\n\n`systemctl restart mysql`\n\nSi intentamos acceder a través de mysql -u root -p y fallamos la contraseña se mantendrá registrado en el log:\n\n![image](/images/audit-19.png)\n\nAhora nos conectaremos con el usuario SCOTT, crearemos la tabla personaje del anterior ejercicio de postgres y haremos varios inserts:\n\n```\nCREATE TABLE personaje (\ncodpersonaje varchar (3),\nnombre varchar (15),\naltura decimal (3,2),\npeso decimal (3),\nraza varchar (10) DEFAULT ('Humano'),\nCONSTRAINT pk_codpersonaje PRIMARY KEY (codpersonaje),\nCONSTRAINT ck_codpersonaje CHECK (codpersonaje REGEXP '^1.*'),\nconstraint ck_nombre CHECK (nombre REGEXP '^[A-Z][a-z]*')\n);\n\n\n\ninsert into personaje values ('101','Solaire',1.70,80,'humano');\ninsert into personaje values ('102','Artorias',1.90,90,'hueco');\ninsert into personaje values ('103','Gargola',3.10,680,'Gárgola');\n```\n\nAl terminar, nos vamos al fichero de log `cat /var/log/mysql/mysql.log` y podemos ver cada uno de las acciones que hemos realizado:\n\n![image](/images/audit-20.png)\n\nAhora vamos a realizar el ejercicio 4 de manera que solo audite cada vez que el usuario inserte o actualice el salario de un empleado que sea mayor de 2000:\n\n```\nCREATE TABLE auditoria_emp (\n  id INT NOT NULL AUTO_INCREMENT,\n  EMPNO INT NOT NULL,\n  SALARIO DECIMAL(7, 2) NOT NULL,\n  ACCION VARCHAR(10) NOT NULL,\n  FECHA_HORA TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  PRIMARY KEY (id)\n);\n```\n\nVamos a explicar esta tabla:\n\n- La tabla contiene un id que es autoincremental, lo cual nos permitirá identificar cada uno de los registros de la tabla aunque se repitan datos, la cual haremos primary key.\n- el código del empleado el cual nos servirá para identificar el empleado que ha sufrido el cambio.\n- el salario que será mayor de 2000 para que se pueda auditar.\n- La fecha y hora del sistema en ese momento.\n\n\nAhora vamos a crear el disparador bastante sencillo que nos permitirá auditar cada vez que el salario de un empleado sea mayor de 2000:\n\n```\nDELIMITER //\n\nCREATE TRIGGER tr_insert_emp\nAFTER INSERT ON EMP\nFOR EACH ROW\nBEGIN\n  IF NEW.SAL > 2000 THEN\n    INSERT INTO auditoria_emp (EMPNO, SALARIO, ACCION) VALUES (NEW.EMPNO, NEW.SAL, 'INSERT');\n  END IF;\nEND //\n\nDELIMITER ;\n```\n\n```\nDELIMITER //\n\nCREATE TRIGGER tr_update_emp\nAFTER UPDATE ON EMP\nFOR EACH ROW\nBEGIN\n  IF NEW.SAL > 2000 THEN\n    INSERT INTO auditoria_emp (EMPNO, SALARIO, ACCION) VALUES (NEW.EMPNO, NEW.SAL, 'UPDATE');\n  END IF;\nEND //\n\nDELIMITER ;\n```\n\nInsertamos y actualizamos registros:\n\n```\nINSERT INTO EMP VALUES(7911, 'JAMES', 'CLERK', 7698,'1981-12-03', 2950, NULL, 30);\nUPDATE EMP SET SAL = 3000 WHERE EMPNO = 7369;\n```\n\n\n\nY aquí el resultado junto con la acción de insertar o actualizar un salario a más de 2000:\n\n![image](/images/audit-21.png)\n\n## 9.  Averigua las posibilidades que ofrece MongoDB para auditar los cambios que va sufriendo un documento. Demuestra su funcionamiento.\n\nLas posibilidades que ofrece MongoDB para auditar los cambios que va sufriendo un documento son las siguientes:\n\n\n\nPodemos activar las auditorías en un fichero JSON desde el fichero de configuración:\n`nano /etc/mongod.conf`\n\n\n```\nauditLog:\n  destination: file\n  format: JSON\n  path: /var/log/mongodb/auditLog.json\n```\n\nTambién podremos activar las auditorías en el syslog desde el fichero de configuración:\nnano /etc/mongod.conf\n\n```\nauditLog:\n  destination: syslog\n```\n\nTambién podemos habilitar las auditorías en un fichero BSON desde el fichero de configuración:\nnano /etc/mongod.conf\n\n```\nauditLog:\n  destination: file\n  format: BSON\n  path: /var/log/mongodb/auditLog.bson\n```\n\nHabilitar las auditorías en la consola desde el fichero de configuración:\nnano /etc/mongod.conf\n\n```\nauditLog:\n  destination: console\n```\n\n\n\nVamos a empezar a crear el usuario en la base de datos, la cual más tarde importará unos 140 documentos que poseo.\n\n```\ndb.createUser(\n   {\n     user: \"admin\", \n     pwd: \"admin\", \n     roles: [ { role: \"dbOwner\", db: \"souls\" } ]\n   }\n )\n```\n\n\nEn la documentación oficial de mongo especifica que recomienda la auditoría en formato BSON, ya que los JSON degradan la eficiencia de la auditoría.\n\n![image](/images/audit-25.png)\n\nPor ende elijo mostrar la auditoría en formato BSON:\n\n```\nnano /etc/mongod.conf\n\nauditLog:\n  destination: file\n  format: BSON\n  path: /var/log/mongodb/auditLog.bson\n```\n\nATENCIÓN: mongodb trabaja con ficheros bson, el cual es un lenguaje interpretado por la máquina específicamente creado por mongodb, por lo que no podremos visualizarlo con el comando `cat` o `less` como normalmente se hace con con los ficheros de texto plano, para ello utilizaremos el comando `bsondump` que nos permite visualizar el contenido de un fichero BSON y lo transforma a JSON.\n\n```\nbsondump /var/log/mongodb/auditLog.bson | jq\n```\n\nEntonces... por qué no he elegido el formato JSON si al final lo transformo a JSON? Pues porque al elegir el JSON directamente haces que lmongo sea la que traduzca directamente el BSON a JSON, lo cual hace que la base de datos tenga que hacer un trabajo extra que no es necesario, por lo que es mejor que la base de datos realice la auditoría con BSON y nosotros con la computación de la máquina del cliente lo transformemos a JSON cuando queramos visualizarlo.\n\nEn nuestro caso con 140 documentos es una diferencia mínima, pero si tuviéramos millones de documentos, la diferencia sería notable.\n\nAhora vamos a proceder a importar los documentos a la base de datos souls:\n\n\n```\nmongoimport --db souls --type=json --file DarkSoulsWeapons.json --jsonArray\n```\n\n![image](/images/audit-24.png)\n\nAhora vamos a comprobar que se ha registrado la importación en el fichero de auditoría:\n\n![image](/images/audit-26.png)\n\n\nComo podemos ver se ha realizado la acción de mongoimport y ha actuado sobre la base de datos y colección souls/soulsweapons.\n\nHan pasado varios días, me levanto una mañana y descubro que alguien ha borrado todos los documentos de la colección soulsweapons, por lo que voy a proceder a realizar una auditoría de la base de datos para descubrir quien ha sido el culpable:\n\nResulta que un usuario con un nick un tanto sospechoso ha entrado en la base de datos souls, lo podemos ver a través del ActionType y user,db:\n\n![image](/images/audit-27.png)\n\nPero esto no dice nada sobre lo que el usuario ha podido hacer, debemos indagar un poco más de su actividad una vez logueado en la base de datos, por lo que podemos filtrar ahora que conocemos los valores que hay que observar:\n\n```\nbsondump /var/log/mongodb/auditLog.bson | jq | egrep 'user|atype|ns''\n```\n\nOJO!! Este usuario ha hecho un drop de la colección soulsweapons, ahora sí que podemos decir que esta persona ha sido la culpable.\n\n![image](/images/audit-29.png)\n\n\n\n## 10. Averigua si en MongoDB se pueden auditar los accesos a una colección concreta. Demuestra su funcionamiento.\n\nComo buenos administradores de sistemas tenemos la copia de la información guardada, entonces vamos a comenzar auditando la colección soulsweapons:\n\nEn el ejercicio anterior entre los valores que hemos filtrado se encuentra el campo ns, este es el campo del namespace, el cual es \"nombrebasededatos.coleccion\" así que vamos a establecer un filtro en el archivo de configuración de mongo para que comience a auditar la colección soulsweapons:\n\n\nEntramos como administrador en la base de datos admin y ejecutamos el siguiente comando:\n\n```\nuse souls\ndb.setProfilingLevel(2)\n```\n\nA partir de ahora todas las acciones que se realicen sobre la colección, podrán ser auditadas de manera que sabremos incluso qué se está insertando:\n\n\n```\ndb.system.profile.find({\n   \"ns\": \"souls.DarkSoulsWeapons\",\n   \"op\": {\n      \"$in\": [\n         \"insert\",\n         \"update\",\n         \"delete\"\n      ]\n   }\n})\n```\n\n![image](/images/audit-31.png)\n\n\nComo podemos ver, el usuario admin ha insertado un documento en la colección soulsweapons.\n\n","slug":"auditoria","published":1,"date":"2023-02-21T08:39:02.627Z","updated":"2023-02-24T04:15:59.063Z","_id":"cleezyw3s0000idi5dh110ycs","comments":1,"layout":"post","photos":[],"link":"","content":"<p><img src=\"/images/audit-logo.png\" alt=\"image\"></p>\n<h2 id=\"1-activa-desde-sqlplus-la-auditoría-de-los-intentos-de-acceso-exitosos-al-sistema-comprueba-su-funcionamiento\"><a class=\"markdownIt-Anchor\" href=\"#1-activa-desde-sqlplus-la-auditoría-de-los-intentos-de-acceso-exitosos-al-sistema-comprueba-su-funcionamiento\">#</a> 1. Activa desde SQL*Plus la auditoría de los intentos de acceso exitosos al sistema. Comprueba su funcionamiento.</h2>\n<p>Vemos si tenemos activado el registro de auditoría:</p>\n<pre><code>SELECT name, value FROM v$parameter WHERE name = 'audit_trail';\n</code></pre>\n<p>También podemos emplear la siguiente sentencia:</p>\n<pre><code>SHOW PARAMETER AUDIT\n</code></pre>\n<p><img src=\"/images/audit-1.png\" alt=\"image\"></p>\n<p>Emplearemos la siguiente sentencia para activar la auditoría:</p>\n<pre><code>AUDIT CREATE SESSION WHENEVER SUCCESSFUL;\n</code></pre>\n<p>Ahora nos desconectamos del susuario administrador y entraremos con el de antonio:</p>\n<p><img src=\"/images/audit-2.png\" alt=\"image\"></p>\n<pre><code>SELECT OS_USERNAME, USERNAME, EXTENDED_TIMESTAMP, ACTION_NAME FROM DBA_AUDIT_SESSION WHERE USERNAME = 'ANTONIO';\n</code></pre>\n<p><img src=\"/images/audit-3.png\" alt=\"image\"></p>\n<p>Como podemos ver el usuario ha quedado registrado en la tabla DBA_AUDIT_SESSION.</p>\n<h2 id=\"2-realiza-un-procedimiento-en-plsql-que-te-muestre-los-accesos-fallidos-junto-con-el-motivo-de-los-mismos-transformando-el-código-de-error-almacenado-en-un-mensaje-de-texto-comprensible-contempla-todos-los-motivos-posibles-para-que-un-acceso-sea-fallido\"><a class=\"markdownIt-Anchor\" href=\"#2-realiza-un-procedimiento-en-plsql-que-te-muestre-los-accesos-fallidos-junto-con-el-motivo-de-los-mismos-transformando-el-código-de-error-almacenado-en-un-mensaje-de-texto-comprensible-contempla-todos-los-motivos-posibles-para-que-un-acceso-sea-fallido\">#</a> 2. Realiza un procedimiento en PL/SQL que te muestre los accesos fallidos junto con el motivo de los mismos, transformando el código de error almacenado en un mensaje de texto comprensible. Contempla todos los motivos posibles para que un acceso sea fallido.</h2>\n<pre><code>CREATE OR REPLACE PROCEDURE AUDIT_ACCESOS\nIS\ncursor c_conexion is SELECT OS_USERNAME,TIMESTAMP, USERNAME, RETURNCODE FROM DBA_AUDIT_SESSION;\nBEGIN\nfor v_conexion in c_conexion loop\n    Dbms_Output.Put_Line(v_conexion.OS_USERNAME);\n    Dbms_Output.Put_Line(v_conexion.USERNAME);\n    Dbms_Output.Put_Line(v_conexion.TIMESTAMP);\n    MOSTRAR_DEF_ERROR(v_conexion.RETURNCODE);\nend loop;\nEND;\n/\n\nCREATE OR REPLACE PROCEDURE MOSTRAR_DEF_ERROR (p_codigo NUMBER)\nIS\nBEGIN\nIF p_codigo = 1017 THEN\n    dbms_Output.Put_Line('Error ' || p_codigo || ' El usuario o la contraseña no existe');\nELSIF p_codigo = 2391 THEN\n    dbms_Output.Put_Line('Error ' || p_codigo || ' Excedidas las conexiones simultáneas permitidas');\nELSIF p_codigo = 1045 THEN\n    dbms_Output.Put_Line('Error ' || p_codigo || ' El usuario no tiene permisos de creación de sesión');\nELSIF p_codigo = 28001 THEN\n    dbms_Output.Put_Line('Error ' || p_codigo || ' La contraseña del usuario ha caducado');\nELSIF p_codigo = 28009 THEN\n    dbms_Output.Put_Line('Error ' || p_codigo || ' La conexión debe ser a través de SYS o SYSOPER');\nELSIF p_codigo = 1034 THEN\n    dbms_Output.Put_Line('Error ' || p_codigo || ' La base de datos no está levantada');\nEND IF;\nEND;\n/\n</code></pre>\n<p><img src=\"/images/audit-4.png\" alt=\"image\"></p>\n<h2 id=\"3-activa-la-auditoría-de-las-operaciones-dml-realizadas-por-scott-comprueba-su-funcionamiento\"><a class=\"markdownIt-Anchor\" href=\"#3-activa-la-auditoría-de-las-operaciones-dml-realizadas-por-scott-comprueba-su-funcionamiento\">#</a> 3. Activa la auditoría de las operaciones DML realizadas por SCOTT. Comprueba su funcionamiento.</h2>\n<pre><code>AUDIT INSERT TABLE, UPDATE TABLE, DELETE TABLE BY SCOTT BY ACCESS;\n</code></pre>\n<p>Ahora vamos a rellenar con diferentes cambios para registrarlo en la auditoría:</p>\n<p><img src=\"/images/audit-5.png\" alt=\"image\"></p>\n<p>Y con la siguiente sentencia podemos ver los cambios que se han realizado desde el usuario sys:</p>\n<pre><code>SELECT OS_USERNAME, USERNAME, TIMESTAMP, ACTION_NAME FROM DBA_AUDIT_OBJECT WHERE USERNAME = 'SCOTT';\n</code></pre>\n<p><img src=\"/images/audit-6.png\" alt=\"image\"></p>\n<h2 id=\"4-realiza-una-auditoría-de-grano-fino-para-almacenar-información-sobre-la-inserción-de-empleados-con-sueldo-superior-a-2000-en-la-tabla-emp-de-scott\"><a class=\"markdownIt-Anchor\" href=\"#4-realiza-una-auditoría-de-grano-fino-para-almacenar-información-sobre-la-inserción-de-empleados-con-sueldo-superior-a-2000-en-la-tabla-emp-de-scott\">#</a> 4. Realiza una auditoría de grano fino para almacenar información sobre la inserción de empleados con sueldo superior a 2000 en la tabla emp de scott.</h2>\n<p>¿Qué es una auditoría de grano fino?</p>\n<p>Una auditoría de grano fino es una auditoría más detallada que no solo contempla el hecho de inserción de filas y columnas sino que también pueden auditarse qué datos han cambiado para así tener un major control sobre la base de datos.</p>\n<p>Así que con el objeto DBMS_FGA.ADD_POLICY podemos crear una auditoría de grano fino para la tabla emp de scott:</p>\n<pre><code>BEGIN\n    DBMS_FGA.ADD_POLICY (\n        object_schema      =&gt;  'SCOTT',\n        object_name        =&gt;  'EMP',\n        policy_name        =&gt;  'AUDIT_EMP_SAL',\n        audit_condition    =&gt;  'SAL &gt; 2000',\n        statement_types    =&gt;  'INSERT'\n    );\nEND;\n/\n</code></pre>\n<p><img src=\"/images/audit-7.png\" alt=\"image\"></p>\n<p>Ahora vamos a insertar un empleado con un salario superior a 2000 con el usuario SCOTT:</p>\n<p><img src=\"/images/audit-8.png\" alt=\"image\"></p>\n<p>Y entramos en como administrador de nuevo y comprobamos que se ha registrado el insert que contiene el salario mayor a 2000:</p>\n<pre><code>SELECT DB_USER, OBJECT_NAME, SQL_TEXT, TIMESTAMP FROM DBA_FGA_AUDIT_TRAIL WHERE POLICY_NAME='AUDIT_EMP_SAL';\n</code></pre>\n<p><img src=\"/images/audit-9.png\" alt=\"image\"></p>\n<p>Alternativamente podríamos hacer nosotros nuestra auditoría con un trigger, como veremos en los siguientes casos, pero viendo que la utilidad de DBMS_FGA es más sencilla y rápida, es la que hemos empleado en este caso.</p>\n<h2 id=\"5-explica-la-diferencia-entre-auditar-una-operación-by-access-o-by-session-ilustrándolo-con-ejemplos\"><a class=\"markdownIt-Anchor\" href=\"#5-explica-la-diferencia-entre-auditar-una-operación-by-access-o-by-session-ilustrándolo-con-ejemplos\">#</a> 5. Explica la diferencia entre auditar una operación by access o by session ilustrándolo con ejemplos.</h2>\n<p>La auditoría by access registra cada acceso a los objetos de la base de datos, mientras que la auditoría by session registra la actividad del usuario solo una vez, lo que evita recursividad. La elección de qué tipo de auditoría utilizar dependerá de los objetivos de la auditoría y del nivel de detalle necesario para cumplirlos, siendo así más detallado el hecho de la auditoría by access.</p>\n<p>Como ejemplos podemos tomar de ejercicios anteriores la auditoría de accesos exitosos:</p>\n<p><img src=\"/images/audit-3.png\" alt=\"image\"></p>\n<p>Y la auditoría by session:</p>\n<p><img src=\"/images/audit-6.png\" alt=\"image\"></p>\n<h2 id=\"6-documenta-las-diferencias-entre-los-valores-db-y-db-extended-del-parámetro-audit_trail-de-oracle-demuéstralas-poniendo-un-ejemplo-de-la-información-sobre-una-operación-concreta-recopilada-con-cada-uno-de-ellos\"><a class=\"markdownIt-Anchor\" href=\"#6-documenta-las-diferencias-entre-los-valores-db-y-db-extended-del-parámetro-audit_trail-de-oracle-demuéstralas-poniendo-un-ejemplo-de-la-información-sobre-una-operación-concreta-recopilada-con-cada-uno-de-ellos\">#</a> 6. Documenta las diferencias entre los valores db y db, extended del parámetro audit_trail de ORACLE. Demuéstralas poniendo un ejemplo de la información sobre una operación concreta recopilada con cada uno de ellos.</h2>\n<p>Los valores que alberga el parámetro deb y db extended son los mismos, exceptos en varias columnas, que es SQLBIND y SQLTEXT:</p>\n<p>Si añadimor SQLBIND a nuestra consulta podemos ver que no logra encontrar el campo SQLBIND:</p>\n<pre><code>SELECT DB_USER, OBJECT_NAME, SQL_TEXT, TIMESTAMP FROM DBA_FGA_AUDIT_TRAIL WHERE POLICY_NAME='AUDIT_EMP_SAL';\n</code></pre>\n<p><img src=\"/images/audit-10.png\" alt=\"image\"></p>\n<p>Con esto podemos ver el parámetro audit_trail como vimos en el ejercicio 1:</p>\n<pre><code>SHOW PARAMETER AUDIT\n</code></pre>\n<p><img src=\"/images/audit-1.png\" alt=\"image\"></p>\n<p>Entonces, si queremos cambiar el valor de audit_trail a db extended, debemos hacer lo siguiente:</p>\n<pre><code>ALTER SYSTEM SET audit_trail = DB,EXTENDED SCOPE=SPFILE;\n</code></pre>\n<p>Y seguidamente reiniciar la base de datos:</p>\n<pre><code>shutdown\nstartup\n</code></pre>\n<p>Ahora podemos comprobar que se encuentra de manera extendida:</p>\n<p><img src=\"/images/audit-11.png\" alt=\"image\"></p>\n<p>Y al entrar en la base de datos con el usuario SCOTT y hacer un insert en la tabla emp, podemos ver que ahora si se encuentra el campo SQLBIND y SQLTEXT:</p>\n<pre><code>SELECT USERNAME,ACTION_NAME,TIMESTAMP, OBJ_NAME, SQL_TEXT, SQL_BIND from DBA_AUDIT_OBJECT where USERNAME='SCOTT';\n</code></pre>\n<p><img src=\"/images/audit-12.png\" alt=\"image\"></p>\n<h2 id=\"7-averigua-si-en-postgres-se-pueden-realizar-los-cuatro-primeros-apartados-si-es-así-documenta-el-proceso-adecuadamente\"><a class=\"markdownIt-Anchor\" href=\"#7-averigua-si-en-postgres-se-pueden-realizar-los-cuatro-primeros-apartados-si-es-así-documenta-el-proceso-adecuadamente\">#</a> 7. Averigua si en Postgres se pueden realizar los cuatro primeros apartados. Si es así, documenta el proceso adecuadamente.</h2>\n<p>En postgres podemos ver gracias a la ruta  <code>/var/log/postgresql/postgresql-13-main.log</code>  los logs de intentos fallidos al sistema:</p>\n<p><img src=\"/images/audit-13.png\" alt=\"image\"></p>\n<p>A parte de esto, Postgres no contempla las auditorías, para ello debemos descargar una herramienta de terceros llamada audit trigger 91 plus que nos permitirá realizar auditorías en la base de datos.</p>\n<p>Seguidamente importaremos el esquema de base de datos a nuestro sistema gestor de base de datos:</p>\n<pre><code>\\i audit.sql\n</code></pre>\n<p>Como podemos contemplar en la imagen se ha creado diferentes funciones, tablas y disparadores que nos permitirán realizar auditorías en la base de datos:</p>\n<p><img src=\"/images/audit-14.png\" alt=\"image\"></p>\n<p>Vamos a activar la auditoría de la tabla personaje:</p>\n<pre><code>SELECT audit.audit_table('personaje');\n</code></pre>\n<p><img src=\"/images/audit-16.png\" alt=\"image\"></p>\n<p>AHora vamos a insertar un nuevo registro en la tabla personaje:</p>\n<p><img src=\"/images/audit-15.png\" alt=\"image\"></p>\n<p>Seguidamente vamos a comprobar que funciona la auditoría:</p>\n<pre><code>select session_user_name, action, table_name, action_tstamp_clk, client_query \nfrom audit.logged_actions;\n</code></pre>\n<p><img src=\"/images/audit-17.png\" alt=\"image\"></p>\n<p>Nota: para poder realizar la auditoría de manera correcta, la importación del esquema debe hacerse dentro de la base de datos con la que se va a trabajar, de manera que si queremos que se audite la tabla personaje de la base de datos souls, deberemos importar el esquema dentro de esta base de datos.</p>\n<p>Ahora vamos a resolver el ejercicio 4 que consiste en crear una política de auditoría que registre los accesos a la tabla EMP de SCOTT que tengan un salario superior a 2000, por defecto no tiene una funcionalidad bd como pudiese tenerlo Oracle, pero sí que podemos crear un trigger que nos permita realizar esta auditoría.</p>\n<p>Primero crearemos la tabla auditoria_emp:</p>\n<pre><code>CREATE TABLE auditoria_emp (\n  id SERIAL PRIMARY KEY,\n  EMPNO INT NOT NULL,\n  ACCION VARCHAR(10) NOT NULL,\n  SALARIO DECIMAL(7, 2) NOT NULL,\n  FECHA_HORA TIMESTAMP NOT NULL DEFAULT NOW()\n);\n</code></pre>\n<p>Vamos a explicar esta tabla:</p>\n<ul>\n<li>id: es un campo autoincremental que nos permitirá identificar cada registro de la tabla.</li>\n<li>EMPNO: es el número de empleado.</li>\n<li>ACCION: es el salario del empleado.</li>\n<li>SALARIO: es el salario del empleado.</li>\n<li>FECHA_HORA: es la fecha y hora en la que se ha realizado la acción.</li>\n</ul>\n<pre><code>CREATE OR REPLACE FUNCTION insert_auditoria_emp()\nRETURNS TRIGGER AS $$\nBEGIN\n  INSERT INTO auditoria_emp (EMPNO, SALARIO, ACCION)\n  VALUES (NEW.EMPNO, NEW.SAL, 'INSERT');\n  RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER tr_insert_emp\nAFTER INSERT ON EMP\nFOR EACH ROW\nWHEN (NEW.SAL &gt; 2000)\nEXECUTE FUNCTION insert_auditoria_emp();\n</code></pre>\n<pre><code>CREATE OR REPLACE FUNCTION update_auditoria_emp()\nRETURNS TRIGGER AS $$\nBEGIN\n  INSERT INTO auditoria_emp (EMPNO, SALARIO, ACCION)\n  VALUES (NEW.EMPNO, NEW.SAL, 'UPDATE');\n  RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER tr_update_emp\nAFTER UPDATE ON EMP\nFOR EACH ROW\nWHEN (NEW.SAL &gt; 2000)\nEXECUTE FUNCTION update_auditoria_emp();\n</code></pre>\n<p>Ahora vamos a insertar un registro y seguidamente actualizar otro para comprobar que funciona correctamente:</p>\n<pre><code>INSERT INTO EMP VALUES(7909, 'JAMES', 'CLERK', 7698, '1981-12-03', 2950, NULL, 30);\nUPDATE EMP SET SAL = 4000 WHERE EMPNO = 7369;\n</code></pre>\n<p><img src=\"/images/audit-22.png\" alt=\"image\"></p>\n<h2 id=\"8-averigua-si-en-mysql-se-pueden-realizar-los-apartados-1-3-y-4-si-es-así-documenta-el-proceso-adecuadamente\"><a class=\"markdownIt-Anchor\" href=\"#8-averigua-si-en-mysql-se-pueden-realizar-los-apartados-1-3-y-4-si-es-así-documenta-el-proceso-adecuadamente\">#</a> 8. Averigua si en MySQL se pueden realizar los apartados 1, 3 y 4. Si es así, documenta el proceso adecuadamente.</h2>\n<p>Primero para activar la auditoría en Maríadb, que es la alternativa más a MySQL, debemos modificar el archivo de configuración que se encuentra en  <code>/etc/mysql/mariadb.conf.d/50-server.cnf</code>  y descomentar las líneas que vemos en la siguiente imagen:</p>\n<p><img src=\"/images/audit-18.png\" alt=\"image\"></p>\n<p>Seguidamente necesitamos que el usuario mysql tenga permisos para poder escribir en el fichero que hemos descomentado en la línea de configuración  <code>log_error</code> :</p>\n<p><code>chown -R mysql: /var/log/mysql</code></p>\n<p>seguidamente reiniciamos el servicio:</p>\n<p><code>systemctl restart mysql</code></p>\n<p>Si intentamos acceder a través de mysql -u root -p y fallamos la contraseña se mantendrá registrado en el log:</p>\n<p><img src=\"/images/audit-19.png\" alt=\"image\"></p>\n<p>Ahora nos conectaremos con el usuario SCOTT, crearemos la tabla personaje del anterior ejercicio de postgres y haremos varios inserts:</p>\n<pre><code>CREATE TABLE personaje (\ncodpersonaje varchar (3),\nnombre varchar (15),\naltura decimal (3,2),\npeso decimal (3),\nraza varchar (10) DEFAULT ('Humano'),\nCONSTRAINT pk_codpersonaje PRIMARY KEY (codpersonaje),\nCONSTRAINT ck_codpersonaje CHECK (codpersonaje REGEXP '^1.*'),\nconstraint ck_nombre CHECK (nombre REGEXP '^[A-Z][a-z]*')\n);\n\n\n\ninsert into personaje values ('101','Solaire',1.70,80,'humano');\ninsert into personaje values ('102','Artorias',1.90,90,'hueco');\ninsert into personaje values ('103','Gargola',3.10,680,'Gárgola');\n</code></pre>\n<p>Al terminar, nos vamos al fichero de log  <code>cat /var/log/mysql/mysql.log</code>  y podemos ver cada uno de las acciones que hemos realizado:</p>\n<p><img src=\"/images/audit-20.png\" alt=\"image\"></p>\n<p>Ahora vamos a realizar el ejercicio 4 de manera que solo audite cada vez que el usuario inserte o actualice el salario de un empleado que sea mayor de 2000:</p>\n<pre><code>CREATE TABLE auditoria_emp (\n  id INT NOT NULL AUTO_INCREMENT,\n  EMPNO INT NOT NULL,\n  SALARIO DECIMAL(7, 2) NOT NULL,\n  ACCION VARCHAR(10) NOT NULL,\n  FECHA_HORA TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  PRIMARY KEY (id)\n);\n</code></pre>\n<p>Vamos a explicar esta tabla:</p>\n<ul>\n<li>La tabla contiene un id que es autoincremental, lo cual nos permitirá identificar cada uno de los registros de la tabla aunque se repitan datos, la cual haremos primary key.</li>\n<li>el código del empleado el cual nos servirá para identificar el empleado que ha sufrido el cambio.</li>\n<li>el salario que será mayor de 2000 para que se pueda auditar.</li>\n<li>La fecha y hora del sistema en ese momento.</li>\n</ul>\n<p>Ahora vamos a crear el disparador bastante sencillo que nos permitirá auditar cada vez que el salario de un empleado sea mayor de 2000:</p>\n<pre><code>DELIMITER //\n\nCREATE TRIGGER tr_insert_emp\nAFTER INSERT ON EMP\nFOR EACH ROW\nBEGIN\n  IF NEW.SAL &gt; 2000 THEN\n    INSERT INTO auditoria_emp (EMPNO, SALARIO, ACCION) VALUES (NEW.EMPNO, NEW.SAL, 'INSERT');\n  END IF;\nEND //\n\nDELIMITER ;\n</code></pre>\n<pre><code>DELIMITER //\n\nCREATE TRIGGER tr_update_emp\nAFTER UPDATE ON EMP\nFOR EACH ROW\nBEGIN\n  IF NEW.SAL &gt; 2000 THEN\n    INSERT INTO auditoria_emp (EMPNO, SALARIO, ACCION) VALUES (NEW.EMPNO, NEW.SAL, 'UPDATE');\n  END IF;\nEND //\n\nDELIMITER ;\n</code></pre>\n<p>Insertamos y actualizamos registros:</p>\n<pre><code>INSERT INTO EMP VALUES(7911, 'JAMES', 'CLERK', 7698,'1981-12-03', 2950, NULL, 30);\nUPDATE EMP SET SAL = 3000 WHERE EMPNO = 7369;\n</code></pre>\n<p>Y aquí el resultado junto con la acción de insertar o actualizar un salario a más de 2000:</p>\n<p><img src=\"/images/audit-21.png\" alt=\"image\"></p>\n<h2 id=\"9-averigua-las-posibilidades-que-ofrece-mongodb-para-auditar-los-cambios-que-va-sufriendo-un-documento-demuestra-su-funcionamiento\"><a class=\"markdownIt-Anchor\" href=\"#9-averigua-las-posibilidades-que-ofrece-mongodb-para-auditar-los-cambios-que-va-sufriendo-un-documento-demuestra-su-funcionamiento\">#</a> 9.  Averigua las posibilidades que ofrece MongoDB para auditar los cambios que va sufriendo un documento. Demuestra su funcionamiento.</h2>\n<p>Las posibilidades que ofrece MongoDB para auditar los cambios que va sufriendo un documento son las siguientes:</p>\n<p>Podemos activar las auditorías en un fichero JSON desde el fichero de configuración:<br>\n <code>nano /etc/mongod.conf</code></p>\n<pre><code>auditLog:\n  destination: file\n  format: JSON\n  path: /var/log/mongodb/auditLog.json\n</code></pre>\n<p>También podremos activar las auditorías en el syslog desde el fichero de configuración:<br>\nnano /etc/mongod.conf</p>\n<pre><code>auditLog:\n  destination: syslog\n</code></pre>\n<p>También podemos habilitar las auditorías en un fichero BSON desde el fichero de configuración:<br>\nnano /etc/mongod.conf</p>\n<pre><code>auditLog:\n  destination: file\n  format: BSON\n  path: /var/log/mongodb/auditLog.bson\n</code></pre>\n<p>Habilitar las auditorías en la consola desde el fichero de configuración:<br>\nnano /etc/mongod.conf</p>\n<pre><code>auditLog:\n  destination: console\n</code></pre>\n<p>Vamos a empezar a crear el usuario en la base de datos, la cual más tarde importará unos 140 documentos que poseo.</p>\n<pre><code>db.createUser(\n   &#123;\n     user: &quot;admin&quot;, \n     pwd: &quot;admin&quot;, \n     roles: [ &#123; role: &quot;dbOwner&quot;, db: &quot;souls&quot; &#125; ]\n   &#125;\n )\n</code></pre>\n<p>En la documentación oficial de mongo especifica que recomienda la auditoría en formato BSON, ya que los JSON degradan la eficiencia de la auditoría.</p>\n<p><img src=\"/images/audit-25.png\" alt=\"image\"></p>\n<p>Por ende elijo mostrar la auditoría en formato BSON:</p>\n<pre><code>nano /etc/mongod.conf\n\nauditLog:\n  destination: file\n  format: BSON\n  path: /var/log/mongodb/auditLog.bson\n</code></pre>\n<p>ATENCIÓN: mongodb trabaja con ficheros bson, el cual es un lenguaje interpretado por la máquina específicamente creado por mongodb, por lo que no podremos visualizarlo con el comando  <code>cat</code>  o  <code>less</code>  como normalmente se hace con con los ficheros de texto plano, para ello utilizaremos el comando  <code>bsondump</code>  que nos permite visualizar el contenido de un fichero BSON y lo transforma a JSON.</p>\n<pre><code>bsondump /var/log/mongodb/auditLog.bson | jq\n</code></pre>\n<p>Entonces… por qué no he elegido el formato JSON si al final lo transformo a JSON? Pues porque al elegir el JSON directamente haces que lmongo sea la que traduzca directamente el BSON a JSON, lo cual hace que la base de datos tenga que hacer un trabajo extra que no es necesario, por lo que es mejor que la base de datos realice la auditoría con BSON y nosotros con la computación de la máquina del cliente lo transformemos a JSON cuando queramos visualizarlo.</p>\n<p>En nuestro caso con 140 documentos es una diferencia mínima, pero si tuviéramos millones de documentos, la diferencia sería notable.</p>\n<p>Ahora vamos a proceder a importar los documentos a la base de datos souls:</p>\n<pre><code>mongoimport --db souls --type=json --file DarkSoulsWeapons.json --jsonArray\n</code></pre>\n<p><img src=\"/images/audit-24.png\" alt=\"image\"></p>\n<p>Ahora vamos a comprobar que se ha registrado la importación en el fichero de auditoría:</p>\n<p><img src=\"/images/audit-26.png\" alt=\"image\"></p>\n<p>Como podemos ver se ha realizado la acción de mongoimport y ha actuado sobre la base de datos y colección souls/soulsweapons.</p>\n<p>Han pasado varios días, me levanto una mañana y descubro que alguien ha borrado todos los documentos de la colección soulsweapons, por lo que voy a proceder a realizar una auditoría de la base de datos para descubrir quien ha sido el culpable:</p>\n<p>Resulta que un usuario con un nick un tanto sospechoso ha entrado en la base de datos souls, lo podemos ver a través del ActionType y user,db:</p>\n<p><img src=\"/images/audit-27.png\" alt=\"image\"></p>\n<p>Pero esto no dice nada sobre lo que el usuario ha podido hacer, debemos indagar un poco más de su actividad una vez logueado en la base de datos, por lo que podemos filtrar ahora que conocemos los valores que hay que observar:</p>\n<pre><code>bsondump /var/log/mongodb/auditLog.bson | jq | egrep 'user|atype|ns''\n</code></pre>\n<p>OJO!! Este usuario ha hecho un drop de la colección soulsweapons, ahora sí que podemos decir que esta persona ha sido la culpable.</p>\n<p><img src=\"/images/audit-29.png\" alt=\"image\"></p>\n<h2 id=\"10-averigua-si-en-mongodb-se-pueden-auditar-los-accesos-a-una-colección-concreta-demuestra-su-funcionamiento\"><a class=\"markdownIt-Anchor\" href=\"#10-averigua-si-en-mongodb-se-pueden-auditar-los-accesos-a-una-colección-concreta-demuestra-su-funcionamiento\">#</a> 10. Averigua si en MongoDB se pueden auditar los accesos a una colección concreta. Demuestra su funcionamiento.</h2>\n<p>Como buenos administradores de sistemas tenemos la copia de la información guardada, entonces vamos a comenzar auditando la colección soulsweapons:</p>\n<p>En el ejercicio anterior entre los valores que hemos filtrado se encuentra el campo ns, este es el campo del namespace, el cual es “nombrebasededatos.coleccion” así que vamos a establecer un filtro en el archivo de configuración de mongo para que comience a auditar la colección soulsweapons:</p>\n<p>Entramos como administrador en la base de datos admin y ejecutamos el siguiente comando:</p>\n<pre><code>use souls\ndb.setProfilingLevel(2)\n</code></pre>\n<p>A partir de ahora todas las acciones que se realicen sobre la colección, podrán ser auditadas de manera que sabremos incluso qué se está insertando:</p>\n<pre><code>db.system.profile.find(&#123;\n   &quot;ns&quot;: &quot;souls.DarkSoulsWeapons&quot;,\n   &quot;op&quot;: &#123;\n      &quot;$in&quot;: [\n         &quot;insert&quot;,\n         &quot;update&quot;,\n         &quot;delete&quot;\n      ]\n   &#125;\n&#125;)\n</code></pre>\n<p><img src=\"/images/audit-31.png\" alt=\"image\"></p>\n<p>Como podemos ver, el usuario admin ha insertado un documento en la colección soulsweapons.</p>\n","site":{"data":{}},"length":14144,"excerpt":"","more":"<p><img src=\"/images/audit-logo.png\" alt=\"image\"></p>\n<h2 id=\"1-activa-desde-sqlplus-la-auditoría-de-los-intentos-de-acceso-exitosos-al-sistema-comprueba-su-funcionamiento\"><a class=\"markdownIt-Anchor\" href=\"#1-activa-desde-sqlplus-la-auditoría-de-los-intentos-de-acceso-exitosos-al-sistema-comprueba-su-funcionamiento\">#</a> 1. Activa desde SQL*Plus la auditoría de los intentos de acceso exitosos al sistema. Comprueba su funcionamiento.</h2>\n<p>Vemos si tenemos activado el registro de auditoría:</p>\n<pre><code>SELECT name, value FROM v$parameter WHERE name = 'audit_trail';\n</code></pre>\n<p>También podemos emplear la siguiente sentencia:</p>\n<pre><code>SHOW PARAMETER AUDIT\n</code></pre>\n<p><img src=\"/images/audit-1.png\" alt=\"image\"></p>\n<p>Emplearemos la siguiente sentencia para activar la auditoría:</p>\n<pre><code>AUDIT CREATE SESSION WHENEVER SUCCESSFUL;\n</code></pre>\n<p>Ahora nos desconectamos del susuario administrador y entraremos con el de antonio:</p>\n<p><img src=\"/images/audit-2.png\" alt=\"image\"></p>\n<pre><code>SELECT OS_USERNAME, USERNAME, EXTENDED_TIMESTAMP, ACTION_NAME FROM DBA_AUDIT_SESSION WHERE USERNAME = 'ANTONIO';\n</code></pre>\n<p><img src=\"/images/audit-3.png\" alt=\"image\"></p>\n<p>Como podemos ver el usuario ha quedado registrado en la tabla DBA_AUDIT_SESSION.</p>\n<h2 id=\"2-realiza-un-procedimiento-en-plsql-que-te-muestre-los-accesos-fallidos-junto-con-el-motivo-de-los-mismos-transformando-el-código-de-error-almacenado-en-un-mensaje-de-texto-comprensible-contempla-todos-los-motivos-posibles-para-que-un-acceso-sea-fallido\"><a class=\"markdownIt-Anchor\" href=\"#2-realiza-un-procedimiento-en-plsql-que-te-muestre-los-accesos-fallidos-junto-con-el-motivo-de-los-mismos-transformando-el-código-de-error-almacenado-en-un-mensaje-de-texto-comprensible-contempla-todos-los-motivos-posibles-para-que-un-acceso-sea-fallido\">#</a> 2. Realiza un procedimiento en PL/SQL que te muestre los accesos fallidos junto con el motivo de los mismos, transformando el código de error almacenado en un mensaje de texto comprensible. Contempla todos los motivos posibles para que un acceso sea fallido.</h2>\n<pre><code>CREATE OR REPLACE PROCEDURE AUDIT_ACCESOS\nIS\ncursor c_conexion is SELECT OS_USERNAME,TIMESTAMP, USERNAME, RETURNCODE FROM DBA_AUDIT_SESSION;\nBEGIN\nfor v_conexion in c_conexion loop\n    Dbms_Output.Put_Line(v_conexion.OS_USERNAME);\n    Dbms_Output.Put_Line(v_conexion.USERNAME);\n    Dbms_Output.Put_Line(v_conexion.TIMESTAMP);\n    MOSTRAR_DEF_ERROR(v_conexion.RETURNCODE);\nend loop;\nEND;\n/\n\nCREATE OR REPLACE PROCEDURE MOSTRAR_DEF_ERROR (p_codigo NUMBER)\nIS\nBEGIN\nIF p_codigo = 1017 THEN\n    dbms_Output.Put_Line('Error ' || p_codigo || ' El usuario o la contraseña no existe');\nELSIF p_codigo = 2391 THEN\n    dbms_Output.Put_Line('Error ' || p_codigo || ' Excedidas las conexiones simultáneas permitidas');\nELSIF p_codigo = 1045 THEN\n    dbms_Output.Put_Line('Error ' || p_codigo || ' El usuario no tiene permisos de creación de sesión');\nELSIF p_codigo = 28001 THEN\n    dbms_Output.Put_Line('Error ' || p_codigo || ' La contraseña del usuario ha caducado');\nELSIF p_codigo = 28009 THEN\n    dbms_Output.Put_Line('Error ' || p_codigo || ' La conexión debe ser a través de SYS o SYSOPER');\nELSIF p_codigo = 1034 THEN\n    dbms_Output.Put_Line('Error ' || p_codigo || ' La base de datos no está levantada');\nEND IF;\nEND;\n/\n</code></pre>\n<p><img src=\"/images/audit-4.png\" alt=\"image\"></p>\n<h2 id=\"3-activa-la-auditoría-de-las-operaciones-dml-realizadas-por-scott-comprueba-su-funcionamiento\"><a class=\"markdownIt-Anchor\" href=\"#3-activa-la-auditoría-de-las-operaciones-dml-realizadas-por-scott-comprueba-su-funcionamiento\">#</a> 3. Activa la auditoría de las operaciones DML realizadas por SCOTT. Comprueba su funcionamiento.</h2>\n<pre><code>AUDIT INSERT TABLE, UPDATE TABLE, DELETE TABLE BY SCOTT BY ACCESS;\n</code></pre>\n<p>Ahora vamos a rellenar con diferentes cambios para registrarlo en la auditoría:</p>\n<p><img src=\"/images/audit-5.png\" alt=\"image\"></p>\n<p>Y con la siguiente sentencia podemos ver los cambios que se han realizado desde el usuario sys:</p>\n<pre><code>SELECT OS_USERNAME, USERNAME, TIMESTAMP, ACTION_NAME FROM DBA_AUDIT_OBJECT WHERE USERNAME = 'SCOTT';\n</code></pre>\n<p><img src=\"/images/audit-6.png\" alt=\"image\"></p>\n<h2 id=\"4-realiza-una-auditoría-de-grano-fino-para-almacenar-información-sobre-la-inserción-de-empleados-con-sueldo-superior-a-2000-en-la-tabla-emp-de-scott\"><a class=\"markdownIt-Anchor\" href=\"#4-realiza-una-auditoría-de-grano-fino-para-almacenar-información-sobre-la-inserción-de-empleados-con-sueldo-superior-a-2000-en-la-tabla-emp-de-scott\">#</a> 4. Realiza una auditoría de grano fino para almacenar información sobre la inserción de empleados con sueldo superior a 2000 en la tabla emp de scott.</h2>\n<p>¿Qué es una auditoría de grano fino?</p>\n<p>Una auditoría de grano fino es una auditoría más detallada que no solo contempla el hecho de inserción de filas y columnas sino que también pueden auditarse qué datos han cambiado para así tener un major control sobre la base de datos.</p>\n<p>Así que con el objeto DBMS_FGA.ADD_POLICY podemos crear una auditoría de grano fino para la tabla emp de scott:</p>\n<pre><code>BEGIN\n    DBMS_FGA.ADD_POLICY (\n        object_schema      =&gt;  'SCOTT',\n        object_name        =&gt;  'EMP',\n        policy_name        =&gt;  'AUDIT_EMP_SAL',\n        audit_condition    =&gt;  'SAL &gt; 2000',\n        statement_types    =&gt;  'INSERT'\n    );\nEND;\n/\n</code></pre>\n<p><img src=\"/images/audit-7.png\" alt=\"image\"></p>\n<p>Ahora vamos a insertar un empleado con un salario superior a 2000 con el usuario SCOTT:</p>\n<p><img src=\"/images/audit-8.png\" alt=\"image\"></p>\n<p>Y entramos en como administrador de nuevo y comprobamos que se ha registrado el insert que contiene el salario mayor a 2000:</p>\n<pre><code>SELECT DB_USER, OBJECT_NAME, SQL_TEXT, TIMESTAMP FROM DBA_FGA_AUDIT_TRAIL WHERE POLICY_NAME='AUDIT_EMP_SAL';\n</code></pre>\n<p><img src=\"/images/audit-9.png\" alt=\"image\"></p>\n<p>Alternativamente podríamos hacer nosotros nuestra auditoría con un trigger, como veremos en los siguientes casos, pero viendo que la utilidad de DBMS_FGA es más sencilla y rápida, es la que hemos empleado en este caso.</p>\n<h2 id=\"5-explica-la-diferencia-entre-auditar-una-operación-by-access-o-by-session-ilustrándolo-con-ejemplos\"><a class=\"markdownIt-Anchor\" href=\"#5-explica-la-diferencia-entre-auditar-una-operación-by-access-o-by-session-ilustrándolo-con-ejemplos\">#</a> 5. Explica la diferencia entre auditar una operación by access o by session ilustrándolo con ejemplos.</h2>\n<p>La auditoría by access registra cada acceso a los objetos de la base de datos, mientras que la auditoría by session registra la actividad del usuario solo una vez, lo que evita recursividad. La elección de qué tipo de auditoría utilizar dependerá de los objetivos de la auditoría y del nivel de detalle necesario para cumplirlos, siendo así más detallado el hecho de la auditoría by access.</p>\n<p>Como ejemplos podemos tomar de ejercicios anteriores la auditoría de accesos exitosos:</p>\n<p><img src=\"/images/audit-3.png\" alt=\"image\"></p>\n<p>Y la auditoría by session:</p>\n<p><img src=\"/images/audit-6.png\" alt=\"image\"></p>\n<h2 id=\"6-documenta-las-diferencias-entre-los-valores-db-y-db-extended-del-parámetro-audit_trail-de-oracle-demuéstralas-poniendo-un-ejemplo-de-la-información-sobre-una-operación-concreta-recopilada-con-cada-uno-de-ellos\"><a class=\"markdownIt-Anchor\" href=\"#6-documenta-las-diferencias-entre-los-valores-db-y-db-extended-del-parámetro-audit_trail-de-oracle-demuéstralas-poniendo-un-ejemplo-de-la-información-sobre-una-operación-concreta-recopilada-con-cada-uno-de-ellos\">#</a> 6. Documenta las diferencias entre los valores db y db, extended del parámetro audit_trail de ORACLE. Demuéstralas poniendo un ejemplo de la información sobre una operación concreta recopilada con cada uno de ellos.</h2>\n<p>Los valores que alberga el parámetro deb y db extended son los mismos, exceptos en varias columnas, que es SQLBIND y SQLTEXT:</p>\n<p>Si añadimor SQLBIND a nuestra consulta podemos ver que no logra encontrar el campo SQLBIND:</p>\n<pre><code>SELECT DB_USER, OBJECT_NAME, SQL_TEXT, TIMESTAMP FROM DBA_FGA_AUDIT_TRAIL WHERE POLICY_NAME='AUDIT_EMP_SAL';\n</code></pre>\n<p><img src=\"/images/audit-10.png\" alt=\"image\"></p>\n<p>Con esto podemos ver el parámetro audit_trail como vimos en el ejercicio 1:</p>\n<pre><code>SHOW PARAMETER AUDIT\n</code></pre>\n<p><img src=\"/images/audit-1.png\" alt=\"image\"></p>\n<p>Entonces, si queremos cambiar el valor de audit_trail a db extended, debemos hacer lo siguiente:</p>\n<pre><code>ALTER SYSTEM SET audit_trail = DB,EXTENDED SCOPE=SPFILE;\n</code></pre>\n<p>Y seguidamente reiniciar la base de datos:</p>\n<pre><code>shutdown\nstartup\n</code></pre>\n<p>Ahora podemos comprobar que se encuentra de manera extendida:</p>\n<p><img src=\"/images/audit-11.png\" alt=\"image\"></p>\n<p>Y al entrar en la base de datos con el usuario SCOTT y hacer un insert en la tabla emp, podemos ver que ahora si se encuentra el campo SQLBIND y SQLTEXT:</p>\n<pre><code>SELECT USERNAME,ACTION_NAME,TIMESTAMP, OBJ_NAME, SQL_TEXT, SQL_BIND from DBA_AUDIT_OBJECT where USERNAME='SCOTT';\n</code></pre>\n<p><img src=\"/images/audit-12.png\" alt=\"image\"></p>\n<h2 id=\"7-averigua-si-en-postgres-se-pueden-realizar-los-cuatro-primeros-apartados-si-es-así-documenta-el-proceso-adecuadamente\"><a class=\"markdownIt-Anchor\" href=\"#7-averigua-si-en-postgres-se-pueden-realizar-los-cuatro-primeros-apartados-si-es-así-documenta-el-proceso-adecuadamente\">#</a> 7. Averigua si en Postgres se pueden realizar los cuatro primeros apartados. Si es así, documenta el proceso adecuadamente.</h2>\n<p>En postgres podemos ver gracias a la ruta  <code>/var/log/postgresql/postgresql-13-main.log</code>  los logs de intentos fallidos al sistema:</p>\n<p><img src=\"/images/audit-13.png\" alt=\"image\"></p>\n<p>A parte de esto, Postgres no contempla las auditorías, para ello debemos descargar una herramienta de terceros llamada audit trigger 91 plus que nos permitirá realizar auditorías en la base de datos.</p>\n<p>Seguidamente importaremos el esquema de base de datos a nuestro sistema gestor de base de datos:</p>\n<pre><code>\\i audit.sql\n</code></pre>\n<p>Como podemos contemplar en la imagen se ha creado diferentes funciones, tablas y disparadores que nos permitirán realizar auditorías en la base de datos:</p>\n<p><img src=\"/images/audit-14.png\" alt=\"image\"></p>\n<p>Vamos a activar la auditoría de la tabla personaje:</p>\n<pre><code>SELECT audit.audit_table('personaje');\n</code></pre>\n<p><img src=\"/images/audit-16.png\" alt=\"image\"></p>\n<p>AHora vamos a insertar un nuevo registro en la tabla personaje:</p>\n<p><img src=\"/images/audit-15.png\" alt=\"image\"></p>\n<p>Seguidamente vamos a comprobar que funciona la auditoría:</p>\n<pre><code>select session_user_name, action, table_name, action_tstamp_clk, client_query \nfrom audit.logged_actions;\n</code></pre>\n<p><img src=\"/images/audit-17.png\" alt=\"image\"></p>\n<p>Nota: para poder realizar la auditoría de manera correcta, la importación del esquema debe hacerse dentro de la base de datos con la que se va a trabajar, de manera que si queremos que se audite la tabla personaje de la base de datos souls, deberemos importar el esquema dentro de esta base de datos.</p>\n<p>Ahora vamos a resolver el ejercicio 4 que consiste en crear una política de auditoría que registre los accesos a la tabla EMP de SCOTT que tengan un salario superior a 2000, por defecto no tiene una funcionalidad bd como pudiese tenerlo Oracle, pero sí que podemos crear un trigger que nos permita realizar esta auditoría.</p>\n<p>Primero crearemos la tabla auditoria_emp:</p>\n<pre><code>CREATE TABLE auditoria_emp (\n  id SERIAL PRIMARY KEY,\n  EMPNO INT NOT NULL,\n  ACCION VARCHAR(10) NOT NULL,\n  SALARIO DECIMAL(7, 2) NOT NULL,\n  FECHA_HORA TIMESTAMP NOT NULL DEFAULT NOW()\n);\n</code></pre>\n<p>Vamos a explicar esta tabla:</p>\n<ul>\n<li>id: es un campo autoincremental que nos permitirá identificar cada registro de la tabla.</li>\n<li>EMPNO: es el número de empleado.</li>\n<li>ACCION: es el salario del empleado.</li>\n<li>SALARIO: es el salario del empleado.</li>\n<li>FECHA_HORA: es la fecha y hora en la que se ha realizado la acción.</li>\n</ul>\n<pre><code>CREATE OR REPLACE FUNCTION insert_auditoria_emp()\nRETURNS TRIGGER AS $$\nBEGIN\n  INSERT INTO auditoria_emp (EMPNO, SALARIO, ACCION)\n  VALUES (NEW.EMPNO, NEW.SAL, 'INSERT');\n  RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER tr_insert_emp\nAFTER INSERT ON EMP\nFOR EACH ROW\nWHEN (NEW.SAL &gt; 2000)\nEXECUTE FUNCTION insert_auditoria_emp();\n</code></pre>\n<pre><code>CREATE OR REPLACE FUNCTION update_auditoria_emp()\nRETURNS TRIGGER AS $$\nBEGIN\n  INSERT INTO auditoria_emp (EMPNO, SALARIO, ACCION)\n  VALUES (NEW.EMPNO, NEW.SAL, 'UPDATE');\n  RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER tr_update_emp\nAFTER UPDATE ON EMP\nFOR EACH ROW\nWHEN (NEW.SAL &gt; 2000)\nEXECUTE FUNCTION update_auditoria_emp();\n</code></pre>\n<p>Ahora vamos a insertar un registro y seguidamente actualizar otro para comprobar que funciona correctamente:</p>\n<pre><code>INSERT INTO EMP VALUES(7909, 'JAMES', 'CLERK', 7698, '1981-12-03', 2950, NULL, 30);\nUPDATE EMP SET SAL = 4000 WHERE EMPNO = 7369;\n</code></pre>\n<p><img src=\"/images/audit-22.png\" alt=\"image\"></p>\n<h2 id=\"8-averigua-si-en-mysql-se-pueden-realizar-los-apartados-1-3-y-4-si-es-así-documenta-el-proceso-adecuadamente\"><a class=\"markdownIt-Anchor\" href=\"#8-averigua-si-en-mysql-se-pueden-realizar-los-apartados-1-3-y-4-si-es-así-documenta-el-proceso-adecuadamente\">#</a> 8. Averigua si en MySQL se pueden realizar los apartados 1, 3 y 4. Si es así, documenta el proceso adecuadamente.</h2>\n<p>Primero para activar la auditoría en Maríadb, que es la alternativa más a MySQL, debemos modificar el archivo de configuración que se encuentra en  <code>/etc/mysql/mariadb.conf.d/50-server.cnf</code>  y descomentar las líneas que vemos en la siguiente imagen:</p>\n<p><img src=\"/images/audit-18.png\" alt=\"image\"></p>\n<p>Seguidamente necesitamos que el usuario mysql tenga permisos para poder escribir en el fichero que hemos descomentado en la línea de configuración  <code>log_error</code> :</p>\n<p><code>chown -R mysql: /var/log/mysql</code></p>\n<p>seguidamente reiniciamos el servicio:</p>\n<p><code>systemctl restart mysql</code></p>\n<p>Si intentamos acceder a través de mysql -u root -p y fallamos la contraseña se mantendrá registrado en el log:</p>\n<p><img src=\"/images/audit-19.png\" alt=\"image\"></p>\n<p>Ahora nos conectaremos con el usuario SCOTT, crearemos la tabla personaje del anterior ejercicio de postgres y haremos varios inserts:</p>\n<pre><code>CREATE TABLE personaje (\ncodpersonaje varchar (3),\nnombre varchar (15),\naltura decimal (3,2),\npeso decimal (3),\nraza varchar (10) DEFAULT ('Humano'),\nCONSTRAINT pk_codpersonaje PRIMARY KEY (codpersonaje),\nCONSTRAINT ck_codpersonaje CHECK (codpersonaje REGEXP '^1.*'),\nconstraint ck_nombre CHECK (nombre REGEXP '^[A-Z][a-z]*')\n);\n\n\n\ninsert into personaje values ('101','Solaire',1.70,80,'humano');\ninsert into personaje values ('102','Artorias',1.90,90,'hueco');\ninsert into personaje values ('103','Gargola',3.10,680,'Gárgola');\n</code></pre>\n<p>Al terminar, nos vamos al fichero de log  <code>cat /var/log/mysql/mysql.log</code>  y podemos ver cada uno de las acciones que hemos realizado:</p>\n<p><img src=\"/images/audit-20.png\" alt=\"image\"></p>\n<p>Ahora vamos a realizar el ejercicio 4 de manera que solo audite cada vez que el usuario inserte o actualice el salario de un empleado que sea mayor de 2000:</p>\n<pre><code>CREATE TABLE auditoria_emp (\n  id INT NOT NULL AUTO_INCREMENT,\n  EMPNO INT NOT NULL,\n  SALARIO DECIMAL(7, 2) NOT NULL,\n  ACCION VARCHAR(10) NOT NULL,\n  FECHA_HORA TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  PRIMARY KEY (id)\n);\n</code></pre>\n<p>Vamos a explicar esta tabla:</p>\n<ul>\n<li>La tabla contiene un id que es autoincremental, lo cual nos permitirá identificar cada uno de los registros de la tabla aunque se repitan datos, la cual haremos primary key.</li>\n<li>el código del empleado el cual nos servirá para identificar el empleado que ha sufrido el cambio.</li>\n<li>el salario que será mayor de 2000 para que se pueda auditar.</li>\n<li>La fecha y hora del sistema en ese momento.</li>\n</ul>\n<p>Ahora vamos a crear el disparador bastante sencillo que nos permitirá auditar cada vez que el salario de un empleado sea mayor de 2000:</p>\n<pre><code>DELIMITER //\n\nCREATE TRIGGER tr_insert_emp\nAFTER INSERT ON EMP\nFOR EACH ROW\nBEGIN\n  IF NEW.SAL &gt; 2000 THEN\n    INSERT INTO auditoria_emp (EMPNO, SALARIO, ACCION) VALUES (NEW.EMPNO, NEW.SAL, 'INSERT');\n  END IF;\nEND //\n\nDELIMITER ;\n</code></pre>\n<pre><code>DELIMITER //\n\nCREATE TRIGGER tr_update_emp\nAFTER UPDATE ON EMP\nFOR EACH ROW\nBEGIN\n  IF NEW.SAL &gt; 2000 THEN\n    INSERT INTO auditoria_emp (EMPNO, SALARIO, ACCION) VALUES (NEW.EMPNO, NEW.SAL, 'UPDATE');\n  END IF;\nEND //\n\nDELIMITER ;\n</code></pre>\n<p>Insertamos y actualizamos registros:</p>\n<pre><code>INSERT INTO EMP VALUES(7911, 'JAMES', 'CLERK', 7698,'1981-12-03', 2950, NULL, 30);\nUPDATE EMP SET SAL = 3000 WHERE EMPNO = 7369;\n</code></pre>\n<p>Y aquí el resultado junto con la acción de insertar o actualizar un salario a más de 2000:</p>\n<p><img src=\"/images/audit-21.png\" alt=\"image\"></p>\n<h2 id=\"9-averigua-las-posibilidades-que-ofrece-mongodb-para-auditar-los-cambios-que-va-sufriendo-un-documento-demuestra-su-funcionamiento\"><a class=\"markdownIt-Anchor\" href=\"#9-averigua-las-posibilidades-que-ofrece-mongodb-para-auditar-los-cambios-que-va-sufriendo-un-documento-demuestra-su-funcionamiento\">#</a> 9.  Averigua las posibilidades que ofrece MongoDB para auditar los cambios que va sufriendo un documento. Demuestra su funcionamiento.</h2>\n<p>Las posibilidades que ofrece MongoDB para auditar los cambios que va sufriendo un documento son las siguientes:</p>\n<p>Podemos activar las auditorías en un fichero JSON desde el fichero de configuración:<br>\n <code>nano /etc/mongod.conf</code></p>\n<pre><code>auditLog:\n  destination: file\n  format: JSON\n  path: /var/log/mongodb/auditLog.json\n</code></pre>\n<p>También podremos activar las auditorías en el syslog desde el fichero de configuración:<br>\nnano /etc/mongod.conf</p>\n<pre><code>auditLog:\n  destination: syslog\n</code></pre>\n<p>También podemos habilitar las auditorías en un fichero BSON desde el fichero de configuración:<br>\nnano /etc/mongod.conf</p>\n<pre><code>auditLog:\n  destination: file\n  format: BSON\n  path: /var/log/mongodb/auditLog.bson\n</code></pre>\n<p>Habilitar las auditorías en la consola desde el fichero de configuración:<br>\nnano /etc/mongod.conf</p>\n<pre><code>auditLog:\n  destination: console\n</code></pre>\n<p>Vamos a empezar a crear el usuario en la base de datos, la cual más tarde importará unos 140 documentos que poseo.</p>\n<pre><code>db.createUser(\n   &#123;\n     user: &quot;admin&quot;, \n     pwd: &quot;admin&quot;, \n     roles: [ &#123; role: &quot;dbOwner&quot;, db: &quot;souls&quot; &#125; ]\n   &#125;\n )\n</code></pre>\n<p>En la documentación oficial de mongo especifica que recomienda la auditoría en formato BSON, ya que los JSON degradan la eficiencia de la auditoría.</p>\n<p><img src=\"/images/audit-25.png\" alt=\"image\"></p>\n<p>Por ende elijo mostrar la auditoría en formato BSON:</p>\n<pre><code>nano /etc/mongod.conf\n\nauditLog:\n  destination: file\n  format: BSON\n  path: /var/log/mongodb/auditLog.bson\n</code></pre>\n<p>ATENCIÓN: mongodb trabaja con ficheros bson, el cual es un lenguaje interpretado por la máquina específicamente creado por mongodb, por lo que no podremos visualizarlo con el comando  <code>cat</code>  o  <code>less</code>  como normalmente se hace con con los ficheros de texto plano, para ello utilizaremos el comando  <code>bsondump</code>  que nos permite visualizar el contenido de un fichero BSON y lo transforma a JSON.</p>\n<pre><code>bsondump /var/log/mongodb/auditLog.bson | jq\n</code></pre>\n<p>Entonces… por qué no he elegido el formato JSON si al final lo transformo a JSON? Pues porque al elegir el JSON directamente haces que lmongo sea la que traduzca directamente el BSON a JSON, lo cual hace que la base de datos tenga que hacer un trabajo extra que no es necesario, por lo que es mejor que la base de datos realice la auditoría con BSON y nosotros con la computación de la máquina del cliente lo transformemos a JSON cuando queramos visualizarlo.</p>\n<p>En nuestro caso con 140 documentos es una diferencia mínima, pero si tuviéramos millones de documentos, la diferencia sería notable.</p>\n<p>Ahora vamos a proceder a importar los documentos a la base de datos souls:</p>\n<pre><code>mongoimport --db souls --type=json --file DarkSoulsWeapons.json --jsonArray\n</code></pre>\n<p><img src=\"/images/audit-24.png\" alt=\"image\"></p>\n<p>Ahora vamos a comprobar que se ha registrado la importación en el fichero de auditoría:</p>\n<p><img src=\"/images/audit-26.png\" alt=\"image\"></p>\n<p>Como podemos ver se ha realizado la acción de mongoimport y ha actuado sobre la base de datos y colección souls/soulsweapons.</p>\n<p>Han pasado varios días, me levanto una mañana y descubro que alguien ha borrado todos los documentos de la colección soulsweapons, por lo que voy a proceder a realizar una auditoría de la base de datos para descubrir quien ha sido el culpable:</p>\n<p>Resulta que un usuario con un nick un tanto sospechoso ha entrado en la base de datos souls, lo podemos ver a través del ActionType y user,db:</p>\n<p><img src=\"/images/audit-27.png\" alt=\"image\"></p>\n<p>Pero esto no dice nada sobre lo que el usuario ha podido hacer, debemos indagar un poco más de su actividad una vez logueado en la base de datos, por lo que podemos filtrar ahora que conocemos los valores que hay que observar:</p>\n<pre><code>bsondump /var/log/mongodb/auditLog.bson | jq | egrep 'user|atype|ns''\n</code></pre>\n<p>OJO!! Este usuario ha hecho un drop de la colección soulsweapons, ahora sí que podemos decir que esta persona ha sido la culpable.</p>\n<p><img src=\"/images/audit-29.png\" alt=\"image\"></p>\n<h2 id=\"10-averigua-si-en-mongodb-se-pueden-auditar-los-accesos-a-una-colección-concreta-demuestra-su-funcionamiento\"><a class=\"markdownIt-Anchor\" href=\"#10-averigua-si-en-mongodb-se-pueden-auditar-los-accesos-a-una-colección-concreta-demuestra-su-funcionamiento\">#</a> 10. Averigua si en MongoDB se pueden auditar los accesos a una colección concreta. Demuestra su funcionamiento.</h2>\n<p>Como buenos administradores de sistemas tenemos la copia de la información guardada, entonces vamos a comenzar auditando la colección soulsweapons:</p>\n<p>En el ejercicio anterior entre los valores que hemos filtrado se encuentra el campo ns, este es el campo del namespace, el cual es “nombrebasededatos.coleccion” así que vamos a establecer un filtro en el archivo de configuración de mongo para que comience a auditar la colección soulsweapons:</p>\n<p>Entramos como administrador en la base de datos admin y ejecutamos el siguiente comando:</p>\n<pre><code>use souls\ndb.setProfilingLevel(2)\n</code></pre>\n<p>A partir de ahora todas las acciones que se realicen sobre la colección, podrán ser auditadas de manera que sabremos incluso qué se está insertando:</p>\n<pre><code>db.system.profile.find(&#123;\n   &quot;ns&quot;: &quot;souls.DarkSoulsWeapons&quot;,\n   &quot;op&quot;: &#123;\n      &quot;$in&quot;: [\n         &quot;insert&quot;,\n         &quot;update&quot;,\n         &quot;delete&quot;\n      ]\n   &#125;\n&#125;)\n</code></pre>\n<p><img src=\"/images/audit-31.png\" alt=\"image\"></p>\n<p>Como podemos ver, el usuario admin ha insertado un documento en la colección soulsweapons.</p>\n"},{"title":"Trabajando con los charts de Helm","Categoria":"Orquestación","_content":"\n\n![helm](/images/logo-helm.png)\n\n## Instalación de un CMS con Helm\n\n\nAhora vamos a trabajar con helm, para ello debemos descargarlo de su página oficial:\n\n```\nwget https://get.helm.sh/helm-v3.11.0-linux-amd64.tar.gz\n```\n\nDescomprimimos el archivo y lo movemos a la carpeta /usr/local/bin\n\n```\ntar zxvf helm-v3.11.0-linux-amd64.tar.gz\nsudo install helm /usr/local/bin/\n```\n\nEjecutamos el siguiente comando para que helm pueda acceder a los repositorios de charts:\n\n```\nhelm version\n```\n\nAhora vamos a añadir el siguiente repositorio en helm:\n\n```\nhelm repo add \"stable\" \"https://charts.helm.sh/stable\" --force-update\n```\n\nCon el siguiente comando podemos ver los repositorios que tenemos añadidos:\n\n```\nhelm repo list\n```\n\n![helm](/images/helm-1.png)\n\nAhora vamos a instalar un CMS con helm, para ello vamos a descargar el repositorio de bitnami:\n\n```\nhelm repo add bitnami https://charts.bitnami.com/bitnami\n```\n\n```\nhelm repo update\nhelm repo list\n```\n\n## Pantallazo con la búsqueda del chart con el comando helm\n\nVamos a buscar dentro de los repositorios el CMS que queremos instalar, que en nuestro caso es wordpress:\n\n```\nhelm search repo wordpress\n```\n\n![helm](/images/helm-2.png)\n\nAhora vamos a instalar el CMS con helm, especificaremos el tipo de servicio que queremos que sea NodePort para poder acceder al recurso:\n\n```\nhelm install wordpress bitnami/wordpress --set service.type=NodePort\n```\n\n## Pantallazo donde se compruebe que se ha desplegado de forma correcta.\n\nSi seguimos las instrucciones que nos da helm, podremos acceder al CMS desde el navegador:\n\n\n\n![helm](/images/helm-3.png)\n\n\nCon las variables y echo podemos obtener la IP del nodo y el puerto que nos ha asignado el servicio:\n\n![helm](/images/helm-4.png)\n\n\n\n## Pantallazo donde se vean los Pods, ReplicaSets, Deployments y Services que se han creado.\n\n\n\n![helm](/images/helm-6.png)\n\n\n\nAquí vemos como está funcionando el wordpress:\n\n![helm](/images/helm-5.png)\n\n\nPor último, vamos a eliminar el CMS que hemos instalado con helm:\n\n```\nhelm delete wordpress\n```\n\n\n## Pantallazo donde se vea el acceso al blog y se vea tu nombre como título del blog.\n\n![helm](/images/helm-7.png)","source":"_posts/helm.md","raw":"---\ntitle: Trabajando con los charts de Helm\nCategoria: Orquestación\n---\n\n\n![helm](/images/logo-helm.png)\n\n## Instalación de un CMS con Helm\n\n\nAhora vamos a trabajar con helm, para ello debemos descargarlo de su página oficial:\n\n```\nwget https://get.helm.sh/helm-v3.11.0-linux-amd64.tar.gz\n```\n\nDescomprimimos el archivo y lo movemos a la carpeta /usr/local/bin\n\n```\ntar zxvf helm-v3.11.0-linux-amd64.tar.gz\nsudo install helm /usr/local/bin/\n```\n\nEjecutamos el siguiente comando para que helm pueda acceder a los repositorios de charts:\n\n```\nhelm version\n```\n\nAhora vamos a añadir el siguiente repositorio en helm:\n\n```\nhelm repo add \"stable\" \"https://charts.helm.sh/stable\" --force-update\n```\n\nCon el siguiente comando podemos ver los repositorios que tenemos añadidos:\n\n```\nhelm repo list\n```\n\n![helm](/images/helm-1.png)\n\nAhora vamos a instalar un CMS con helm, para ello vamos a descargar el repositorio de bitnami:\n\n```\nhelm repo add bitnami https://charts.bitnami.com/bitnami\n```\n\n```\nhelm repo update\nhelm repo list\n```\n\n## Pantallazo con la búsqueda del chart con el comando helm\n\nVamos a buscar dentro de los repositorios el CMS que queremos instalar, que en nuestro caso es wordpress:\n\n```\nhelm search repo wordpress\n```\n\n![helm](/images/helm-2.png)\n\nAhora vamos a instalar el CMS con helm, especificaremos el tipo de servicio que queremos que sea NodePort para poder acceder al recurso:\n\n```\nhelm install wordpress bitnami/wordpress --set service.type=NodePort\n```\n\n## Pantallazo donde se compruebe que se ha desplegado de forma correcta.\n\nSi seguimos las instrucciones que nos da helm, podremos acceder al CMS desde el navegador:\n\n\n\n![helm](/images/helm-3.png)\n\n\nCon las variables y echo podemos obtener la IP del nodo y el puerto que nos ha asignado el servicio:\n\n![helm](/images/helm-4.png)\n\n\n\n## Pantallazo donde se vean los Pods, ReplicaSets, Deployments y Services que se han creado.\n\n\n\n![helm](/images/helm-6.png)\n\n\n\nAquí vemos como está funcionando el wordpress:\n\n![helm](/images/helm-5.png)\n\n\nPor último, vamos a eliminar el CMS que hemos instalado con helm:\n\n```\nhelm delete wordpress\n```\n\n\n## Pantallazo donde se vea el acceso al blog y se vea tu nombre como título del blog.\n\n![helm](/images/helm-7.png)","slug":"helm","published":1,"date":"2023-02-23T08:19:45.946Z","updated":"2023-02-24T00:06:37.211Z","_id":"clehrp4js0000y6i5fustbvev","comments":1,"layout":"post","photos":[],"link":"","content":"<p><img src=\"/images/logo-helm.png\" alt=\"helm\"></p>\n<h2 id=\"Instalacion-de-un-CMS-con-Helm\"><a href=\"#Instalacion-de-un-CMS-con-Helm\" class=\"headerlink\" title=\"Instalación de un CMS con Helm\"></a>Instalación de un CMS con Helm</h2><p>Ahora vamos a trabajar con helm, para ello debemos descargarlo de su página oficial:</p>\n<pre><code>wget https://get.helm.sh/helm-v3.11.0-linux-amd64.tar.gz\n</code></pre>\n<p>Descomprimimos el archivo y lo movemos a la carpeta &#x2F;usr&#x2F;local&#x2F;bin</p>\n<pre><code>tar zxvf helm-v3.11.0-linux-amd64.tar.gz\nsudo install helm /usr/local/bin/\n</code></pre>\n<p>Ejecutamos el siguiente comando para que helm pueda acceder a los repositorios de charts:</p>\n<pre><code>helm version\n</code></pre>\n<p>Ahora vamos a añadir el siguiente repositorio en helm:</p>\n<pre><code>helm repo add &quot;stable&quot; &quot;https://charts.helm.sh/stable&quot; --force-update\n</code></pre>\n<p>Con el siguiente comando podemos ver los repositorios que tenemos añadidos:</p>\n<pre><code>helm repo list\n</code></pre>\n<p><img src=\"/images/helm-1.png\" alt=\"helm\"></p>\n<p>Ahora vamos a instalar un CMS con helm, para ello vamos a descargar el repositorio de bitnami:</p>\n<pre><code>helm repo add bitnami https://charts.bitnami.com/bitnami\n</code></pre>\n<pre><code>helm repo update\nhelm repo list\n</code></pre>\n<h2 id=\"Pantallazo-con-la-busqueda-del-chart-con-el-comando-helm\"><a href=\"#Pantallazo-con-la-busqueda-del-chart-con-el-comando-helm\" class=\"headerlink\" title=\"Pantallazo con la búsqueda del chart con el comando helm\"></a>Pantallazo con la búsqueda del chart con el comando helm</h2><p>Vamos a buscar dentro de los repositorios el CMS que queremos instalar, que en nuestro caso es wordpress:</p>\n<pre><code>helm search repo wordpress\n</code></pre>\n<p><img src=\"/images/helm-2.png\" alt=\"helm\"></p>\n<p>Ahora vamos a instalar el CMS con helm, especificaremos el tipo de servicio que queremos que sea NodePort para poder acceder al recurso:</p>\n<pre><code>helm install wordpress bitnami/wordpress --set service.type=NodePort\n</code></pre>\n<h2 id=\"Pantallazo-donde-se-compruebe-que-se-ha-desplegado-de-forma-correcta\"><a href=\"#Pantallazo-donde-se-compruebe-que-se-ha-desplegado-de-forma-correcta\" class=\"headerlink\" title=\"Pantallazo donde se compruebe que se ha desplegado de forma correcta.\"></a>Pantallazo donde se compruebe que se ha desplegado de forma correcta.</h2><p>Si seguimos las instrucciones que nos da helm, podremos acceder al CMS desde el navegador:</p>\n<p><img src=\"/images/helm-3.png\" alt=\"helm\"></p>\n<p>Con las variables y echo podemos obtener la IP del nodo y el puerto que nos ha asignado el servicio:</p>\n<p><img src=\"/images/helm-4.png\" alt=\"helm\"></p>\n<h2 id=\"Pantallazo-donde-se-vean-los-Pods-ReplicaSets-Deployments-y-Services-que-se-han-creado\"><a href=\"#Pantallazo-donde-se-vean-los-Pods-ReplicaSets-Deployments-y-Services-que-se-han-creado\" class=\"headerlink\" title=\"Pantallazo donde se vean los Pods, ReplicaSets, Deployments y Services que se han creado.\"></a>Pantallazo donde se vean los Pods, ReplicaSets, Deployments y Services que se han creado.</h2><p><img src=\"/images/helm-6.png\" alt=\"helm\"></p>\n<p>Aquí vemos como está funcionando el wordpress:</p>\n<p><img src=\"/images/helm-5.png\" alt=\"helm\"></p>\n<p>Por último, vamos a eliminar el CMS que hemos instalado con helm:</p>\n<pre><code>helm delete wordpress\n</code></pre>\n<h2 id=\"Pantallazo-donde-se-vea-el-acceso-al-blog-y-se-vea-tu-nombre-como-titulo-del-blog\"><a href=\"#Pantallazo-donde-se-vea-el-acceso-al-blog-y-se-vea-tu-nombre-como-titulo-del-blog\" class=\"headerlink\" title=\"Pantallazo donde se vea el acceso al blog y se vea tu nombre como título del blog.\"></a>Pantallazo donde se vea el acceso al blog y se vea tu nombre como título del blog.</h2><p><img src=\"/images/helm-7.png\" alt=\"helm\"></p>\n","site":{"data":{}},"length":1547,"excerpt":"","more":"<p><img src=\"/images/logo-helm.png\" alt=\"helm\"></p>\n<h2 id=\"Instalacion-de-un-CMS-con-Helm\"><a href=\"#Instalacion-de-un-CMS-con-Helm\" class=\"headerlink\" title=\"Instalación de un CMS con Helm\"></a>Instalación de un CMS con Helm</h2><p>Ahora vamos a trabajar con helm, para ello debemos descargarlo de su página oficial:</p>\n<pre><code>wget https://get.helm.sh/helm-v3.11.0-linux-amd64.tar.gz\n</code></pre>\n<p>Descomprimimos el archivo y lo movemos a la carpeta &#x2F;usr&#x2F;local&#x2F;bin</p>\n<pre><code>tar zxvf helm-v3.11.0-linux-amd64.tar.gz\nsudo install helm /usr/local/bin/\n</code></pre>\n<p>Ejecutamos el siguiente comando para que helm pueda acceder a los repositorios de charts:</p>\n<pre><code>helm version\n</code></pre>\n<p>Ahora vamos a añadir el siguiente repositorio en helm:</p>\n<pre><code>helm repo add &quot;stable&quot; &quot;https://charts.helm.sh/stable&quot; --force-update\n</code></pre>\n<p>Con el siguiente comando podemos ver los repositorios que tenemos añadidos:</p>\n<pre><code>helm repo list\n</code></pre>\n<p><img src=\"/images/helm-1.png\" alt=\"helm\"></p>\n<p>Ahora vamos a instalar un CMS con helm, para ello vamos a descargar el repositorio de bitnami:</p>\n<pre><code>helm repo add bitnami https://charts.bitnami.com/bitnami\n</code></pre>\n<pre><code>helm repo update\nhelm repo list\n</code></pre>\n<h2 id=\"Pantallazo-con-la-busqueda-del-chart-con-el-comando-helm\"><a href=\"#Pantallazo-con-la-busqueda-del-chart-con-el-comando-helm\" class=\"headerlink\" title=\"Pantallazo con la búsqueda del chart con el comando helm\"></a>Pantallazo con la búsqueda del chart con el comando helm</h2><p>Vamos a buscar dentro de los repositorios el CMS que queremos instalar, que en nuestro caso es wordpress:</p>\n<pre><code>helm search repo wordpress\n</code></pre>\n<p><img src=\"/images/helm-2.png\" alt=\"helm\"></p>\n<p>Ahora vamos a instalar el CMS con helm, especificaremos el tipo de servicio que queremos que sea NodePort para poder acceder al recurso:</p>\n<pre><code>helm install wordpress bitnami/wordpress --set service.type=NodePort\n</code></pre>\n<h2 id=\"Pantallazo-donde-se-compruebe-que-se-ha-desplegado-de-forma-correcta\"><a href=\"#Pantallazo-donde-se-compruebe-que-se-ha-desplegado-de-forma-correcta\" class=\"headerlink\" title=\"Pantallazo donde se compruebe que se ha desplegado de forma correcta.\"></a>Pantallazo donde se compruebe que se ha desplegado de forma correcta.</h2><p>Si seguimos las instrucciones que nos da helm, podremos acceder al CMS desde el navegador:</p>\n<p><img src=\"/images/helm-3.png\" alt=\"helm\"></p>\n<p>Con las variables y echo podemos obtener la IP del nodo y el puerto que nos ha asignado el servicio:</p>\n<p><img src=\"/images/helm-4.png\" alt=\"helm\"></p>\n<h2 id=\"Pantallazo-donde-se-vean-los-Pods-ReplicaSets-Deployments-y-Services-que-se-han-creado\"><a href=\"#Pantallazo-donde-se-vean-los-Pods-ReplicaSets-Deployments-y-Services-que-se-han-creado\" class=\"headerlink\" title=\"Pantallazo donde se vean los Pods, ReplicaSets, Deployments y Services que se han creado.\"></a>Pantallazo donde se vean los Pods, ReplicaSets, Deployments y Services que se han creado.</h2><p><img src=\"/images/helm-6.png\" alt=\"helm\"></p>\n<p>Aquí vemos como está funcionando el wordpress:</p>\n<p><img src=\"/images/helm-5.png\" alt=\"helm\"></p>\n<p>Por último, vamos a eliminar el CMS que hemos instalado con helm:</p>\n<pre><code>helm delete wordpress\n</code></pre>\n<h2 id=\"Pantallazo-donde-se-vea-el-acceso-al-blog-y-se-vea-tu-nombre-como-titulo-del-blog\"><a href=\"#Pantallazo-donde-se-vea-el-acceso-al-blog-y-se-vea-tu-nombre-como-titulo-del-blog\" class=\"headerlink\" title=\"Pantallazo donde se vea el acceso al blog y se vea tu nombre como título del blog.\"></a>Pantallazo donde se vea el acceso al blog y se vea tu nombre como título del blog.</h2><p><img src=\"/images/helm-7.png\" alt=\"helm\"></p>\n"},{"title":"LDAPs","Categoría":"Sistemas Operativos","_content":"\n![ldaps](/images/ldaps-logo.png)\n\n# LDAPs\n\n## LDAPs en Alfa\n\nPrimero vamos a generar tanto el certificado público como el privado:\n\n```\nopenssl genrsa 4096 > /etc/ssl/private/alfa.key\nopenssl req -new -key /etc/ssl/private/alfa.key -out alfa.csr\n```\n\nAhora vamos a descargar el csr, lo enviaremos a la entidad certificadora del IES Gonzalo Nazareno, y cuando nos devuelvan el certificado público, lo guardaremos en el servidor como alfa.crt.\n\nUna vez tengamos el certificado público, lo importaremos en el servidor:\n\n\n```\nmv alfa.crt /etc/ssl/certs/\n\nmv gonzalonazareno.crt /etc/ssl/certs/\n\nchown root:root /etc/ssl/certs/alfa.crt\n\nchown root:root /etc/ssl/certs/gonzalonazareno.crt\n```\n\n\nAhora debemos instalar acl para que openldap pueda acceder a los certificados:\n\n```\napt install acl\n\nsetfacl -m u:openldap:r-x /etc/ssl/private\n\nsetfacl -m u:openldap:r-x /etc/ssl/private/alfa.key\n\ngetfacl /etc/ssl/private\n\ngetfacl /etc/ssl/private/alfa.key\n```\n\n\n![getfacl](/images/ldaps-1.png)\n\n\nnano ldaps.diff\n\n```\ndn: cn=config\nchangetype: modify\nreplace: olcTLSCACertificateFile\nolcTLSCACertificateFile: /etc/ssl/certs/gonzalonazareno.crt\n-\nreplace: olcTLSCertificateKeyFile\nolcTLSCertificateKeyFile: /etc/ssl/private/alfa.key\n-\nreplace: olcTLSCertificateFile\nolcTLSCertificateFile: /etc/ssl/certs/alfa.crt\n```\n\nAhora importamos el diff:\n\n```\nldapmodify -Y EXTERNAL -H ldapi:/// -f ldaps.ldif\n```\n\n![ldapmodify](/images/ldaps-2.png)\n\nSustituímos la línea en:\n\nnano /etc/default/slapd\n\n```\nSLAPD_SERVICES=\"ldaps:///\"\n```\n\n```\ncp /etc/ssl/certs/gonzalonazareno.crt /usr/local/share/ca-certificates/\nupdate-ca-certificates\n```\n\nPodemos comprobar que todo funciona correctamente desde alfa ejecutando el siguiente comando:\n\n```\nldapsearch -x -b \"dc=antonio,dc=gonzalonazareno,dc=org\" -H ldaps://localhost:636\n```\n\n![ldapsearch](/images/ldaps-4.png)\n\n\n## LDAPs en Delta\n\nAhora desde nuestro local enviamos a delta el crt de la CA que es el gonzalonazareno.crt:\n\n```\nscp gonzalonazareno.crt antonio@delta:\n```\n\n![scp](/images/ldaps-3.png)\n\nAhora entramos a delta:\n\n```\nmv gonzalonazareno.crt /usr/local/share/ca-certificates/\nchown root:root /usr/local/share/ca-certificates/gonzalonazareno.crt\nupdate-ca-certificates\n```\n\n\n\nUna vez hecho esto ejecutamos el siguiente comando para comprobar que todo funciona correctamente:\n\n```\nldapsearch -x -b \"dc=antonio,dc=gonzalonazareno,dc=org\" -H ldaps://alfa.antonio.gonzalonazareno.org:636\n```\n\n\n![ldapsearch](/images/ldaps-5.png)\n\n\n\n\n\nTras esto forzamos a delta a que utilice solamente LDAPS:\n\n```\nnano /etc/ldap/ldap.conf\n\nURI     ldaps://192.168.0.1\n```\n\n\n## LDAPs en Bravo:\n\n\nVolvemos a mandar el certificado de la CA de local a bravo:\n\n```\nscp gonzalonazareno.crt antonio@bravo:\n```\n\n![scp](/images/ldaps-6.png)\n\nAhora entramos a bravo:\n\n```\nmv gonzalonazareno.crt /etc/pki/ca-trust/source/anchors/\nchown root:root /etc/pki/ca-trust/source/anchors/gonzalonazareno.crt\nupdate-ca-trust\n```\n\nvolvemos a hacer lo mismo en bravo para forzar el uso de LDAPS:\n\n```\nnano /etc/openldap/ldap.conf\n\nURI ldaps://alfa.antonio.gonzalonazareno.org\n```\n\nAhora comprobamos que funcina ejecutando el mismo comando que en delta ya que el host sigue siendo alfa:\n\n![ldapsearch](/images/ldaps-7.png)\n\n\n\n\nHacemos que conecte el servidor de bravo con el nfs que se encuentra en alfa:\n\n\nnano /etc/systemd/system/home.mount\n\n```\n[Unit]\nDescription= Montaje de carpeta home para NFS\n\n[Mount]\nWhat=172.16.0.1:/home/antonio/nfs/\nWhere=/home\nType=nfs\nOptions=defaults\n\n[Install]\nWantedBy=multi-user.target\n\n```\n\nluego vamos a reninicar el servicio de ldap en rocky:\n\n```\nsystemctl restart sssd\n```\n\n\n\n\nAhora comprobamos que el nfs con el usuario macarena creado en alfa a través de ldap puede acceder a la carpeta home de bravo, leer y crear ficheros:\n\n![ldapsearch](/images/ldaps-8.gif)","source":"_posts/LDAPs.md","raw":"---\ntitle: LDAPs\nCategoría: Sistemas Operativos\n---\n\n![ldaps](/images/ldaps-logo.png)\n\n# LDAPs\n\n## LDAPs en Alfa\n\nPrimero vamos a generar tanto el certificado público como el privado:\n\n```\nopenssl genrsa 4096 > /etc/ssl/private/alfa.key\nopenssl req -new -key /etc/ssl/private/alfa.key -out alfa.csr\n```\n\nAhora vamos a descargar el csr, lo enviaremos a la entidad certificadora del IES Gonzalo Nazareno, y cuando nos devuelvan el certificado público, lo guardaremos en el servidor como alfa.crt.\n\nUna vez tengamos el certificado público, lo importaremos en el servidor:\n\n\n```\nmv alfa.crt /etc/ssl/certs/\n\nmv gonzalonazareno.crt /etc/ssl/certs/\n\nchown root:root /etc/ssl/certs/alfa.crt\n\nchown root:root /etc/ssl/certs/gonzalonazareno.crt\n```\n\n\nAhora debemos instalar acl para que openldap pueda acceder a los certificados:\n\n```\napt install acl\n\nsetfacl -m u:openldap:r-x /etc/ssl/private\n\nsetfacl -m u:openldap:r-x /etc/ssl/private/alfa.key\n\ngetfacl /etc/ssl/private\n\ngetfacl /etc/ssl/private/alfa.key\n```\n\n\n![getfacl](/images/ldaps-1.png)\n\n\nnano ldaps.diff\n\n```\ndn: cn=config\nchangetype: modify\nreplace: olcTLSCACertificateFile\nolcTLSCACertificateFile: /etc/ssl/certs/gonzalonazareno.crt\n-\nreplace: olcTLSCertificateKeyFile\nolcTLSCertificateKeyFile: /etc/ssl/private/alfa.key\n-\nreplace: olcTLSCertificateFile\nolcTLSCertificateFile: /etc/ssl/certs/alfa.crt\n```\n\nAhora importamos el diff:\n\n```\nldapmodify -Y EXTERNAL -H ldapi:/// -f ldaps.ldif\n```\n\n![ldapmodify](/images/ldaps-2.png)\n\nSustituímos la línea en:\n\nnano /etc/default/slapd\n\n```\nSLAPD_SERVICES=\"ldaps:///\"\n```\n\n```\ncp /etc/ssl/certs/gonzalonazareno.crt /usr/local/share/ca-certificates/\nupdate-ca-certificates\n```\n\nPodemos comprobar que todo funciona correctamente desde alfa ejecutando el siguiente comando:\n\n```\nldapsearch -x -b \"dc=antonio,dc=gonzalonazareno,dc=org\" -H ldaps://localhost:636\n```\n\n![ldapsearch](/images/ldaps-4.png)\n\n\n## LDAPs en Delta\n\nAhora desde nuestro local enviamos a delta el crt de la CA que es el gonzalonazareno.crt:\n\n```\nscp gonzalonazareno.crt antonio@delta:\n```\n\n![scp](/images/ldaps-3.png)\n\nAhora entramos a delta:\n\n```\nmv gonzalonazareno.crt /usr/local/share/ca-certificates/\nchown root:root /usr/local/share/ca-certificates/gonzalonazareno.crt\nupdate-ca-certificates\n```\n\n\n\nUna vez hecho esto ejecutamos el siguiente comando para comprobar que todo funciona correctamente:\n\n```\nldapsearch -x -b \"dc=antonio,dc=gonzalonazareno,dc=org\" -H ldaps://alfa.antonio.gonzalonazareno.org:636\n```\n\n\n![ldapsearch](/images/ldaps-5.png)\n\n\n\n\n\nTras esto forzamos a delta a que utilice solamente LDAPS:\n\n```\nnano /etc/ldap/ldap.conf\n\nURI     ldaps://192.168.0.1\n```\n\n\n## LDAPs en Bravo:\n\n\nVolvemos a mandar el certificado de la CA de local a bravo:\n\n```\nscp gonzalonazareno.crt antonio@bravo:\n```\n\n![scp](/images/ldaps-6.png)\n\nAhora entramos a bravo:\n\n```\nmv gonzalonazareno.crt /etc/pki/ca-trust/source/anchors/\nchown root:root /etc/pki/ca-trust/source/anchors/gonzalonazareno.crt\nupdate-ca-trust\n```\n\nvolvemos a hacer lo mismo en bravo para forzar el uso de LDAPS:\n\n```\nnano /etc/openldap/ldap.conf\n\nURI ldaps://alfa.antonio.gonzalonazareno.org\n```\n\nAhora comprobamos que funcina ejecutando el mismo comando que en delta ya que el host sigue siendo alfa:\n\n![ldapsearch](/images/ldaps-7.png)\n\n\n\n\nHacemos que conecte el servidor de bravo con el nfs que se encuentra en alfa:\n\n\nnano /etc/systemd/system/home.mount\n\n```\n[Unit]\nDescription= Montaje de carpeta home para NFS\n\n[Mount]\nWhat=172.16.0.1:/home/antonio/nfs/\nWhere=/home\nType=nfs\nOptions=defaults\n\n[Install]\nWantedBy=multi-user.target\n\n```\n\nluego vamos a reninicar el servicio de ldap en rocky:\n\n```\nsystemctl restart sssd\n```\n\n\n\n\nAhora comprobamos que el nfs con el usuario macarena creado en alfa a través de ldap puede acceder a la carpeta home de bravo, leer y crear ficheros:\n\n![ldapsearch](/images/ldaps-8.gif)","slug":"LDAPs","published":1,"date":"2023-03-01T18:49:24.643Z","updated":"2023-03-02T13:26:29.047Z","_id":"cleqboid50000k8i51tco2gw5","comments":1,"layout":"post","photos":[],"link":"","content":"<p><img src=\"/images/ldaps-logo.png\" alt=\"ldaps\"></p>\n<h1 id=\"LDAPs\"><a href=\"#LDAPs\" class=\"headerlink\" title=\"LDAPs\"></a>LDAPs</h1><h2 id=\"LDAPs-en-Alfa\"><a href=\"#LDAPs-en-Alfa\" class=\"headerlink\" title=\"LDAPs en Alfa\"></a>LDAPs en Alfa</h2><p>Primero vamos a generar tanto el certificado público como el privado:</p>\n<pre><code>openssl genrsa 4096 &gt; /etc/ssl/private/alfa.key\nopenssl req -new -key /etc/ssl/private/alfa.key -out alfa.csr\n</code></pre>\n<p>Ahora vamos a descargar el csr, lo enviaremos a la entidad certificadora del IES Gonzalo Nazareno, y cuando nos devuelvan el certificado público, lo guardaremos en el servidor como alfa.crt.</p>\n<p>Una vez tengamos el certificado público, lo importaremos en el servidor:</p>\n<pre><code>mv alfa.crt /etc/ssl/certs/\n\nmv gonzalonazareno.crt /etc/ssl/certs/\n\nchown root:root /etc/ssl/certs/alfa.crt\n\nchown root:root /etc/ssl/certs/gonzalonazareno.crt\n</code></pre>\n<p>Ahora debemos instalar acl para que openldap pueda acceder a los certificados:</p>\n<pre><code>apt install acl\n\nsetfacl -m u:openldap:r-x /etc/ssl/private\n\nsetfacl -m u:openldap:r-x /etc/ssl/private/alfa.key\n\ngetfacl /etc/ssl/private\n\ngetfacl /etc/ssl/private/alfa.key\n</code></pre>\n<p><img src=\"/images/ldaps-1.png\" alt=\"getfacl\"></p>\n<p>nano ldaps.diff</p>\n<pre><code>dn: cn=config\nchangetype: modify\nreplace: olcTLSCACertificateFile\nolcTLSCACertificateFile: /etc/ssl/certs/gonzalonazareno.crt\n-\nreplace: olcTLSCertificateKeyFile\nolcTLSCertificateKeyFile: /etc/ssl/private/alfa.key\n-\nreplace: olcTLSCertificateFile\nolcTLSCertificateFile: /etc/ssl/certs/alfa.crt\n</code></pre>\n<p>Ahora importamos el diff:</p>\n<pre><code>ldapmodify -Y EXTERNAL -H ldapi:/// -f ldaps.ldif\n</code></pre>\n<p><img src=\"/images/ldaps-2.png\" alt=\"ldapmodify\"></p>\n<p>Sustituímos la línea en:</p>\n<p>nano &#x2F;etc&#x2F;default&#x2F;slapd</p>\n<pre><code>SLAPD_SERVICES=&quot;ldaps:///&quot;\n</code></pre>\n<pre><code>cp /etc/ssl/certs/gonzalonazareno.crt /usr/local/share/ca-certificates/\nupdate-ca-certificates\n</code></pre>\n<p>Podemos comprobar que todo funciona correctamente desde alfa ejecutando el siguiente comando:</p>\n<pre><code>ldapsearch -x -b &quot;dc=antonio,dc=gonzalonazareno,dc=org&quot; -H ldaps://localhost:636\n</code></pre>\n<p><img src=\"/images/ldaps-4.png\" alt=\"ldapsearch\"></p>\n<h2 id=\"LDAPs-en-Delta\"><a href=\"#LDAPs-en-Delta\" class=\"headerlink\" title=\"LDAPs en Delta\"></a>LDAPs en Delta</h2><p>Ahora desde nuestro local enviamos a delta el crt de la CA que es el gonzalonazareno.crt:</p>\n<pre><code>scp gonzalonazareno.crt antonio@delta:\n</code></pre>\n<p><img src=\"/images/ldaps-3.png\" alt=\"scp\"></p>\n<p>Ahora entramos a delta:</p>\n<pre><code>mv gonzalonazareno.crt /usr/local/share/ca-certificates/\nchown root:root /usr/local/share/ca-certificates/gonzalonazareno.crt\nupdate-ca-certificates\n</code></pre>\n<p>Una vez hecho esto ejecutamos el siguiente comando para comprobar que todo funciona correctamente:</p>\n<pre><code>ldapsearch -x -b &quot;dc=antonio,dc=gonzalonazareno,dc=org&quot; -H ldaps://alfa.antonio.gonzalonazareno.org:636\n</code></pre>\n<p><img src=\"/images/ldaps-5.png\" alt=\"ldapsearch\"></p>\n<p>Tras esto forzamos a delta a que utilice solamente LDAPS:</p>\n<pre><code>nano /etc/ldap/ldap.conf\n\nURI     ldaps://192.168.0.1\n</code></pre>\n<h2 id=\"LDAPs-en-Bravo\"><a href=\"#LDAPs-en-Bravo\" class=\"headerlink\" title=\"LDAPs en Bravo:\"></a>LDAPs en Bravo:</h2><p>Volvemos a mandar el certificado de la CA de local a bravo:</p>\n<pre><code>scp gonzalonazareno.crt antonio@bravo:\n</code></pre>\n<p><img src=\"/images/ldaps-6.png\" alt=\"scp\"></p>\n<p>Ahora entramos a bravo:</p>\n<pre><code>mv gonzalonazareno.crt /etc/pki/ca-trust/source/anchors/\nchown root:root /etc/pki/ca-trust/source/anchors/gonzalonazareno.crt\nupdate-ca-trust\n</code></pre>\n<p>volvemos a hacer lo mismo en bravo para forzar el uso de LDAPS:</p>\n<pre><code>nano /etc/openldap/ldap.conf\n\nURI ldaps://alfa.antonio.gonzalonazareno.org\n</code></pre>\n<p>Ahora comprobamos que funcina ejecutando el mismo comando que en delta ya que el host sigue siendo alfa:</p>\n<p><img src=\"/images/ldaps-7.png\" alt=\"ldapsearch\"></p>\n<p>Hacemos que conecte el servidor de bravo con el nfs que se encuentra en alfa:</p>\n<p>nano &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;home.mount</p>\n<pre><code>[Unit]\nDescription= Montaje de carpeta home para NFS\n\n[Mount]\nWhat=172.16.0.1:/home/antonio/nfs/\nWhere=/home\nType=nfs\nOptions=defaults\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>\n<p>luego vamos a reninicar el servicio de ldap en rocky:</p>\n<pre><code>systemctl restart sssd\n</code></pre>\n<p>Ahora comprobamos que el nfs con el usuario macarena creado en alfa a través de ldap puede acceder a la carpeta home de bravo, leer y crear ficheros:</p>\n<p><img src=\"/images/ldaps-8.gif\" alt=\"ldapsearch\"></p>\n","site":{"data":{}},"length":2963,"excerpt":"","more":"<p><img src=\"/images/ldaps-logo.png\" alt=\"ldaps\"></p>\n<h1 id=\"LDAPs\"><a href=\"#LDAPs\" class=\"headerlink\" title=\"LDAPs\"></a>LDAPs</h1><h2 id=\"LDAPs-en-Alfa\"><a href=\"#LDAPs-en-Alfa\" class=\"headerlink\" title=\"LDAPs en Alfa\"></a>LDAPs en Alfa</h2><p>Primero vamos a generar tanto el certificado público como el privado:</p>\n<pre><code>openssl genrsa 4096 &gt; /etc/ssl/private/alfa.key\nopenssl req -new -key /etc/ssl/private/alfa.key -out alfa.csr\n</code></pre>\n<p>Ahora vamos a descargar el csr, lo enviaremos a la entidad certificadora del IES Gonzalo Nazareno, y cuando nos devuelvan el certificado público, lo guardaremos en el servidor como alfa.crt.</p>\n<p>Una vez tengamos el certificado público, lo importaremos en el servidor:</p>\n<pre><code>mv alfa.crt /etc/ssl/certs/\n\nmv gonzalonazareno.crt /etc/ssl/certs/\n\nchown root:root /etc/ssl/certs/alfa.crt\n\nchown root:root /etc/ssl/certs/gonzalonazareno.crt\n</code></pre>\n<p>Ahora debemos instalar acl para que openldap pueda acceder a los certificados:</p>\n<pre><code>apt install acl\n\nsetfacl -m u:openldap:r-x /etc/ssl/private\n\nsetfacl -m u:openldap:r-x /etc/ssl/private/alfa.key\n\ngetfacl /etc/ssl/private\n\ngetfacl /etc/ssl/private/alfa.key\n</code></pre>\n<p><img src=\"/images/ldaps-1.png\" alt=\"getfacl\"></p>\n<p>nano ldaps.diff</p>\n<pre><code>dn: cn=config\nchangetype: modify\nreplace: olcTLSCACertificateFile\nolcTLSCACertificateFile: /etc/ssl/certs/gonzalonazareno.crt\n-\nreplace: olcTLSCertificateKeyFile\nolcTLSCertificateKeyFile: /etc/ssl/private/alfa.key\n-\nreplace: olcTLSCertificateFile\nolcTLSCertificateFile: /etc/ssl/certs/alfa.crt\n</code></pre>\n<p>Ahora importamos el diff:</p>\n<pre><code>ldapmodify -Y EXTERNAL -H ldapi:/// -f ldaps.ldif\n</code></pre>\n<p><img src=\"/images/ldaps-2.png\" alt=\"ldapmodify\"></p>\n<p>Sustituímos la línea en:</p>\n<p>nano &#x2F;etc&#x2F;default&#x2F;slapd</p>\n<pre><code>SLAPD_SERVICES=&quot;ldaps:///&quot;\n</code></pre>\n<pre><code>cp /etc/ssl/certs/gonzalonazareno.crt /usr/local/share/ca-certificates/\nupdate-ca-certificates\n</code></pre>\n<p>Podemos comprobar que todo funciona correctamente desde alfa ejecutando el siguiente comando:</p>\n<pre><code>ldapsearch -x -b &quot;dc=antonio,dc=gonzalonazareno,dc=org&quot; -H ldaps://localhost:636\n</code></pre>\n<p><img src=\"/images/ldaps-4.png\" alt=\"ldapsearch\"></p>\n<h2 id=\"LDAPs-en-Delta\"><a href=\"#LDAPs-en-Delta\" class=\"headerlink\" title=\"LDAPs en Delta\"></a>LDAPs en Delta</h2><p>Ahora desde nuestro local enviamos a delta el crt de la CA que es el gonzalonazareno.crt:</p>\n<pre><code>scp gonzalonazareno.crt antonio@delta:\n</code></pre>\n<p><img src=\"/images/ldaps-3.png\" alt=\"scp\"></p>\n<p>Ahora entramos a delta:</p>\n<pre><code>mv gonzalonazareno.crt /usr/local/share/ca-certificates/\nchown root:root /usr/local/share/ca-certificates/gonzalonazareno.crt\nupdate-ca-certificates\n</code></pre>\n<p>Una vez hecho esto ejecutamos el siguiente comando para comprobar que todo funciona correctamente:</p>\n<pre><code>ldapsearch -x -b &quot;dc=antonio,dc=gonzalonazareno,dc=org&quot; -H ldaps://alfa.antonio.gonzalonazareno.org:636\n</code></pre>\n<p><img src=\"/images/ldaps-5.png\" alt=\"ldapsearch\"></p>\n<p>Tras esto forzamos a delta a que utilice solamente LDAPS:</p>\n<pre><code>nano /etc/ldap/ldap.conf\n\nURI     ldaps://192.168.0.1\n</code></pre>\n<h2 id=\"LDAPs-en-Bravo\"><a href=\"#LDAPs-en-Bravo\" class=\"headerlink\" title=\"LDAPs en Bravo:\"></a>LDAPs en Bravo:</h2><p>Volvemos a mandar el certificado de la CA de local a bravo:</p>\n<pre><code>scp gonzalonazareno.crt antonio@bravo:\n</code></pre>\n<p><img src=\"/images/ldaps-6.png\" alt=\"scp\"></p>\n<p>Ahora entramos a bravo:</p>\n<pre><code>mv gonzalonazareno.crt /etc/pki/ca-trust/source/anchors/\nchown root:root /etc/pki/ca-trust/source/anchors/gonzalonazareno.crt\nupdate-ca-trust\n</code></pre>\n<p>volvemos a hacer lo mismo en bravo para forzar el uso de LDAPS:</p>\n<pre><code>nano /etc/openldap/ldap.conf\n\nURI ldaps://alfa.antonio.gonzalonazareno.org\n</code></pre>\n<p>Ahora comprobamos que funcina ejecutando el mismo comando que en delta ya que el host sigue siendo alfa:</p>\n<p><img src=\"/images/ldaps-7.png\" alt=\"ldapsearch\"></p>\n<p>Hacemos que conecte el servidor de bravo con el nfs que se encuentra en alfa:</p>\n<p>nano &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;home.mount</p>\n<pre><code>[Unit]\nDescription= Montaje de carpeta home para NFS\n\n[Mount]\nWhat=172.16.0.1:/home/antonio/nfs/\nWhere=/home\nType=nfs\nOptions=defaults\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>\n<p>luego vamos a reninicar el servicio de ldap en rocky:</p>\n<pre><code>systemctl restart sssd\n</code></pre>\n<p>Ahora comprobamos que el nfs con el usuario macarena creado en alfa a través de ldap puede acceder a la carpeta home de bravo, leer y crear ficheros:</p>\n<p><img src=\"/images/ldaps-8.gif\" alt=\"ldapsearch\"></p>\n"},{"title":"Docker","Categoría":"Contenedores","_content":"\n![imagen](/images/docker-logo-2.png)\n\n\n## Tarea 1: Creación de una imagen docker con una aplicación web desde una imagen base\n\n- Entrega la url del repositorio GitHub donde tengas los ficheros necesarios para hacer la construcción de la imagen.\n\nhttps://github.com/Evanticks/bookmedik-docker/tree/main/tarea-1\n\n- Entrega una captura de pantalla donde se vea la imagen en el registro de tu entorno de desarrollo.\n\n![imagen](/images/docker-1.png)\n\n\nPara esta práctica vamos a comenzar creando una red diferente a la default para que las máquinas que se conecten a ella puedan comunicarse entre sí a través de resolución de nombres.\n\n```\ndocker network create red_bookmedik\n```\n\n\nAhora vamos a crear el contenedor de MYSQL, que contendrá los valores por defecto de bookmedik:\n\n```\ndocker run -d --name mariadb -v bookmedik_vol:/var/lib/mysql --network red_bookmedik -e MARIADB_ROOT_PASSWORD=root -e MARIADB_DATABASE=bookmedik -e MARIADB_USER=bookmedik -e MARIADB_PASSWORD=bookmedik mariadb\n```\n\n\nAhora vamos a realizar la clonación de la aplicación bookmedik y lo vamos a clonar en nuestro entorno de trabajo:\n\n```\ngit@github.com:Evanticks/bookmedik.git\n```\n\nDespués de esto nos vamos al schema.sql y eliminaremos las líneas de creación de la base de datos ya que en el otro contenedor ya la hemos creado.\n\nSeguidamente nos vamos a core/controller/Database.php y modificamos las variables de conexión para que se conecte a la base de datos del contenedor de mariadb.\n\n```\n<?php\nclass Database {\n        public static $db;\n        public static $con;\n        function Database(){\n                $this->user=getenv('USUARIO_BOOKMEDIK');$this->pass=getenv('CONTRA_BOOKMEDIK');$this->host=getenv('DATABASE_HOST');$this->ddbb=getenv('NOMBRE_DB');\n        }\n\n        function connect(){\n                $con = new mysqli($this->host,$this->user,$this->pass,$this->ddbb);\n                $con->query(\"set sql_mode=''\");\n                return $con;\n        }\n\n        public static function getCon(){\n                if(self::$con==null && self::$db==null){\n                        self::$db = new Database();\n                        self::$con = self::$db->connect();\n                }\n                return self::$con;\n        }\n\n}\n?>\n\n```\n\n\n```\nsudo nano script.sh\n\n#! /bin/sh\n\nwhile ! mysql -u ${USUARIO_BOOKMEDIK} -p${CONTRA_BOOKMEDIK} -h ${DATABASE_HOST}  -e \";\" ; do\n        sleep 1\ndone\nmysql -u $USUARIO_BOOKMEDIK --password=$CONTRA_BOOKMEDIK -h $DATABASE_HOST $NOMBRE_DB < /var/www/html/schema.sql\n/usr/sbin/apache2ctl -D FOREGROUND\n\n```\n\nCon este script que añadiremos dentro del contenedor especificaremos que espere a que el contenedor de mariadb esté listo para poder ejecutar el script de creación de la base de datos.\n\n\nAhora vamos a construir el contenedor de bookmedik:\n\n```\ndocker build -t evanticks/bookmedik:v1 .\ndocker push evanticks/bookmedik:v1\n```\n\n![imagen](/images/docker-4.png)\n\n\nUna vez hecho esto vamos a crear el docker-compose.yml para poder levantar el contenedor de bookmedik y el de mariadb.\n\n\n## Tarea 2: Despliegue en el entorno de desarrollo\n\n- Entrega la url del repositorio GitHub donde hayas añadido el fichero docker-compose.yml.\n\nhttps://github.com/Evanticks/bookmedik-docker/tree/main/tarea-2\n\n- Entrega la instrucción para ver los dos contenedores del escenario funcionando.\n\n```\ndocker ps\n\ndocker-compose ps\n```\n\n![imagen](/images/docker-2.png)\n\n- Entrega una captura de pantalla donde se vea funcionando la aplicación, una vez que te has logueado.\n\n![imagen](/images/docker-3.png)\n\n---\n\ndocker-compose.yaml\n\n```\nversion: '3.1'\nservices:\n  bookmedik:\n    container_name: bookmedik-app\n    image: evanticks/bookmedik:v1\n    restart: always\n    environment:\n      USUARIO_BOOKMEDIK: admin\n      CONTRA_BOOKMEDIK: admin\n      DATABASE_HOST: bd_mariadb\n      NOMBRE_DB: bookmedik\n    ports:\n      - 8081:80\n    depends_on:\n      - db\n  db:\n    container_name: bd_mariadb\n    image: mariadb:10.5.19\n    restart: always\n    environment:\n      MARIADB_ROOT_PASSWORD: root\n      MARIADB_DATABASE: bookmedik\n      MARIADB_USER: admin\n      MARIADB_PASSWORD: admin\n    volumes:\n      - mariadb_data:/var/lib/mysql\nvolumes:\n    mariadb_data:\n```\n\n\nLuego lo ejecutaremos con el siguiente comando:\n\n```\ndocker-compose up -d\n```\n\nPara borrarlo junto con el almacenamiento creado ejecutaremos:\n\n```\ndocker-compose down -v\n```\n\n## Tarea 3: Creación de una imagen docker con una aplicación web desde una imagen PHP\n\n- Entrega la url del repositorio GitHub donde hayas añadido el fichero docker-compose.yml.\n\nhttps://github.com/Evanticks/bookmedik-docker/tree/main/tarea-3\n\n- Entrega la instrucción para ver los dos contenedores del escenario funcionando.\n\n```\ndocker ps\n\ndocker-compose ps\n```\n\n![imagen](/images/docker-5.png)\n\n- Entrega una captura de pantalla donde se vea funcionando la aplicación, una vez que te has logueado.\n\n![imagen](/images/docker-6.png)\n\n\nAhora procedamos a explicar los pasos que hemos seguido para realizar esta tarea.\n\nEn esta ocasión vamos a editar el dockerfile para que instale una imagen de php-apache y no una imagen de apache solamente, y le otorgaremos unos determinados paquetes para qeu funcione correctamente la conexión con la base de datos.\n\n```\nnano Dockerfile\n\nFROM php:7.4-apache-bullseye\nMAINTAINER Antonio Marchán Posada \"wildworld14@gmail.com\"\nRUN apt update && apt upgrade -y && docker-php-ext-install mysqli pdo pdo_mysql && apt install mariadb-client -y && apt clean && rm -rf /var/lib/apt/lists/*\nADD bookmedik /var/www/html/\nADD script.sh /opt/\nRUN chmod +x /opt/script.sh\nENTRYPOINT [\"/opt/script.sh\"]\n```\n\n- mysqli: Instala la extensión mysqli, que proporciona una interfaz orientada a objetos para interactuar con la base de datos MySQL.\n- pdo: Instala la extensión PDO (PHP Data Objects), que proporciona una interfaz consistente para acceder a varias bases de datos, incluyendo MySQL.\n- pdo_mysql: Instala el controlador PDO para MySQL, que permite que PHP se comunique con una base de datos MySQL utilizando PDO.\n\n\nAhora vamos a construir el contenedor de bookmedik:\n\n```\ndocker build -t evanticks/bookmedik:v2 .\ndocker push evanticks/bookmedik:v2\n```\n\n\nLuego vamos a tomar nuestro docker-compose que ya habíamos creado en la tarea anterior y le añadiremos el nuevo contenedor v2.\n\n\n```\nnano docker-compose.yml\n\nversion: '3.1'\nservices:\n  bookmedik:\n    container_name: bookmedik-app\n    image: evanticks/bookmedik:v2\n    restart: always\n    environment:\n      USUARIO_BOOKMEDIK: admin\n      CONTRA_BOOKMEDIK: admin\n      DATABASE_HOST: bd_mariadb\n      NOMBRE_DB: bookmedik\n    ports:\n      - 8081:80\n    depends_on:\n      - db\n  db:\n    container_name: bd_mariadb\n    image: mariadb:10.5.19\n    restart: always\n    environment:\n      MARIADB_ROOT_PASSWORD: root\n      MARIADB_DATABASE: bookmedik\n      MARIADB_USER: admin\n      MARIADB_PASSWORD: admin\n    volumes:\n      - mariadb_data:/var/lib/mysql\nvolumes:\n    mariadb_data:\n```\n\nUna vez hecho esto, los contenedores funcionarán correctamente.\n\n\n## Tarea 4: Ejecución de una aplicación PHP en docker con nginx (OPTATIVA)\n\n- Entrega la url del repositorio GitHub donde tengas los ficheros necesarios para hacer la construcción de la imagen.\n\nhttps://github.com/Evanticks/bookmedik-docker/tree/main/tarea-4\n\n- Entrega una captura de pantalla donde se vea la imagen en el registro de tu entorno de desarrollo.\n\n![imagen](/images/docker-7.png)\n\n- Entrega la instrucción para ver los tres contenedores del escenario funcionando.\n\n![imagen](/images/docker-8.png)\n\n- Entrega una captura de pantalla donde se vea funcionando la aplicación, una vez que te has logueado.\n\n![imagen](/images/docker-9.png)\n\n### Contenedor Nginx\n\nEl nginx el cual se encontrará la aplicación web, se encargará de recibir las peticiones de los clientes y de redirigirlas al contenedor de PHP-FPM que crearemos más adelante, que serán los encargados de procesarlas y devolver el resultado al cliente.\n\nPara ello antes debemos crear un fichero de configuración para hacer uso de php-fpm, para ello crearemos un fichero llamado default.conf el cual luego añadiremos a través del Dockerfile a la ruta /etc/nginx/conf.d/default.conf.\n\nnano default.conf\n\n```\nserver {\n    listen       80;\n    listen  [::]:80;\n    server_name  localhost;\n    error_log  /var/log/nginx/error.log;\n    access_log /var/log/nginx/access.log;\n    root   /usr/share/nginx/html;\n    index  index.php index.html;\n\n    location ~ \\.php$ {\n        try_files $uri =404;\n        fastcgi_split_path_info ^(.+\\.php)(/.+)$;\n        fastcgi_pass book_php:9000;\n        fastcgi_index index.php;\n        include fastcgi_params;\n        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;\n        fastcgi_param PATH_INFO $fastcgi_path_info;\n    }\n}\n```\n\nEl correspondiente script.sh que se ejecutará al iniciar el contenedor será el siguiente:\n\n```\n#! /bin/sh\n\nsleep 10\n\nmysql -u $USUARIO_BOOKMEDIK --password=$CONTRA_BOOKMEDIK -h $DATABASE_HOST $NOMBRE_DB < /usr/share/nginx/html/schema.sql\nnginx -g \"daemon off;\"\n```\n\nAhora empaquetamos y subimos a dockerhub:\n\n```\ndocker build -t evanticks/bookmedik:v3 .\ndocker push evanticks/bookmedik:v3\n```\n\n### Contenedor PHP-FPM\n\nAhora ejecutaremos el siguiente dockerfile el cual instalará mysqli que sirve para conectarse a la base de datos.\n\n```\nFROM php:7.4-fpm-bullseye\nMAINTAINER Antonio Marchán Posada \"wildworld14@gmail.com\"\nRUN docker-php-ext-install mysqli\n```\n\nAhora empaquetamos y subimos a dockerhub:\n\n```\ndocker build -t evanticks/fpm7.4-mysql:v1 .\ndocker push evanticks/fpm7.4-mysql:v1\n```\n\n### Docker-compose\n\n```\nversion: '3.1'\nservices:\n  bookmedik:\n    container_name: bookmedik-app\n    image: evanticks/bookmedik:v3\n    restart: always\n    environment:\n      USUARIO_BOOKMEDIK: admin\n      CONTRA_BOOKMEDIK: admin\n      DATABASE_HOST: bd_mariadb\n      NOMBRE_DB: bookmedik\n    ports:\n      - 8082:80\n    depends_on:\n      - db\n      - php\n    volumes:\n      - phpdocs:/usr/share/nginx/html/\n  db:\n    container_name: bd_mariadb\n    image: mariadb\n    restart: always\n    environment:\n      MARIADB_ROOT_PASSWORD: root\n      MARIADB_DATABASE: bookmedik\n      MARIADB_USER: admin\n      MARIADB_PASSWORD: admin\n    volumes:\n      - mariadb_data:/var/lib/mysql\n  php:\n    container_name: book_php\n    image: evanticks/fpm7.4-mysql:v1\n    restart: always\n    environment:\n      USUARIO_BOOKMEDIK: admin\n      CONTRA_BOOKMEDIK: admin\n      DATABASE_HOST: bd_mariadb\n      NOMBRE_DB: bookmedik\n    volumes:\n      - phpdocs:/usr/share/nginx/html/\n\nvolumes:\n    mariadb_data:\n    phpdocs:\n```\n\n## Tarea 5: Puesta en producción de nuestra aplicación\n\nPara poner en producción nuestra aplicación debemos de configurar el nginx para que funcione con el certificado SSL de Let's Encrypt.\n\n```\n/etc/nginx/sites-available/bookmedik\n```\n\nY pondremos la siguiente configuración en el puerto 8084, el cual después deberemos cambiar en el docker-compose.yml.\n\n```\nserver {\n        listen 80;\n        listen [::]:80;\n\n        server_name bookmedik.entrebytes.org;\n\n        return 301 https://$host$request_uri;\n}\n\nserver {\n        listen 443 ssl http2;\n        listen [::]:443 ssl http2;\n\n        ssl    on;\n        ssl_certificate /etc/letsencrypt/live/bookmedik.entrebytes.org/fullchain.pem;\n        ssl_certificate_key /etc/letsencrypt/live/bookmedik.entrebytes.org/privkey.pem;\n\n        index index.html index.php index.htm index.nginx-debian.html;\n\n        server_name bookmedik.entrebytes.org;\n\n        location / {\n                proxy_pass http://localhost:8084;\n                include proxy_params;\n        }\n}\n```\n\nAhora vamos a generar el certificado bookmedik.entrebytes.org, para ello antes debemos poner un CNAME bookmedik.entrebytes.org que señale a nuestro servidor.\n\nTras esto en la VPS ejecutaremos el siguiente comando:\n\n```\nsystemctl nginx stop\ncertbot certonly --standalone -d bookmedik.entrebytes.org\nsystemctl nginx start\n```\n\nPor último para que descargue y ponga en producción los contenedores ejecutaremos:\n\n```\nversion: '3.1'\nservices:\n  bookmedik:\n    container_name: bookmedik-app\n    image: evanticks/bookmedik:v2\n    restart: always\n    environment:\n      USUARIO_BOOKMEDIK: admin\n      CONTRA_BOOKMEDIK: admin\n      DATABASE_HOST: bd_mariadb\n      NOMBRE_DB: bookmedik\n    ports:\n      - 8084:80\n    depends_on:\n      - db\n  db:\n    container_name: bd_mariadb\n    image: mariadb\n    restart: always\n    environment:\n      MARIADB_ROOT_PASSWORD: root\n      MARIADB_DATABASE: bookmedik\n      MARIADB_USER: admin\n      MARIADB_PASSWORD: admin\n    volumes:\n      - mariadb_data:/var/lib/mysql\nvolumes:\n    mariadb_data:\n\n```\n\n```\ndocker-compose up -d\n```\n\nY con esto ya lo tendríamos en producción.\n\n- Entrega una captura de pantalla de Docker Hub donde se vea tu imagen subida.\n\n![imagen](/images/docker-10.png)\n\n- Entrega la configuración de nginx.\n\n```\nserver {\n        listen 80;\n        listen [::]:80;\n\n        server_name bookmedik.entrebytes.org;\n\n        return 301 https://$host$request_uri;\n}\n\nserver {\n        listen 443 ssl http2;\n        listen [::]:443 ssl http2;\n\n        ssl    on;\n        ssl_certificate /etc/letsencrypt/live/bookmedik.entrebytes.org/fullchain.pem;\n        ssl_certificate_key /etc/letsencrypt/live/bookmedik.entrebytes.org/privkey.pem;\n\n        index index.html index.php index.htm index.nginx-debian.html;\n\n        server_name bookmedik.entrebytes.org;\n\n        location / {\n                proxy_pass http://localhost:8084;\n                include proxy_params;\n        }\n}\n```\n\n- Entrega una captura de pantalla donde se vea funcionando la aplicación, una vez que te has logueado.\n\n\n![imagen](/images/docker-11.png)\n\n## Tarea 6: Modificación de la aplicación\n\n- Entrega una captura de pantalla de Docker Hub donde se vea tu imagen subida.\n\n![imagen](/images/docker-13.png)\n\n- Entrega una captura de pantalla donde se vea funcionando la aplicación, una vez que te has logueado.\n\nEn mi caso lo pongo antes para que se pueda apreciar el cambio en producción.\n\n![imagen](/images/docker-12.png)","source":"_posts/docker-practica.md","raw":"---\ntitle: Docker\nCategoría: Contenedores\n---\n\n![imagen](/images/docker-logo-2.png)\n\n\n## Tarea 1: Creación de una imagen docker con una aplicación web desde una imagen base\n\n- Entrega la url del repositorio GitHub donde tengas los ficheros necesarios para hacer la construcción de la imagen.\n\nhttps://github.com/Evanticks/bookmedik-docker/tree/main/tarea-1\n\n- Entrega una captura de pantalla donde se vea la imagen en el registro de tu entorno de desarrollo.\n\n![imagen](/images/docker-1.png)\n\n\nPara esta práctica vamos a comenzar creando una red diferente a la default para que las máquinas que se conecten a ella puedan comunicarse entre sí a través de resolución de nombres.\n\n```\ndocker network create red_bookmedik\n```\n\n\nAhora vamos a crear el contenedor de MYSQL, que contendrá los valores por defecto de bookmedik:\n\n```\ndocker run -d --name mariadb -v bookmedik_vol:/var/lib/mysql --network red_bookmedik -e MARIADB_ROOT_PASSWORD=root -e MARIADB_DATABASE=bookmedik -e MARIADB_USER=bookmedik -e MARIADB_PASSWORD=bookmedik mariadb\n```\n\n\nAhora vamos a realizar la clonación de la aplicación bookmedik y lo vamos a clonar en nuestro entorno de trabajo:\n\n```\ngit@github.com:Evanticks/bookmedik.git\n```\n\nDespués de esto nos vamos al schema.sql y eliminaremos las líneas de creación de la base de datos ya que en el otro contenedor ya la hemos creado.\n\nSeguidamente nos vamos a core/controller/Database.php y modificamos las variables de conexión para que se conecte a la base de datos del contenedor de mariadb.\n\n```\n<?php\nclass Database {\n        public static $db;\n        public static $con;\n        function Database(){\n                $this->user=getenv('USUARIO_BOOKMEDIK');$this->pass=getenv('CONTRA_BOOKMEDIK');$this->host=getenv('DATABASE_HOST');$this->ddbb=getenv('NOMBRE_DB');\n        }\n\n        function connect(){\n                $con = new mysqli($this->host,$this->user,$this->pass,$this->ddbb);\n                $con->query(\"set sql_mode=''\");\n                return $con;\n        }\n\n        public static function getCon(){\n                if(self::$con==null && self::$db==null){\n                        self::$db = new Database();\n                        self::$con = self::$db->connect();\n                }\n                return self::$con;\n        }\n\n}\n?>\n\n```\n\n\n```\nsudo nano script.sh\n\n#! /bin/sh\n\nwhile ! mysql -u ${USUARIO_BOOKMEDIK} -p${CONTRA_BOOKMEDIK} -h ${DATABASE_HOST}  -e \";\" ; do\n        sleep 1\ndone\nmysql -u $USUARIO_BOOKMEDIK --password=$CONTRA_BOOKMEDIK -h $DATABASE_HOST $NOMBRE_DB < /var/www/html/schema.sql\n/usr/sbin/apache2ctl -D FOREGROUND\n\n```\n\nCon este script que añadiremos dentro del contenedor especificaremos que espere a que el contenedor de mariadb esté listo para poder ejecutar el script de creación de la base de datos.\n\n\nAhora vamos a construir el contenedor de bookmedik:\n\n```\ndocker build -t evanticks/bookmedik:v1 .\ndocker push evanticks/bookmedik:v1\n```\n\n![imagen](/images/docker-4.png)\n\n\nUna vez hecho esto vamos a crear el docker-compose.yml para poder levantar el contenedor de bookmedik y el de mariadb.\n\n\n## Tarea 2: Despliegue en el entorno de desarrollo\n\n- Entrega la url del repositorio GitHub donde hayas añadido el fichero docker-compose.yml.\n\nhttps://github.com/Evanticks/bookmedik-docker/tree/main/tarea-2\n\n- Entrega la instrucción para ver los dos contenedores del escenario funcionando.\n\n```\ndocker ps\n\ndocker-compose ps\n```\n\n![imagen](/images/docker-2.png)\n\n- Entrega una captura de pantalla donde se vea funcionando la aplicación, una vez que te has logueado.\n\n![imagen](/images/docker-3.png)\n\n---\n\ndocker-compose.yaml\n\n```\nversion: '3.1'\nservices:\n  bookmedik:\n    container_name: bookmedik-app\n    image: evanticks/bookmedik:v1\n    restart: always\n    environment:\n      USUARIO_BOOKMEDIK: admin\n      CONTRA_BOOKMEDIK: admin\n      DATABASE_HOST: bd_mariadb\n      NOMBRE_DB: bookmedik\n    ports:\n      - 8081:80\n    depends_on:\n      - db\n  db:\n    container_name: bd_mariadb\n    image: mariadb:10.5.19\n    restart: always\n    environment:\n      MARIADB_ROOT_PASSWORD: root\n      MARIADB_DATABASE: bookmedik\n      MARIADB_USER: admin\n      MARIADB_PASSWORD: admin\n    volumes:\n      - mariadb_data:/var/lib/mysql\nvolumes:\n    mariadb_data:\n```\n\n\nLuego lo ejecutaremos con el siguiente comando:\n\n```\ndocker-compose up -d\n```\n\nPara borrarlo junto con el almacenamiento creado ejecutaremos:\n\n```\ndocker-compose down -v\n```\n\n## Tarea 3: Creación de una imagen docker con una aplicación web desde una imagen PHP\n\n- Entrega la url del repositorio GitHub donde hayas añadido el fichero docker-compose.yml.\n\nhttps://github.com/Evanticks/bookmedik-docker/tree/main/tarea-3\n\n- Entrega la instrucción para ver los dos contenedores del escenario funcionando.\n\n```\ndocker ps\n\ndocker-compose ps\n```\n\n![imagen](/images/docker-5.png)\n\n- Entrega una captura de pantalla donde se vea funcionando la aplicación, una vez que te has logueado.\n\n![imagen](/images/docker-6.png)\n\n\nAhora procedamos a explicar los pasos que hemos seguido para realizar esta tarea.\n\nEn esta ocasión vamos a editar el dockerfile para que instale una imagen de php-apache y no una imagen de apache solamente, y le otorgaremos unos determinados paquetes para qeu funcione correctamente la conexión con la base de datos.\n\n```\nnano Dockerfile\n\nFROM php:7.4-apache-bullseye\nMAINTAINER Antonio Marchán Posada \"wildworld14@gmail.com\"\nRUN apt update && apt upgrade -y && docker-php-ext-install mysqli pdo pdo_mysql && apt install mariadb-client -y && apt clean && rm -rf /var/lib/apt/lists/*\nADD bookmedik /var/www/html/\nADD script.sh /opt/\nRUN chmod +x /opt/script.sh\nENTRYPOINT [\"/opt/script.sh\"]\n```\n\n- mysqli: Instala la extensión mysqli, que proporciona una interfaz orientada a objetos para interactuar con la base de datos MySQL.\n- pdo: Instala la extensión PDO (PHP Data Objects), que proporciona una interfaz consistente para acceder a varias bases de datos, incluyendo MySQL.\n- pdo_mysql: Instala el controlador PDO para MySQL, que permite que PHP se comunique con una base de datos MySQL utilizando PDO.\n\n\nAhora vamos a construir el contenedor de bookmedik:\n\n```\ndocker build -t evanticks/bookmedik:v2 .\ndocker push evanticks/bookmedik:v2\n```\n\n\nLuego vamos a tomar nuestro docker-compose que ya habíamos creado en la tarea anterior y le añadiremos el nuevo contenedor v2.\n\n\n```\nnano docker-compose.yml\n\nversion: '3.1'\nservices:\n  bookmedik:\n    container_name: bookmedik-app\n    image: evanticks/bookmedik:v2\n    restart: always\n    environment:\n      USUARIO_BOOKMEDIK: admin\n      CONTRA_BOOKMEDIK: admin\n      DATABASE_HOST: bd_mariadb\n      NOMBRE_DB: bookmedik\n    ports:\n      - 8081:80\n    depends_on:\n      - db\n  db:\n    container_name: bd_mariadb\n    image: mariadb:10.5.19\n    restart: always\n    environment:\n      MARIADB_ROOT_PASSWORD: root\n      MARIADB_DATABASE: bookmedik\n      MARIADB_USER: admin\n      MARIADB_PASSWORD: admin\n    volumes:\n      - mariadb_data:/var/lib/mysql\nvolumes:\n    mariadb_data:\n```\n\nUna vez hecho esto, los contenedores funcionarán correctamente.\n\n\n## Tarea 4: Ejecución de una aplicación PHP en docker con nginx (OPTATIVA)\n\n- Entrega la url del repositorio GitHub donde tengas los ficheros necesarios para hacer la construcción de la imagen.\n\nhttps://github.com/Evanticks/bookmedik-docker/tree/main/tarea-4\n\n- Entrega una captura de pantalla donde se vea la imagen en el registro de tu entorno de desarrollo.\n\n![imagen](/images/docker-7.png)\n\n- Entrega la instrucción para ver los tres contenedores del escenario funcionando.\n\n![imagen](/images/docker-8.png)\n\n- Entrega una captura de pantalla donde se vea funcionando la aplicación, una vez que te has logueado.\n\n![imagen](/images/docker-9.png)\n\n### Contenedor Nginx\n\nEl nginx el cual se encontrará la aplicación web, se encargará de recibir las peticiones de los clientes y de redirigirlas al contenedor de PHP-FPM que crearemos más adelante, que serán los encargados de procesarlas y devolver el resultado al cliente.\n\nPara ello antes debemos crear un fichero de configuración para hacer uso de php-fpm, para ello crearemos un fichero llamado default.conf el cual luego añadiremos a través del Dockerfile a la ruta /etc/nginx/conf.d/default.conf.\n\nnano default.conf\n\n```\nserver {\n    listen       80;\n    listen  [::]:80;\n    server_name  localhost;\n    error_log  /var/log/nginx/error.log;\n    access_log /var/log/nginx/access.log;\n    root   /usr/share/nginx/html;\n    index  index.php index.html;\n\n    location ~ \\.php$ {\n        try_files $uri =404;\n        fastcgi_split_path_info ^(.+\\.php)(/.+)$;\n        fastcgi_pass book_php:9000;\n        fastcgi_index index.php;\n        include fastcgi_params;\n        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;\n        fastcgi_param PATH_INFO $fastcgi_path_info;\n    }\n}\n```\n\nEl correspondiente script.sh que se ejecutará al iniciar el contenedor será el siguiente:\n\n```\n#! /bin/sh\n\nsleep 10\n\nmysql -u $USUARIO_BOOKMEDIK --password=$CONTRA_BOOKMEDIK -h $DATABASE_HOST $NOMBRE_DB < /usr/share/nginx/html/schema.sql\nnginx -g \"daemon off;\"\n```\n\nAhora empaquetamos y subimos a dockerhub:\n\n```\ndocker build -t evanticks/bookmedik:v3 .\ndocker push evanticks/bookmedik:v3\n```\n\n### Contenedor PHP-FPM\n\nAhora ejecutaremos el siguiente dockerfile el cual instalará mysqli que sirve para conectarse a la base de datos.\n\n```\nFROM php:7.4-fpm-bullseye\nMAINTAINER Antonio Marchán Posada \"wildworld14@gmail.com\"\nRUN docker-php-ext-install mysqli\n```\n\nAhora empaquetamos y subimos a dockerhub:\n\n```\ndocker build -t evanticks/fpm7.4-mysql:v1 .\ndocker push evanticks/fpm7.4-mysql:v1\n```\n\n### Docker-compose\n\n```\nversion: '3.1'\nservices:\n  bookmedik:\n    container_name: bookmedik-app\n    image: evanticks/bookmedik:v3\n    restart: always\n    environment:\n      USUARIO_BOOKMEDIK: admin\n      CONTRA_BOOKMEDIK: admin\n      DATABASE_HOST: bd_mariadb\n      NOMBRE_DB: bookmedik\n    ports:\n      - 8082:80\n    depends_on:\n      - db\n      - php\n    volumes:\n      - phpdocs:/usr/share/nginx/html/\n  db:\n    container_name: bd_mariadb\n    image: mariadb\n    restart: always\n    environment:\n      MARIADB_ROOT_PASSWORD: root\n      MARIADB_DATABASE: bookmedik\n      MARIADB_USER: admin\n      MARIADB_PASSWORD: admin\n    volumes:\n      - mariadb_data:/var/lib/mysql\n  php:\n    container_name: book_php\n    image: evanticks/fpm7.4-mysql:v1\n    restart: always\n    environment:\n      USUARIO_BOOKMEDIK: admin\n      CONTRA_BOOKMEDIK: admin\n      DATABASE_HOST: bd_mariadb\n      NOMBRE_DB: bookmedik\n    volumes:\n      - phpdocs:/usr/share/nginx/html/\n\nvolumes:\n    mariadb_data:\n    phpdocs:\n```\n\n## Tarea 5: Puesta en producción de nuestra aplicación\n\nPara poner en producción nuestra aplicación debemos de configurar el nginx para que funcione con el certificado SSL de Let's Encrypt.\n\n```\n/etc/nginx/sites-available/bookmedik\n```\n\nY pondremos la siguiente configuración en el puerto 8084, el cual después deberemos cambiar en el docker-compose.yml.\n\n```\nserver {\n        listen 80;\n        listen [::]:80;\n\n        server_name bookmedik.entrebytes.org;\n\n        return 301 https://$host$request_uri;\n}\n\nserver {\n        listen 443 ssl http2;\n        listen [::]:443 ssl http2;\n\n        ssl    on;\n        ssl_certificate /etc/letsencrypt/live/bookmedik.entrebytes.org/fullchain.pem;\n        ssl_certificate_key /etc/letsencrypt/live/bookmedik.entrebytes.org/privkey.pem;\n\n        index index.html index.php index.htm index.nginx-debian.html;\n\n        server_name bookmedik.entrebytes.org;\n\n        location / {\n                proxy_pass http://localhost:8084;\n                include proxy_params;\n        }\n}\n```\n\nAhora vamos a generar el certificado bookmedik.entrebytes.org, para ello antes debemos poner un CNAME bookmedik.entrebytes.org que señale a nuestro servidor.\n\nTras esto en la VPS ejecutaremos el siguiente comando:\n\n```\nsystemctl nginx stop\ncertbot certonly --standalone -d bookmedik.entrebytes.org\nsystemctl nginx start\n```\n\nPor último para que descargue y ponga en producción los contenedores ejecutaremos:\n\n```\nversion: '3.1'\nservices:\n  bookmedik:\n    container_name: bookmedik-app\n    image: evanticks/bookmedik:v2\n    restart: always\n    environment:\n      USUARIO_BOOKMEDIK: admin\n      CONTRA_BOOKMEDIK: admin\n      DATABASE_HOST: bd_mariadb\n      NOMBRE_DB: bookmedik\n    ports:\n      - 8084:80\n    depends_on:\n      - db\n  db:\n    container_name: bd_mariadb\n    image: mariadb\n    restart: always\n    environment:\n      MARIADB_ROOT_PASSWORD: root\n      MARIADB_DATABASE: bookmedik\n      MARIADB_USER: admin\n      MARIADB_PASSWORD: admin\n    volumes:\n      - mariadb_data:/var/lib/mysql\nvolumes:\n    mariadb_data:\n\n```\n\n```\ndocker-compose up -d\n```\n\nY con esto ya lo tendríamos en producción.\n\n- Entrega una captura de pantalla de Docker Hub donde se vea tu imagen subida.\n\n![imagen](/images/docker-10.png)\n\n- Entrega la configuración de nginx.\n\n```\nserver {\n        listen 80;\n        listen [::]:80;\n\n        server_name bookmedik.entrebytes.org;\n\n        return 301 https://$host$request_uri;\n}\n\nserver {\n        listen 443 ssl http2;\n        listen [::]:443 ssl http2;\n\n        ssl    on;\n        ssl_certificate /etc/letsencrypt/live/bookmedik.entrebytes.org/fullchain.pem;\n        ssl_certificate_key /etc/letsencrypt/live/bookmedik.entrebytes.org/privkey.pem;\n\n        index index.html index.php index.htm index.nginx-debian.html;\n\n        server_name bookmedik.entrebytes.org;\n\n        location / {\n                proxy_pass http://localhost:8084;\n                include proxy_params;\n        }\n}\n```\n\n- Entrega una captura de pantalla donde se vea funcionando la aplicación, una vez que te has logueado.\n\n\n![imagen](/images/docker-11.png)\n\n## Tarea 6: Modificación de la aplicación\n\n- Entrega una captura de pantalla de Docker Hub donde se vea tu imagen subida.\n\n![imagen](/images/docker-13.png)\n\n- Entrega una captura de pantalla donde se vea funcionando la aplicación, una vez que te has logueado.\n\nEn mi caso lo pongo antes para que se pueda apreciar el cambio en producción.\n\n![imagen](/images/docker-12.png)","slug":"docker-practica","published":1,"date":"2023-02-24T08:54:39.282Z","updated":"2023-03-01T23:44:06.704Z","_id":"cleqboidh0001k8i5evn2b2f4","comments":1,"layout":"post","photos":[],"link":"","content":"<p><img src=\"/images/docker-logo-2.png\" alt=\"imagen\"></p>\n<h2 id=\"tarea-1-creación-de-una-imagen-docker-con-una-aplicación-web-desde-una-imagen-base\"><a class=\"markdownIt-Anchor\" href=\"#tarea-1-creación-de-una-imagen-docker-con-una-aplicación-web-desde-una-imagen-base\">#</a> Tarea 1: Creación de una imagen docker con una aplicación web desde una imagen base</h2>\n<ul>\n<li>Entrega la url del repositorio GitHub donde tengas los ficheros necesarios para hacer la construcción de la imagen.</li>\n</ul>\n<p><a href=\"https://github.com/Evanticks/bookmedik-docker/tree/main/tarea-1\">https://github.com/Evanticks/bookmedik-docker/tree/main/tarea-1</a></p>\n<ul>\n<li>Entrega una captura de pantalla donde se vea la imagen en el registro de tu entorno de desarrollo.</li>\n</ul>\n<p><img src=\"/images/docker-1.png\" alt=\"imagen\"></p>\n<p>Para esta práctica vamos a comenzar creando una red diferente a la default para que las máquinas que se conecten a ella puedan comunicarse entre sí a través de resolución de nombres.</p>\n<pre><code>docker network create red_bookmedik\n</code></pre>\n<p>Ahora vamos a crear el contenedor de MYSQL, que contendrá los valores por defecto de bookmedik:</p>\n<pre><code>docker run -d --name mariadb -v bookmedik_vol:/var/lib/mysql --network red_bookmedik -e MARIADB_ROOT_PASSWORD=root -e MARIADB_DATABASE=bookmedik -e MARIADB_USER=bookmedik -e MARIADB_PASSWORD=bookmedik mariadb\n</code></pre>\n<p>Ahora vamos a realizar la clonación de la aplicación bookmedik y lo vamos a clonar en nuestro entorno de trabajo:</p>\n<pre><code>git@github.com:Evanticks/bookmedik.git\n</code></pre>\n<p>Después de esto nos vamos al schema.sql y eliminaremos las líneas de creación de la base de datos ya que en el otro contenedor ya la hemos creado.</p>\n<p>Seguidamente nos vamos a core/controller/Database.php y modificamos las variables de conexión para que se conecte a la base de datos del contenedor de mariadb.</p>\n<pre><code>&lt;?php\nclass Database &#123;\n        public static $db;\n        public static $con;\n        function Database()&#123;\n                $this-&gt;user=getenv('USUARIO_BOOKMEDIK');$this-&gt;pass=getenv('CONTRA_BOOKMEDIK');$this-&gt;host=getenv('DATABASE_HOST');$this-&gt;ddbb=getenv('NOMBRE_DB');\n        &#125;\n\n        function connect()&#123;\n                $con = new mysqli($this-&gt;host,$this-&gt;user,$this-&gt;pass,$this-&gt;ddbb);\n                $con-&gt;query(&quot;set sql_mode=''&quot;);\n                return $con;\n        &#125;\n\n        public static function getCon()&#123;\n                if(self::$con==null &amp;&amp; self::$db==null)&#123;\n                        self::$db = new Database();\n                        self::$con = self::$db-&gt;connect();\n                &#125;\n                return self::$con;\n        &#125;\n\n&#125;\n?&gt;\n\n</code></pre>\n<pre><code>sudo nano script.sh\n\n#! /bin/sh\n\nwhile ! mysql -u $&#123;USUARIO_BOOKMEDIK&#125; -p$&#123;CONTRA_BOOKMEDIK&#125; -h $&#123;DATABASE_HOST&#125;  -e &quot;;&quot; ; do\n        sleep 1\ndone\nmysql -u $USUARIO_BOOKMEDIK --password=$CONTRA_BOOKMEDIK -h $DATABASE_HOST $NOMBRE_DB &lt; /var/www/html/schema.sql\n/usr/sbin/apache2ctl -D FOREGROUND\n\n</code></pre>\n<p>Con este script que añadiremos dentro del contenedor especificaremos que espere a que el contenedor de mariadb esté listo para poder ejecutar el script de creación de la base de datos.</p>\n<p>Ahora vamos a construir el contenedor de bookmedik:</p>\n<pre><code>docker build -t evanticks/bookmedik:v1 .\ndocker push evanticks/bookmedik:v1\n</code></pre>\n<p><img src=\"/images/docker-4.png\" alt=\"imagen\"></p>\n<p>Una vez hecho esto vamos a crear el docker-compose.yml para poder levantar el contenedor de bookmedik y el de mariadb.</p>\n<h2 id=\"tarea-2-despliegue-en-el-entorno-de-desarrollo\"><a class=\"markdownIt-Anchor\" href=\"#tarea-2-despliegue-en-el-entorno-de-desarrollo\">#</a> Tarea 2: Despliegue en el entorno de desarrollo</h2>\n<ul>\n<li>Entrega la url del repositorio GitHub donde hayas añadido el fichero docker-compose.yml.</li>\n</ul>\n<p><a href=\"https://github.com/Evanticks/bookmedik-docker/tree/main/tarea-2\">https://github.com/Evanticks/bookmedik-docker/tree/main/tarea-2</a></p>\n<ul>\n<li>Entrega la instrucción para ver los dos contenedores del escenario funcionando.</li>\n</ul>\n<pre><code>docker ps\n\ndocker-compose ps\n</code></pre>\n<p><img src=\"/images/docker-2.png\" alt=\"imagen\"></p>\n<ul>\n<li>Entrega una captura de pantalla donde se vea funcionando la aplicación, una vez que te has logueado.</li>\n</ul>\n<p><img src=\"/images/docker-3.png\" alt=\"imagen\"></p>\n<hr>\n<p>docker-compose.yaml</p>\n<pre><code>version: '3.1'\nservices:\n  bookmedik:\n    container_name: bookmedik-app\n    image: evanticks/bookmedik:v1\n    restart: always\n    environment:\n      USUARIO_BOOKMEDIK: admin\n      CONTRA_BOOKMEDIK: admin\n      DATABASE_HOST: bd_mariadb\n      NOMBRE_DB: bookmedik\n    ports:\n      - 8081:80\n    depends_on:\n      - db\n  db:\n    container_name: bd_mariadb\n    image: mariadb:10.5.19\n    restart: always\n    environment:\n      MARIADB_ROOT_PASSWORD: root\n      MARIADB_DATABASE: bookmedik\n      MARIADB_USER: admin\n      MARIADB_PASSWORD: admin\n    volumes:\n      - mariadb_data:/var/lib/mysql\nvolumes:\n    mariadb_data:\n</code></pre>\n<p>Luego lo ejecutaremos con el siguiente comando:</p>\n<pre><code>docker-compose up -d\n</code></pre>\n<p>Para borrarlo junto con el almacenamiento creado ejecutaremos:</p>\n<pre><code>docker-compose down -v\n</code></pre>\n<h2 id=\"tarea-3-creación-de-una-imagen-docker-con-una-aplicación-web-desde-una-imagen-php\"><a class=\"markdownIt-Anchor\" href=\"#tarea-3-creación-de-una-imagen-docker-con-una-aplicación-web-desde-una-imagen-php\">#</a> Tarea 3: Creación de una imagen docker con una aplicación web desde una imagen PHP</h2>\n<ul>\n<li>Entrega la url del repositorio GitHub donde hayas añadido el fichero docker-compose.yml.</li>\n</ul>\n<p><a href=\"https://github.com/Evanticks/bookmedik-docker/tree/main/tarea-3\">https://github.com/Evanticks/bookmedik-docker/tree/main/tarea-3</a></p>\n<ul>\n<li>Entrega la instrucción para ver los dos contenedores del escenario funcionando.</li>\n</ul>\n<pre><code>docker ps\n\ndocker-compose ps\n</code></pre>\n<p><img src=\"/images/docker-5.png\" alt=\"imagen\"></p>\n<ul>\n<li>Entrega una captura de pantalla donde se vea funcionando la aplicación, una vez que te has logueado.</li>\n</ul>\n<p><img src=\"/images/docker-6.png\" alt=\"imagen\"></p>\n<p>Ahora procedamos a explicar los pasos que hemos seguido para realizar esta tarea.</p>\n<p>En esta ocasión vamos a editar el dockerfile para que instale una imagen de php-apache y no una imagen de apache solamente, y le otorgaremos unos determinados paquetes para qeu funcione correctamente la conexión con la base de datos.</p>\n<pre><code>nano Dockerfile\n\nFROM php:7.4-apache-bullseye\nMAINTAINER Antonio Marchán Posada &quot;wildworld14@gmail.com&quot;\nRUN apt update &amp;&amp; apt upgrade -y &amp;&amp; docker-php-ext-install mysqli pdo pdo_mysql &amp;&amp; apt install mariadb-client -y &amp;&amp; apt clean &amp;&amp; rm -rf /var/lib/apt/lists/*\nADD bookmedik /var/www/html/\nADD script.sh /opt/\nRUN chmod +x /opt/script.sh\nENTRYPOINT [&quot;/opt/script.sh&quot;]\n</code></pre>\n<ul>\n<li>mysqli: Instala la extensión mysqli, que proporciona una interfaz orientada a objetos para interactuar con la base de datos MySQL.</li>\n<li>pdo: Instala la extensión PDO (PHP Data Objects), que proporciona una interfaz consistente para acceder a varias bases de datos, incluyendo MySQL.</li>\n<li>pdo_mysql: Instala el controlador PDO para MySQL, que permite que PHP se comunique con una base de datos MySQL utilizando PDO.</li>\n</ul>\n<p>Ahora vamos a construir el contenedor de bookmedik:</p>\n<pre><code>docker build -t evanticks/bookmedik:v2 .\ndocker push evanticks/bookmedik:v2\n</code></pre>\n<p>Luego vamos a tomar nuestro docker-compose que ya habíamos creado en la tarea anterior y le añadiremos el nuevo contenedor v2.</p>\n<pre><code>nano docker-compose.yml\n\nversion: '3.1'\nservices:\n  bookmedik:\n    container_name: bookmedik-app\n    image: evanticks/bookmedik:v2\n    restart: always\n    environment:\n      USUARIO_BOOKMEDIK: admin\n      CONTRA_BOOKMEDIK: admin\n      DATABASE_HOST: bd_mariadb\n      NOMBRE_DB: bookmedik\n    ports:\n      - 8081:80\n    depends_on:\n      - db\n  db:\n    container_name: bd_mariadb\n    image: mariadb:10.5.19\n    restart: always\n    environment:\n      MARIADB_ROOT_PASSWORD: root\n      MARIADB_DATABASE: bookmedik\n      MARIADB_USER: admin\n      MARIADB_PASSWORD: admin\n    volumes:\n      - mariadb_data:/var/lib/mysql\nvolumes:\n    mariadb_data:\n</code></pre>\n<p>Una vez hecho esto, los contenedores funcionarán correctamente.</p>\n<h2 id=\"tarea-4-ejecución-de-una-aplicación-php-en-docker-con-nginx-optativa\"><a class=\"markdownIt-Anchor\" href=\"#tarea-4-ejecución-de-una-aplicación-php-en-docker-con-nginx-optativa\">#</a> Tarea 4: Ejecución de una aplicación PHP en docker con nginx (OPTATIVA)</h2>\n<ul>\n<li>Entrega la url del repositorio GitHub donde tengas los ficheros necesarios para hacer la construcción de la imagen.</li>\n</ul>\n<p><a href=\"https://github.com/Evanticks/bookmedik-docker/tree/main/tarea-4\">https://github.com/Evanticks/bookmedik-docker/tree/main/tarea-4</a></p>\n<ul>\n<li>Entrega una captura de pantalla donde se vea la imagen en el registro de tu entorno de desarrollo.</li>\n</ul>\n<p><img src=\"/images/docker-7.png\" alt=\"imagen\"></p>\n<ul>\n<li>Entrega la instrucción para ver los tres contenedores del escenario funcionando.</li>\n</ul>\n<p><img src=\"/images/docker-8.png\" alt=\"imagen\"></p>\n<ul>\n<li>Entrega una captura de pantalla donde se vea funcionando la aplicación, una vez que te has logueado.</li>\n</ul>\n<p><img src=\"/images/docker-9.png\" alt=\"imagen\"></p>\n<h3 id=\"contenedor-nginx\"><a class=\"markdownIt-Anchor\" href=\"#contenedor-nginx\">#</a> Contenedor Nginx</h3>\n<p>El nginx el cual se encontrará la aplicación web, se encargará de recibir las peticiones de los clientes y de redirigirlas al contenedor de PHP-FPM que crearemos más adelante, que serán los encargados de procesarlas y devolver el resultado al cliente.</p>\n<p>Para ello antes debemos crear un fichero de configuración para hacer uso de php-fpm, para ello crearemos un fichero llamado default.conf el cual luego añadiremos a través del Dockerfile a la ruta /etc/nginx/conf.d/default.conf.</p>\n<p>nano default.conf</p>\n<pre><code>server &#123;\n    listen       80;\n    listen  [::]:80;\n    server_name  localhost;\n    error_log  /var/log/nginx/error.log;\n    access_log /var/log/nginx/access.log;\n    root   /usr/share/nginx/html;\n    index  index.php index.html;\n\n    location ~ \\.php$ &#123;\n        try_files $uri =404;\n        fastcgi_split_path_info ^(.+\\.php)(/.+)$;\n        fastcgi_pass book_php:9000;\n        fastcgi_index index.php;\n        include fastcgi_params;\n        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;\n        fastcgi_param PATH_INFO $fastcgi_path_info;\n    &#125;\n&#125;\n</code></pre>\n<p>El correspondiente <a href=\"http://script.sh\">script.sh</a> que se ejecutará al iniciar el contenedor será el siguiente:</p>\n<pre><code>#! /bin/sh\n\nsleep 10\n\nmysql -u $USUARIO_BOOKMEDIK --password=$CONTRA_BOOKMEDIK -h $DATABASE_HOST $NOMBRE_DB &lt; /usr/share/nginx/html/schema.sql\nnginx -g &quot;daemon off;&quot;\n</code></pre>\n<p>Ahora empaquetamos y subimos a dockerhub:</p>\n<pre><code>docker build -t evanticks/bookmedik:v3 .\ndocker push evanticks/bookmedik:v3\n</code></pre>\n<h3 id=\"contenedor-php-fpm\"><a class=\"markdownIt-Anchor\" href=\"#contenedor-php-fpm\">#</a> Contenedor PHP-FPM</h3>\n<p>Ahora ejecutaremos el siguiente dockerfile el cual instalará mysqli que sirve para conectarse a la base de datos.</p>\n<pre><code>FROM php:7.4-fpm-bullseye\nMAINTAINER Antonio Marchán Posada &quot;wildworld14@gmail.com&quot;\nRUN docker-php-ext-install mysqli\n</code></pre>\n<p>Ahora empaquetamos y subimos a dockerhub:</p>\n<pre><code>docker build -t evanticks/fpm7.4-mysql:v1 .\ndocker push evanticks/fpm7.4-mysql:v1\n</code></pre>\n<h3 id=\"docker-compose\"><a class=\"markdownIt-Anchor\" href=\"#docker-compose\">#</a> Docker-compose</h3>\n<pre><code>version: '3.1'\nservices:\n  bookmedik:\n    container_name: bookmedik-app\n    image: evanticks/bookmedik:v3\n    restart: always\n    environment:\n      USUARIO_BOOKMEDIK: admin\n      CONTRA_BOOKMEDIK: admin\n      DATABASE_HOST: bd_mariadb\n      NOMBRE_DB: bookmedik\n    ports:\n      - 8082:80\n    depends_on:\n      - db\n      - php\n    volumes:\n      - phpdocs:/usr/share/nginx/html/\n  db:\n    container_name: bd_mariadb\n    image: mariadb\n    restart: always\n    environment:\n      MARIADB_ROOT_PASSWORD: root\n      MARIADB_DATABASE: bookmedik\n      MARIADB_USER: admin\n      MARIADB_PASSWORD: admin\n    volumes:\n      - mariadb_data:/var/lib/mysql\n  php:\n    container_name: book_php\n    image: evanticks/fpm7.4-mysql:v1\n    restart: always\n    environment:\n      USUARIO_BOOKMEDIK: admin\n      CONTRA_BOOKMEDIK: admin\n      DATABASE_HOST: bd_mariadb\n      NOMBRE_DB: bookmedik\n    volumes:\n      - phpdocs:/usr/share/nginx/html/\n\nvolumes:\n    mariadb_data:\n    phpdocs:\n</code></pre>\n<h2 id=\"tarea-5-puesta-en-producción-de-nuestra-aplicación\"><a class=\"markdownIt-Anchor\" href=\"#tarea-5-puesta-en-producción-de-nuestra-aplicación\">#</a> Tarea 5: Puesta en producción de nuestra aplicación</h2>\n<p>Para poner en producción nuestra aplicación debemos de configurar el nginx para que funcione con el certificado SSL de Let’s Encrypt.</p>\n<pre><code>/etc/nginx/sites-available/bookmedik\n</code></pre>\n<p>Y pondremos la siguiente configuración en el puerto 8084, el cual después deberemos cambiar en el docker-compose.yml.</p>\n<pre><code>server &#123;\n        listen 80;\n        listen [::]:80;\n\n        server_name bookmedik.entrebytes.org;\n\n        return 301 https://$host$request_uri;\n&#125;\n\nserver &#123;\n        listen 443 ssl http2;\n        listen [::]:443 ssl http2;\n\n        ssl    on;\n        ssl_certificate /etc/letsencrypt/live/bookmedik.entrebytes.org/fullchain.pem;\n        ssl_certificate_key /etc/letsencrypt/live/bookmedik.entrebytes.org/privkey.pem;\n\n        index index.html index.php index.htm index.nginx-debian.html;\n\n        server_name bookmedik.entrebytes.org;\n\n        location / &#123;\n                proxy_pass http://localhost:8084;\n                include proxy_params;\n        &#125;\n&#125;\n</code></pre>\n<p>Ahora vamos a generar el certificado <a href=\"http://bookmedik.entrebytes.org\">bookmedik.entrebytes.org</a>, para ello antes debemos poner un CNAME <a href=\"http://bookmedik.entrebytes.org\">bookmedik.entrebytes.org</a> que señale a nuestro servidor.</p>\n<p>Tras esto en la VPS ejecutaremos el siguiente comando:</p>\n<pre><code>systemctl nginx stop\ncertbot certonly --standalone -d bookmedik.entrebytes.org\nsystemctl nginx start\n</code></pre>\n<p>Por último para que descargue y ponga en producción los contenedores ejecutaremos:</p>\n<pre><code>version: '3.1'\nservices:\n  bookmedik:\n    container_name: bookmedik-app\n    image: evanticks/bookmedik:v2\n    restart: always\n    environment:\n      USUARIO_BOOKMEDIK: admin\n      CONTRA_BOOKMEDIK: admin\n      DATABASE_HOST: bd_mariadb\n      NOMBRE_DB: bookmedik\n    ports:\n      - 8084:80\n    depends_on:\n      - db\n  db:\n    container_name: bd_mariadb\n    image: mariadb\n    restart: always\n    environment:\n      MARIADB_ROOT_PASSWORD: root\n      MARIADB_DATABASE: bookmedik\n      MARIADB_USER: admin\n      MARIADB_PASSWORD: admin\n    volumes:\n      - mariadb_data:/var/lib/mysql\nvolumes:\n    mariadb_data:\n\n</code></pre>\n<pre><code>docker-compose up -d\n</code></pre>\n<p>Y con esto ya lo tendríamos en producción.</p>\n<ul>\n<li>Entrega una captura de pantalla de Docker Hub donde se vea tu imagen subida.</li>\n</ul>\n<p><img src=\"/images/docker-10.png\" alt=\"imagen\"></p>\n<ul>\n<li>Entrega la configuración de nginx.</li>\n</ul>\n<pre><code>server &#123;\n        listen 80;\n        listen [::]:80;\n\n        server_name bookmedik.entrebytes.org;\n\n        return 301 https://$host$request_uri;\n&#125;\n\nserver &#123;\n        listen 443 ssl http2;\n        listen [::]:443 ssl http2;\n\n        ssl    on;\n        ssl_certificate /etc/letsencrypt/live/bookmedik.entrebytes.org/fullchain.pem;\n        ssl_certificate_key /etc/letsencrypt/live/bookmedik.entrebytes.org/privkey.pem;\n\n        index index.html index.php index.htm index.nginx-debian.html;\n\n        server_name bookmedik.entrebytes.org;\n\n        location / &#123;\n                proxy_pass http://localhost:8084;\n                include proxy_params;\n        &#125;\n&#125;\n</code></pre>\n<ul>\n<li>Entrega una captura de pantalla donde se vea funcionando la aplicación, una vez que te has logueado.</li>\n</ul>\n<p><img src=\"/images/docker-11.png\" alt=\"imagen\"></p>\n<h2 id=\"tarea-6-modificación-de-la-aplicación\"><a class=\"markdownIt-Anchor\" href=\"#tarea-6-modificación-de-la-aplicación\">#</a> Tarea 6: Modificación de la aplicación</h2>\n<ul>\n<li>Entrega una captura de pantalla de Docker Hub donde se vea tu imagen subida.</li>\n</ul>\n<p><img src=\"/images/docker-13.png\" alt=\"imagen\"></p>\n<ul>\n<li>Entrega una captura de pantalla donde se vea funcionando la aplicación, una vez que te has logueado.</li>\n</ul>\n<p>En mi caso lo pongo antes para que se pueda apreciar el cambio en producción.</p>\n<p><img src=\"/images/docker-12.png\" alt=\"imagen\"></p>\n","site":{"data":{}},"length":10792,"excerpt":"","more":"<p><img src=\"/images/docker-logo-2.png\" alt=\"imagen\"></p>\n<h2 id=\"tarea-1-creación-de-una-imagen-docker-con-una-aplicación-web-desde-una-imagen-base\"><a class=\"markdownIt-Anchor\" href=\"#tarea-1-creación-de-una-imagen-docker-con-una-aplicación-web-desde-una-imagen-base\">#</a> Tarea 1: Creación de una imagen docker con una aplicación web desde una imagen base</h2>\n<ul>\n<li>Entrega la url del repositorio GitHub donde tengas los ficheros necesarios para hacer la construcción de la imagen.</li>\n</ul>\n<p><a href=\"https://github.com/Evanticks/bookmedik-docker/tree/main/tarea-1\">https://github.com/Evanticks/bookmedik-docker/tree/main/tarea-1</a></p>\n<ul>\n<li>Entrega una captura de pantalla donde se vea la imagen en el registro de tu entorno de desarrollo.</li>\n</ul>\n<p><img src=\"/images/docker-1.png\" alt=\"imagen\"></p>\n<p>Para esta práctica vamos a comenzar creando una red diferente a la default para que las máquinas que se conecten a ella puedan comunicarse entre sí a través de resolución de nombres.</p>\n<pre><code>docker network create red_bookmedik\n</code></pre>\n<p>Ahora vamos a crear el contenedor de MYSQL, que contendrá los valores por defecto de bookmedik:</p>\n<pre><code>docker run -d --name mariadb -v bookmedik_vol:/var/lib/mysql --network red_bookmedik -e MARIADB_ROOT_PASSWORD=root -e MARIADB_DATABASE=bookmedik -e MARIADB_USER=bookmedik -e MARIADB_PASSWORD=bookmedik mariadb\n</code></pre>\n<p>Ahora vamos a realizar la clonación de la aplicación bookmedik y lo vamos a clonar en nuestro entorno de trabajo:</p>\n<pre><code>git@github.com:Evanticks/bookmedik.git\n</code></pre>\n<p>Después de esto nos vamos al schema.sql y eliminaremos las líneas de creación de la base de datos ya que en el otro contenedor ya la hemos creado.</p>\n<p>Seguidamente nos vamos a core/controller/Database.php y modificamos las variables de conexión para que se conecte a la base de datos del contenedor de mariadb.</p>\n<pre><code>&lt;?php\nclass Database &#123;\n        public static $db;\n        public static $con;\n        function Database()&#123;\n                $this-&gt;user=getenv('USUARIO_BOOKMEDIK');$this-&gt;pass=getenv('CONTRA_BOOKMEDIK');$this-&gt;host=getenv('DATABASE_HOST');$this-&gt;ddbb=getenv('NOMBRE_DB');\n        &#125;\n\n        function connect()&#123;\n                $con = new mysqli($this-&gt;host,$this-&gt;user,$this-&gt;pass,$this-&gt;ddbb);\n                $con-&gt;query(&quot;set sql_mode=''&quot;);\n                return $con;\n        &#125;\n\n        public static function getCon()&#123;\n                if(self::$con==null &amp;&amp; self::$db==null)&#123;\n                        self::$db = new Database();\n                        self::$con = self::$db-&gt;connect();\n                &#125;\n                return self::$con;\n        &#125;\n\n&#125;\n?&gt;\n\n</code></pre>\n<pre><code>sudo nano script.sh\n\n#! /bin/sh\n\nwhile ! mysql -u $&#123;USUARIO_BOOKMEDIK&#125; -p$&#123;CONTRA_BOOKMEDIK&#125; -h $&#123;DATABASE_HOST&#125;  -e &quot;;&quot; ; do\n        sleep 1\ndone\nmysql -u $USUARIO_BOOKMEDIK --password=$CONTRA_BOOKMEDIK -h $DATABASE_HOST $NOMBRE_DB &lt; /var/www/html/schema.sql\n/usr/sbin/apache2ctl -D FOREGROUND\n\n</code></pre>\n<p>Con este script que añadiremos dentro del contenedor especificaremos que espere a que el contenedor de mariadb esté listo para poder ejecutar el script de creación de la base de datos.</p>\n<p>Ahora vamos a construir el contenedor de bookmedik:</p>\n<pre><code>docker build -t evanticks/bookmedik:v1 .\ndocker push evanticks/bookmedik:v1\n</code></pre>\n<p><img src=\"/images/docker-4.png\" alt=\"imagen\"></p>\n<p>Una vez hecho esto vamos a crear el docker-compose.yml para poder levantar el contenedor de bookmedik y el de mariadb.</p>\n<h2 id=\"tarea-2-despliegue-en-el-entorno-de-desarrollo\"><a class=\"markdownIt-Anchor\" href=\"#tarea-2-despliegue-en-el-entorno-de-desarrollo\">#</a> Tarea 2: Despliegue en el entorno de desarrollo</h2>\n<ul>\n<li>Entrega la url del repositorio GitHub donde hayas añadido el fichero docker-compose.yml.</li>\n</ul>\n<p><a href=\"https://github.com/Evanticks/bookmedik-docker/tree/main/tarea-2\">https://github.com/Evanticks/bookmedik-docker/tree/main/tarea-2</a></p>\n<ul>\n<li>Entrega la instrucción para ver los dos contenedores del escenario funcionando.</li>\n</ul>\n<pre><code>docker ps\n\ndocker-compose ps\n</code></pre>\n<p><img src=\"/images/docker-2.png\" alt=\"imagen\"></p>\n<ul>\n<li>Entrega una captura de pantalla donde se vea funcionando la aplicación, una vez que te has logueado.</li>\n</ul>\n<p><img src=\"/images/docker-3.png\" alt=\"imagen\"></p>\n<hr>\n<p>docker-compose.yaml</p>\n<pre><code>version: '3.1'\nservices:\n  bookmedik:\n    container_name: bookmedik-app\n    image: evanticks/bookmedik:v1\n    restart: always\n    environment:\n      USUARIO_BOOKMEDIK: admin\n      CONTRA_BOOKMEDIK: admin\n      DATABASE_HOST: bd_mariadb\n      NOMBRE_DB: bookmedik\n    ports:\n      - 8081:80\n    depends_on:\n      - db\n  db:\n    container_name: bd_mariadb\n    image: mariadb:10.5.19\n    restart: always\n    environment:\n      MARIADB_ROOT_PASSWORD: root\n      MARIADB_DATABASE: bookmedik\n      MARIADB_USER: admin\n      MARIADB_PASSWORD: admin\n    volumes:\n      - mariadb_data:/var/lib/mysql\nvolumes:\n    mariadb_data:\n</code></pre>\n<p>Luego lo ejecutaremos con el siguiente comando:</p>\n<pre><code>docker-compose up -d\n</code></pre>\n<p>Para borrarlo junto con el almacenamiento creado ejecutaremos:</p>\n<pre><code>docker-compose down -v\n</code></pre>\n<h2 id=\"tarea-3-creación-de-una-imagen-docker-con-una-aplicación-web-desde-una-imagen-php\"><a class=\"markdownIt-Anchor\" href=\"#tarea-3-creación-de-una-imagen-docker-con-una-aplicación-web-desde-una-imagen-php\">#</a> Tarea 3: Creación de una imagen docker con una aplicación web desde una imagen PHP</h2>\n<ul>\n<li>Entrega la url del repositorio GitHub donde hayas añadido el fichero docker-compose.yml.</li>\n</ul>\n<p><a href=\"https://github.com/Evanticks/bookmedik-docker/tree/main/tarea-3\">https://github.com/Evanticks/bookmedik-docker/tree/main/tarea-3</a></p>\n<ul>\n<li>Entrega la instrucción para ver los dos contenedores del escenario funcionando.</li>\n</ul>\n<pre><code>docker ps\n\ndocker-compose ps\n</code></pre>\n<p><img src=\"/images/docker-5.png\" alt=\"imagen\"></p>\n<ul>\n<li>Entrega una captura de pantalla donde se vea funcionando la aplicación, una vez que te has logueado.</li>\n</ul>\n<p><img src=\"/images/docker-6.png\" alt=\"imagen\"></p>\n<p>Ahora procedamos a explicar los pasos que hemos seguido para realizar esta tarea.</p>\n<p>En esta ocasión vamos a editar el dockerfile para que instale una imagen de php-apache y no una imagen de apache solamente, y le otorgaremos unos determinados paquetes para qeu funcione correctamente la conexión con la base de datos.</p>\n<pre><code>nano Dockerfile\n\nFROM php:7.4-apache-bullseye\nMAINTAINER Antonio Marchán Posada &quot;wildworld14@gmail.com&quot;\nRUN apt update &amp;&amp; apt upgrade -y &amp;&amp; docker-php-ext-install mysqli pdo pdo_mysql &amp;&amp; apt install mariadb-client -y &amp;&amp; apt clean &amp;&amp; rm -rf /var/lib/apt/lists/*\nADD bookmedik /var/www/html/\nADD script.sh /opt/\nRUN chmod +x /opt/script.sh\nENTRYPOINT [&quot;/opt/script.sh&quot;]\n</code></pre>\n<ul>\n<li>mysqli: Instala la extensión mysqli, que proporciona una interfaz orientada a objetos para interactuar con la base de datos MySQL.</li>\n<li>pdo: Instala la extensión PDO (PHP Data Objects), que proporciona una interfaz consistente para acceder a varias bases de datos, incluyendo MySQL.</li>\n<li>pdo_mysql: Instala el controlador PDO para MySQL, que permite que PHP se comunique con una base de datos MySQL utilizando PDO.</li>\n</ul>\n<p>Ahora vamos a construir el contenedor de bookmedik:</p>\n<pre><code>docker build -t evanticks/bookmedik:v2 .\ndocker push evanticks/bookmedik:v2\n</code></pre>\n<p>Luego vamos a tomar nuestro docker-compose que ya habíamos creado en la tarea anterior y le añadiremos el nuevo contenedor v2.</p>\n<pre><code>nano docker-compose.yml\n\nversion: '3.1'\nservices:\n  bookmedik:\n    container_name: bookmedik-app\n    image: evanticks/bookmedik:v2\n    restart: always\n    environment:\n      USUARIO_BOOKMEDIK: admin\n      CONTRA_BOOKMEDIK: admin\n      DATABASE_HOST: bd_mariadb\n      NOMBRE_DB: bookmedik\n    ports:\n      - 8081:80\n    depends_on:\n      - db\n  db:\n    container_name: bd_mariadb\n    image: mariadb:10.5.19\n    restart: always\n    environment:\n      MARIADB_ROOT_PASSWORD: root\n      MARIADB_DATABASE: bookmedik\n      MARIADB_USER: admin\n      MARIADB_PASSWORD: admin\n    volumes:\n      - mariadb_data:/var/lib/mysql\nvolumes:\n    mariadb_data:\n</code></pre>\n<p>Una vez hecho esto, los contenedores funcionarán correctamente.</p>\n<h2 id=\"tarea-4-ejecución-de-una-aplicación-php-en-docker-con-nginx-optativa\"><a class=\"markdownIt-Anchor\" href=\"#tarea-4-ejecución-de-una-aplicación-php-en-docker-con-nginx-optativa\">#</a> Tarea 4: Ejecución de una aplicación PHP en docker con nginx (OPTATIVA)</h2>\n<ul>\n<li>Entrega la url del repositorio GitHub donde tengas los ficheros necesarios para hacer la construcción de la imagen.</li>\n</ul>\n<p><a href=\"https://github.com/Evanticks/bookmedik-docker/tree/main/tarea-4\">https://github.com/Evanticks/bookmedik-docker/tree/main/tarea-4</a></p>\n<ul>\n<li>Entrega una captura de pantalla donde se vea la imagen en el registro de tu entorno de desarrollo.</li>\n</ul>\n<p><img src=\"/images/docker-7.png\" alt=\"imagen\"></p>\n<ul>\n<li>Entrega la instrucción para ver los tres contenedores del escenario funcionando.</li>\n</ul>\n<p><img src=\"/images/docker-8.png\" alt=\"imagen\"></p>\n<ul>\n<li>Entrega una captura de pantalla donde se vea funcionando la aplicación, una vez que te has logueado.</li>\n</ul>\n<p><img src=\"/images/docker-9.png\" alt=\"imagen\"></p>\n<h3 id=\"contenedor-nginx\"><a class=\"markdownIt-Anchor\" href=\"#contenedor-nginx\">#</a> Contenedor Nginx</h3>\n<p>El nginx el cual se encontrará la aplicación web, se encargará de recibir las peticiones de los clientes y de redirigirlas al contenedor de PHP-FPM que crearemos más adelante, que serán los encargados de procesarlas y devolver el resultado al cliente.</p>\n<p>Para ello antes debemos crear un fichero de configuración para hacer uso de php-fpm, para ello crearemos un fichero llamado default.conf el cual luego añadiremos a través del Dockerfile a la ruta /etc/nginx/conf.d/default.conf.</p>\n<p>nano default.conf</p>\n<pre><code>server &#123;\n    listen       80;\n    listen  [::]:80;\n    server_name  localhost;\n    error_log  /var/log/nginx/error.log;\n    access_log /var/log/nginx/access.log;\n    root   /usr/share/nginx/html;\n    index  index.php index.html;\n\n    location ~ \\.php$ &#123;\n        try_files $uri =404;\n        fastcgi_split_path_info ^(.+\\.php)(/.+)$;\n        fastcgi_pass book_php:9000;\n        fastcgi_index index.php;\n        include fastcgi_params;\n        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;\n        fastcgi_param PATH_INFO $fastcgi_path_info;\n    &#125;\n&#125;\n</code></pre>\n<p>El correspondiente <a href=\"http://script.sh\">script.sh</a> que se ejecutará al iniciar el contenedor será el siguiente:</p>\n<pre><code>#! /bin/sh\n\nsleep 10\n\nmysql -u $USUARIO_BOOKMEDIK --password=$CONTRA_BOOKMEDIK -h $DATABASE_HOST $NOMBRE_DB &lt; /usr/share/nginx/html/schema.sql\nnginx -g &quot;daemon off;&quot;\n</code></pre>\n<p>Ahora empaquetamos y subimos a dockerhub:</p>\n<pre><code>docker build -t evanticks/bookmedik:v3 .\ndocker push evanticks/bookmedik:v3\n</code></pre>\n<h3 id=\"contenedor-php-fpm\"><a class=\"markdownIt-Anchor\" href=\"#contenedor-php-fpm\">#</a> Contenedor PHP-FPM</h3>\n<p>Ahora ejecutaremos el siguiente dockerfile el cual instalará mysqli que sirve para conectarse a la base de datos.</p>\n<pre><code>FROM php:7.4-fpm-bullseye\nMAINTAINER Antonio Marchán Posada &quot;wildworld14@gmail.com&quot;\nRUN docker-php-ext-install mysqli\n</code></pre>\n<p>Ahora empaquetamos y subimos a dockerhub:</p>\n<pre><code>docker build -t evanticks/fpm7.4-mysql:v1 .\ndocker push evanticks/fpm7.4-mysql:v1\n</code></pre>\n<h3 id=\"docker-compose\"><a class=\"markdownIt-Anchor\" href=\"#docker-compose\">#</a> Docker-compose</h3>\n<pre><code>version: '3.1'\nservices:\n  bookmedik:\n    container_name: bookmedik-app\n    image: evanticks/bookmedik:v3\n    restart: always\n    environment:\n      USUARIO_BOOKMEDIK: admin\n      CONTRA_BOOKMEDIK: admin\n      DATABASE_HOST: bd_mariadb\n      NOMBRE_DB: bookmedik\n    ports:\n      - 8082:80\n    depends_on:\n      - db\n      - php\n    volumes:\n      - phpdocs:/usr/share/nginx/html/\n  db:\n    container_name: bd_mariadb\n    image: mariadb\n    restart: always\n    environment:\n      MARIADB_ROOT_PASSWORD: root\n      MARIADB_DATABASE: bookmedik\n      MARIADB_USER: admin\n      MARIADB_PASSWORD: admin\n    volumes:\n      - mariadb_data:/var/lib/mysql\n  php:\n    container_name: book_php\n    image: evanticks/fpm7.4-mysql:v1\n    restart: always\n    environment:\n      USUARIO_BOOKMEDIK: admin\n      CONTRA_BOOKMEDIK: admin\n      DATABASE_HOST: bd_mariadb\n      NOMBRE_DB: bookmedik\n    volumes:\n      - phpdocs:/usr/share/nginx/html/\n\nvolumes:\n    mariadb_data:\n    phpdocs:\n</code></pre>\n<h2 id=\"tarea-5-puesta-en-producción-de-nuestra-aplicación\"><a class=\"markdownIt-Anchor\" href=\"#tarea-5-puesta-en-producción-de-nuestra-aplicación\">#</a> Tarea 5: Puesta en producción de nuestra aplicación</h2>\n<p>Para poner en producción nuestra aplicación debemos de configurar el nginx para que funcione con el certificado SSL de Let’s Encrypt.</p>\n<pre><code>/etc/nginx/sites-available/bookmedik\n</code></pre>\n<p>Y pondremos la siguiente configuración en el puerto 8084, el cual después deberemos cambiar en el docker-compose.yml.</p>\n<pre><code>server &#123;\n        listen 80;\n        listen [::]:80;\n\n        server_name bookmedik.entrebytes.org;\n\n        return 301 https://$host$request_uri;\n&#125;\n\nserver &#123;\n        listen 443 ssl http2;\n        listen [::]:443 ssl http2;\n\n        ssl    on;\n        ssl_certificate /etc/letsencrypt/live/bookmedik.entrebytes.org/fullchain.pem;\n        ssl_certificate_key /etc/letsencrypt/live/bookmedik.entrebytes.org/privkey.pem;\n\n        index index.html index.php index.htm index.nginx-debian.html;\n\n        server_name bookmedik.entrebytes.org;\n\n        location / &#123;\n                proxy_pass http://localhost:8084;\n                include proxy_params;\n        &#125;\n&#125;\n</code></pre>\n<p>Ahora vamos a generar el certificado <a href=\"http://bookmedik.entrebytes.org\">bookmedik.entrebytes.org</a>, para ello antes debemos poner un CNAME <a href=\"http://bookmedik.entrebytes.org\">bookmedik.entrebytes.org</a> que señale a nuestro servidor.</p>\n<p>Tras esto en la VPS ejecutaremos el siguiente comando:</p>\n<pre><code>systemctl nginx stop\ncertbot certonly --standalone -d bookmedik.entrebytes.org\nsystemctl nginx start\n</code></pre>\n<p>Por último para que descargue y ponga en producción los contenedores ejecutaremos:</p>\n<pre><code>version: '3.1'\nservices:\n  bookmedik:\n    container_name: bookmedik-app\n    image: evanticks/bookmedik:v2\n    restart: always\n    environment:\n      USUARIO_BOOKMEDIK: admin\n      CONTRA_BOOKMEDIK: admin\n      DATABASE_HOST: bd_mariadb\n      NOMBRE_DB: bookmedik\n    ports:\n      - 8084:80\n    depends_on:\n      - db\n  db:\n    container_name: bd_mariadb\n    image: mariadb\n    restart: always\n    environment:\n      MARIADB_ROOT_PASSWORD: root\n      MARIADB_DATABASE: bookmedik\n      MARIADB_USER: admin\n      MARIADB_PASSWORD: admin\n    volumes:\n      - mariadb_data:/var/lib/mysql\nvolumes:\n    mariadb_data:\n\n</code></pre>\n<pre><code>docker-compose up -d\n</code></pre>\n<p>Y con esto ya lo tendríamos en producción.</p>\n<ul>\n<li>Entrega una captura de pantalla de Docker Hub donde se vea tu imagen subida.</li>\n</ul>\n<p><img src=\"/images/docker-10.png\" alt=\"imagen\"></p>\n<ul>\n<li>Entrega la configuración de nginx.</li>\n</ul>\n<pre><code>server &#123;\n        listen 80;\n        listen [::]:80;\n\n        server_name bookmedik.entrebytes.org;\n\n        return 301 https://$host$request_uri;\n&#125;\n\nserver &#123;\n        listen 443 ssl http2;\n        listen [::]:443 ssl http2;\n\n        ssl    on;\n        ssl_certificate /etc/letsencrypt/live/bookmedik.entrebytes.org/fullchain.pem;\n        ssl_certificate_key /etc/letsencrypt/live/bookmedik.entrebytes.org/privkey.pem;\n\n        index index.html index.php index.htm index.nginx-debian.html;\n\n        server_name bookmedik.entrebytes.org;\n\n        location / &#123;\n                proxy_pass http://localhost:8084;\n                include proxy_params;\n        &#125;\n&#125;\n</code></pre>\n<ul>\n<li>Entrega una captura de pantalla donde se vea funcionando la aplicación, una vez que te has logueado.</li>\n</ul>\n<p><img src=\"/images/docker-11.png\" alt=\"imagen\"></p>\n<h2 id=\"tarea-6-modificación-de-la-aplicación\"><a class=\"markdownIt-Anchor\" href=\"#tarea-6-modificación-de-la-aplicación\">#</a> Tarea 6: Modificación de la aplicación</h2>\n<ul>\n<li>Entrega una captura de pantalla de Docker Hub donde se vea tu imagen subida.</li>\n</ul>\n<p><img src=\"/images/docker-13.png\" alt=\"imagen\"></p>\n<ul>\n<li>Entrega una captura de pantalla donde se vea funcionando la aplicación, una vez que te has logueado.</li>\n</ul>\n<p>En mi caso lo pongo antes para que se pueda apreciar el cambio en producción.</p>\n<p><img src=\"/images/docker-12.png\" alt=\"imagen\"></p>\n"},{"_content":"- La máquina Alfa tiene un servidor ssh escuchando por el puerto 22, pero al acceder desde el exterior habrá que conectar al puerto 2222.\n\n\n```\n\niptables -A PREROUTING -t nat -i ens4 -p tcp --dport 22 -j REDIRECT --to-port 2222\n```\n\n\n- Desde Delta y Bravo se debe permitir la conexión ssh por el puerto 22 a la máquina Alfa.\n- La máquina Alfa debe tener permitido el tráfico para la interfaz loopback.\n\n```\niptables -A INPUT -i lo -j ACCEPT\niptables -A OUTPUT -o lo -j ACCEPT\n```\n- A la máquina Alfa se le puede hacer ping desde la DMZ, pero desde la LAN se le debe rechazar la conexión (REJECT) y desde el exterior se rechazará de manera silenciosa.\n- La máquina Alfa puede hacer ping a la LAN, la DMZ y al exterior.\n- Desde la máquina Bravo se puede hacer ping y conexión ssh a las máquinas de la LAN.\n- Desde cualquier máquina de la LAN se puede conectar por ssh a la máquina Bravo.\n- Configura la máquina Alfa para que las máquinas de LAN y DMZ puedan acceder al exterior.\n- Las máquinas de la LAN pueden hacer ping al exterior y navegar.\n- La máquina Bravo puede navegar. Instala un servidor web, un servidor ftp y un servidor de correos si no los tienes aún.\n- Configura la máquina Alfa para que los servicios web y ftp sean accesibles desde el exterior.\n- El servidor web y el servidor ftp deben ser accesibles desde la LAN y desde el exterior.\n- El servidor de correos sólo debe ser accesible desde la LAN.\n- En la máquina Charlie instala un servidor mysql si no lo tiene aún. A este servidor se puede acceder desde la DMZ, pero no desde el exterior.\n- Evita ataques DoS por ICMP Flood, limitando el número de peticiones por segundo desde una misma IP.\n- Evita ataques DoS por SYN Flood.\n- Evita que realicen escaneos de puertos a Alfa.","source":"_posts/firewall-3.md","raw":"- La máquina Alfa tiene un servidor ssh escuchando por el puerto 22, pero al acceder desde el exterior habrá que conectar al puerto 2222.\n\n\n```\n\niptables -A PREROUTING -t nat -i ens4 -p tcp --dport 22 -j REDIRECT --to-port 2222\n```\n\n\n- Desde Delta y Bravo se debe permitir la conexión ssh por el puerto 22 a la máquina Alfa.\n- La máquina Alfa debe tener permitido el tráfico para la interfaz loopback.\n\n```\niptables -A INPUT -i lo -j ACCEPT\niptables -A OUTPUT -o lo -j ACCEPT\n```\n- A la máquina Alfa se le puede hacer ping desde la DMZ, pero desde la LAN se le debe rechazar la conexión (REJECT) y desde el exterior se rechazará de manera silenciosa.\n- La máquina Alfa puede hacer ping a la LAN, la DMZ y al exterior.\n- Desde la máquina Bravo se puede hacer ping y conexión ssh a las máquinas de la LAN.\n- Desde cualquier máquina de la LAN se puede conectar por ssh a la máquina Bravo.\n- Configura la máquina Alfa para que las máquinas de LAN y DMZ puedan acceder al exterior.\n- Las máquinas de la LAN pueden hacer ping al exterior y navegar.\n- La máquina Bravo puede navegar. Instala un servidor web, un servidor ftp y un servidor de correos si no los tienes aún.\n- Configura la máquina Alfa para que los servicios web y ftp sean accesibles desde el exterior.\n- El servidor web y el servidor ftp deben ser accesibles desde la LAN y desde el exterior.\n- El servidor de correos sólo debe ser accesible desde la LAN.\n- En la máquina Charlie instala un servidor mysql si no lo tiene aún. A este servidor se puede acceder desde la DMZ, pero no desde el exterior.\n- Evita ataques DoS por ICMP Flood, limitando el número de peticiones por segundo desde una misma IP.\n- Evita ataques DoS por SYN Flood.\n- Evita que realicen escaneos de puertos a Alfa.","slug":"firewall-3","published":1,"date":"2023-03-03T01:27:16.003Z","updated":"2023-03-03T02:44:31.403Z","title":"","comments":1,"layout":"post","photos":[],"link":"","_id":"clevfuvrd0000yji5fw8ib3nd","content":"<ul>\n<li>La máquina Alfa tiene un servidor ssh escuchando por el puerto 22, pero al acceder desde el exterior habrá que conectar al puerto 2222.</li>\n</ul>\n<pre><code>\niptables -A PREROUTING -t nat -i ens4 -p tcp --dport 22 -j REDIRECT --to-port 2222\n</code></pre>\n<ul>\n<li>Desde Delta y Bravo se debe permitir la conexión ssh por el puerto 22 a la máquina Alfa.</li>\n<li>La máquina Alfa debe tener permitido el tráfico para la interfaz loopback.</li>\n</ul>\n<pre><code>iptables -A INPUT -i lo -j ACCEPT\niptables -A OUTPUT -o lo -j ACCEPT\n</code></pre>\n<ul>\n<li>A la máquina Alfa se le puede hacer ping desde la DMZ, pero desde la LAN se le debe rechazar la conexión (REJECT) y desde el exterior se rechazará de manera silenciosa.</li>\n<li>La máquina Alfa puede hacer ping a la LAN, la DMZ y al exterior.</li>\n<li>Desde la máquina Bravo se puede hacer ping y conexión ssh a las máquinas de la LAN.</li>\n<li>Desde cualquier máquina de la LAN se puede conectar por ssh a la máquina Bravo.</li>\n<li>Configura la máquina Alfa para que las máquinas de LAN y DMZ puedan acceder al exterior.</li>\n<li>Las máquinas de la LAN pueden hacer ping al exterior y navegar.</li>\n<li>La máquina Bravo puede navegar. Instala un servidor web, un servidor ftp y un servidor de correos si no los tienes aún.</li>\n<li>Configura la máquina Alfa para que los servicios web y ftp sean accesibles desde el exterior.</li>\n<li>El servidor web y el servidor ftp deben ser accesibles desde la LAN y desde el exterior.</li>\n<li>El servidor de correos sólo debe ser accesible desde la LAN.</li>\n<li>En la máquina Charlie instala un servidor mysql si no lo tiene aún. A este servidor se puede acceder desde la DMZ, pero no desde el exterior.</li>\n<li>Evita ataques DoS por ICMP Flood, limitando el número de peticiones por segundo desde una misma IP.</li>\n<li>Evita ataques DoS por SYN Flood.</li>\n<li>Evita que realicen escaneos de puertos a Alfa.</li>\n</ul>\n","site":{"data":{}},"length":1376,"excerpt":"","more":"<ul>\n<li>La máquina Alfa tiene un servidor ssh escuchando por el puerto 22, pero al acceder desde el exterior habrá que conectar al puerto 2222.</li>\n</ul>\n<pre><code>\niptables -A PREROUTING -t nat -i ens4 -p tcp --dport 22 -j REDIRECT --to-port 2222\n</code></pre>\n<ul>\n<li>Desde Delta y Bravo se debe permitir la conexión ssh por el puerto 22 a la máquina Alfa.</li>\n<li>La máquina Alfa debe tener permitido el tráfico para la interfaz loopback.</li>\n</ul>\n<pre><code>iptables -A INPUT -i lo -j ACCEPT\niptables -A OUTPUT -o lo -j ACCEPT\n</code></pre>\n<ul>\n<li>A la máquina Alfa se le puede hacer ping desde la DMZ, pero desde la LAN se le debe rechazar la conexión (REJECT) y desde el exterior se rechazará de manera silenciosa.</li>\n<li>La máquina Alfa puede hacer ping a la LAN, la DMZ y al exterior.</li>\n<li>Desde la máquina Bravo se puede hacer ping y conexión ssh a las máquinas de la LAN.</li>\n<li>Desde cualquier máquina de la LAN se puede conectar por ssh a la máquina Bravo.</li>\n<li>Configura la máquina Alfa para que las máquinas de LAN y DMZ puedan acceder al exterior.</li>\n<li>Las máquinas de la LAN pueden hacer ping al exterior y navegar.</li>\n<li>La máquina Bravo puede navegar. Instala un servidor web, un servidor ftp y un servidor de correos si no los tienes aún.</li>\n<li>Configura la máquina Alfa para que los servicios web y ftp sean accesibles desde el exterior.</li>\n<li>El servidor web y el servidor ftp deben ser accesibles desde la LAN y desde el exterior.</li>\n<li>El servidor de correos sólo debe ser accesible desde la LAN.</li>\n<li>En la máquina Charlie instala un servidor mysql si no lo tiene aún. A este servidor se puede acceder desde la DMZ, pero no desde el exterior.</li>\n<li>Evita ataques DoS por ICMP Flood, limitando el número de peticiones por segundo desde una misma IP.</li>\n<li>Evita ataques DoS por SYN Flood.</li>\n<li>Evita que realicen escaneos de puertos a Alfa.</li>\n</ul>\n"},{"title":"Docker Django","Categoría":"Contenedores","_content":"\n\n![docker](/images/docker-django.png)\n\n\n\n\n# Dockerizar la aplicación Django\n\n## Cambios en la aplicación\n\nEn este post vamos a dockerizar la aplicación python de Django:\n\nPara ello lo primero que tenemos que hacer es obtener la aplicación que vamos a dockerizar, la cual procederá de aquí:\n\nhttps://github.com/Evanticks/docker-django\n\nTras clonarlo en nuestro entorno de desarrollo, procederemos a cambiar varios aspectos los cuales nos servirán para obtener las variables de entorno al haber importado el os, entonces nos vamos a `django_tutorial/django_tutorial/settings.py` y añadimos las siguientes instrucciones:\n\n\n```\nimport os\n```\n\nEsta opción es opcional, si lo ponemos luego podremos especificar en el docker-compose.yml los host permitidos para realizar la conexión a nuestra aplicación.\n\n```\nALLOWED_HOSTS = [os.environ.get(\"ALLOWED_HOSTS\")]\n```\n\nLa base de datos vamos a cambiarla, cuando antes era un sqlite3 ahora es un mariadb, por tanto vamos a poner variables de entorno que afecten a mysql:\n\n```\nDATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.mysql',\n        'NAME': os.environ.get(\"DJANGODB\"),\n        'USER': os.environ.get('DJANGODB_USER'),\n        'PASSWORD': os.environ.get(\"DJANGODB_PASS\"),\n        'HOST': os.environ.get('DJANGODB_HOST'),\n        'PORT': '3306',\n    }\n}\n```\n\nUna vez hecho esto, nuestra aplicación buscará las variables de entorno que le asignemos al crear el contenedor, lo haremos luego a través de docker-compose.\n\n```\nSTATIC_ROOT = os.path.join(BASE_DIR, 'static')\n```\n\nSTATIC_ROOT es la ruta donde se almacenarán los archivos generados estáticos, en nuestro caso será la carpeta static.\n\n```\nCSRF_TRUSTED_ORIGINS = ['http://*.entrebytes.org','http://*.127.0.0.1','https://*.entrebytes.org','https://*.127.0.0.1']\n```\n\nEn Python, la variable CSRF_TRUSTED_ORIGINS se utiliza en aplicaciones web Django para especificar una lista de orígenes que se consideran confiables para la protección CSRF (Cross-site Request Forgery).\n\nCSRF es un tipo de ataque que se produce cuando un atacante engaña a un usuario para que realice una acción no deseada en una aplicación web. La protección CSRF se utiliza para evitar que los atacantes realicen este tipo de ataques mediante la validación del origen de la solicitud, el cual será nuestro dominio.\n\n\nUna vez hecho esto, podemos hacer un commit y subirlo a nuestro repositorio, porque al crear el Dockerfile necesitará obtener los archivos de la aplicación modificada.\n\n## Script de migraciones.sh\n\n```\n#! /bin/sh\n\nsleep 2\npython3 manage.py makemigrations\npython3 manage.py migrate\npython3 manage.py createsuperuser --noinput\npython3 manage.py collectstatic --no-input\npython3 manage.py runserver 0.0.0.0:4000\n```\n\n- El contenedor por defecto ejecutará sh\n- damos dos segundos antes de realizar alguna acción para que pueda conectarse a la base de datos\n- makemigrations crea las migraciones a la base de datos\n- creamos un usuario administrador de manera no interactiva\n- creamos las colecciones estáticas de la carpeta static\n- ejecutamos el servidor de django en el puerto 4000\n\n\n## Creación del Dockerfile\n\n\n```\nFROM python:3\nWORKDIR /usr/src/app\nMAINTAINER Antonio Marchán \"wildworld14@gmail.com\"\nRUN pip install --root-user-action=ignore --upgrade pip && pip install --root-user-action=ignore django mysqlclient && git clone https://github.com/Evanticks/docker-django.git /usr/src/app && mkdir static\nADD migraciones.sh /usr/src/app/\nRUN chmod +x /usr/src/app/migraciones.sh\nENTRYPOINT [\"/usr/src/app/migraciones.sh\"]\n```\n\n\n- Se aplicará una imagen base de python3\n- directorio donde se alojará la aplicación\n- Mantenedor de la imagen\n- ignora la petición de permisos de usuario root upgradeando pip de la imagen python e instalando django y mysqlclient a través de pip, a su vez clonamos nuestra aplicación y creamos un directorio llamado static que será donde se genere el contenido estático de la aplicación.\n- Enviamos migraciones.sh al directorio de trabajo /usr/src/app\n- Le damos permisos de ejecución al archivo migraciones.sh\n- Con entrypoint estamos ejecutando el script de migraciones.sh al iniciar el contenedor.\n\n\nTras esto, ejecutamos el siguiente comando para crear la imagen y la subiremos a dockerhub:\n\n```\ndocker build -t evanticks/django_tutorial:v1 .\ndocker push evanticks/django_tutorial:v1\n```\n\n## Creación del docker-compose.yml\n\n```\nversion: '3.1'\nservices:\n  django-tutorial:\n    container_name: django-tutorial\n    image: evanticks/django_tutorial:v1\n    restart: always\n    environment:\n      ALLOWED_HOSTS: \"*\"\n      DJANGODB_HOST: django-mariadb\n      DJANGODB_USUARIO: django\n      DJANGODB_CONTRASENA: django\n      NAME: django     \n      DJANGO_SUPERUSER_PASSWORD: admin\n      DJANGO_SUPERUSER_USERNAME: admin\n      DJANGO_SUPERUSER_EMAIL: admin@example.org\n    ports:\n      - 8082:4000\n    depends_on:\n      - db_django\n  db_django:\n    container_name: django-mariadb\n    image: mariadb:10.5\n    restart: always\n    environment:\n      MARIADB_ROOT_PASSWORD: root\n      MARIADB_DATABASE: django\n      MARIADB_USER: django\n      MARIADB_PASSWORD: django\n    volumes:\n      - mariadb_data_django:/var/lib/mysql\nvolumes:\n    mariadb_data_django:\n```\n\n```\nDocker-compose up -d\n```\n\n![docker](/images/django-1.png)\n\n\nY aquí podemos ver la aplicación funcionando en el entorno de desarrollo:\n\n![docker](/images/django-2.png)\n\n## Puesta en producción de nuestra aplicación\n\n\nPrimer crearemos nuestro virtual host en `/etc/nginx/sites-available/docker-django`:\n\n\n```\nserver {\n        listen 80;\n        listen [::]:80;\n\n        server_name django.entrebytes.org;\n\n        return 301 https://$host$request_uri;\n}\n\nserver {\n        listen 443 ssl http2;\n        listen [::]:443 ssl http2;\n\n        ssl    on;\n        ssl_certificate /etc/letsencrypt/live/django.entrebytes.org/fullchain.pem;\n        ssl_certificate_key /etc/letsencrypt/live/django.entrebytes.org/privkey.pem;\n\n        index index.html index.php index.htm index.nginx-debian.html;\n\n        server_name django.entrebytes.org;\n\n        location / {\n                proxy_pass http://localhost:8082;\n                include proxy_params;\n        }\n}\n\n```\n\nAhora vamos a generar el certificado bookmedik.entrebytes.org, para ello antes debemos poner un CNAME bookmedik.entrebytes.org que señale a nuestro servidor.\n\nTras esto haremos un stop al servicio nginx y ejecutaremos certbot para generar el certificado, activamos el sitio y reiniciamos nginx:\n\n```\nsystemctl stop nginx\n\ncertbot certonly --standalone -d django.entrebytes.org\n\nln -s /etc/nginx/sites-available/django-docker /etc/nginx/sites-enabled/\n\nsystemctl start nginx\n```\n\nA continuación crearemos un directorio donde guardaremos el docker-compose generado y lo ejecutaremos:\n\n```\ndocker-compose up -d\n```\n\nY tras esto, podemos ver que en nuestro servidor estamos alojando la aplicación completamente funcional:\n\n![docker](/images/django-3.png)","source":"_posts/docker-django.md","raw":"---\ntitle: Docker Django\nCategoría: Contenedores\n---\n\n\n![docker](/images/docker-django.png)\n\n\n\n\n# Dockerizar la aplicación Django\n\n## Cambios en la aplicación\n\nEn este post vamos a dockerizar la aplicación python de Django:\n\nPara ello lo primero que tenemos que hacer es obtener la aplicación que vamos a dockerizar, la cual procederá de aquí:\n\nhttps://github.com/Evanticks/docker-django\n\nTras clonarlo en nuestro entorno de desarrollo, procederemos a cambiar varios aspectos los cuales nos servirán para obtener las variables de entorno al haber importado el os, entonces nos vamos a `django_tutorial/django_tutorial/settings.py` y añadimos las siguientes instrucciones:\n\n\n```\nimport os\n```\n\nEsta opción es opcional, si lo ponemos luego podremos especificar en el docker-compose.yml los host permitidos para realizar la conexión a nuestra aplicación.\n\n```\nALLOWED_HOSTS = [os.environ.get(\"ALLOWED_HOSTS\")]\n```\n\nLa base de datos vamos a cambiarla, cuando antes era un sqlite3 ahora es un mariadb, por tanto vamos a poner variables de entorno que afecten a mysql:\n\n```\nDATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.mysql',\n        'NAME': os.environ.get(\"DJANGODB\"),\n        'USER': os.environ.get('DJANGODB_USER'),\n        'PASSWORD': os.environ.get(\"DJANGODB_PASS\"),\n        'HOST': os.environ.get('DJANGODB_HOST'),\n        'PORT': '3306',\n    }\n}\n```\n\nUna vez hecho esto, nuestra aplicación buscará las variables de entorno que le asignemos al crear el contenedor, lo haremos luego a través de docker-compose.\n\n```\nSTATIC_ROOT = os.path.join(BASE_DIR, 'static')\n```\n\nSTATIC_ROOT es la ruta donde se almacenarán los archivos generados estáticos, en nuestro caso será la carpeta static.\n\n```\nCSRF_TRUSTED_ORIGINS = ['http://*.entrebytes.org','http://*.127.0.0.1','https://*.entrebytes.org','https://*.127.0.0.1']\n```\n\nEn Python, la variable CSRF_TRUSTED_ORIGINS se utiliza en aplicaciones web Django para especificar una lista de orígenes que se consideran confiables para la protección CSRF (Cross-site Request Forgery).\n\nCSRF es un tipo de ataque que se produce cuando un atacante engaña a un usuario para que realice una acción no deseada en una aplicación web. La protección CSRF se utiliza para evitar que los atacantes realicen este tipo de ataques mediante la validación del origen de la solicitud, el cual será nuestro dominio.\n\n\nUna vez hecho esto, podemos hacer un commit y subirlo a nuestro repositorio, porque al crear el Dockerfile necesitará obtener los archivos de la aplicación modificada.\n\n## Script de migraciones.sh\n\n```\n#! /bin/sh\n\nsleep 2\npython3 manage.py makemigrations\npython3 manage.py migrate\npython3 manage.py createsuperuser --noinput\npython3 manage.py collectstatic --no-input\npython3 manage.py runserver 0.0.0.0:4000\n```\n\n- El contenedor por defecto ejecutará sh\n- damos dos segundos antes de realizar alguna acción para que pueda conectarse a la base de datos\n- makemigrations crea las migraciones a la base de datos\n- creamos un usuario administrador de manera no interactiva\n- creamos las colecciones estáticas de la carpeta static\n- ejecutamos el servidor de django en el puerto 4000\n\n\n## Creación del Dockerfile\n\n\n```\nFROM python:3\nWORKDIR /usr/src/app\nMAINTAINER Antonio Marchán \"wildworld14@gmail.com\"\nRUN pip install --root-user-action=ignore --upgrade pip && pip install --root-user-action=ignore django mysqlclient && git clone https://github.com/Evanticks/docker-django.git /usr/src/app && mkdir static\nADD migraciones.sh /usr/src/app/\nRUN chmod +x /usr/src/app/migraciones.sh\nENTRYPOINT [\"/usr/src/app/migraciones.sh\"]\n```\n\n\n- Se aplicará una imagen base de python3\n- directorio donde se alojará la aplicación\n- Mantenedor de la imagen\n- ignora la petición de permisos de usuario root upgradeando pip de la imagen python e instalando django y mysqlclient a través de pip, a su vez clonamos nuestra aplicación y creamos un directorio llamado static que será donde se genere el contenido estático de la aplicación.\n- Enviamos migraciones.sh al directorio de trabajo /usr/src/app\n- Le damos permisos de ejecución al archivo migraciones.sh\n- Con entrypoint estamos ejecutando el script de migraciones.sh al iniciar el contenedor.\n\n\nTras esto, ejecutamos el siguiente comando para crear la imagen y la subiremos a dockerhub:\n\n```\ndocker build -t evanticks/django_tutorial:v1 .\ndocker push evanticks/django_tutorial:v1\n```\n\n## Creación del docker-compose.yml\n\n```\nversion: '3.1'\nservices:\n  django-tutorial:\n    container_name: django-tutorial\n    image: evanticks/django_tutorial:v1\n    restart: always\n    environment:\n      ALLOWED_HOSTS: \"*\"\n      DJANGODB_HOST: django-mariadb\n      DJANGODB_USUARIO: django\n      DJANGODB_CONTRASENA: django\n      NAME: django     \n      DJANGO_SUPERUSER_PASSWORD: admin\n      DJANGO_SUPERUSER_USERNAME: admin\n      DJANGO_SUPERUSER_EMAIL: admin@example.org\n    ports:\n      - 8082:4000\n    depends_on:\n      - db_django\n  db_django:\n    container_name: django-mariadb\n    image: mariadb:10.5\n    restart: always\n    environment:\n      MARIADB_ROOT_PASSWORD: root\n      MARIADB_DATABASE: django\n      MARIADB_USER: django\n      MARIADB_PASSWORD: django\n    volumes:\n      - mariadb_data_django:/var/lib/mysql\nvolumes:\n    mariadb_data_django:\n```\n\n```\nDocker-compose up -d\n```\n\n![docker](/images/django-1.png)\n\n\nY aquí podemos ver la aplicación funcionando en el entorno de desarrollo:\n\n![docker](/images/django-2.png)\n\n## Puesta en producción de nuestra aplicación\n\n\nPrimer crearemos nuestro virtual host en `/etc/nginx/sites-available/docker-django`:\n\n\n```\nserver {\n        listen 80;\n        listen [::]:80;\n\n        server_name django.entrebytes.org;\n\n        return 301 https://$host$request_uri;\n}\n\nserver {\n        listen 443 ssl http2;\n        listen [::]:443 ssl http2;\n\n        ssl    on;\n        ssl_certificate /etc/letsencrypt/live/django.entrebytes.org/fullchain.pem;\n        ssl_certificate_key /etc/letsencrypt/live/django.entrebytes.org/privkey.pem;\n\n        index index.html index.php index.htm index.nginx-debian.html;\n\n        server_name django.entrebytes.org;\n\n        location / {\n                proxy_pass http://localhost:8082;\n                include proxy_params;\n        }\n}\n\n```\n\nAhora vamos a generar el certificado bookmedik.entrebytes.org, para ello antes debemos poner un CNAME bookmedik.entrebytes.org que señale a nuestro servidor.\n\nTras esto haremos un stop al servicio nginx y ejecutaremos certbot para generar el certificado, activamos el sitio y reiniciamos nginx:\n\n```\nsystemctl stop nginx\n\ncertbot certonly --standalone -d django.entrebytes.org\n\nln -s /etc/nginx/sites-available/django-docker /etc/nginx/sites-enabled/\n\nsystemctl start nginx\n```\n\nA continuación crearemos un directorio donde guardaremos el docker-compose generado y lo ejecutaremos:\n\n```\ndocker-compose up -d\n```\n\nY tras esto, podemos ver que en nuestro servidor estamos alojando la aplicación completamente funcional:\n\n![docker](/images/django-3.png)","slug":"docker-django","published":1,"date":"2023-03-03T10:06:07.718Z","updated":"2023-03-05T15:11:22.456Z","_id":"clevfuvri0001yji5fmr2d8rk","comments":1,"layout":"post","photos":[],"link":"","content":"<p><img src=\"/images/docker-django.png\" alt=\"docker\"></p>\n<h1 id=\"dockerizar-la-aplicación-django\"><a class=\"markdownIt-Anchor\" href=\"#dockerizar-la-aplicación-django\">#</a> Dockerizar la aplicación Django</h1>\n<h2 id=\"cambios-en-la-aplicación\"><a class=\"markdownIt-Anchor\" href=\"#cambios-en-la-aplicación\">#</a> Cambios en la aplicación</h2>\n<p>En este post vamos a dockerizar la aplicación python de Django:</p>\n<p>Para ello lo primero que tenemos que hacer es obtener la aplicación que vamos a dockerizar, la cual procederá de aquí:</p>\n<p><a href=\"https://github.com/Evanticks/docker-django\">https://github.com/Evanticks/docker-django</a></p>\n<p>Tras clonarlo en nuestro entorno de desarrollo, procederemos a cambiar varios aspectos los cuales nos servirán para obtener las variables de entorno al haber importado el os, entonces nos vamos a  <code>django_tutorial/django_tutorial/settings.py</code>  y añadimos las siguientes instrucciones:</p>\n<pre><code>import os\n</code></pre>\n<p>Esta opción es opcional, si lo ponemos luego podremos especificar en el docker-compose.yml los host permitidos para realizar la conexión a nuestra aplicación.</p>\n<pre><code>ALLOWED_HOSTS = [os.environ.get(&quot;ALLOWED_HOSTS&quot;)]\n</code></pre>\n<p>La base de datos vamos a cambiarla, cuando antes era un sqlite3 ahora es un mariadb, por tanto vamos a poner variables de entorno que afecten a mysql:</p>\n<pre><code>DATABASES = &#123;\n    'default': &#123;\n        'ENGINE': 'django.db.backends.mysql',\n        'NAME': os.environ.get(&quot;DJANGODB&quot;),\n        'USER': os.environ.get('DJANGODB_USER'),\n        'PASSWORD': os.environ.get(&quot;DJANGODB_PASS&quot;),\n        'HOST': os.environ.get('DJANGODB_HOST'),\n        'PORT': '3306',\n    &#125;\n&#125;\n</code></pre>\n<p>Una vez hecho esto, nuestra aplicación buscará las variables de entorno que le asignemos al crear el contenedor, lo haremos luego a través de docker-compose.</p>\n<pre><code>STATIC_ROOT = os.path.join(BASE_DIR, 'static')\n</code></pre>\n<p>STATIC_ROOT es la ruta donde se almacenarán los archivos generados estáticos, en nuestro caso será la carpeta static.</p>\n<pre><code>CSRF_TRUSTED_ORIGINS = ['http://*.entrebytes.org','http://*.127.0.0.1','https://*.entrebytes.org','https://*.127.0.0.1']\n</code></pre>\n<p>En Python, la variable CSRF_TRUSTED_ORIGINS se utiliza en aplicaciones web Django para especificar una lista de orígenes que se consideran confiables para la protección CSRF (Cross-site Request Forgery).</p>\n<p>CSRF es un tipo de ataque que se produce cuando un atacante engaña a un usuario para que realice una acción no deseada en una aplicación web. La protección CSRF se utiliza para evitar que los atacantes realicen este tipo de ataques mediante la validación del origen de la solicitud, el cual será nuestro dominio.</p>\n<p>Una vez hecho esto, podemos hacer un commit y subirlo a nuestro repositorio, porque al crear el Dockerfile necesitará obtener los archivos de la aplicación modificada.</p>\n<h2 id=\"script-de-migracionessh\"><a class=\"markdownIt-Anchor\" href=\"#script-de-migracionessh\">#</a> Script de <a href=\"http://migraciones.sh\">migraciones.sh</a></h2>\n<pre><code>#! /bin/sh\n\nsleep 2\npython3 manage.py makemigrations\npython3 manage.py migrate\npython3 manage.py createsuperuser --noinput\npython3 manage.py collectstatic --no-input\npython3 manage.py runserver 0.0.0.0:4000\n</code></pre>\n<ul>\n<li>El contenedor por defecto ejecutará sh</li>\n<li>damos dos segundos antes de realizar alguna acción para que pueda conectarse a la base de datos</li>\n<li>makemigrations crea las migraciones a la base de datos</li>\n<li>creamos un usuario administrador de manera no interactiva</li>\n<li>creamos las colecciones estáticas de la carpeta static</li>\n<li>ejecutamos el servidor de django en el puerto 4000</li>\n</ul>\n<h2 id=\"creación-del-dockerfile\"><a class=\"markdownIt-Anchor\" href=\"#creación-del-dockerfile\">#</a> Creación del Dockerfile</h2>\n<pre><code>FROM python:3\nWORKDIR /usr/src/app\nMAINTAINER Antonio Marchán &quot;wildworld14@gmail.com&quot;\nRUN pip install --root-user-action=ignore --upgrade pip &amp;&amp; pip install --root-user-action=ignore django mysqlclient &amp;&amp; git clone https://github.com/Evanticks/docker-django.git /usr/src/app &amp;&amp; mkdir static\nADD migraciones.sh /usr/src/app/\nRUN chmod +x /usr/src/app/migraciones.sh\nENTRYPOINT [&quot;/usr/src/app/migraciones.sh&quot;]\n</code></pre>\n<ul>\n<li>Se aplicará una imagen base de python3</li>\n<li>directorio donde se alojará la aplicación</li>\n<li>Mantenedor de la imagen</li>\n<li>ignora la petición de permisos de usuario root upgradeando pip de la imagen python e instalando django y mysqlclient a través de pip, a su vez clonamos nuestra aplicación y creamos un directorio llamado static que será donde se genere el contenido estático de la aplicación.</li>\n<li>Enviamos <a href=\"http://migraciones.sh\">migraciones.sh</a> al directorio de trabajo /usr/src/app</li>\n<li>Le damos permisos de ejecución al archivo <a href=\"http://migraciones.sh\">migraciones.sh</a></li>\n<li>Con entrypoint estamos ejecutando el script de <a href=\"http://migraciones.sh\">migraciones.sh</a> al iniciar el contenedor.</li>\n</ul>\n<p>Tras esto, ejecutamos el siguiente comando para crear la imagen y la subiremos a dockerhub:</p>\n<pre><code>docker build -t evanticks/django_tutorial:v1 .\ndocker push evanticks/django_tutorial:v1\n</code></pre>\n<h2 id=\"creación-del-docker-composeyml\"><a class=\"markdownIt-Anchor\" href=\"#creación-del-docker-composeyml\">#</a> Creación del docker-compose.yml</h2>\n<pre><code>version: '3.1'\nservices:\n  django-tutorial:\n    container_name: django-tutorial\n    image: evanticks/django_tutorial:v1\n    restart: always\n    environment:\n      ALLOWED_HOSTS: &quot;*&quot;\n      DJANGODB_HOST: django-mariadb\n      DJANGODB_USUARIO: django\n      DJANGODB_CONTRASENA: django\n      NAME: django     \n      DJANGO_SUPERUSER_PASSWORD: admin\n      DJANGO_SUPERUSER_USERNAME: admin\n      DJANGO_SUPERUSER_EMAIL: admin@example.org\n    ports:\n      - 8082:4000\n    depends_on:\n      - db_django\n  db_django:\n    container_name: django-mariadb\n    image: mariadb:10.5\n    restart: always\n    environment:\n      MARIADB_ROOT_PASSWORD: root\n      MARIADB_DATABASE: django\n      MARIADB_USER: django\n      MARIADB_PASSWORD: django\n    volumes:\n      - mariadb_data_django:/var/lib/mysql\nvolumes:\n    mariadb_data_django:\n</code></pre>\n<pre><code>Docker-compose up -d\n</code></pre>\n<p><img src=\"/images/django-1.png\" alt=\"docker\"></p>\n<p>Y aquí podemos ver la aplicación funcionando en el entorno de desarrollo:</p>\n<p><img src=\"/images/django-2.png\" alt=\"docker\"></p>\n<h2 id=\"puesta-en-producción-de-nuestra-aplicación\"><a class=\"markdownIt-Anchor\" href=\"#puesta-en-producción-de-nuestra-aplicación\">#</a> Puesta en producción de nuestra aplicación</h2>\n<p>Primer crearemos nuestro virtual host en  <code>/etc/nginx/sites-available/docker-django</code> :</p>\n<pre><code>server &#123;\n        listen 80;\n        listen [::]:80;\n\n        server_name django.entrebytes.org;\n\n        return 301 https://$host$request_uri;\n&#125;\n\nserver &#123;\n        listen 443 ssl http2;\n        listen [::]:443 ssl http2;\n\n        ssl    on;\n        ssl_certificate /etc/letsencrypt/live/django.entrebytes.org/fullchain.pem;\n        ssl_certificate_key /etc/letsencrypt/live/django.entrebytes.org/privkey.pem;\n\n        index index.html index.php index.htm index.nginx-debian.html;\n\n        server_name django.entrebytes.org;\n\n        location / &#123;\n                proxy_pass http://localhost:8082;\n                include proxy_params;\n        &#125;\n&#125;\n\n</code></pre>\n<p>Ahora vamos a generar el certificado <a href=\"http://bookmedik.entrebytes.org\">bookmedik.entrebytes.org</a>, para ello antes debemos poner un CNAME <a href=\"http://bookmedik.entrebytes.org\">bookmedik.entrebytes.org</a> que señale a nuestro servidor.</p>\n<p>Tras esto haremos un stop al servicio nginx y ejecutaremos certbot para generar el certificado, activamos el sitio y reiniciamos nginx:</p>\n<pre><code>systemctl stop nginx\n\ncertbot certonly --standalone -d django.entrebytes.org\n\nln -s /etc/nginx/sites-available/django-docker /etc/nginx/sites-enabled/\n\nsystemctl start nginx\n</code></pre>\n<p>A continuación crearemos un directorio donde guardaremos el docker-compose generado y lo ejecutaremos:</p>\n<pre><code>docker-compose up -d\n</code></pre>\n<p>Y tras esto, podemos ver que en nuestro servidor estamos alojando la aplicación completamente funcional:</p>\n<p><img src=\"/images/django-3.png\" alt=\"docker\"></p>\n","site":{"data":{}},"length":5589,"excerpt":"","more":"<p><img src=\"/images/docker-django.png\" alt=\"docker\"></p>\n<h1 id=\"dockerizar-la-aplicación-django\"><a class=\"markdownIt-Anchor\" href=\"#dockerizar-la-aplicación-django\">#</a> Dockerizar la aplicación Django</h1>\n<h2 id=\"cambios-en-la-aplicación\"><a class=\"markdownIt-Anchor\" href=\"#cambios-en-la-aplicación\">#</a> Cambios en la aplicación</h2>\n<p>En este post vamos a dockerizar la aplicación python de Django:</p>\n<p>Para ello lo primero que tenemos que hacer es obtener la aplicación que vamos a dockerizar, la cual procederá de aquí:</p>\n<p><a href=\"https://github.com/Evanticks/docker-django\">https://github.com/Evanticks/docker-django</a></p>\n<p>Tras clonarlo en nuestro entorno de desarrollo, procederemos a cambiar varios aspectos los cuales nos servirán para obtener las variables de entorno al haber importado el os, entonces nos vamos a  <code>django_tutorial/django_tutorial/settings.py</code>  y añadimos las siguientes instrucciones:</p>\n<pre><code>import os\n</code></pre>\n<p>Esta opción es opcional, si lo ponemos luego podremos especificar en el docker-compose.yml los host permitidos para realizar la conexión a nuestra aplicación.</p>\n<pre><code>ALLOWED_HOSTS = [os.environ.get(&quot;ALLOWED_HOSTS&quot;)]\n</code></pre>\n<p>La base de datos vamos a cambiarla, cuando antes era un sqlite3 ahora es un mariadb, por tanto vamos a poner variables de entorno que afecten a mysql:</p>\n<pre><code>DATABASES = &#123;\n    'default': &#123;\n        'ENGINE': 'django.db.backends.mysql',\n        'NAME': os.environ.get(&quot;DJANGODB&quot;),\n        'USER': os.environ.get('DJANGODB_USER'),\n        'PASSWORD': os.environ.get(&quot;DJANGODB_PASS&quot;),\n        'HOST': os.environ.get('DJANGODB_HOST'),\n        'PORT': '3306',\n    &#125;\n&#125;\n</code></pre>\n<p>Una vez hecho esto, nuestra aplicación buscará las variables de entorno que le asignemos al crear el contenedor, lo haremos luego a través de docker-compose.</p>\n<pre><code>STATIC_ROOT = os.path.join(BASE_DIR, 'static')\n</code></pre>\n<p>STATIC_ROOT es la ruta donde se almacenarán los archivos generados estáticos, en nuestro caso será la carpeta static.</p>\n<pre><code>CSRF_TRUSTED_ORIGINS = ['http://*.entrebytes.org','http://*.127.0.0.1','https://*.entrebytes.org','https://*.127.0.0.1']\n</code></pre>\n<p>En Python, la variable CSRF_TRUSTED_ORIGINS se utiliza en aplicaciones web Django para especificar una lista de orígenes que se consideran confiables para la protección CSRF (Cross-site Request Forgery).</p>\n<p>CSRF es un tipo de ataque que se produce cuando un atacante engaña a un usuario para que realice una acción no deseada en una aplicación web. La protección CSRF se utiliza para evitar que los atacantes realicen este tipo de ataques mediante la validación del origen de la solicitud, el cual será nuestro dominio.</p>\n<p>Una vez hecho esto, podemos hacer un commit y subirlo a nuestro repositorio, porque al crear el Dockerfile necesitará obtener los archivos de la aplicación modificada.</p>\n<h2 id=\"script-de-migracionessh\"><a class=\"markdownIt-Anchor\" href=\"#script-de-migracionessh\">#</a> Script de <a href=\"http://migraciones.sh\">migraciones.sh</a></h2>\n<pre><code>#! /bin/sh\n\nsleep 2\npython3 manage.py makemigrations\npython3 manage.py migrate\npython3 manage.py createsuperuser --noinput\npython3 manage.py collectstatic --no-input\npython3 manage.py runserver 0.0.0.0:4000\n</code></pre>\n<ul>\n<li>El contenedor por defecto ejecutará sh</li>\n<li>damos dos segundos antes de realizar alguna acción para que pueda conectarse a la base de datos</li>\n<li>makemigrations crea las migraciones a la base de datos</li>\n<li>creamos un usuario administrador de manera no interactiva</li>\n<li>creamos las colecciones estáticas de la carpeta static</li>\n<li>ejecutamos el servidor de django en el puerto 4000</li>\n</ul>\n<h2 id=\"creación-del-dockerfile\"><a class=\"markdownIt-Anchor\" href=\"#creación-del-dockerfile\">#</a> Creación del Dockerfile</h2>\n<pre><code>FROM python:3\nWORKDIR /usr/src/app\nMAINTAINER Antonio Marchán &quot;wildworld14@gmail.com&quot;\nRUN pip install --root-user-action=ignore --upgrade pip &amp;&amp; pip install --root-user-action=ignore django mysqlclient &amp;&amp; git clone https://github.com/Evanticks/docker-django.git /usr/src/app &amp;&amp; mkdir static\nADD migraciones.sh /usr/src/app/\nRUN chmod +x /usr/src/app/migraciones.sh\nENTRYPOINT [&quot;/usr/src/app/migraciones.sh&quot;]\n</code></pre>\n<ul>\n<li>Se aplicará una imagen base de python3</li>\n<li>directorio donde se alojará la aplicación</li>\n<li>Mantenedor de la imagen</li>\n<li>ignora la petición de permisos de usuario root upgradeando pip de la imagen python e instalando django y mysqlclient a través de pip, a su vez clonamos nuestra aplicación y creamos un directorio llamado static que será donde se genere el contenido estático de la aplicación.</li>\n<li>Enviamos <a href=\"http://migraciones.sh\">migraciones.sh</a> al directorio de trabajo /usr/src/app</li>\n<li>Le damos permisos de ejecución al archivo <a href=\"http://migraciones.sh\">migraciones.sh</a></li>\n<li>Con entrypoint estamos ejecutando el script de <a href=\"http://migraciones.sh\">migraciones.sh</a> al iniciar el contenedor.</li>\n</ul>\n<p>Tras esto, ejecutamos el siguiente comando para crear la imagen y la subiremos a dockerhub:</p>\n<pre><code>docker build -t evanticks/django_tutorial:v1 .\ndocker push evanticks/django_tutorial:v1\n</code></pre>\n<h2 id=\"creación-del-docker-composeyml\"><a class=\"markdownIt-Anchor\" href=\"#creación-del-docker-composeyml\">#</a> Creación del docker-compose.yml</h2>\n<pre><code>version: '3.1'\nservices:\n  django-tutorial:\n    container_name: django-tutorial\n    image: evanticks/django_tutorial:v1\n    restart: always\n    environment:\n      ALLOWED_HOSTS: &quot;*&quot;\n      DJANGODB_HOST: django-mariadb\n      DJANGODB_USUARIO: django\n      DJANGODB_CONTRASENA: django\n      NAME: django     \n      DJANGO_SUPERUSER_PASSWORD: admin\n      DJANGO_SUPERUSER_USERNAME: admin\n      DJANGO_SUPERUSER_EMAIL: admin@example.org\n    ports:\n      - 8082:4000\n    depends_on:\n      - db_django\n  db_django:\n    container_name: django-mariadb\n    image: mariadb:10.5\n    restart: always\n    environment:\n      MARIADB_ROOT_PASSWORD: root\n      MARIADB_DATABASE: django\n      MARIADB_USER: django\n      MARIADB_PASSWORD: django\n    volumes:\n      - mariadb_data_django:/var/lib/mysql\nvolumes:\n    mariadb_data_django:\n</code></pre>\n<pre><code>Docker-compose up -d\n</code></pre>\n<p><img src=\"/images/django-1.png\" alt=\"docker\"></p>\n<p>Y aquí podemos ver la aplicación funcionando en el entorno de desarrollo:</p>\n<p><img src=\"/images/django-2.png\" alt=\"docker\"></p>\n<h2 id=\"puesta-en-producción-de-nuestra-aplicación\"><a class=\"markdownIt-Anchor\" href=\"#puesta-en-producción-de-nuestra-aplicación\">#</a> Puesta en producción de nuestra aplicación</h2>\n<p>Primer crearemos nuestro virtual host en  <code>/etc/nginx/sites-available/docker-django</code> :</p>\n<pre><code>server &#123;\n        listen 80;\n        listen [::]:80;\n\n        server_name django.entrebytes.org;\n\n        return 301 https://$host$request_uri;\n&#125;\n\nserver &#123;\n        listen 443 ssl http2;\n        listen [::]:443 ssl http2;\n\n        ssl    on;\n        ssl_certificate /etc/letsencrypt/live/django.entrebytes.org/fullchain.pem;\n        ssl_certificate_key /etc/letsencrypt/live/django.entrebytes.org/privkey.pem;\n\n        index index.html index.php index.htm index.nginx-debian.html;\n\n        server_name django.entrebytes.org;\n\n        location / &#123;\n                proxy_pass http://localhost:8082;\n                include proxy_params;\n        &#125;\n&#125;\n\n</code></pre>\n<p>Ahora vamos a generar el certificado <a href=\"http://bookmedik.entrebytes.org\">bookmedik.entrebytes.org</a>, para ello antes debemos poner un CNAME <a href=\"http://bookmedik.entrebytes.org\">bookmedik.entrebytes.org</a> que señale a nuestro servidor.</p>\n<p>Tras esto haremos un stop al servicio nginx y ejecutaremos certbot para generar el certificado, activamos el sitio y reiniciamos nginx:</p>\n<pre><code>systemctl stop nginx\n\ncertbot certonly --standalone -d django.entrebytes.org\n\nln -s /etc/nginx/sites-available/django-docker /etc/nginx/sites-enabled/\n\nsystemctl start nginx\n</code></pre>\n<p>A continuación crearemos un directorio donde guardaremos el docker-compose generado y lo ejecutaremos:</p>\n<pre><code>docker-compose up -d\n</code></pre>\n<p>Y tras esto, podemos ver que en nuestro servidor estamos alojando la aplicación completamente funcional:</p>\n<p><img src=\"/images/django-3.png\" alt=\"docker\"></p>\n"},{"title":"Práctica Kubernetes","Categoría":"Contenedores","_content":"\n\n![kubernetes](/images/k8s-logo-2.png)\n\n\n## Archivos de configuración de Kubernetes\n\n```\nkubectl create cm bd-datos --from-literal=bd_user=bookmedik \\\n                           --from-literal=bd_dbname=bookmedik \\\n                           --from-literal=bd_host=mariadb-service \\\n                           -o yaml --dry-run=client > bd_datos_configmap.yaml\n\n\n\nkubectl create secret generic bd-passwords --from-literal=bd_password=bookmedik \\\n                                           --from-literal=bd_rootpassword=root \\\n                                           -o yaml --dry-run=client > bd_passwords_secret.yaml\n```\n\n\nbookmedik-deployment.yaml\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: bookmedik-deployment\n  labels:\n    app: bookmedik\n    type: frontend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: bookmedik\n      type: frontend\n  template:\n    metadata:\n      labels:\n        app: bookmedik\n        type: frontend\n    spec:\n      volumes:\n        - name: bookmedik-pvc\n          persistentVolumeClaim:\n            claimName: bookmedik-pvc\n      containers:\n        - name: contenedor-bookmedik\n          image: evanticks/bookmedik:v1_3\n#          volumeMounts:\n#            - mountPath: /var/www/html/\n#              name: bookmedik-pvc\n          ports:\n            - containerPort: 80\n              name: http-port\n          env:\n            - name: USUARIO_BOOKMEDIK\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_user\n            - name: NOMBRE_DB\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_dbname\n            - name: DATABASE_HOST\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_host\n            - name: CONTRA_BOOKMEDIK\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_password\n\n```\n\nmariadb-deployment.yaml\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mariadb-deployment\n  labels:\n    app: bookmedik\n    type: database\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: bookmedik\n      type: database\n  template:\n    metadata:\n      labels:\n        app: bookmedik\n        type: database\n    spec:\n      volumes:\n        - name: mariadb-pvc\n          persistentVolumeClaim:\n            claimName: mariadb-pvc\n      containers:\n        - name: contenedor-mariadb\n          image: mariadb\n          ports:\n            - containerPort: 3306\n              name: db-port\n          volumeMounts:\n            - mountPath: \"/var/lib/mysql\"\n              name: mariadb-pvc\n          env:\n            - name: MYSQL_USER\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_user\n            - name: MYSQL_DATABASE\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_dbname\n#            - name: MARIADB_HOST\n#              valueFrom:\n#                configMapKeyRef:\n#                  name: bd-datos\n#                  key: bd_host\n            - name: MYSQL_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_password\n            - name: MYSQL_ROOT_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_rootpassword\n```\n\n\nbookmedik-srv.yaml\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: bookmedik\n  labels:\n    app: bookmedik\n    type: frontend\nspec:\n  selector:\n    app: bookmedik\n    type: frontend\n  ports:\n  - name: http-sv-port\n    port: 80\n    targetPort: http-port\n  type: NodePort\n```\n\nmaria-srv.yaml\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: mariadb-service\n  labels:\n    app: bookmedik\n    type: database\nspec:\n  selector:\n    app: bookmedik\n    type: database\n  ports:\n  - port: 3306\n    targetPort: db-port\n  type: ClusterIP\n```\n\nbookmedik-pvc.yaml \n\n```\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n    name: bookmedik-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 4Gi\n```\n\nmariadb-pvc.yaml  \n\n```\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n    name: mariadb-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 4Gi\n```\n\ncat ingress.yaml\n\n```\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: bookmedik\nspec:\n  rules:\n  - host: www.antonio.org\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: bookmedik\n            port:\n              number: 80\n```\n\n## Entrega de la práctica\n\n- Salida de los comando que nos posibilitan ver los recursos que has creado en el cluster.\n\n```\nkubectl get all,pv,pvc,cm,secret\n\nNAME                                        READY   STATUS    RESTARTS   AGE\npod/bookmedik-deployment-57988bfdd9-6zljr   1/1     Running   0          9m12s\npod/mariadb-deployment-7cd7fb9cd8-2tsts     1/1     Running   0          36m\n\nNAME                      TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE\nservice/bookmedik         NodePort    10.100.41.241   <none>        80:30814/TCP   63m\nservice/kubernetes        ClusterIP   10.96.0.1       <none>        443/TCP        3h21m\nservice/mariadb-service   ClusterIP   10.103.3.28     <none>        3306/TCP       63m\n\nNAME                                   READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/bookmedik-deployment   1/1     1            1           55m\ndeployment.apps/mariadb-deployment     1/1     1            1           36m\n\nNAME                                              DESIRED   CURRENT   READY   AGE\nreplicaset.apps/bookmedik-deployment-57988bfdd9   1         1         1       9m12s\nreplicaset.apps/bookmedik-deployment-85bff5fdfd   0         0         0       55m\nreplicaset.apps/mariadb-deployment-7cd7fb9cd8     1         1         1       36m\n\nNAME                                                        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                   STORAGECLASS   REASON   AGE\npersistentvolume/pvc-0f3db0b9-81d5-4574-abeb-2da92aa82a44   4Gi        RWO            Delete           Bound    default/bookmedik-pvc   standard                63m\npersistentvolume/pvc-fe594844-a9e4-4390-986a-7950611dee65   4Gi        RWO            Delete           Bound    default/mariadb-pvc     standard                63m\n\nNAME                                  STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\npersistentvolumeclaim/bookmedik-pvc   Bound    pvc-0f3db0b9-81d5-4574-abeb-2da92aa82a44   4Gi        RWO            standard       63m\npersistentvolumeclaim/mariadb-pvc     Bound    pvc-fe594844-a9e4-4390-986a-7950611dee65   4Gi        RWO            standard       63m\n\nNAME                         DATA   AGE\nconfigmap/bd-datos           3      63m\nconfigmap/kube-root-ca.crt   1      3h21m\n\nNAME                  TYPE     DATA   AGE\nsecret/bd-passwords   Opaque   2      63m\n\n```\n\n- Pantallazo accediendo a la aplicación utilizando el servicio.\n\n```\nminikube get service bookmedik\n```\n\n![bookmedik-0](/images/bookmedik-7.png)\n\n- Pantallazo accediendo a la aplicación utilizando el ingress.\n\n![bookmedik-1](/images/bookmedik-1.png)\n\n- Elimina el despliegue de la base datos, vuelve a crearla y comprueba que la aplicación no ha perdido los datos.\n\n![bookmedik-2](/images/bookmedik-2.gif)\n\n\n\n- Escala la aplicación con 3 replicas. Muestra la salida oportuna para ver los pods que se han creado.\n\n```\nkubectl get pods\n\nkubectl scale deployment bookmedik-deployment --replicas=3\n```\n\n![bookmedik-3](/images/bookmedik-2.png)\n\n\n- Modifica la aplicación, vuelve a crear una imagen con la nueva versión y actualiza el despliegue. No te olvide de anotar la modificación. Muestra la salida del historial de despliegue, la salida de kubectl get all y un pantallazo donde se vea la modificación que has realizado.\n\nNos vamos a bookmedik/core/app/view/pacients-view.php y cambiamos el texto Nombre completo por Nombre y Apellidos.\n\n\n![bookmedik-4](/images/bookmedik-3.png)\n\n```\ndocker build -t evanticks/bookmedik:v1_3 .\ndocker push evanticks/bookmedik:v1_3\n```\n\nAhora editamos la el bookmedik-deployment.yaml y cambiamos la imagen por la nueva.\n\n![bookmedik-5](/images/bookmedik-4.png)\n\n```\nkubectl apply -f bookmedik-deployment.yaml\n```\n\n```\nkubectl annotate deployments.apps/bookmedik-deployment kubernetes.io/change-cause=\"He cambiado el título del nombre del paciente\"\n```\n\n![bookmedik-6](/images/bookmedik-5.png)\n\nY aquí podemos ver como ha cambiado la aplicación:\n\n![bookmedik-7](/images/bookmedik-6.png)\n\nY aquí la salida de kubectl get all:\n\n```\nNAME                                        READY   STATUS    RESTARTS   AGE\npod/bookmedik-deployment-57988bfdd9-6zljr   1/1     Running   0          8m24s\npod/mariadb-deployment-7cd7fb9cd8-2tsts     1/1     Running   0          35m\n\nNAME                      TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE\nservice/bookmedik         NodePort    10.100.41.241   <none>        80:30814/TCP   62m\nservice/kubernetes        ClusterIP   10.96.0.1       <none>        443/TCP        3h20m\nservice/mariadb-service   ClusterIP   10.103.3.28     <none>        3306/TCP       62m\n\nNAME                                   READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/bookmedik-deployment   1/1     1            1           54m\ndeployment.apps/mariadb-deployment     1/1     1            1           35m\n\nNAME                                              DESIRED   CURRENT   READY   AGE\nreplicaset.apps/bookmedik-deployment-57988bfdd9   1         1         1       8m24s\nreplicaset.apps/bookmedik-deployment-85bff5fdfd   0         0         0       54m\nreplicaset.apps/mariadb-deployment-7cd7fb9cd8     1         1         1       35m\n\n```\n\n- Entrega la url del repositorio donde están los ficheros yaml.\n\nhttps://github.com/Evanticks/kubernetes-practica\n\n\n## K3S\n\nTendremos 4 nodos, un maestro y 3 esclavos. El maestro tendrá el rol de controlador y los esclavos de nodos de trabajo, lo haremos a través del siguiente vagrantfile:\n\n```\nVagrant.configure(\"2\") do |config|\n    config.vm.box = \"debian/bullseye64\"\n    config.vm.box_check_update = false\n    config.vm.synced_folder \".\", \"/vagrant\", disabled: true\n    config.vm.provider \"libvirt\" do |v|\n      v.memory = 1024\n      v.cpus = 1\n    end\n    config.vm.define \"master\" do |master|\n      master.vm.hostname = \"master\"\n      master.vm.network \"private_network\",\n        :libvirt__network_name => \"k3s-vagrant\",\n        :ip => \"10.10.10.10\",\n        :libvirt__dhcp_enabled => false,\n        :libvirt__forward_mode => \"veryisolated\"\n    end\n    config.vm.define \"nodo1\" do |nodo1|\n      nodo1.vm.hostname = \"nodo1\"\n      nodo1.vm.network \"private_network\",\n        :libvirt__network_name => \"k3s-vagrant\",\n        :ip => \"10.10.10.20\",\n        :libvirt__dhcp_enabled => false,\n        :libvirt__forward_mode => \"veryisolated\"\n    end\n    config.vm.define \"nodo2\" do |nodo2|\n      nodo2.vm.hostname = \"nodo2\"\n      nodo2.vm.network \"private_network\",\n        :libvirt__network_name => \"k3s-vagrant\",\n        :ip => \"10.10.10.30\",\n        :libvirt__dhcp_enabled => false,\n        :libvirt__forward_mode => \"veryisolated\"\n    end\n    config.vm.define \"nodo2\" do |nodo2|\n        nodo2.vm.hostname = \"nodo2\"\n        nodo2.vm.network \"private_network\",\n          :libvirt__network_name => \"k3s-vagrant\",\n          :ip => \"10.10.10.40\",\n          :libvirt__dhcp_enabled => false,\n          :libvirt__forward_mode => \"veryisolated\"\n    end\n  end\n```\n\nTras esto entramos en el nodo maestro y ejecutamos el siguiente comando como administrador:\n\n```\napt update\n\napt install curl -y\n\ncurl -sfL https://get.k3s.io | sh -\n```\n\nTras esto ejecutamso un `cat /var/lib/rancher/k3s/server/node-token` para que ese token lo podamos usar en los nodos esclavos.\n\nEn los nodos esclavos utilizamos el siguiente comando:\n\n```\napt update\n\napt install curl -y\n\ncurl -sfL https://get.k3s.io | K3S_URL=https://10.10.10.10:6443 K3S_TOKEN=K10cd69b71c10ac263c200b4bfb2747bff1d5563fdce2076454533940bc0be0b848::server:fdf97632c55a66fff13d217e2a5ca407 sh -\n```\n\nTras esto, si lo hemos hecho en los 3 nodos esclavos, veremos en el nodo maestro que tenemos 4 nodos:\n\n```\nkubectl get nodes\n```\n\n![k3s-1](/images/bookmedik-8.png)\n\nAhora vamos a clonar el repositorio con nuestros yaml:\n\n```\ngit clone https://github.com/Evanticks/kubernetes-practica.git\n```\n\neditamos el ingress.yaml para adaptarlo a nuestra configuración:\n```\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: bookmedik\nspec:\n  rules:\n  - host: www.bookantonio.org\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: bookmedik\n            port:\n              number: 80\n```\n\nAhora ejecutamos un `kubectl apply -f .` para que se creen los recursos.\n\nTan solo faltaría ingresar en /etc/hosts la ip de la máquina maestra y luego www.bookantonio.org.\n\n![k3s-2](/images/bookmedik-9.png)","source":"_posts/k8s.md","raw":"---\ntitle: Práctica Kubernetes\nCategoría: Contenedores\n---\n\n\n![kubernetes](/images/k8s-logo-2.png)\n\n\n## Archivos de configuración de Kubernetes\n\n```\nkubectl create cm bd-datos --from-literal=bd_user=bookmedik \\\n                           --from-literal=bd_dbname=bookmedik \\\n                           --from-literal=bd_host=mariadb-service \\\n                           -o yaml --dry-run=client > bd_datos_configmap.yaml\n\n\n\nkubectl create secret generic bd-passwords --from-literal=bd_password=bookmedik \\\n                                           --from-literal=bd_rootpassword=root \\\n                                           -o yaml --dry-run=client > bd_passwords_secret.yaml\n```\n\n\nbookmedik-deployment.yaml\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: bookmedik-deployment\n  labels:\n    app: bookmedik\n    type: frontend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: bookmedik\n      type: frontend\n  template:\n    metadata:\n      labels:\n        app: bookmedik\n        type: frontend\n    spec:\n      volumes:\n        - name: bookmedik-pvc\n          persistentVolumeClaim:\n            claimName: bookmedik-pvc\n      containers:\n        - name: contenedor-bookmedik\n          image: evanticks/bookmedik:v1_3\n#          volumeMounts:\n#            - mountPath: /var/www/html/\n#              name: bookmedik-pvc\n          ports:\n            - containerPort: 80\n              name: http-port\n          env:\n            - name: USUARIO_BOOKMEDIK\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_user\n            - name: NOMBRE_DB\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_dbname\n            - name: DATABASE_HOST\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_host\n            - name: CONTRA_BOOKMEDIK\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_password\n\n```\n\nmariadb-deployment.yaml\n\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mariadb-deployment\n  labels:\n    app: bookmedik\n    type: database\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: bookmedik\n      type: database\n  template:\n    metadata:\n      labels:\n        app: bookmedik\n        type: database\n    spec:\n      volumes:\n        - name: mariadb-pvc\n          persistentVolumeClaim:\n            claimName: mariadb-pvc\n      containers:\n        - name: contenedor-mariadb\n          image: mariadb\n          ports:\n            - containerPort: 3306\n              name: db-port\n          volumeMounts:\n            - mountPath: \"/var/lib/mysql\"\n              name: mariadb-pvc\n          env:\n            - name: MYSQL_USER\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_user\n            - name: MYSQL_DATABASE\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_dbname\n#            - name: MARIADB_HOST\n#              valueFrom:\n#                configMapKeyRef:\n#                  name: bd-datos\n#                  key: bd_host\n            - name: MYSQL_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_password\n            - name: MYSQL_ROOT_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_rootpassword\n```\n\n\nbookmedik-srv.yaml\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: bookmedik\n  labels:\n    app: bookmedik\n    type: frontend\nspec:\n  selector:\n    app: bookmedik\n    type: frontend\n  ports:\n  - name: http-sv-port\n    port: 80\n    targetPort: http-port\n  type: NodePort\n```\n\nmaria-srv.yaml\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: mariadb-service\n  labels:\n    app: bookmedik\n    type: database\nspec:\n  selector:\n    app: bookmedik\n    type: database\n  ports:\n  - port: 3306\n    targetPort: db-port\n  type: ClusterIP\n```\n\nbookmedik-pvc.yaml \n\n```\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n    name: bookmedik-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 4Gi\n```\n\nmariadb-pvc.yaml  \n\n```\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n    name: mariadb-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 4Gi\n```\n\ncat ingress.yaml\n\n```\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: bookmedik\nspec:\n  rules:\n  - host: www.antonio.org\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: bookmedik\n            port:\n              number: 80\n```\n\n## Entrega de la práctica\n\n- Salida de los comando que nos posibilitan ver los recursos que has creado en el cluster.\n\n```\nkubectl get all,pv,pvc,cm,secret\n\nNAME                                        READY   STATUS    RESTARTS   AGE\npod/bookmedik-deployment-57988bfdd9-6zljr   1/1     Running   0          9m12s\npod/mariadb-deployment-7cd7fb9cd8-2tsts     1/1     Running   0          36m\n\nNAME                      TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE\nservice/bookmedik         NodePort    10.100.41.241   <none>        80:30814/TCP   63m\nservice/kubernetes        ClusterIP   10.96.0.1       <none>        443/TCP        3h21m\nservice/mariadb-service   ClusterIP   10.103.3.28     <none>        3306/TCP       63m\n\nNAME                                   READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/bookmedik-deployment   1/1     1            1           55m\ndeployment.apps/mariadb-deployment     1/1     1            1           36m\n\nNAME                                              DESIRED   CURRENT   READY   AGE\nreplicaset.apps/bookmedik-deployment-57988bfdd9   1         1         1       9m12s\nreplicaset.apps/bookmedik-deployment-85bff5fdfd   0         0         0       55m\nreplicaset.apps/mariadb-deployment-7cd7fb9cd8     1         1         1       36m\n\nNAME                                                        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                   STORAGECLASS   REASON   AGE\npersistentvolume/pvc-0f3db0b9-81d5-4574-abeb-2da92aa82a44   4Gi        RWO            Delete           Bound    default/bookmedik-pvc   standard                63m\npersistentvolume/pvc-fe594844-a9e4-4390-986a-7950611dee65   4Gi        RWO            Delete           Bound    default/mariadb-pvc     standard                63m\n\nNAME                                  STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\npersistentvolumeclaim/bookmedik-pvc   Bound    pvc-0f3db0b9-81d5-4574-abeb-2da92aa82a44   4Gi        RWO            standard       63m\npersistentvolumeclaim/mariadb-pvc     Bound    pvc-fe594844-a9e4-4390-986a-7950611dee65   4Gi        RWO            standard       63m\n\nNAME                         DATA   AGE\nconfigmap/bd-datos           3      63m\nconfigmap/kube-root-ca.crt   1      3h21m\n\nNAME                  TYPE     DATA   AGE\nsecret/bd-passwords   Opaque   2      63m\n\n```\n\n- Pantallazo accediendo a la aplicación utilizando el servicio.\n\n```\nminikube get service bookmedik\n```\n\n![bookmedik-0](/images/bookmedik-7.png)\n\n- Pantallazo accediendo a la aplicación utilizando el ingress.\n\n![bookmedik-1](/images/bookmedik-1.png)\n\n- Elimina el despliegue de la base datos, vuelve a crearla y comprueba que la aplicación no ha perdido los datos.\n\n![bookmedik-2](/images/bookmedik-2.gif)\n\n\n\n- Escala la aplicación con 3 replicas. Muestra la salida oportuna para ver los pods que se han creado.\n\n```\nkubectl get pods\n\nkubectl scale deployment bookmedik-deployment --replicas=3\n```\n\n![bookmedik-3](/images/bookmedik-2.png)\n\n\n- Modifica la aplicación, vuelve a crear una imagen con la nueva versión y actualiza el despliegue. No te olvide de anotar la modificación. Muestra la salida del historial de despliegue, la salida de kubectl get all y un pantallazo donde se vea la modificación que has realizado.\n\nNos vamos a bookmedik/core/app/view/pacients-view.php y cambiamos el texto Nombre completo por Nombre y Apellidos.\n\n\n![bookmedik-4](/images/bookmedik-3.png)\n\n```\ndocker build -t evanticks/bookmedik:v1_3 .\ndocker push evanticks/bookmedik:v1_3\n```\n\nAhora editamos la el bookmedik-deployment.yaml y cambiamos la imagen por la nueva.\n\n![bookmedik-5](/images/bookmedik-4.png)\n\n```\nkubectl apply -f bookmedik-deployment.yaml\n```\n\n```\nkubectl annotate deployments.apps/bookmedik-deployment kubernetes.io/change-cause=\"He cambiado el título del nombre del paciente\"\n```\n\n![bookmedik-6](/images/bookmedik-5.png)\n\nY aquí podemos ver como ha cambiado la aplicación:\n\n![bookmedik-7](/images/bookmedik-6.png)\n\nY aquí la salida de kubectl get all:\n\n```\nNAME                                        READY   STATUS    RESTARTS   AGE\npod/bookmedik-deployment-57988bfdd9-6zljr   1/1     Running   0          8m24s\npod/mariadb-deployment-7cd7fb9cd8-2tsts     1/1     Running   0          35m\n\nNAME                      TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE\nservice/bookmedik         NodePort    10.100.41.241   <none>        80:30814/TCP   62m\nservice/kubernetes        ClusterIP   10.96.0.1       <none>        443/TCP        3h20m\nservice/mariadb-service   ClusterIP   10.103.3.28     <none>        3306/TCP       62m\n\nNAME                                   READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/bookmedik-deployment   1/1     1            1           54m\ndeployment.apps/mariadb-deployment     1/1     1            1           35m\n\nNAME                                              DESIRED   CURRENT   READY   AGE\nreplicaset.apps/bookmedik-deployment-57988bfdd9   1         1         1       8m24s\nreplicaset.apps/bookmedik-deployment-85bff5fdfd   0         0         0       54m\nreplicaset.apps/mariadb-deployment-7cd7fb9cd8     1         1         1       35m\n\n```\n\n- Entrega la url del repositorio donde están los ficheros yaml.\n\nhttps://github.com/Evanticks/kubernetes-practica\n\n\n## K3S\n\nTendremos 4 nodos, un maestro y 3 esclavos. El maestro tendrá el rol de controlador y los esclavos de nodos de trabajo, lo haremos a través del siguiente vagrantfile:\n\n```\nVagrant.configure(\"2\") do |config|\n    config.vm.box = \"debian/bullseye64\"\n    config.vm.box_check_update = false\n    config.vm.synced_folder \".\", \"/vagrant\", disabled: true\n    config.vm.provider \"libvirt\" do |v|\n      v.memory = 1024\n      v.cpus = 1\n    end\n    config.vm.define \"master\" do |master|\n      master.vm.hostname = \"master\"\n      master.vm.network \"private_network\",\n        :libvirt__network_name => \"k3s-vagrant\",\n        :ip => \"10.10.10.10\",\n        :libvirt__dhcp_enabled => false,\n        :libvirt__forward_mode => \"veryisolated\"\n    end\n    config.vm.define \"nodo1\" do |nodo1|\n      nodo1.vm.hostname = \"nodo1\"\n      nodo1.vm.network \"private_network\",\n        :libvirt__network_name => \"k3s-vagrant\",\n        :ip => \"10.10.10.20\",\n        :libvirt__dhcp_enabled => false,\n        :libvirt__forward_mode => \"veryisolated\"\n    end\n    config.vm.define \"nodo2\" do |nodo2|\n      nodo2.vm.hostname = \"nodo2\"\n      nodo2.vm.network \"private_network\",\n        :libvirt__network_name => \"k3s-vagrant\",\n        :ip => \"10.10.10.30\",\n        :libvirt__dhcp_enabled => false,\n        :libvirt__forward_mode => \"veryisolated\"\n    end\n    config.vm.define \"nodo2\" do |nodo2|\n        nodo2.vm.hostname = \"nodo2\"\n        nodo2.vm.network \"private_network\",\n          :libvirt__network_name => \"k3s-vagrant\",\n          :ip => \"10.10.10.40\",\n          :libvirt__dhcp_enabled => false,\n          :libvirt__forward_mode => \"veryisolated\"\n    end\n  end\n```\n\nTras esto entramos en el nodo maestro y ejecutamos el siguiente comando como administrador:\n\n```\napt update\n\napt install curl -y\n\ncurl -sfL https://get.k3s.io | sh -\n```\n\nTras esto ejecutamso un `cat /var/lib/rancher/k3s/server/node-token` para que ese token lo podamos usar en los nodos esclavos.\n\nEn los nodos esclavos utilizamos el siguiente comando:\n\n```\napt update\n\napt install curl -y\n\ncurl -sfL https://get.k3s.io | K3S_URL=https://10.10.10.10:6443 K3S_TOKEN=K10cd69b71c10ac263c200b4bfb2747bff1d5563fdce2076454533940bc0be0b848::server:fdf97632c55a66fff13d217e2a5ca407 sh -\n```\n\nTras esto, si lo hemos hecho en los 3 nodos esclavos, veremos en el nodo maestro que tenemos 4 nodos:\n\n```\nkubectl get nodes\n```\n\n![k3s-1](/images/bookmedik-8.png)\n\nAhora vamos a clonar el repositorio con nuestros yaml:\n\n```\ngit clone https://github.com/Evanticks/kubernetes-practica.git\n```\n\neditamos el ingress.yaml para adaptarlo a nuestra configuración:\n```\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: bookmedik\nspec:\n  rules:\n  - host: www.bookantonio.org\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: bookmedik\n            port:\n              number: 80\n```\n\nAhora ejecutamos un `kubectl apply -f .` para que se creen los recursos.\n\nTan solo faltaría ingresar en /etc/hosts la ip de la máquina maestra y luego www.bookantonio.org.\n\n![k3s-2](/images/bookmedik-9.png)","slug":"k8s","published":1,"date":"2023-03-05T15:11:39.872Z","updated":"2023-03-05T23:59:47.559Z","_id":"clew1zldr0000g8i5az770w8v","comments":1,"layout":"post","photos":[],"link":"","content":"<p><img src=\"/images/k8s-logo-2.png\" alt=\"kubernetes\"></p>\n<h2 id=\"archivos-de-configuración-de-kubernetes\"><a class=\"markdownIt-Anchor\" href=\"#archivos-de-configuración-de-kubernetes\">#</a> Archivos de configuración de Kubernetes</h2>\n<pre><code>kubectl create cm bd-datos --from-literal=bd_user=bookmedik \\\n                           --from-literal=bd_dbname=bookmedik \\\n                           --from-literal=bd_host=mariadb-service \\\n                           -o yaml --dry-run=client &gt; bd_datos_configmap.yaml\n\n\n\nkubectl create secret generic bd-passwords --from-literal=bd_password=bookmedik \\\n                                           --from-literal=bd_rootpassword=root \\\n                                           -o yaml --dry-run=client &gt; bd_passwords_secret.yaml\n</code></pre>\n<p>bookmedik-deployment.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: bookmedik-deployment\n  labels:\n    app: bookmedik\n    type: frontend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: bookmedik\n      type: frontend\n  template:\n    metadata:\n      labels:\n        app: bookmedik\n        type: frontend\n    spec:\n      volumes:\n        - name: bookmedik-pvc\n          persistentVolumeClaim:\n            claimName: bookmedik-pvc\n      containers:\n        - name: contenedor-bookmedik\n          image: evanticks/bookmedik:v1_3\n#          volumeMounts:\n#            - mountPath: /var/www/html/\n#              name: bookmedik-pvc\n          ports:\n            - containerPort: 80\n              name: http-port\n          env:\n            - name: USUARIO_BOOKMEDIK\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_user\n            - name: NOMBRE_DB\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_dbname\n            - name: DATABASE_HOST\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_host\n            - name: CONTRA_BOOKMEDIK\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_password\n\n</code></pre>\n<p>mariadb-deployment.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mariadb-deployment\n  labels:\n    app: bookmedik\n    type: database\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: bookmedik\n      type: database\n  template:\n    metadata:\n      labels:\n        app: bookmedik\n        type: database\n    spec:\n      volumes:\n        - name: mariadb-pvc\n          persistentVolumeClaim:\n            claimName: mariadb-pvc\n      containers:\n        - name: contenedor-mariadb\n          image: mariadb\n          ports:\n            - containerPort: 3306\n              name: db-port\n          volumeMounts:\n            - mountPath: &quot;/var/lib/mysql&quot;\n              name: mariadb-pvc\n          env:\n            - name: MYSQL_USER\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_user\n            - name: MYSQL_DATABASE\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_dbname\n#            - name: MARIADB_HOST\n#              valueFrom:\n#                configMapKeyRef:\n#                  name: bd-datos\n#                  key: bd_host\n            - name: MYSQL_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_password\n            - name: MYSQL_ROOT_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_rootpassword\n</code></pre>\n<p>bookmedik-srv.yaml</p>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: bookmedik\n  labels:\n    app: bookmedik\n    type: frontend\nspec:\n  selector:\n    app: bookmedik\n    type: frontend\n  ports:\n  - name: http-sv-port\n    port: 80\n    targetPort: http-port\n  type: NodePort\n</code></pre>\n<p>maria-srv.yaml</p>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: mariadb-service\n  labels:\n    app: bookmedik\n    type: database\nspec:\n  selector:\n    app: bookmedik\n    type: database\n  ports:\n  - port: 3306\n    targetPort: db-port\n  type: ClusterIP\n</code></pre>\n<p>bookmedik-pvc.yaml</p>\n<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n    name: bookmedik-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 4Gi\n</code></pre>\n<p>mariadb-pvc.yaml</p>\n<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n    name: mariadb-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 4Gi\n</code></pre>\n<p>cat ingress.yaml</p>\n<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: bookmedik\nspec:\n  rules:\n  - host: www.antonio.org\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: bookmedik\n            port:\n              number: 80\n</code></pre>\n<h2 id=\"entrega-de-la-práctica\"><a class=\"markdownIt-Anchor\" href=\"#entrega-de-la-práctica\">#</a> Entrega de la práctica</h2>\n<ul>\n<li>Salida de los comando que nos posibilitan ver los recursos que has creado en el cluster.</li>\n</ul>\n<pre><code>kubectl get all,pv,pvc,cm,secret\n\nNAME                                        READY   STATUS    RESTARTS   AGE\npod/bookmedik-deployment-57988bfdd9-6zljr   1/1     Running   0          9m12s\npod/mariadb-deployment-7cd7fb9cd8-2tsts     1/1     Running   0          36m\n\nNAME                      TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE\nservice/bookmedik         NodePort    10.100.41.241   &lt;none&gt;        80:30814/TCP   63m\nservice/kubernetes        ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP        3h21m\nservice/mariadb-service   ClusterIP   10.103.3.28     &lt;none&gt;        3306/TCP       63m\n\nNAME                                   READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/bookmedik-deployment   1/1     1            1           55m\ndeployment.apps/mariadb-deployment     1/1     1            1           36m\n\nNAME                                              DESIRED   CURRENT   READY   AGE\nreplicaset.apps/bookmedik-deployment-57988bfdd9   1         1         1       9m12s\nreplicaset.apps/bookmedik-deployment-85bff5fdfd   0         0         0       55m\nreplicaset.apps/mariadb-deployment-7cd7fb9cd8     1         1         1       36m\n\nNAME                                                        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                   STORAGECLASS   REASON   AGE\npersistentvolume/pvc-0f3db0b9-81d5-4574-abeb-2da92aa82a44   4Gi        RWO            Delete           Bound    default/bookmedik-pvc   standard                63m\npersistentvolume/pvc-fe594844-a9e4-4390-986a-7950611dee65   4Gi        RWO            Delete           Bound    default/mariadb-pvc     standard                63m\n\nNAME                                  STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\npersistentvolumeclaim/bookmedik-pvc   Bound    pvc-0f3db0b9-81d5-4574-abeb-2da92aa82a44   4Gi        RWO            standard       63m\npersistentvolumeclaim/mariadb-pvc     Bound    pvc-fe594844-a9e4-4390-986a-7950611dee65   4Gi        RWO            standard       63m\n\nNAME                         DATA   AGE\nconfigmap/bd-datos           3      63m\nconfigmap/kube-root-ca.crt   1      3h21m\n\nNAME                  TYPE     DATA   AGE\nsecret/bd-passwords   Opaque   2      63m\n\n</code></pre>\n<ul>\n<li>Pantallazo accediendo a la aplicación utilizando el servicio.</li>\n</ul>\n<pre><code>minikube get service bookmedik\n</code></pre>\n<p><img src=\"/images/bookmedik-7.png\" alt=\"bookmedik-0\"></p>\n<ul>\n<li>Pantallazo accediendo a la aplicación utilizando el ingress.</li>\n</ul>\n<p><img src=\"/images/bookmedik-1.png\" alt=\"bookmedik-1\"></p>\n<ul>\n<li>Elimina el despliegue de la base datos, vuelve a crearla y comprueba que la aplicación no ha perdido los datos.</li>\n</ul>\n<p><img src=\"/images/bookmedik-2.gif\" alt=\"bookmedik-2\"></p>\n<ul>\n<li>Escala la aplicación con 3 replicas. Muestra la salida oportuna para ver los pods que se han creado.</li>\n</ul>\n<pre><code>kubectl get pods\n\nkubectl scale deployment bookmedik-deployment --replicas=3\n</code></pre>\n<p><img src=\"/images/bookmedik-2.png\" alt=\"bookmedik-3\"></p>\n<ul>\n<li>Modifica la aplicación, vuelve a crear una imagen con la nueva versión y actualiza el despliegue. No te olvide de anotar la modificación. Muestra la salida del historial de despliegue, la salida de kubectl get all y un pantallazo donde se vea la modificación que has realizado.</li>\n</ul>\n<p>Nos vamos a bookmedik/core/app/view/pacients-view.php y cambiamos el texto Nombre completo por Nombre y Apellidos.</p>\n<p><img src=\"/images/bookmedik-3.png\" alt=\"bookmedik-4\"></p>\n<pre><code>docker build -t evanticks/bookmedik:v1_3 .\ndocker push evanticks/bookmedik:v1_3\n</code></pre>\n<p>Ahora editamos la el bookmedik-deployment.yaml y cambiamos la imagen por la nueva.</p>\n<p><img src=\"/images/bookmedik-4.png\" alt=\"bookmedik-5\"></p>\n<pre><code>kubectl apply -f bookmedik-deployment.yaml\n</code></pre>\n<pre><code>kubectl annotate deployments.apps/bookmedik-deployment kubernetes.io/change-cause=&quot;He cambiado el título del nombre del paciente&quot;\n</code></pre>\n<p><img src=\"/images/bookmedik-5.png\" alt=\"bookmedik-6\"></p>\n<p>Y aquí podemos ver como ha cambiado la aplicación:</p>\n<p><img src=\"/images/bookmedik-6.png\" alt=\"bookmedik-7\"></p>\n<p>Y aquí la salida de kubectl get all:</p>\n<pre><code>NAME                                        READY   STATUS    RESTARTS   AGE\npod/bookmedik-deployment-57988bfdd9-6zljr   1/1     Running   0          8m24s\npod/mariadb-deployment-7cd7fb9cd8-2tsts     1/1     Running   0          35m\n\nNAME                      TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE\nservice/bookmedik         NodePort    10.100.41.241   &lt;none&gt;        80:30814/TCP   62m\nservice/kubernetes        ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP        3h20m\nservice/mariadb-service   ClusterIP   10.103.3.28     &lt;none&gt;        3306/TCP       62m\n\nNAME                                   READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/bookmedik-deployment   1/1     1            1           54m\ndeployment.apps/mariadb-deployment     1/1     1            1           35m\n\nNAME                                              DESIRED   CURRENT   READY   AGE\nreplicaset.apps/bookmedik-deployment-57988bfdd9   1         1         1       8m24s\nreplicaset.apps/bookmedik-deployment-85bff5fdfd   0         0         0       54m\nreplicaset.apps/mariadb-deployment-7cd7fb9cd8     1         1         1       35m\n\n</code></pre>\n<ul>\n<li>Entrega la url del repositorio donde están los ficheros yaml.</li>\n</ul>\n<p><a href=\"https://github.com/Evanticks/kubernetes-practica\">https://github.com/Evanticks/kubernetes-practica</a></p>\n<h2 id=\"k3s\"><a class=\"markdownIt-Anchor\" href=\"#k3s\">#</a> K3S</h2>\n<p>Tendremos 4 nodos, un maestro y 3 esclavos. El maestro tendrá el rol de controlador y los esclavos de nodos de trabajo, lo haremos a través del siguiente vagrantfile:</p>\n<pre><code>Vagrant.configure(&quot;2&quot;) do |config|\n    config.vm.box = &quot;debian/bullseye64&quot;\n    config.vm.box_check_update = false\n    config.vm.synced_folder &quot;.&quot;, &quot;/vagrant&quot;, disabled: true\n    config.vm.provider &quot;libvirt&quot; do |v|\n      v.memory = 1024\n      v.cpus = 1\n    end\n    config.vm.define &quot;master&quot; do |master|\n      master.vm.hostname = &quot;master&quot;\n      master.vm.network &quot;private_network&quot;,\n        :libvirt__network_name =&gt; &quot;k3s-vagrant&quot;,\n        :ip =&gt; &quot;10.10.10.10&quot;,\n        :libvirt__dhcp_enabled =&gt; false,\n        :libvirt__forward_mode =&gt; &quot;veryisolated&quot;\n    end\n    config.vm.define &quot;nodo1&quot; do |nodo1|\n      nodo1.vm.hostname = &quot;nodo1&quot;\n      nodo1.vm.network &quot;private_network&quot;,\n        :libvirt__network_name =&gt; &quot;k3s-vagrant&quot;,\n        :ip =&gt; &quot;10.10.10.20&quot;,\n        :libvirt__dhcp_enabled =&gt; false,\n        :libvirt__forward_mode =&gt; &quot;veryisolated&quot;\n    end\n    config.vm.define &quot;nodo2&quot; do |nodo2|\n      nodo2.vm.hostname = &quot;nodo2&quot;\n      nodo2.vm.network &quot;private_network&quot;,\n        :libvirt__network_name =&gt; &quot;k3s-vagrant&quot;,\n        :ip =&gt; &quot;10.10.10.30&quot;,\n        :libvirt__dhcp_enabled =&gt; false,\n        :libvirt__forward_mode =&gt; &quot;veryisolated&quot;\n    end\n    config.vm.define &quot;nodo2&quot; do |nodo2|\n        nodo2.vm.hostname = &quot;nodo2&quot;\n        nodo2.vm.network &quot;private_network&quot;,\n          :libvirt__network_name =&gt; &quot;k3s-vagrant&quot;,\n          :ip =&gt; &quot;10.10.10.40&quot;,\n          :libvirt__dhcp_enabled =&gt; false,\n          :libvirt__forward_mode =&gt; &quot;veryisolated&quot;\n    end\n  end\n</code></pre>\n<p>Tras esto entramos en el nodo maestro y ejecutamos el siguiente comando como administrador:</p>\n<pre><code>apt update\n\napt install curl -y\n\ncurl -sfL https://get.k3s.io | sh -\n</code></pre>\n<p>Tras esto ejecutamso un  <code>cat /var/lib/rancher/k3s/server/node-token</code>  para que ese token lo podamos usar en los nodos esclavos.</p>\n<p>En los nodos esclavos utilizamos el siguiente comando:</p>\n<pre><code>apt update\n\napt install curl -y\n\ncurl -sfL https://get.k3s.io | K3S_URL=https://10.10.10.10:6443 K3S_TOKEN=K10cd69b71c10ac263c200b4bfb2747bff1d5563fdce2076454533940bc0be0b848::server:fdf97632c55a66fff13d217e2a5ca407 sh -\n</code></pre>\n<p>Tras esto, si lo hemos hecho en los 3 nodos esclavos, veremos en el nodo maestro que tenemos 4 nodos:</p>\n<pre><code>kubectl get nodes\n</code></pre>\n<p><img src=\"/images/bookmedik-8.png\" alt=\"k3s-1\"></p>\n<p>Ahora vamos a clonar el repositorio con nuestros yaml:</p>\n<pre><code>git clone https://github.com/Evanticks/kubernetes-practica.git\n</code></pre>\n<p>editamos el ingress.yaml para adaptarlo a nuestra configuración:</p>\n<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: bookmedik\nspec:\n  rules:\n  - host: www.bookantonio.org\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: bookmedik\n            port:\n              number: 80\n</code></pre>\n<p>Ahora ejecutamos un  <code>kubectl apply -f .</code>  para que se creen los recursos.</p>\n<p>Tan solo faltaría ingresar en /etc/hosts la ip de la máquina maestra y luego <a href=\"http://www.bookantonio.org\">www.bookantonio.org</a>.</p>\n<p><img src=\"/images/bookmedik-9.png\" alt=\"k3s-2\"></p>\n","site":{"data":{}},"length":8764,"excerpt":"","more":"<p><img src=\"/images/k8s-logo-2.png\" alt=\"kubernetes\"></p>\n<h2 id=\"archivos-de-configuración-de-kubernetes\"><a class=\"markdownIt-Anchor\" href=\"#archivos-de-configuración-de-kubernetes\">#</a> Archivos de configuración de Kubernetes</h2>\n<pre><code>kubectl create cm bd-datos --from-literal=bd_user=bookmedik \\\n                           --from-literal=bd_dbname=bookmedik \\\n                           --from-literal=bd_host=mariadb-service \\\n                           -o yaml --dry-run=client &gt; bd_datos_configmap.yaml\n\n\n\nkubectl create secret generic bd-passwords --from-literal=bd_password=bookmedik \\\n                                           --from-literal=bd_rootpassword=root \\\n                                           -o yaml --dry-run=client &gt; bd_passwords_secret.yaml\n</code></pre>\n<p>bookmedik-deployment.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: bookmedik-deployment\n  labels:\n    app: bookmedik\n    type: frontend\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: bookmedik\n      type: frontend\n  template:\n    metadata:\n      labels:\n        app: bookmedik\n        type: frontend\n    spec:\n      volumes:\n        - name: bookmedik-pvc\n          persistentVolumeClaim:\n            claimName: bookmedik-pvc\n      containers:\n        - name: contenedor-bookmedik\n          image: evanticks/bookmedik:v1_3\n#          volumeMounts:\n#            - mountPath: /var/www/html/\n#              name: bookmedik-pvc\n          ports:\n            - containerPort: 80\n              name: http-port\n          env:\n            - name: USUARIO_BOOKMEDIK\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_user\n            - name: NOMBRE_DB\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_dbname\n            - name: DATABASE_HOST\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_host\n            - name: CONTRA_BOOKMEDIK\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_password\n\n</code></pre>\n<p>mariadb-deployment.yaml</p>\n<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mariadb-deployment\n  labels:\n    app: bookmedik\n    type: database\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: bookmedik\n      type: database\n  template:\n    metadata:\n      labels:\n        app: bookmedik\n        type: database\n    spec:\n      volumes:\n        - name: mariadb-pvc\n          persistentVolumeClaim:\n            claimName: mariadb-pvc\n      containers:\n        - name: contenedor-mariadb\n          image: mariadb\n          ports:\n            - containerPort: 3306\n              name: db-port\n          volumeMounts:\n            - mountPath: &quot;/var/lib/mysql&quot;\n              name: mariadb-pvc\n          env:\n            - name: MYSQL_USER\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_user\n            - name: MYSQL_DATABASE\n              valueFrom:\n                configMapKeyRef:\n                  name: bd-datos\n                  key: bd_dbname\n#            - name: MARIADB_HOST\n#              valueFrom:\n#                configMapKeyRef:\n#                  name: bd-datos\n#                  key: bd_host\n            - name: MYSQL_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_password\n            - name: MYSQL_ROOT_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: bd-passwords\n                  key: bd_rootpassword\n</code></pre>\n<p>bookmedik-srv.yaml</p>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: bookmedik\n  labels:\n    app: bookmedik\n    type: frontend\nspec:\n  selector:\n    app: bookmedik\n    type: frontend\n  ports:\n  - name: http-sv-port\n    port: 80\n    targetPort: http-port\n  type: NodePort\n</code></pre>\n<p>maria-srv.yaml</p>\n<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: mariadb-service\n  labels:\n    app: bookmedik\n    type: database\nspec:\n  selector:\n    app: bookmedik\n    type: database\n  ports:\n  - port: 3306\n    targetPort: db-port\n  type: ClusterIP\n</code></pre>\n<p>bookmedik-pvc.yaml</p>\n<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n    name: bookmedik-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 4Gi\n</code></pre>\n<p>mariadb-pvc.yaml</p>\n<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n    name: mariadb-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 4Gi\n</code></pre>\n<p>cat ingress.yaml</p>\n<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: bookmedik\nspec:\n  rules:\n  - host: www.antonio.org\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: bookmedik\n            port:\n              number: 80\n</code></pre>\n<h2 id=\"entrega-de-la-práctica\"><a class=\"markdownIt-Anchor\" href=\"#entrega-de-la-práctica\">#</a> Entrega de la práctica</h2>\n<ul>\n<li>Salida de los comando que nos posibilitan ver los recursos que has creado en el cluster.</li>\n</ul>\n<pre><code>kubectl get all,pv,pvc,cm,secret\n\nNAME                                        READY   STATUS    RESTARTS   AGE\npod/bookmedik-deployment-57988bfdd9-6zljr   1/1     Running   0          9m12s\npod/mariadb-deployment-7cd7fb9cd8-2tsts     1/1     Running   0          36m\n\nNAME                      TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE\nservice/bookmedik         NodePort    10.100.41.241   &lt;none&gt;        80:30814/TCP   63m\nservice/kubernetes        ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP        3h21m\nservice/mariadb-service   ClusterIP   10.103.3.28     &lt;none&gt;        3306/TCP       63m\n\nNAME                                   READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/bookmedik-deployment   1/1     1            1           55m\ndeployment.apps/mariadb-deployment     1/1     1            1           36m\n\nNAME                                              DESIRED   CURRENT   READY   AGE\nreplicaset.apps/bookmedik-deployment-57988bfdd9   1         1         1       9m12s\nreplicaset.apps/bookmedik-deployment-85bff5fdfd   0         0         0       55m\nreplicaset.apps/mariadb-deployment-7cd7fb9cd8     1         1         1       36m\n\nNAME                                                        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                   STORAGECLASS   REASON   AGE\npersistentvolume/pvc-0f3db0b9-81d5-4574-abeb-2da92aa82a44   4Gi        RWO            Delete           Bound    default/bookmedik-pvc   standard                63m\npersistentvolume/pvc-fe594844-a9e4-4390-986a-7950611dee65   4Gi        RWO            Delete           Bound    default/mariadb-pvc     standard                63m\n\nNAME                                  STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\npersistentvolumeclaim/bookmedik-pvc   Bound    pvc-0f3db0b9-81d5-4574-abeb-2da92aa82a44   4Gi        RWO            standard       63m\npersistentvolumeclaim/mariadb-pvc     Bound    pvc-fe594844-a9e4-4390-986a-7950611dee65   4Gi        RWO            standard       63m\n\nNAME                         DATA   AGE\nconfigmap/bd-datos           3      63m\nconfigmap/kube-root-ca.crt   1      3h21m\n\nNAME                  TYPE     DATA   AGE\nsecret/bd-passwords   Opaque   2      63m\n\n</code></pre>\n<ul>\n<li>Pantallazo accediendo a la aplicación utilizando el servicio.</li>\n</ul>\n<pre><code>minikube get service bookmedik\n</code></pre>\n<p><img src=\"/images/bookmedik-7.png\" alt=\"bookmedik-0\"></p>\n<ul>\n<li>Pantallazo accediendo a la aplicación utilizando el ingress.</li>\n</ul>\n<p><img src=\"/images/bookmedik-1.png\" alt=\"bookmedik-1\"></p>\n<ul>\n<li>Elimina el despliegue de la base datos, vuelve a crearla y comprueba que la aplicación no ha perdido los datos.</li>\n</ul>\n<p><img src=\"/images/bookmedik-2.gif\" alt=\"bookmedik-2\"></p>\n<ul>\n<li>Escala la aplicación con 3 replicas. Muestra la salida oportuna para ver los pods que se han creado.</li>\n</ul>\n<pre><code>kubectl get pods\n\nkubectl scale deployment bookmedik-deployment --replicas=3\n</code></pre>\n<p><img src=\"/images/bookmedik-2.png\" alt=\"bookmedik-3\"></p>\n<ul>\n<li>Modifica la aplicación, vuelve a crear una imagen con la nueva versión y actualiza el despliegue. No te olvide de anotar la modificación. Muestra la salida del historial de despliegue, la salida de kubectl get all y un pantallazo donde se vea la modificación que has realizado.</li>\n</ul>\n<p>Nos vamos a bookmedik/core/app/view/pacients-view.php y cambiamos el texto Nombre completo por Nombre y Apellidos.</p>\n<p><img src=\"/images/bookmedik-3.png\" alt=\"bookmedik-4\"></p>\n<pre><code>docker build -t evanticks/bookmedik:v1_3 .\ndocker push evanticks/bookmedik:v1_3\n</code></pre>\n<p>Ahora editamos la el bookmedik-deployment.yaml y cambiamos la imagen por la nueva.</p>\n<p><img src=\"/images/bookmedik-4.png\" alt=\"bookmedik-5\"></p>\n<pre><code>kubectl apply -f bookmedik-deployment.yaml\n</code></pre>\n<pre><code>kubectl annotate deployments.apps/bookmedik-deployment kubernetes.io/change-cause=&quot;He cambiado el título del nombre del paciente&quot;\n</code></pre>\n<p><img src=\"/images/bookmedik-5.png\" alt=\"bookmedik-6\"></p>\n<p>Y aquí podemos ver como ha cambiado la aplicación:</p>\n<p><img src=\"/images/bookmedik-6.png\" alt=\"bookmedik-7\"></p>\n<p>Y aquí la salida de kubectl get all:</p>\n<pre><code>NAME                                        READY   STATUS    RESTARTS   AGE\npod/bookmedik-deployment-57988bfdd9-6zljr   1/1     Running   0          8m24s\npod/mariadb-deployment-7cd7fb9cd8-2tsts     1/1     Running   0          35m\n\nNAME                      TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE\nservice/bookmedik         NodePort    10.100.41.241   &lt;none&gt;        80:30814/TCP   62m\nservice/kubernetes        ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP        3h20m\nservice/mariadb-service   ClusterIP   10.103.3.28     &lt;none&gt;        3306/TCP       62m\n\nNAME                                   READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/bookmedik-deployment   1/1     1            1           54m\ndeployment.apps/mariadb-deployment     1/1     1            1           35m\n\nNAME                                              DESIRED   CURRENT   READY   AGE\nreplicaset.apps/bookmedik-deployment-57988bfdd9   1         1         1       8m24s\nreplicaset.apps/bookmedik-deployment-85bff5fdfd   0         0         0       54m\nreplicaset.apps/mariadb-deployment-7cd7fb9cd8     1         1         1       35m\n\n</code></pre>\n<ul>\n<li>Entrega la url del repositorio donde están los ficheros yaml.</li>\n</ul>\n<p><a href=\"https://github.com/Evanticks/kubernetes-practica\">https://github.com/Evanticks/kubernetes-practica</a></p>\n<h2 id=\"k3s\"><a class=\"markdownIt-Anchor\" href=\"#k3s\">#</a> K3S</h2>\n<p>Tendremos 4 nodos, un maestro y 3 esclavos. El maestro tendrá el rol de controlador y los esclavos de nodos de trabajo, lo haremos a través del siguiente vagrantfile:</p>\n<pre><code>Vagrant.configure(&quot;2&quot;) do |config|\n    config.vm.box = &quot;debian/bullseye64&quot;\n    config.vm.box_check_update = false\n    config.vm.synced_folder &quot;.&quot;, &quot;/vagrant&quot;, disabled: true\n    config.vm.provider &quot;libvirt&quot; do |v|\n      v.memory = 1024\n      v.cpus = 1\n    end\n    config.vm.define &quot;master&quot; do |master|\n      master.vm.hostname = &quot;master&quot;\n      master.vm.network &quot;private_network&quot;,\n        :libvirt__network_name =&gt; &quot;k3s-vagrant&quot;,\n        :ip =&gt; &quot;10.10.10.10&quot;,\n        :libvirt__dhcp_enabled =&gt; false,\n        :libvirt__forward_mode =&gt; &quot;veryisolated&quot;\n    end\n    config.vm.define &quot;nodo1&quot; do |nodo1|\n      nodo1.vm.hostname = &quot;nodo1&quot;\n      nodo1.vm.network &quot;private_network&quot;,\n        :libvirt__network_name =&gt; &quot;k3s-vagrant&quot;,\n        :ip =&gt; &quot;10.10.10.20&quot;,\n        :libvirt__dhcp_enabled =&gt; false,\n        :libvirt__forward_mode =&gt; &quot;veryisolated&quot;\n    end\n    config.vm.define &quot;nodo2&quot; do |nodo2|\n      nodo2.vm.hostname = &quot;nodo2&quot;\n      nodo2.vm.network &quot;private_network&quot;,\n        :libvirt__network_name =&gt; &quot;k3s-vagrant&quot;,\n        :ip =&gt; &quot;10.10.10.30&quot;,\n        :libvirt__dhcp_enabled =&gt; false,\n        :libvirt__forward_mode =&gt; &quot;veryisolated&quot;\n    end\n    config.vm.define &quot;nodo2&quot; do |nodo2|\n        nodo2.vm.hostname = &quot;nodo2&quot;\n        nodo2.vm.network &quot;private_network&quot;,\n          :libvirt__network_name =&gt; &quot;k3s-vagrant&quot;,\n          :ip =&gt; &quot;10.10.10.40&quot;,\n          :libvirt__dhcp_enabled =&gt; false,\n          :libvirt__forward_mode =&gt; &quot;veryisolated&quot;\n    end\n  end\n</code></pre>\n<p>Tras esto entramos en el nodo maestro y ejecutamos el siguiente comando como administrador:</p>\n<pre><code>apt update\n\napt install curl -y\n\ncurl -sfL https://get.k3s.io | sh -\n</code></pre>\n<p>Tras esto ejecutamso un  <code>cat /var/lib/rancher/k3s/server/node-token</code>  para que ese token lo podamos usar en los nodos esclavos.</p>\n<p>En los nodos esclavos utilizamos el siguiente comando:</p>\n<pre><code>apt update\n\napt install curl -y\n\ncurl -sfL https://get.k3s.io | K3S_URL=https://10.10.10.10:6443 K3S_TOKEN=K10cd69b71c10ac263c200b4bfb2747bff1d5563fdce2076454533940bc0be0b848::server:fdf97632c55a66fff13d217e2a5ca407 sh -\n</code></pre>\n<p>Tras esto, si lo hemos hecho en los 3 nodos esclavos, veremos en el nodo maestro que tenemos 4 nodos:</p>\n<pre><code>kubectl get nodes\n</code></pre>\n<p><img src=\"/images/bookmedik-8.png\" alt=\"k3s-1\"></p>\n<p>Ahora vamos a clonar el repositorio con nuestros yaml:</p>\n<pre><code>git clone https://github.com/Evanticks/kubernetes-practica.git\n</code></pre>\n<p>editamos el ingress.yaml para adaptarlo a nuestra configuración:</p>\n<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: bookmedik\nspec:\n  rules:\n  - host: www.bookantonio.org\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: bookmedik\n            port:\n              number: 80\n</code></pre>\n<p>Ahora ejecutamos un  <code>kubectl apply -f .</code>  para que se creen los recursos.</p>\n<p>Tan solo faltaría ingresar en /etc/hosts la ip de la máquina maestra y luego <a href=\"http://www.bookantonio.org\">www.bookantonio.org</a>.</p>\n<p><img src=\"/images/bookmedik-9.png\" alt=\"k3s-2\"></p>\n"},{"title":"Migración CentOS","Categoría":"Administración de sistemas","_content":"\n\n\n# Migración CentOS\n![](/images/centos-26.png)\n\n\n\n## Analiza el desencadenante de la retirada de centOS 8 del mercado\n\nLa retirada de Centos8 del mercado por parte de Redhat fue debido a que cambiaría la estrategia de desarrollo de CentOS.\n\nEn su lugar, Red Hat presentó CentOS Stream, que es una distribución continua de código abierto basada en el mismo código fuente que RHEL y que se actualiza más rápidamente que CentOS. Red Hat declaró que CentOS Stream se centraría en proporcionar a los desarrolladores una vista previa temprana del próximo lanzamiento de RHEL y en ofrecer una plataforma para el desarrollo de aplicaciones basadas en RHEL.\n\nCentOS 8 tenía un ciclo de vida útil previsto hasta 2029. \n\nCon la retirada, los usuarios ya no recibirán actualizaciones de seguridad ni parches de errores, lo que significa que tendrán que buscar alternativas para mantener sus sistemas seguros.\n\n\nMi opinión es que la retirada de centos 8 produce una desconfianza en la continuidad de los productosde redhat, aunque la nueva distribución de Rocky Linux puede ser una buena alternativa al cambio.\n\n\n\n\n## RHEL9\n\nDescargamos la iso de RHEL9 desde la página de redhat:\n\n![image](/images/centos-15.png)\n\nLuego procedemos a instalarlo en nuestra máquina virtual:\n\n![image](/images/centos-14.png)\n\nUna vez instalado, si ejecutamos subscription-manager register nos pedirá que introduzcamos el usuario y la contraseña de nuestra cuenta de redhat:\n\n![image](/images/centos-16.png)\n\nAhora podemos ver que la máquina está asociada a la cuenta, entonces nos hemos dado de alta.\n\nSi ahora realizamos un yum update pues tendremos a nuestra disposición los paquetes de RHEL9:\n\n![image](/images/centos-17.png)\n\nRed Hat Enterprise Linux 9 (RHEL9) es un sistema operativo de código abierto desarrollado y mantenido por Red Hat. Está diseñado para ser una plataforma estable y segura para entornos empresariales y de servidor.\n\n\n## CentOS Stream\n\n\nPrimero descargamos la iso de CentOS Stream desde la página de centos:\n\n![image](/images/centos-18.png)\n\n\n\nProcedemos a iniciar la máquina virtual con la iso de CentOS Stream:\n\n![image](/images/centos-19.png)\n\n\nInstalamos CentOS Stream:\n\n![image](/images/centos-20.png)\n\n\nY aquí podemos ver como está instalada:\n\n![image](/images/centos-21.png)\n\n\nAhora vamos a hablar un poco de lo que es Centos Stream y lo que lo diferencia de RHEL9:\nCentos Stream es una distribución que tiene apoyo de la comunidad, se actualiza constantemente entonces puede ser menos estable para un entorno de producción, pero es una buena opción para entornos de desarrollo y pruebas.\n\nAunque sea gratis, no cuenta con el soporte a largo plazo con la que cuenta RHEL.\n\n\n## Descarga de iso\n\nAlma Linux, soporte a largo plazo: Si necesita una distribución que ofrezca soporte a largo plazo, entonces AlmaLinux y VZLinux pueden ser buenas opciones. Ambas distribuciones ofrecen soporte hasta 2029, lo que significa que puede contar con actualizaciones de seguridad y parches de errores durante muchos años.\n\nRocky Linux, comunidad de usuarios: Si está buscando una distribución con una gran comunidad de usuarios, entonces Rocky Linux puede ser una buena opción. Esta distribución fue creada por la comunidad de usuarios de CentOS y tiene una gran cantidad de seguidores y desarrolladores.\n\neurolinux, enfoque en la estabilidad: Si necesita una distribución que se centre en la estabilidad y la confiabilidad, entonces euroLinux es una buena opción. Esta distribución se basa en CentOS, pero con enfoque en estabilidad y seguridad, lo que significa que puede ser una buena opción para entornos empresariales y de producción críticos.\n\nVZlinux, adaptabilidad y escalabilidad: Si necesita una distribución que pueda adaptarse a diferentes entornos y escalar según sea necesario, entonces VZLinux es una buena opción. Esta distribución es conocida por su capacidad para ejecutarse en diferentes entornos de virtualización y contenedores, lo que la hace ideal para proyectos de infraestructura en la nube y para empresas que buscan una distribución escalable.\n\nEn nuestro caso vamos a elegir eurolinux ya que nos vamos a basar en la simulación de un entorno de producción estable y seguro.\n\nDescargamos eurolinux desde la página oficial:\n\n![image](/images/centos-22.png)\n\nAhora vamos a instalar la iso de eurolinux en nuestra máquina virtual:\n\n![image](/images/centos-23.png)\n\nPodemos apreciar que tiene el mismo instalador que centos, ya que se basa en la misma distribución:\n\n![image](/images/centos-24.png)\n\n![image](/images/centos-25.png)\n\n\nUna vez instalado, podemos ver la distribución de eurolinux:\n\n![image](/images/centos-27.png)\n\nNo la he configurado con interfaz gráfica ya que sería para entornos de producción y sería aumentar el consumo de recursos, eurolinux es una alternativa muy buena para un entorno de producción estable y seguro como podría serlo debian o ubuntu.\n\n\n\n## Migración Centos - Rocky Linux\n\n\n### Migración de Centos 7 a 8\n\nusamos uname -r para ver si tenemos la última versión:\n\n![image](/images/centos-1.png)\n\n\nsudo vi /etc/sysconfig/network-scripts/ifcfg-eth0\n\nAhora que tenemos conexión nos vamos a la terminal y nos conectamos a través de ssh:\n\n```\nyum install epel-release -y\n```\n\n![image](/images/centos-2.png)\n\n```\n\nrpmconf -a\n\nsudo package-cleanup --leaves\n\nsudo package-cleanup --orphans\n\n\nsudo yum install -y dnf\n\ndnf remove -y yum yum-metadata-parser\n\nrm -Rf /etc/yum\n\ndnf -y makecache\n\ndnf -y upgrade\n```\n\n![image](/images/centos-3.png)\n\n\ntras varios minutos, ejecutaremos el siguiente comando:\n\ndnf install http://vault.centos.org/8.5.2111/BaseOS/x86_64/os/Packages/{centos-linux-repos-8-3.el8.noarch.rpm,centos-linux-release-8.5-1.2111.el8.noarch.rpm,centos-gpg-keys-8-3.el8.noarch.rpm}\n\n![image](/images/centos-5.png)\n\ndnf upgrade -y epel-release\n\n![image](/images/centos-6.png)\n\n```\ncd /etc/yum.repos.d\nsudo mkdir backups\nsudo mv CentOS-* backups\n```\n\n\nremovemos las dependencias sin utilizar:\n\n```\nrpm -e `rpm -q kernel` --nodeps\nrpm -e `rpm -q kernel-devel` --nodeps\n```\n\n```\ndnf -y --releasever=8 --allowerasing --setopt=deltarpm=false distro-sync\n```\n\ninstalamos kernel-core:\n\n```\ndnf -y install kernel-core\n```\n\nEl kernel-core incluye los controladores y módulos del kernel para la administración de dispositivos de hardware, el sistema de archivos, la gestión de procesos y otros componentes esenciales del sistema operativo.\n\n\n\n```\ndnf -y groupupdate \"Core\" \"Minimal Install\" \"Servidor con GUI\"\n\n\nsystemctl set-default graphical.target\n```\n\n```\nreboot\n```\n\n\n ### Migración de Centos 8 a Rocky Linux\n\nAhora al iniciar sesión podremos ver que tenemos el escritorio de GNOME de centos 8:\n\n![image](/images/centos-8.png)\n\n\nY ya tendríamos centos 8:\n\n![image](/images/centos-9.png)\n\n\nAhora vamos a proceder a migrar de Centos 8 que es una solución sin soporte a Rocky Linux:\n\n```\nwget https://raw.githubusercontent.com/rocky-linux/rocky-tools/main/migrate2rocky/migrate2rocky.sh\n\n\nchmod u+x migrate2rocky.sh\n./migrate2rocky.sh -r\n```\n\nCon la opción -r especificamos que va a migrarse a rocky linux\n\nTras esperar unos minutos, nos pedirá que reiniciemos el sistema:\n\n![image](/images/centos-10.png)\n\nAquí podemos ver el entorno gráfico\n\n![image](/images/centos-11.png)\n\nY si ejecutamos el comando `cat /etc/redhat-release` nos dirá que tenemos Rocky Linux 8.\n\n![image](/images/centos-13.png)\n\nCon esto ya podemos dar por finalizada la migración de centos 7 a 8, y de 8 a rocky linux.","source":"_posts/centos8.md","raw":"---\ntitle: Migración CentOS\nCategoría: Administración de sistemas\n---\n\n\n\n# Migración CentOS\n![](/images/centos-26.png)\n\n\n\n## Analiza el desencadenante de la retirada de centOS 8 del mercado\n\nLa retirada de Centos8 del mercado por parte de Redhat fue debido a que cambiaría la estrategia de desarrollo de CentOS.\n\nEn su lugar, Red Hat presentó CentOS Stream, que es una distribución continua de código abierto basada en el mismo código fuente que RHEL y que se actualiza más rápidamente que CentOS. Red Hat declaró que CentOS Stream se centraría en proporcionar a los desarrolladores una vista previa temprana del próximo lanzamiento de RHEL y en ofrecer una plataforma para el desarrollo de aplicaciones basadas en RHEL.\n\nCentOS 8 tenía un ciclo de vida útil previsto hasta 2029. \n\nCon la retirada, los usuarios ya no recibirán actualizaciones de seguridad ni parches de errores, lo que significa que tendrán que buscar alternativas para mantener sus sistemas seguros.\n\n\nMi opinión es que la retirada de centos 8 produce una desconfianza en la continuidad de los productosde redhat, aunque la nueva distribución de Rocky Linux puede ser una buena alternativa al cambio.\n\n\n\n\n## RHEL9\n\nDescargamos la iso de RHEL9 desde la página de redhat:\n\n![image](/images/centos-15.png)\n\nLuego procedemos a instalarlo en nuestra máquina virtual:\n\n![image](/images/centos-14.png)\n\nUna vez instalado, si ejecutamos subscription-manager register nos pedirá que introduzcamos el usuario y la contraseña de nuestra cuenta de redhat:\n\n![image](/images/centos-16.png)\n\nAhora podemos ver que la máquina está asociada a la cuenta, entonces nos hemos dado de alta.\n\nSi ahora realizamos un yum update pues tendremos a nuestra disposición los paquetes de RHEL9:\n\n![image](/images/centos-17.png)\n\nRed Hat Enterprise Linux 9 (RHEL9) es un sistema operativo de código abierto desarrollado y mantenido por Red Hat. Está diseñado para ser una plataforma estable y segura para entornos empresariales y de servidor.\n\n\n## CentOS Stream\n\n\nPrimero descargamos la iso de CentOS Stream desde la página de centos:\n\n![image](/images/centos-18.png)\n\n\n\nProcedemos a iniciar la máquina virtual con la iso de CentOS Stream:\n\n![image](/images/centos-19.png)\n\n\nInstalamos CentOS Stream:\n\n![image](/images/centos-20.png)\n\n\nY aquí podemos ver como está instalada:\n\n![image](/images/centos-21.png)\n\n\nAhora vamos a hablar un poco de lo que es Centos Stream y lo que lo diferencia de RHEL9:\nCentos Stream es una distribución que tiene apoyo de la comunidad, se actualiza constantemente entonces puede ser menos estable para un entorno de producción, pero es una buena opción para entornos de desarrollo y pruebas.\n\nAunque sea gratis, no cuenta con el soporte a largo plazo con la que cuenta RHEL.\n\n\n## Descarga de iso\n\nAlma Linux, soporte a largo plazo: Si necesita una distribución que ofrezca soporte a largo plazo, entonces AlmaLinux y VZLinux pueden ser buenas opciones. Ambas distribuciones ofrecen soporte hasta 2029, lo que significa que puede contar con actualizaciones de seguridad y parches de errores durante muchos años.\n\nRocky Linux, comunidad de usuarios: Si está buscando una distribución con una gran comunidad de usuarios, entonces Rocky Linux puede ser una buena opción. Esta distribución fue creada por la comunidad de usuarios de CentOS y tiene una gran cantidad de seguidores y desarrolladores.\n\neurolinux, enfoque en la estabilidad: Si necesita una distribución que se centre en la estabilidad y la confiabilidad, entonces euroLinux es una buena opción. Esta distribución se basa en CentOS, pero con enfoque en estabilidad y seguridad, lo que significa que puede ser una buena opción para entornos empresariales y de producción críticos.\n\nVZlinux, adaptabilidad y escalabilidad: Si necesita una distribución que pueda adaptarse a diferentes entornos y escalar según sea necesario, entonces VZLinux es una buena opción. Esta distribución es conocida por su capacidad para ejecutarse en diferentes entornos de virtualización y contenedores, lo que la hace ideal para proyectos de infraestructura en la nube y para empresas que buscan una distribución escalable.\n\nEn nuestro caso vamos a elegir eurolinux ya que nos vamos a basar en la simulación de un entorno de producción estable y seguro.\n\nDescargamos eurolinux desde la página oficial:\n\n![image](/images/centos-22.png)\n\nAhora vamos a instalar la iso de eurolinux en nuestra máquina virtual:\n\n![image](/images/centos-23.png)\n\nPodemos apreciar que tiene el mismo instalador que centos, ya que se basa en la misma distribución:\n\n![image](/images/centos-24.png)\n\n![image](/images/centos-25.png)\n\n\nUna vez instalado, podemos ver la distribución de eurolinux:\n\n![image](/images/centos-27.png)\n\nNo la he configurado con interfaz gráfica ya que sería para entornos de producción y sería aumentar el consumo de recursos, eurolinux es una alternativa muy buena para un entorno de producción estable y seguro como podría serlo debian o ubuntu.\n\n\n\n## Migración Centos - Rocky Linux\n\n\n### Migración de Centos 7 a 8\n\nusamos uname -r para ver si tenemos la última versión:\n\n![image](/images/centos-1.png)\n\n\nsudo vi /etc/sysconfig/network-scripts/ifcfg-eth0\n\nAhora que tenemos conexión nos vamos a la terminal y nos conectamos a través de ssh:\n\n```\nyum install epel-release -y\n```\n\n![image](/images/centos-2.png)\n\n```\n\nrpmconf -a\n\nsudo package-cleanup --leaves\n\nsudo package-cleanup --orphans\n\n\nsudo yum install -y dnf\n\ndnf remove -y yum yum-metadata-parser\n\nrm -Rf /etc/yum\n\ndnf -y makecache\n\ndnf -y upgrade\n```\n\n![image](/images/centos-3.png)\n\n\ntras varios minutos, ejecutaremos el siguiente comando:\n\ndnf install http://vault.centos.org/8.5.2111/BaseOS/x86_64/os/Packages/{centos-linux-repos-8-3.el8.noarch.rpm,centos-linux-release-8.5-1.2111.el8.noarch.rpm,centos-gpg-keys-8-3.el8.noarch.rpm}\n\n![image](/images/centos-5.png)\n\ndnf upgrade -y epel-release\n\n![image](/images/centos-6.png)\n\n```\ncd /etc/yum.repos.d\nsudo mkdir backups\nsudo mv CentOS-* backups\n```\n\n\nremovemos las dependencias sin utilizar:\n\n```\nrpm -e `rpm -q kernel` --nodeps\nrpm -e `rpm -q kernel-devel` --nodeps\n```\n\n```\ndnf -y --releasever=8 --allowerasing --setopt=deltarpm=false distro-sync\n```\n\ninstalamos kernel-core:\n\n```\ndnf -y install kernel-core\n```\n\nEl kernel-core incluye los controladores y módulos del kernel para la administración de dispositivos de hardware, el sistema de archivos, la gestión de procesos y otros componentes esenciales del sistema operativo.\n\n\n\n```\ndnf -y groupupdate \"Core\" \"Minimal Install\" \"Servidor con GUI\"\n\n\nsystemctl set-default graphical.target\n```\n\n```\nreboot\n```\n\n\n ### Migración de Centos 8 a Rocky Linux\n\nAhora al iniciar sesión podremos ver que tenemos el escritorio de GNOME de centos 8:\n\n![image](/images/centos-8.png)\n\n\nY ya tendríamos centos 8:\n\n![image](/images/centos-9.png)\n\n\nAhora vamos a proceder a migrar de Centos 8 que es una solución sin soporte a Rocky Linux:\n\n```\nwget https://raw.githubusercontent.com/rocky-linux/rocky-tools/main/migrate2rocky/migrate2rocky.sh\n\n\nchmod u+x migrate2rocky.sh\n./migrate2rocky.sh -r\n```\n\nCon la opción -r especificamos que va a migrarse a rocky linux\n\nTras esperar unos minutos, nos pedirá que reiniciemos el sistema:\n\n![image](/images/centos-10.png)\n\nAquí podemos ver el entorno gráfico\n\n![image](/images/centos-11.png)\n\nY si ejecutamos el comando `cat /etc/redhat-release` nos dirá que tenemos Rocky Linux 8.\n\n![image](/images/centos-13.png)\n\nCon esto ya podemos dar por finalizada la migración de centos 7 a 8, y de 8 a rocky linux.","slug":"centos8","published":1,"date":"2023-03-06T12:58:05.207Z","updated":"2023-03-08T11:29:50.828Z","_id":"clexrigym00001gi51q4mgq0g","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"migración-centos\"><a class=\"markdownIt-Anchor\" href=\"#migración-centos\">#</a> Migración CentOS</h1>\n<p><img src=\"/images/centos-26.png\" alt=\"\"></p>\n<h2 id=\"analiza-el-desencadenante-de-la-retirada-de-centos-8-del-mercado\"><a class=\"markdownIt-Anchor\" href=\"#analiza-el-desencadenante-de-la-retirada-de-centos-8-del-mercado\">#</a> Analiza el desencadenante de la retirada de centOS 8 del mercado</h2>\n<p>La retirada de Centos8 del mercado por parte de Redhat fue debido a que cambiaría la estrategia de desarrollo de CentOS.</p>\n<p>En su lugar, Red Hat presentó CentOS Stream, que es una distribución continua de código abierto basada en el mismo código fuente que RHEL y que se actualiza más rápidamente que CentOS. Red Hat declaró que CentOS Stream se centraría en proporcionar a los desarrolladores una vista previa temprana del próximo lanzamiento de RHEL y en ofrecer una plataforma para el desarrollo de aplicaciones basadas en RHEL.</p>\n<p>CentOS 8 tenía un ciclo de vida útil previsto hasta 2029.</p>\n<p>Con la retirada, los usuarios ya no recibirán actualizaciones de seguridad ni parches de errores, lo que significa que tendrán que buscar alternativas para mantener sus sistemas seguros.</p>\n<p>Mi opinión es que la retirada de centos 8 produce una desconfianza en la continuidad de los productosde redhat, aunque la nueva distribución de Rocky Linux puede ser una buena alternativa al cambio.</p>\n<h2 id=\"rhel9\"><a class=\"markdownIt-Anchor\" href=\"#rhel9\">#</a> RHEL9</h2>\n<p>Descargamos la iso de RHEL9 desde la página de redhat:</p>\n<p><img src=\"/images/centos-15.png\" alt=\"image\"></p>\n<p>Luego procedemos a instalarlo en nuestra máquina virtual:</p>\n<p><img src=\"/images/centos-14.png\" alt=\"image\"></p>\n<p>Una vez instalado, si ejecutamos subscription-manager register nos pedirá que introduzcamos el usuario y la contraseña de nuestra cuenta de redhat:</p>\n<p><img src=\"/images/centos-16.png\" alt=\"image\"></p>\n<p>Ahora podemos ver que la máquina está asociada a la cuenta, entonces nos hemos dado de alta.</p>\n<p>Si ahora realizamos un yum update pues tendremos a nuestra disposición los paquetes de RHEL9:</p>\n<p><img src=\"/images/centos-17.png\" alt=\"image\"></p>\n<p>Red Hat Enterprise Linux 9 (RHEL9) es un sistema operativo de código abierto desarrollado y mantenido por Red Hat. Está diseñado para ser una plataforma estable y segura para entornos empresariales y de servidor.</p>\n<h2 id=\"centos-stream\"><a class=\"markdownIt-Anchor\" href=\"#centos-stream\">#</a> CentOS Stream</h2>\n<p>Primero descargamos la iso de CentOS Stream desde la página de centos:</p>\n<p><img src=\"/images/centos-18.png\" alt=\"image\"></p>\n<p>Procedemos a iniciar la máquina virtual con la iso de CentOS Stream:</p>\n<p><img src=\"/images/centos-19.png\" alt=\"image\"></p>\n<p>Instalamos CentOS Stream:</p>\n<p><img src=\"/images/centos-20.png\" alt=\"image\"></p>\n<p>Y aquí podemos ver como está instalada:</p>\n<p><img src=\"/images/centos-21.png\" alt=\"image\"></p>\n<p>Ahora vamos a hablar un poco de lo que es Centos Stream y lo que lo diferencia de RHEL9:<br>\nCentos Stream es una distribución que tiene apoyo de la comunidad, se actualiza constantemente entonces puede ser menos estable para un entorno de producción, pero es una buena opción para entornos de desarrollo y pruebas.</p>\n<p>Aunque sea gratis, no cuenta con el soporte a largo plazo con la que cuenta RHEL.</p>\n<h2 id=\"descarga-de-iso\"><a class=\"markdownIt-Anchor\" href=\"#descarga-de-iso\">#</a> Descarga de iso</h2>\n<p>Alma Linux, soporte a largo plazo: Si necesita una distribución que ofrezca soporte a largo plazo, entonces AlmaLinux y VZLinux pueden ser buenas opciones. Ambas distribuciones ofrecen soporte hasta 2029, lo que significa que puede contar con actualizaciones de seguridad y parches de errores durante muchos años.</p>\n<p>Rocky Linux, comunidad de usuarios: Si está buscando una distribución con una gran comunidad de usuarios, entonces Rocky Linux puede ser una buena opción. Esta distribución fue creada por la comunidad de usuarios de CentOS y tiene una gran cantidad de seguidores y desarrolladores.</p>\n<p>eurolinux, enfoque en la estabilidad: Si necesita una distribución que se centre en la estabilidad y la confiabilidad, entonces euroLinux es una buena opción. Esta distribución se basa en CentOS, pero con enfoque en estabilidad y seguridad, lo que significa que puede ser una buena opción para entornos empresariales y de producción críticos.</p>\n<p>VZlinux, adaptabilidad y escalabilidad: Si necesita una distribución que pueda adaptarse a diferentes entornos y escalar según sea necesario, entonces VZLinux es una buena opción. Esta distribución es conocida por su capacidad para ejecutarse en diferentes entornos de virtualización y contenedores, lo que la hace ideal para proyectos de infraestructura en la nube y para empresas que buscan una distribución escalable.</p>\n<p>En nuestro caso vamos a elegir eurolinux ya que nos vamos a basar en la simulación de un entorno de producción estable y seguro.</p>\n<p>Descargamos eurolinux desde la página oficial:</p>\n<p><img src=\"/images/centos-22.png\" alt=\"image\"></p>\n<p>Ahora vamos a instalar la iso de eurolinux en nuestra máquina virtual:</p>\n<p><img src=\"/images/centos-23.png\" alt=\"image\"></p>\n<p>Podemos apreciar que tiene el mismo instalador que centos, ya que se basa en la misma distribución:</p>\n<p><img src=\"/images/centos-24.png\" alt=\"image\"></p>\n<p><img src=\"/images/centos-25.png\" alt=\"image\"></p>\n<p>Una vez instalado, podemos ver la distribución de eurolinux:</p>\n<p><img src=\"/images/centos-27.png\" alt=\"image\"></p>\n<p>No la he configurado con interfaz gráfica ya que sería para entornos de producción y sería aumentar el consumo de recursos, eurolinux es una alternativa muy buena para un entorno de producción estable y seguro como podría serlo debian o ubuntu.</p>\n<h2 id=\"migración-centos-rocky-linux\"><a class=\"markdownIt-Anchor\" href=\"#migración-centos-rocky-linux\">#</a> Migración Centos - Rocky Linux</h2>\n<h3 id=\"migración-de-centos-7-a-8\"><a class=\"markdownIt-Anchor\" href=\"#migración-de-centos-7-a-8\">#</a> Migración de Centos 7 a 8</h3>\n<p>usamos uname -r para ver si tenemos la última versión:</p>\n<p><img src=\"/images/centos-1.png\" alt=\"image\"></p>\n<p>sudo vi /etc/sysconfig/network-scripts/ifcfg-eth0</p>\n<p>Ahora que tenemos conexión nos vamos a la terminal y nos conectamos a través de ssh:</p>\n<pre><code>yum install epel-release -y\n</code></pre>\n<p><img src=\"/images/centos-2.png\" alt=\"image\"></p>\n<pre><code>\nrpmconf -a\n\nsudo package-cleanup --leaves\n\nsudo package-cleanup --orphans\n\n\nsudo yum install -y dnf\n\ndnf remove -y yum yum-metadata-parser\n\nrm -Rf /etc/yum\n\ndnf -y makecache\n\ndnf -y upgrade\n</code></pre>\n<p><img src=\"/images/centos-3.png\" alt=\"image\"></p>\n<p>tras varios minutos, ejecutaremos el siguiente comando:</p>\n<p centos-linux-repos-8-3.el8.noarch.rpm,centos-linux-release-8.5-1.2111.el8.noarch.rpm,centos-gpg-keys-8-3.el8.noarch.rpm=\"\">dnf install <a href=\"http://vault.centos.org/8.5.2111/BaseOS/x86_64/os/Packages/\">http://vault.centos.org/8.5.2111/BaseOS/x86_64/os/Packages/</a></p>\n<p><img src=\"/images/centos-5.png\" alt=\"image\"></p>\n<p>dnf upgrade -y epel-release</p>\n<p><img src=\"/images/centos-6.png\" alt=\"image\"></p>\n<pre><code>cd /etc/yum.repos.d\nsudo mkdir backups\nsudo mv CentOS-* backups\n</code></pre>\n<p>removemos las dependencias sin utilizar:</p>\n<pre><code>rpm -e `rpm -q kernel` --nodeps\nrpm -e `rpm -q kernel-devel` --nodeps\n</code></pre>\n<pre><code>dnf -y --releasever=8 --allowerasing --setopt=deltarpm=false distro-sync\n</code></pre>\n<p>instalamos kernel-core:</p>\n<pre><code>dnf -y install kernel-core\n</code></pre>\n<p>El kernel-core incluye los controladores y módulos del kernel para la administración de dispositivos de hardware, el sistema de archivos, la gestión de procesos y otros componentes esenciales del sistema operativo.</p>\n<pre><code>dnf -y groupupdate &quot;Core&quot; &quot;Minimal Install&quot; &quot;Servidor con GUI&quot;\n\n\nsystemctl set-default graphical.target\n</code></pre>\n<pre><code>reboot\n</code></pre>\n<h3 id=\"migración-de-centos-8-a-rocky-linux\"><a class=\"markdownIt-Anchor\" href=\"#migración-de-centos-8-a-rocky-linux\">#</a> Migración de Centos 8 a Rocky Linux</h3>\n<p>Ahora al iniciar sesión podremos ver que tenemos el escritorio de GNOME de centos 8:</p>\n<p><img src=\"/images/centos-8.png\" alt=\"image\"></p>\n<p>Y ya tendríamos centos 8:</p>\n<p><img src=\"/images/centos-9.png\" alt=\"image\"></p>\n<p>Ahora vamos a proceder a migrar de Centos 8 que es una solución sin soporte a Rocky Linux:</p>\n<pre><code>wget https://raw.githubusercontent.com/rocky-linux/rocky-tools/main/migrate2rocky/migrate2rocky.sh\n\n\nchmod u+x migrate2rocky.sh\n./migrate2rocky.sh -r\n</code></pre>\n<p>Con la opción -r especificamos que va a migrarse a rocky linux</p>\n<p>Tras esperar unos minutos, nos pedirá que reiniciemos el sistema:</p>\n<p><img src=\"/images/centos-10.png\" alt=\"image\"></p>\n<p>Aquí podemos ver el entorno gráfico</p>\n<p><img src=\"/images/centos-11.png\" alt=\"image\"></p>\n<p>Y si ejecutamos el comando  <code>cat /etc/redhat-release</code>  nos dirá que tenemos Rocky Linux 8.</p>\n<p><img src=\"/images/centos-13.png\" alt=\"image\"></p>\n<p>Con esto ya podemos dar por finalizada la migración de centos 7 a 8, y de 8 a rocky linux.</p>\n","site":{"data":{}},"length":5385,"excerpt":"","more":"<h1 id=\"migración-centos\"><a class=\"markdownIt-Anchor\" href=\"#migración-centos\">#</a> Migración CentOS</h1>\n<p><img src=\"/images/centos-26.png\" alt=\"\"></p>\n<h2 id=\"analiza-el-desencadenante-de-la-retirada-de-centos-8-del-mercado\"><a class=\"markdownIt-Anchor\" href=\"#analiza-el-desencadenante-de-la-retirada-de-centos-8-del-mercado\">#</a> Analiza el desencadenante de la retirada de centOS 8 del mercado</h2>\n<p>La retirada de Centos8 del mercado por parte de Redhat fue debido a que cambiaría la estrategia de desarrollo de CentOS.</p>\n<p>En su lugar, Red Hat presentó CentOS Stream, que es una distribución continua de código abierto basada en el mismo código fuente que RHEL y que se actualiza más rápidamente que CentOS. Red Hat declaró que CentOS Stream se centraría en proporcionar a los desarrolladores una vista previa temprana del próximo lanzamiento de RHEL y en ofrecer una plataforma para el desarrollo de aplicaciones basadas en RHEL.</p>\n<p>CentOS 8 tenía un ciclo de vida útil previsto hasta 2029.</p>\n<p>Con la retirada, los usuarios ya no recibirán actualizaciones de seguridad ni parches de errores, lo que significa que tendrán que buscar alternativas para mantener sus sistemas seguros.</p>\n<p>Mi opinión es que la retirada de centos 8 produce una desconfianza en la continuidad de los productosde redhat, aunque la nueva distribución de Rocky Linux puede ser una buena alternativa al cambio.</p>\n<h2 id=\"rhel9\"><a class=\"markdownIt-Anchor\" href=\"#rhel9\">#</a> RHEL9</h2>\n<p>Descargamos la iso de RHEL9 desde la página de redhat:</p>\n<p><img src=\"/images/centos-15.png\" alt=\"image\"></p>\n<p>Luego procedemos a instalarlo en nuestra máquina virtual:</p>\n<p><img src=\"/images/centos-14.png\" alt=\"image\"></p>\n<p>Una vez instalado, si ejecutamos subscription-manager register nos pedirá que introduzcamos el usuario y la contraseña de nuestra cuenta de redhat:</p>\n<p><img src=\"/images/centos-16.png\" alt=\"image\"></p>\n<p>Ahora podemos ver que la máquina está asociada a la cuenta, entonces nos hemos dado de alta.</p>\n<p>Si ahora realizamos un yum update pues tendremos a nuestra disposición los paquetes de RHEL9:</p>\n<p><img src=\"/images/centos-17.png\" alt=\"image\"></p>\n<p>Red Hat Enterprise Linux 9 (RHEL9) es un sistema operativo de código abierto desarrollado y mantenido por Red Hat. Está diseñado para ser una plataforma estable y segura para entornos empresariales y de servidor.</p>\n<h2 id=\"centos-stream\"><a class=\"markdownIt-Anchor\" href=\"#centos-stream\">#</a> CentOS Stream</h2>\n<p>Primero descargamos la iso de CentOS Stream desde la página de centos:</p>\n<p><img src=\"/images/centos-18.png\" alt=\"image\"></p>\n<p>Procedemos a iniciar la máquina virtual con la iso de CentOS Stream:</p>\n<p><img src=\"/images/centos-19.png\" alt=\"image\"></p>\n<p>Instalamos CentOS Stream:</p>\n<p><img src=\"/images/centos-20.png\" alt=\"image\"></p>\n<p>Y aquí podemos ver como está instalada:</p>\n<p><img src=\"/images/centos-21.png\" alt=\"image\"></p>\n<p>Ahora vamos a hablar un poco de lo que es Centos Stream y lo que lo diferencia de RHEL9:<br>\nCentos Stream es una distribución que tiene apoyo de la comunidad, se actualiza constantemente entonces puede ser menos estable para un entorno de producción, pero es una buena opción para entornos de desarrollo y pruebas.</p>\n<p>Aunque sea gratis, no cuenta con el soporte a largo plazo con la que cuenta RHEL.</p>\n<h2 id=\"descarga-de-iso\"><a class=\"markdownIt-Anchor\" href=\"#descarga-de-iso\">#</a> Descarga de iso</h2>\n<p>Alma Linux, soporte a largo plazo: Si necesita una distribución que ofrezca soporte a largo plazo, entonces AlmaLinux y VZLinux pueden ser buenas opciones. Ambas distribuciones ofrecen soporte hasta 2029, lo que significa que puede contar con actualizaciones de seguridad y parches de errores durante muchos años.</p>\n<p>Rocky Linux, comunidad de usuarios: Si está buscando una distribución con una gran comunidad de usuarios, entonces Rocky Linux puede ser una buena opción. Esta distribución fue creada por la comunidad de usuarios de CentOS y tiene una gran cantidad de seguidores y desarrolladores.</p>\n<p>eurolinux, enfoque en la estabilidad: Si necesita una distribución que se centre en la estabilidad y la confiabilidad, entonces euroLinux es una buena opción. Esta distribución se basa en CentOS, pero con enfoque en estabilidad y seguridad, lo que significa que puede ser una buena opción para entornos empresariales y de producción críticos.</p>\n<p>VZlinux, adaptabilidad y escalabilidad: Si necesita una distribución que pueda adaptarse a diferentes entornos y escalar según sea necesario, entonces VZLinux es una buena opción. Esta distribución es conocida por su capacidad para ejecutarse en diferentes entornos de virtualización y contenedores, lo que la hace ideal para proyectos de infraestructura en la nube y para empresas que buscan una distribución escalable.</p>\n<p>En nuestro caso vamos a elegir eurolinux ya que nos vamos a basar en la simulación de un entorno de producción estable y seguro.</p>\n<p>Descargamos eurolinux desde la página oficial:</p>\n<p><img src=\"/images/centos-22.png\" alt=\"image\"></p>\n<p>Ahora vamos a instalar la iso de eurolinux en nuestra máquina virtual:</p>\n<p><img src=\"/images/centos-23.png\" alt=\"image\"></p>\n<p>Podemos apreciar que tiene el mismo instalador que centos, ya que se basa en la misma distribución:</p>\n<p><img src=\"/images/centos-24.png\" alt=\"image\"></p>\n<p><img src=\"/images/centos-25.png\" alt=\"image\"></p>\n<p>Una vez instalado, podemos ver la distribución de eurolinux:</p>\n<p><img src=\"/images/centos-27.png\" alt=\"image\"></p>\n<p>No la he configurado con interfaz gráfica ya que sería para entornos de producción y sería aumentar el consumo de recursos, eurolinux es una alternativa muy buena para un entorno de producción estable y seguro como podría serlo debian o ubuntu.</p>\n<h2 id=\"migración-centos-rocky-linux\"><a class=\"markdownIt-Anchor\" href=\"#migración-centos-rocky-linux\">#</a> Migración Centos - Rocky Linux</h2>\n<h3 id=\"migración-de-centos-7-a-8\"><a class=\"markdownIt-Anchor\" href=\"#migración-de-centos-7-a-8\">#</a> Migración de Centos 7 a 8</h3>\n<p>usamos uname -r para ver si tenemos la última versión:</p>\n<p><img src=\"/images/centos-1.png\" alt=\"image\"></p>\n<p>sudo vi /etc/sysconfig/network-scripts/ifcfg-eth0</p>\n<p>Ahora que tenemos conexión nos vamos a la terminal y nos conectamos a través de ssh:</p>\n<pre><code>yum install epel-release -y\n</code></pre>\n<p><img src=\"/images/centos-2.png\" alt=\"image\"></p>\n<pre><code>\nrpmconf -a\n\nsudo package-cleanup --leaves\n\nsudo package-cleanup --orphans\n\n\nsudo yum install -y dnf\n\ndnf remove -y yum yum-metadata-parser\n\nrm -Rf /etc/yum\n\ndnf -y makecache\n\ndnf -y upgrade\n</code></pre>\n<p><img src=\"/images/centos-3.png\" alt=\"image\"></p>\n<p>tras varios minutos, ejecutaremos el siguiente comando:</p>\n<p centos-linux-repos-8-3.el8.noarch.rpm,centos-linux-release-8.5-1.2111.el8.noarch.rpm,centos-gpg-keys-8-3.el8.noarch.rpm=\"\">dnf install <a href=\"http://vault.centos.org/8.5.2111/BaseOS/x86_64/os/Packages/\">http://vault.centos.org/8.5.2111/BaseOS/x86_64/os/Packages/</a></p>\n<p><img src=\"/images/centos-5.png\" alt=\"image\"></p>\n<p>dnf upgrade -y epel-release</p>\n<p><img src=\"/images/centos-6.png\" alt=\"image\"></p>\n<pre><code>cd /etc/yum.repos.d\nsudo mkdir backups\nsudo mv CentOS-* backups\n</code></pre>\n<p>removemos las dependencias sin utilizar:</p>\n<pre><code>rpm -e `rpm -q kernel` --nodeps\nrpm -e `rpm -q kernel-devel` --nodeps\n</code></pre>\n<pre><code>dnf -y --releasever=8 --allowerasing --setopt=deltarpm=false distro-sync\n</code></pre>\n<p>instalamos kernel-core:</p>\n<pre><code>dnf -y install kernel-core\n</code></pre>\n<p>El kernel-core incluye los controladores y módulos del kernel para la administración de dispositivos de hardware, el sistema de archivos, la gestión de procesos y otros componentes esenciales del sistema operativo.</p>\n<pre><code>dnf -y groupupdate &quot;Core&quot; &quot;Minimal Install&quot; &quot;Servidor con GUI&quot;\n\n\nsystemctl set-default graphical.target\n</code></pre>\n<pre><code>reboot\n</code></pre>\n<h3 id=\"migración-de-centos-8-a-rocky-linux\"><a class=\"markdownIt-Anchor\" href=\"#migración-de-centos-8-a-rocky-linux\">#</a> Migración de Centos 8 a Rocky Linux</h3>\n<p>Ahora al iniciar sesión podremos ver que tenemos el escritorio de GNOME de centos 8:</p>\n<p><img src=\"/images/centos-8.png\" alt=\"image\"></p>\n<p>Y ya tendríamos centos 8:</p>\n<p><img src=\"/images/centos-9.png\" alt=\"image\"></p>\n<p>Ahora vamos a proceder a migrar de Centos 8 que es una solución sin soporte a Rocky Linux:</p>\n<pre><code>wget https://raw.githubusercontent.com/rocky-linux/rocky-tools/main/migrate2rocky/migrate2rocky.sh\n\n\nchmod u+x migrate2rocky.sh\n./migrate2rocky.sh -r\n</code></pre>\n<p>Con la opción -r especificamos que va a migrarse a rocky linux</p>\n<p>Tras esperar unos minutos, nos pedirá que reiniciemos el sistema:</p>\n<p><img src=\"/images/centos-10.png\" alt=\"image\"></p>\n<p>Aquí podemos ver el entorno gráfico</p>\n<p><img src=\"/images/centos-11.png\" alt=\"image\"></p>\n<p>Y si ejecutamos el comando  <code>cat /etc/redhat-release</code>  nos dirá que tenemos Rocky Linux 8.</p>\n<p><img src=\"/images/centos-13.png\" alt=\"image\"></p>\n<p>Con esto ya podemos dar por finalizada la migración de centos 7 a 8, y de 8 a rocky linux.</p>\n"},{"title":"Introducción a Jenkins","Categoría":"Aplicaciones web","_content":"\n![Jenkins](/images/jenkins-intro.png)\n\n# Introducción a Jenkins\n\n## Taller 1: Corrector ortográfico de documentos markdown (test)\n\nLa URL del tu repositorio GitHub.\n\nhttps://github.com/Evanticks/ic-diccionario\n\nEl contenido de la tu fichero Jenkinfile.\n\n```\npipeline {\n    agent {\n        docker { image 'debian'\n        args '-u root:root'\n        }\n    }\n    stages {\n        stage('Clone') {\n            steps {\n                git branch:'master',url:'https://github.com/Evanticks/ic-diccionario.git'\n            }\n        }\n        stage('Install') {\n            steps {\n                sh 'apt-get update && apt-get install -y aspell-es ' \n            }\n        }\n        stage('Test')\n        {\n            steps {\n                sh '''\n                export LC_ALL=C.UTF-8\n                OUTPUT=`cat doc/*.md | aspell list -d es -p ./.aspell.es.pws`; if [ -n \"$OUTPUT\" ]; then echo $OUTPUT; exit 1; fi'''\n            }\n        }\n    }\n    post {\n         always {\n          mail to: 'root@antonio.gonzalonazareno.org',\n          subject: \"Status of pipeline: ${currentBuild.fullDisplayName}\",\n          body: \"${env.BUILD_URL} has result ${currentBuild.result}\"\n        }\n      }\n}\n```\n\n\nUna captura de pantalla donde se vea la configuración del disparador del pipeline.\n\n\n![Jenkins](/images/jenkins-taller-1-1.png)\n\n\nUna captura de un correo electrónico recibido sin ningún error, y otro con algún error en al ejecución del pipeline.\n\n![Jenkins](/images/jenkins-taller-1-2.png)\n\nAquí podemos ver que al volver a construir el pipeline, nos ha enviado un correo electrónico indicando que el pipeline ha fallado.\n\n![Jenkins](/images/jenkins-taller-1-3.png)\n\n\nY eso es debido a que he puesto a drede un error ortográfico:\n\n![Jenkins](/images/jenkins-taller-1-4.png)\n\n\n## Taller 2: Comprobación de HTML5 válido y despliegue en surge.sh (test y deploy)\n\nLa URL del tu repositorio GitHub.\n\nhttps://github.com/Evanticks/ic-html5\n\nEl contenido de la tu fichero Jenkinfile.\n\n```\npipeline {\n    environment {\n        TOKEN = credentials('SURGE_TOKEN')\n      }\n    agent {\n        docker { image 'josedom24/debian-npm'\n        args '-u root:root'\n        }\n    }\n    stages {\n        stage('Clone') {\n            steps {\n                git branch:'master',url:'https://github.com/Evanticks/ic-html5.git'\n            }\n        }\n        \n        stage('Install surge')\n        {\n            steps {\n                sh 'npm install -g surge'\n            }\n        }\n        stage('Deploy')\n        {\n            steps{\n                sh 'surge ./_build/ antoniomarchan.surge.sh --token $TOKEN'\n            }\n        }\n        \n    }\n}\n```\n\nCaptura de pantalla donde se vea donde has creado las credenciales necesarias.\n\n![Jenkins](/images/jenkins-taller-2-1.png)\n\nExplica la configuración necesaria y una prueba de funcionamiento para que se dispare el pipeline cuando hagamos un push al repositorio.\n\n\nPrimero exponemos el servicio de Jenkins a una url pública gracias a ngrok como explico en https://dit.gonzalonazareno.org/redmine/boards/16/topics/1016\n\nLuego hacemos las credenciales para que Jenkins pueda publicar a través del token de surge.sh\n\nLuego crearemos un webhook ingresando la url pública de ngrok.\n\nY ya con eso a la hora de hacer un push, Jenkins se encargará de construir el pipelinem, tardará 1 minuto.\n\n![Jenkins](/images/jenkins-taller-2-2.gif)\n\n\n## Taller 3: Integración continua de aplicación django (Test)\n\n\nUna captura de pantalla donde se vea la salida de un build que se ha ejecutado de manera correcta.\n\n![Jenkins](/images/jenkins-taller-3-3.png)\n\nModifica el código de la aplicación para que se produzca un fallo en el código. *Recuerda que para hacer fallar un test, no hay que tocar el fichero test.py. Los test no se pasan porque al modificar el código de la aplicación se dejan de cumplir las condiciones indicadas en los test. Recuerda no elegir en el que hemos visto en este taller:mensaje *“No polls are available” **.\n\n![Jenkins](/images/jenkins-taller-3-4.png)\n\n\nUna captura de pantalla donde se vea la salida de un build que se ha ejecutado con errores de testeo.\n\n\n![Jenkins](/images/jenkins-taller-3-5.png)","source":"_posts/jenkins-intro.md","raw":"---\ntitle: Introducción a Jenkins\nCategoría: Aplicaciones web\n---\n\n![Jenkins](/images/jenkins-intro.png)\n\n# Introducción a Jenkins\n\n## Taller 1: Corrector ortográfico de documentos markdown (test)\n\nLa URL del tu repositorio GitHub.\n\nhttps://github.com/Evanticks/ic-diccionario\n\nEl contenido de la tu fichero Jenkinfile.\n\n```\npipeline {\n    agent {\n        docker { image 'debian'\n        args '-u root:root'\n        }\n    }\n    stages {\n        stage('Clone') {\n            steps {\n                git branch:'master',url:'https://github.com/Evanticks/ic-diccionario.git'\n            }\n        }\n        stage('Install') {\n            steps {\n                sh 'apt-get update && apt-get install -y aspell-es ' \n            }\n        }\n        stage('Test')\n        {\n            steps {\n                sh '''\n                export LC_ALL=C.UTF-8\n                OUTPUT=`cat doc/*.md | aspell list -d es -p ./.aspell.es.pws`; if [ -n \"$OUTPUT\" ]; then echo $OUTPUT; exit 1; fi'''\n            }\n        }\n    }\n    post {\n         always {\n          mail to: 'root@antonio.gonzalonazareno.org',\n          subject: \"Status of pipeline: ${currentBuild.fullDisplayName}\",\n          body: \"${env.BUILD_URL} has result ${currentBuild.result}\"\n        }\n      }\n}\n```\n\n\nUna captura de pantalla donde se vea la configuración del disparador del pipeline.\n\n\n![Jenkins](/images/jenkins-taller-1-1.png)\n\n\nUna captura de un correo electrónico recibido sin ningún error, y otro con algún error en al ejecución del pipeline.\n\n![Jenkins](/images/jenkins-taller-1-2.png)\n\nAquí podemos ver que al volver a construir el pipeline, nos ha enviado un correo electrónico indicando que el pipeline ha fallado.\n\n![Jenkins](/images/jenkins-taller-1-3.png)\n\n\nY eso es debido a que he puesto a drede un error ortográfico:\n\n![Jenkins](/images/jenkins-taller-1-4.png)\n\n\n## Taller 2: Comprobación de HTML5 válido y despliegue en surge.sh (test y deploy)\n\nLa URL del tu repositorio GitHub.\n\nhttps://github.com/Evanticks/ic-html5\n\nEl contenido de la tu fichero Jenkinfile.\n\n```\npipeline {\n    environment {\n        TOKEN = credentials('SURGE_TOKEN')\n      }\n    agent {\n        docker { image 'josedom24/debian-npm'\n        args '-u root:root'\n        }\n    }\n    stages {\n        stage('Clone') {\n            steps {\n                git branch:'master',url:'https://github.com/Evanticks/ic-html5.git'\n            }\n        }\n        \n        stage('Install surge')\n        {\n            steps {\n                sh 'npm install -g surge'\n            }\n        }\n        stage('Deploy')\n        {\n            steps{\n                sh 'surge ./_build/ antoniomarchan.surge.sh --token $TOKEN'\n            }\n        }\n        \n    }\n}\n```\n\nCaptura de pantalla donde se vea donde has creado las credenciales necesarias.\n\n![Jenkins](/images/jenkins-taller-2-1.png)\n\nExplica la configuración necesaria y una prueba de funcionamiento para que se dispare el pipeline cuando hagamos un push al repositorio.\n\n\nPrimero exponemos el servicio de Jenkins a una url pública gracias a ngrok como explico en https://dit.gonzalonazareno.org/redmine/boards/16/topics/1016\n\nLuego hacemos las credenciales para que Jenkins pueda publicar a través del token de surge.sh\n\nLuego crearemos un webhook ingresando la url pública de ngrok.\n\nY ya con eso a la hora de hacer un push, Jenkins se encargará de construir el pipelinem, tardará 1 minuto.\n\n![Jenkins](/images/jenkins-taller-2-2.gif)\n\n\n## Taller 3: Integración continua de aplicación django (Test)\n\n\nUna captura de pantalla donde se vea la salida de un build que se ha ejecutado de manera correcta.\n\n![Jenkins](/images/jenkins-taller-3-3.png)\n\nModifica el código de la aplicación para que se produzca un fallo en el código. *Recuerda que para hacer fallar un test, no hay que tocar el fichero test.py. Los test no se pasan porque al modificar el código de la aplicación se dejan de cumplir las condiciones indicadas en los test. Recuerda no elegir en el que hemos visto en este taller:mensaje *“No polls are available” **.\n\n![Jenkins](/images/jenkins-taller-3-4.png)\n\n\nUna captura de pantalla donde se vea la salida de un build que se ha ejecutado con errores de testeo.\n\n\n![Jenkins](/images/jenkins-taller-3-5.png)","slug":"jenkins-intro","published":1,"date":"2023-03-08T12:34:56.264Z","updated":"2023-03-09T01:30:49.445Z","_id":"clf02qas900001ni57t6x4j84","comments":1,"layout":"post","photos":[],"link":"","content":"<p><img src=\"/images/jenkins-intro.png\" alt=\"Jenkins\"></p>\n<h1 id=\"introducción-a-jenkins\"><a class=\"markdownIt-Anchor\" href=\"#introducción-a-jenkins\">#</a> Introducción a Jenkins</h1>\n<h2 id=\"taller-1-corrector-ortográfico-de-documentos-markdown-test\"><a class=\"markdownIt-Anchor\" href=\"#taller-1-corrector-ortográfico-de-documentos-markdown-test\">#</a> Taller 1: Corrector ortográfico de documentos markdown (test)</h2>\n<p>La URL del tu repositorio GitHub.</p>\n<p><a href=\"https://github.com/Evanticks/ic-diccionario\">https://github.com/Evanticks/ic-diccionario</a></p>\n<p>El contenido de la tu fichero Jenkinfile.</p>\n<pre><code>pipeline &#123;\n    agent &#123;\n        docker &#123; image 'debian'\n        args '-u root:root'\n        &#125;\n    &#125;\n    stages &#123;\n        stage('Clone') &#123;\n            steps &#123;\n                git branch:'master',url:'https://github.com/Evanticks/ic-diccionario.git'\n            &#125;\n        &#125;\n        stage('Install') &#123;\n            steps &#123;\n                sh 'apt-get update &amp;&amp; apt-get install -y aspell-es ' \n            &#125;\n        &#125;\n        stage('Test')\n        &#123;\n            steps &#123;\n                sh '''\n                export LC_ALL=C.UTF-8\n                OUTPUT=`cat doc/*.md | aspell list -d es -p ./.aspell.es.pws`; if [ -n &quot;$OUTPUT&quot; ]; then echo $OUTPUT; exit 1; fi'''\n            &#125;\n        &#125;\n    &#125;\n    post &#123;\n         always &#123;\n          mail to: 'root@antonio.gonzalonazareno.org',\n          subject: &quot;Status of pipeline: $&#123;currentBuild.fullDisplayName&#125;&quot;,\n          body: &quot;$&#123;env.BUILD_URL&#125; has result $&#123;currentBuild.result&#125;&quot;\n        &#125;\n      &#125;\n&#125;\n</code></pre>\n<p>Una captura de pantalla donde se vea la configuración del disparador del pipeline.</p>\n<p><img src=\"/images/jenkins-taller-1-1.png\" alt=\"Jenkins\"></p>\n<p>Una captura de un correo electrónico recibido sin ningún error, y otro con algún error en al ejecución del pipeline.</p>\n<p><img src=\"/images/jenkins-taller-1-2.png\" alt=\"Jenkins\"></p>\n<p>Aquí podemos ver que al volver a construir el pipeline, nos ha enviado un correo electrónico indicando que el pipeline ha fallado.</p>\n<p><img src=\"/images/jenkins-taller-1-3.png\" alt=\"Jenkins\"></p>\n<p>Y eso es debido a que he puesto a drede un error ortográfico:</p>\n<p><img src=\"/images/jenkins-taller-1-4.png\" alt=\"Jenkins\"></p>\n<h2 id=\"taller-2-comprobación-de-html5-válido-y-despliegue-en-surgesh-test-y-deploy\"><a class=\"markdownIt-Anchor\" href=\"#taller-2-comprobación-de-html5-válido-y-despliegue-en-surgesh-test-y-deploy\">#</a> Taller 2: Comprobación de HTML5 válido y despliegue en <a href=\"http://surge.sh\">surge.sh</a> (test y deploy)</h2>\n<p>La URL del tu repositorio GitHub.</p>\n<p><a href=\"https://github.com/Evanticks/ic-html5\">https://github.com/Evanticks/ic-html5</a></p>\n<p>El contenido de la tu fichero Jenkinfile.</p>\n<pre><code>pipeline &#123;\n    environment &#123;\n        TOKEN = credentials('SURGE_TOKEN')\n      &#125;\n    agent &#123;\n        docker &#123; image 'josedom24/debian-npm'\n        args '-u root:root'\n        &#125;\n    &#125;\n    stages &#123;\n        stage('Clone') &#123;\n            steps &#123;\n                git branch:'master',url:'https://github.com/Evanticks/ic-html5.git'\n            &#125;\n        &#125;\n        \n        stage('Install surge')\n        &#123;\n            steps &#123;\n                sh 'npm install -g surge'\n            &#125;\n        &#125;\n        stage('Deploy')\n        &#123;\n            steps&#123;\n                sh 'surge ./_build/ antoniomarchan.surge.sh --token $TOKEN'\n            &#125;\n        &#125;\n        \n    &#125;\n&#125;\n</code></pre>\n<p>Captura de pantalla donde se vea donde has creado las credenciales necesarias.</p>\n<p><img src=\"/images/jenkins-taller-2-1.png\" alt=\"Jenkins\"></p>\n<p>Explica la configuración necesaria y una prueba de funcionamiento para que se dispare el pipeline cuando hagamos un push al repositorio.</p>\n<p>Primero exponemos el servicio de Jenkins a una url pública gracias a ngrok como explico en <a href=\"https://dit.gonzalonazareno.org/redmine/boards/16/topics/1016\">https://dit.gonzalonazareno.org/redmine/boards/16/topics/1016</a></p>\n<p>Luego hacemos las credenciales para que Jenkins pueda publicar a través del token de <a href=\"http://surge.sh\">surge.sh</a></p>\n<p>Luego crearemos un webhook ingresando la url pública de ngrok.</p>\n<p>Y ya con eso a la hora de hacer un push, Jenkins se encargará de construir el pipelinem, tardará 1 minuto.</p>\n<p><img src=\"/images/jenkins-taller-2-2.gif\" alt=\"Jenkins\"></p>\n<h2 id=\"taller-3-integración-continua-de-aplicación-django-test\"><a class=\"markdownIt-Anchor\" href=\"#taller-3-integración-continua-de-aplicación-django-test\">#</a> Taller 3: Integración continua de aplicación django (Test)</h2>\n<p>Una captura de pantalla donde se vea la salida de un build que se ha ejecutado de manera correcta.</p>\n<p><img src=\"/images/jenkins-taller-3-3.png\" alt=\"Jenkins\"></p>\n<p>Modifica el código de la aplicación para que se produzca un fallo en el código. *Recuerda que para hacer fallar un test, no hay que tocar el fichero <a href=\"http://test.py\">test.py</a>. Los test no se pasan porque al modificar el código de la aplicación se dejan de cumplir las condiciones indicadas en los test. Recuerda no elegir en el que hemos visto en este taller:mensaje *“No polls are available” **.</p>\n<p><img src=\"/images/jenkins-taller-3-4.png\" alt=\"Jenkins\"></p>\n<p>Una captura de pantalla donde se vea la salida de un build que se ha ejecutado con errores de testeo.</p>\n<p><img src=\"/images/jenkins-taller-3-5.png\" alt=\"Jenkins\"></p>\n","site":{"data":{}},"length":2915,"excerpt":"","more":"<p><img src=\"/images/jenkins-intro.png\" alt=\"Jenkins\"></p>\n<h1 id=\"introducción-a-jenkins\"><a class=\"markdownIt-Anchor\" href=\"#introducción-a-jenkins\">#</a> Introducción a Jenkins</h1>\n<h2 id=\"taller-1-corrector-ortográfico-de-documentos-markdown-test\"><a class=\"markdownIt-Anchor\" href=\"#taller-1-corrector-ortográfico-de-documentos-markdown-test\">#</a> Taller 1: Corrector ortográfico de documentos markdown (test)</h2>\n<p>La URL del tu repositorio GitHub.</p>\n<p><a href=\"https://github.com/Evanticks/ic-diccionario\">https://github.com/Evanticks/ic-diccionario</a></p>\n<p>El contenido de la tu fichero Jenkinfile.</p>\n<pre><code>pipeline &#123;\n    agent &#123;\n        docker &#123; image 'debian'\n        args '-u root:root'\n        &#125;\n    &#125;\n    stages &#123;\n        stage('Clone') &#123;\n            steps &#123;\n                git branch:'master',url:'https://github.com/Evanticks/ic-diccionario.git'\n            &#125;\n        &#125;\n        stage('Install') &#123;\n            steps &#123;\n                sh 'apt-get update &amp;&amp; apt-get install -y aspell-es ' \n            &#125;\n        &#125;\n        stage('Test')\n        &#123;\n            steps &#123;\n                sh '''\n                export LC_ALL=C.UTF-8\n                OUTPUT=`cat doc/*.md | aspell list -d es -p ./.aspell.es.pws`; if [ -n &quot;$OUTPUT&quot; ]; then echo $OUTPUT; exit 1; fi'''\n            &#125;\n        &#125;\n    &#125;\n    post &#123;\n         always &#123;\n          mail to: 'root@antonio.gonzalonazareno.org',\n          subject: &quot;Status of pipeline: $&#123;currentBuild.fullDisplayName&#125;&quot;,\n          body: &quot;$&#123;env.BUILD_URL&#125; has result $&#123;currentBuild.result&#125;&quot;\n        &#125;\n      &#125;\n&#125;\n</code></pre>\n<p>Una captura de pantalla donde se vea la configuración del disparador del pipeline.</p>\n<p><img src=\"/images/jenkins-taller-1-1.png\" alt=\"Jenkins\"></p>\n<p>Una captura de un correo electrónico recibido sin ningún error, y otro con algún error en al ejecución del pipeline.</p>\n<p><img src=\"/images/jenkins-taller-1-2.png\" alt=\"Jenkins\"></p>\n<p>Aquí podemos ver que al volver a construir el pipeline, nos ha enviado un correo electrónico indicando que el pipeline ha fallado.</p>\n<p><img src=\"/images/jenkins-taller-1-3.png\" alt=\"Jenkins\"></p>\n<p>Y eso es debido a que he puesto a drede un error ortográfico:</p>\n<p><img src=\"/images/jenkins-taller-1-4.png\" alt=\"Jenkins\"></p>\n<h2 id=\"taller-2-comprobación-de-html5-válido-y-despliegue-en-surgesh-test-y-deploy\"><a class=\"markdownIt-Anchor\" href=\"#taller-2-comprobación-de-html5-válido-y-despliegue-en-surgesh-test-y-deploy\">#</a> Taller 2: Comprobación de HTML5 válido y despliegue en <a href=\"http://surge.sh\">surge.sh</a> (test y deploy)</h2>\n<p>La URL del tu repositorio GitHub.</p>\n<p><a href=\"https://github.com/Evanticks/ic-html5\">https://github.com/Evanticks/ic-html5</a></p>\n<p>El contenido de la tu fichero Jenkinfile.</p>\n<pre><code>pipeline &#123;\n    environment &#123;\n        TOKEN = credentials('SURGE_TOKEN')\n      &#125;\n    agent &#123;\n        docker &#123; image 'josedom24/debian-npm'\n        args '-u root:root'\n        &#125;\n    &#125;\n    stages &#123;\n        stage('Clone') &#123;\n            steps &#123;\n                git branch:'master',url:'https://github.com/Evanticks/ic-html5.git'\n            &#125;\n        &#125;\n        \n        stage('Install surge')\n        &#123;\n            steps &#123;\n                sh 'npm install -g surge'\n            &#125;\n        &#125;\n        stage('Deploy')\n        &#123;\n            steps&#123;\n                sh 'surge ./_build/ antoniomarchan.surge.sh --token $TOKEN'\n            &#125;\n        &#125;\n        \n    &#125;\n&#125;\n</code></pre>\n<p>Captura de pantalla donde se vea donde has creado las credenciales necesarias.</p>\n<p><img src=\"/images/jenkins-taller-2-1.png\" alt=\"Jenkins\"></p>\n<p>Explica la configuración necesaria y una prueba de funcionamiento para que se dispare el pipeline cuando hagamos un push al repositorio.</p>\n<p>Primero exponemos el servicio de Jenkins a una url pública gracias a ngrok como explico en <a href=\"https://dit.gonzalonazareno.org/redmine/boards/16/topics/1016\">https://dit.gonzalonazareno.org/redmine/boards/16/topics/1016</a></p>\n<p>Luego hacemos las credenciales para que Jenkins pueda publicar a través del token de <a href=\"http://surge.sh\">surge.sh</a></p>\n<p>Luego crearemos un webhook ingresando la url pública de ngrok.</p>\n<p>Y ya con eso a la hora de hacer un push, Jenkins se encargará de construir el pipelinem, tardará 1 minuto.</p>\n<p><img src=\"/images/jenkins-taller-2-2.gif\" alt=\"Jenkins\"></p>\n<h2 id=\"taller-3-integración-continua-de-aplicación-django-test\"><a class=\"markdownIt-Anchor\" href=\"#taller-3-integración-continua-de-aplicación-django-test\">#</a> Taller 3: Integración continua de aplicación django (Test)</h2>\n<p>Una captura de pantalla donde se vea la salida de un build que se ha ejecutado de manera correcta.</p>\n<p><img src=\"/images/jenkins-taller-3-3.png\" alt=\"Jenkins\"></p>\n<p>Modifica el código de la aplicación para que se produzca un fallo en el código. *Recuerda que para hacer fallar un test, no hay que tocar el fichero <a href=\"http://test.py\">test.py</a>. Los test no se pasan porque al modificar el código de la aplicación se dejan de cumplir las condiciones indicadas en los test. Recuerda no elegir en el que hemos visto en este taller:mensaje *“No polls are available” **.</p>\n<p><img src=\"/images/jenkins-taller-3-4.png\" alt=\"Jenkins\"></p>\n<p>Una captura de pantalla donde se vea la salida de un build que se ha ejecutado con errores de testeo.</p>\n<p><img src=\"/images/jenkins-taller-3-5.png\" alt=\"Jenkins\"></p>\n"},{"title":"IC/DC con Jenkins","Categoría":"Aplicaciones web","_content":"\n![Jenkins](/images/jenkins-logo.png)\n\n\n\n\n# Práctica: IC/DC con Jenkins\n\n## Ejercicio 1: Construcción de una imagen docker\n\n\n```\npipeline {\n    environment {\n        IMAGEN = \"evanticks/django_tutorial\"\n        LOGIN = 'USER_DOCKERHUB'\n    }\n    agent none\n    stages {\n        stage(\"Desarrollo\") {\n            agent {\n                docker { image \"python:3\"\n                args '-u root:root'\n                }\n            }\n            stages {\n                stage('Clone') {\n                    steps {\n                        git branch:'main',url:'https://github.com/Evanticks/jenkins-django.git'\n                    }\n                }\n                stage('Install') {\n                    steps {\n                        sh 'pip install -r requirements.txt'\n                    }\n                }\n                stage('Test')\n                {\n                    steps {\n                        sh 'python3 manage.py test'\n                    }\n                }\n\n            }\n        }\n        stage(\"Construccion\") {\n            agent any\n            stages {\n                stage('CloneAnfitrion') {\n                    steps {\n                        git branch:'main',url:'https://github.com/Evanticks/docker-django.git'\n                    }\n                }\n                stage('BuildImage') {\n                    steps {\n                        script {\n                            newApp = docker.build \"$IMAGEN:latest\"\n                        }\n                    }\n                }\n                stage('UploadImage') {\n                    steps {\n                        script {\n                            docker.withRegistry( '', LOGIN ) {\n                                newApp.push()\n                            }\n                        }\n                    }\n                }\n                stage('RemoveImage') {\n                    steps {\n                        sh \"docker rmi $IMAGEN:latest\"\n                    }\n                }\n            }\n        }           \n    }\n    post {\n        always {\n            mail to: 'antonio@gonzalonazareno.org',\n            subject: \"Status of pipeline: ${currentBuild.fullDisplayName}\",\n            body: \"${env.BUILD_URL} has result ${currentBuild.result}\"\n        }\n    }\n}\n```\n\n\n\n\n\n\nUna captura de pantalla donde se vea la salida de un build que se ha ejecutado de manera correcta.\n\n![Jenkins](/images/practica-jenkins-1.png)\n![Jenkins](/images/practica-jenkins-3.png)\nUna captura de pantalla de tu cuenta de Docker Hub donde se vea la imagen subida de último build.\n\n![Jenkins](/images/practica-jenkins-1-1.png)\n\nIntroduce un fallo en el Dockerfile y muestra la salida del build donde se produce el error.\n\n![Jenkins](/images/practica-jenkins-2-2.png)\n\nEntrega la URL del repositorio para ver el Jenkinsfile.\n\nhttps://github.com/Evanticks/jenkins-django\n\nPantallazo con el correo que has recibido de la ejecución del pipeline.\n\n![Jenkins](/images/practica-jenkins-4.png)\n\n\n## Ejercicio 2: Despliegue de la aplicación\n\n\n```\npipeline {\n    environment {\n        IMAGEN = \"evanticks/django_tutorial\"\n        LOGIN = 'USER_DOCKERHUB'\n    }\n    agent none\n    stages {\n        stage(\"Desarrollo\") {\n            agent {\n                docker { image \"python:3\"\n                args '-u root:root'\n                }\n            }\n            stages {\n                stage('Clone') {\n                    steps {\n                        git branch:'main',url:'https://github.com/Evanticks/jenkins-django.git'\n                    }\n                }\n                stage('Install') {\n                    steps {\n                        sh 'pip install -r requirements.txt'\n                    }\n                }\n                stage('Test')\n                {\n                    steps {\n                        sh 'python3 manage.py test'\n                    }\n                }\n\n            }\n        }\n        stage(\"Construccion\") {\n            agent any\n            stages {\n                stage('CloneAnfitrion') {\n                    steps {\n                        git branch:'main',url:'https://github.com/Evanticks/docker-django.git'\n                    }\n                }\n                stage('BuildImage') {\n                    steps {\n                        script {\n                            newApp = docker.build \"$IMAGEN:latest\"\n                        }\n                    }\n                }\n                stage('UploadImage') {\n                    steps {\n                        script {\n                            docker.withRegistry( '', LOGIN ) {\n                                newApp.push()\n                            }\n                        }\n                    }\n                }\n                stage('RemoveImage') {\n                    steps {\n                        sh \"docker rmi $IMAGEN:latest\"\n                    }\n                }\n                stage ('SSH') {\n                    steps{\n                        sshagent(credentials : ['SSH_ROOT']) {\n                            sh 'ssh -o StrictHostKeyChecking=no shinji@evangelion.entrebytes.org docker rmi -f $IMAGEN:latest'\n                            sh 'ssh -o StrictHostKeyChecking=no shinji@evangelion.entrebytes.org wget https://raw.githubusercontent.com/Evanticks/docker-django/main/docker-compose.yaml -O docker-compose.yaml'\n                            sh 'ssh -o StrictHostKeyChecking=no shinji@evangelion.entrebytes.org docker-compose up -d --force-recreate'\n                        }\n                    }\n                }\n            }\n        }           \n    }\n    post {\n        always {\n            mail to: 'antonio@antonio.gonzalonazareno.org',\n            subject: \"Status of pipeline: ${currentBuild.fullDisplayName}\",\n            body: \"${env.BUILD_URL} has result ${currentBuild.result}\"\n        }\n    }\n}\n\n```\n\n\ndocker rmi $(docker images --filter “dangling=true” -q --no-trunc)\n\n\nEl contenido del fichero Jenkinsfile.\n\nEstá arriba.\n\nLas credenciales que has guardado en Jenkins.\n\n![Jenkins](/images/practica-jenkins-5.png)\n\nDemuestra al profesor como se realiza la IC/DC completo.","source":"_posts/jenkins-practica.md","raw":"---\ntitle: IC/DC con Jenkins\nCategoría: Aplicaciones web\n---\n\n![Jenkins](/images/jenkins-logo.png)\n\n\n\n\n# Práctica: IC/DC con Jenkins\n\n## Ejercicio 1: Construcción de una imagen docker\n\n\n```\npipeline {\n    environment {\n        IMAGEN = \"evanticks/django_tutorial\"\n        LOGIN = 'USER_DOCKERHUB'\n    }\n    agent none\n    stages {\n        stage(\"Desarrollo\") {\n            agent {\n                docker { image \"python:3\"\n                args '-u root:root'\n                }\n            }\n            stages {\n                stage('Clone') {\n                    steps {\n                        git branch:'main',url:'https://github.com/Evanticks/jenkins-django.git'\n                    }\n                }\n                stage('Install') {\n                    steps {\n                        sh 'pip install -r requirements.txt'\n                    }\n                }\n                stage('Test')\n                {\n                    steps {\n                        sh 'python3 manage.py test'\n                    }\n                }\n\n            }\n        }\n        stage(\"Construccion\") {\n            agent any\n            stages {\n                stage('CloneAnfitrion') {\n                    steps {\n                        git branch:'main',url:'https://github.com/Evanticks/docker-django.git'\n                    }\n                }\n                stage('BuildImage') {\n                    steps {\n                        script {\n                            newApp = docker.build \"$IMAGEN:latest\"\n                        }\n                    }\n                }\n                stage('UploadImage') {\n                    steps {\n                        script {\n                            docker.withRegistry( '', LOGIN ) {\n                                newApp.push()\n                            }\n                        }\n                    }\n                }\n                stage('RemoveImage') {\n                    steps {\n                        sh \"docker rmi $IMAGEN:latest\"\n                    }\n                }\n            }\n        }           \n    }\n    post {\n        always {\n            mail to: 'antonio@gonzalonazareno.org',\n            subject: \"Status of pipeline: ${currentBuild.fullDisplayName}\",\n            body: \"${env.BUILD_URL} has result ${currentBuild.result}\"\n        }\n    }\n}\n```\n\n\n\n\n\n\nUna captura de pantalla donde se vea la salida de un build que se ha ejecutado de manera correcta.\n\n![Jenkins](/images/practica-jenkins-1.png)\n![Jenkins](/images/practica-jenkins-3.png)\nUna captura de pantalla de tu cuenta de Docker Hub donde se vea la imagen subida de último build.\n\n![Jenkins](/images/practica-jenkins-1-1.png)\n\nIntroduce un fallo en el Dockerfile y muestra la salida del build donde se produce el error.\n\n![Jenkins](/images/practica-jenkins-2-2.png)\n\nEntrega la URL del repositorio para ver el Jenkinsfile.\n\nhttps://github.com/Evanticks/jenkins-django\n\nPantallazo con el correo que has recibido de la ejecución del pipeline.\n\n![Jenkins](/images/practica-jenkins-4.png)\n\n\n## Ejercicio 2: Despliegue de la aplicación\n\n\n```\npipeline {\n    environment {\n        IMAGEN = \"evanticks/django_tutorial\"\n        LOGIN = 'USER_DOCKERHUB'\n    }\n    agent none\n    stages {\n        stage(\"Desarrollo\") {\n            agent {\n                docker { image \"python:3\"\n                args '-u root:root'\n                }\n            }\n            stages {\n                stage('Clone') {\n                    steps {\n                        git branch:'main',url:'https://github.com/Evanticks/jenkins-django.git'\n                    }\n                }\n                stage('Install') {\n                    steps {\n                        sh 'pip install -r requirements.txt'\n                    }\n                }\n                stage('Test')\n                {\n                    steps {\n                        sh 'python3 manage.py test'\n                    }\n                }\n\n            }\n        }\n        stage(\"Construccion\") {\n            agent any\n            stages {\n                stage('CloneAnfitrion') {\n                    steps {\n                        git branch:'main',url:'https://github.com/Evanticks/docker-django.git'\n                    }\n                }\n                stage('BuildImage') {\n                    steps {\n                        script {\n                            newApp = docker.build \"$IMAGEN:latest\"\n                        }\n                    }\n                }\n                stage('UploadImage') {\n                    steps {\n                        script {\n                            docker.withRegistry( '', LOGIN ) {\n                                newApp.push()\n                            }\n                        }\n                    }\n                }\n                stage('RemoveImage') {\n                    steps {\n                        sh \"docker rmi $IMAGEN:latest\"\n                    }\n                }\n                stage ('SSH') {\n                    steps{\n                        sshagent(credentials : ['SSH_ROOT']) {\n                            sh 'ssh -o StrictHostKeyChecking=no shinji@evangelion.entrebytes.org docker rmi -f $IMAGEN:latest'\n                            sh 'ssh -o StrictHostKeyChecking=no shinji@evangelion.entrebytes.org wget https://raw.githubusercontent.com/Evanticks/docker-django/main/docker-compose.yaml -O docker-compose.yaml'\n                            sh 'ssh -o StrictHostKeyChecking=no shinji@evangelion.entrebytes.org docker-compose up -d --force-recreate'\n                        }\n                    }\n                }\n            }\n        }           \n    }\n    post {\n        always {\n            mail to: 'antonio@antonio.gonzalonazareno.org',\n            subject: \"Status of pipeline: ${currentBuild.fullDisplayName}\",\n            body: \"${env.BUILD_URL} has result ${currentBuild.result}\"\n        }\n    }\n}\n\n```\n\n\ndocker rmi $(docker images --filter “dangling=true” -q --no-trunc)\n\n\nEl contenido del fichero Jenkinsfile.\n\nEstá arriba.\n\nLas credenciales que has guardado en Jenkins.\n\n![Jenkins](/images/practica-jenkins-5.png)\n\nDemuestra al profesor como se realiza la IC/DC completo.","slug":"jenkins-practica","published":1,"date":"2023-03-08T19:37:31.646Z","updated":"2023-03-09T01:32:01.289Z","_id":"clf0852bv0000hai581gy2szj","comments":1,"layout":"post","photos":[],"link":"","content":"<p><img src=\"/images/jenkins-logo.png\" alt=\"Jenkins\"></p>\n<h1 id=\"práctica-icdc-con-jenkins\"><a class=\"markdownIt-Anchor\" href=\"#práctica-icdc-con-jenkins\">#</a> Práctica: IC/DC con Jenkins</h1>\n<h2 id=\"ejercicio-1-construcción-de-una-imagen-docker\"><a class=\"markdownIt-Anchor\" href=\"#ejercicio-1-construcción-de-una-imagen-docker\">#</a> Ejercicio 1: Construcción de una imagen docker</h2>\n<pre><code>pipeline &#123;\n    environment &#123;\n        IMAGEN = &quot;evanticks/django_tutorial&quot;\n        LOGIN = 'USER_DOCKERHUB'\n    &#125;\n    agent none\n    stages &#123;\n        stage(&quot;Desarrollo&quot;) &#123;\n            agent &#123;\n                docker &#123; image &quot;python:3&quot;\n                args '-u root:root'\n                &#125;\n            &#125;\n            stages &#123;\n                stage('Clone') &#123;\n                    steps &#123;\n                        git branch:'main',url:'https://github.com/Evanticks/jenkins-django.git'\n                    &#125;\n                &#125;\n                stage('Install') &#123;\n                    steps &#123;\n                        sh 'pip install -r requirements.txt'\n                    &#125;\n                &#125;\n                stage('Test')\n                &#123;\n                    steps &#123;\n                        sh 'python3 manage.py test'\n                    &#125;\n                &#125;\n\n            &#125;\n        &#125;\n        stage(&quot;Construccion&quot;) &#123;\n            agent any\n            stages &#123;\n                stage('CloneAnfitrion') &#123;\n                    steps &#123;\n                        git branch:'main',url:'https://github.com/Evanticks/docker-django.git'\n                    &#125;\n                &#125;\n                stage('BuildImage') &#123;\n                    steps &#123;\n                        script &#123;\n                            newApp = docker.build &quot;$IMAGEN:latest&quot;\n                        &#125;\n                    &#125;\n                &#125;\n                stage('UploadImage') &#123;\n                    steps &#123;\n                        script &#123;\n                            docker.withRegistry( '', LOGIN ) &#123;\n                                newApp.push()\n                            &#125;\n                        &#125;\n                    &#125;\n                &#125;\n                stage('RemoveImage') &#123;\n                    steps &#123;\n                        sh &quot;docker rmi $IMAGEN:latest&quot;\n                    &#125;\n                &#125;\n            &#125;\n        &#125;           \n    &#125;\n    post &#123;\n        always &#123;\n            mail to: 'antonio@gonzalonazareno.org',\n            subject: &quot;Status of pipeline: $&#123;currentBuild.fullDisplayName&#125;&quot;,\n            body: &quot;$&#123;env.BUILD_URL&#125; has result $&#123;currentBuild.result&#125;&quot;\n        &#125;\n    &#125;\n&#125;\n</code></pre>\n<p>Una captura de pantalla donde se vea la salida de un build que se ha ejecutado de manera correcta.</p>\n<p><img src=\"/images/practica-jenkins-1.png\" alt=\"Jenkins\"><br>\n<img src=\"/images/practica-jenkins-3.png\" alt=\"Jenkins\"><br>\nUna captura de pantalla de tu cuenta de Docker Hub donde se vea la imagen subida de último build.</p>\n<p><img src=\"/images/practica-jenkins-1-1.png\" alt=\"Jenkins\"></p>\n<p>Introduce un fallo en el Dockerfile y muestra la salida del build donde se produce el error.</p>\n<p><img src=\"/images/practica-jenkins-2-2.png\" alt=\"Jenkins\"></p>\n<p>Entrega la URL del repositorio para ver el Jenkinsfile.</p>\n<p><a href=\"https://github.com/Evanticks/jenkins-django\">https://github.com/Evanticks/jenkins-django</a></p>\n<p>Pantallazo con el correo que has recibido de la ejecución del pipeline.</p>\n<p><img src=\"/images/practica-jenkins-4.png\" alt=\"Jenkins\"></p>\n<h2 id=\"ejercicio-2-despliegue-de-la-aplicación\"><a class=\"markdownIt-Anchor\" href=\"#ejercicio-2-despliegue-de-la-aplicación\">#</a> Ejercicio 2: Despliegue de la aplicación</h2>\n<pre><code>pipeline &#123;\n    environment &#123;\n        IMAGEN = &quot;evanticks/django_tutorial&quot;\n        LOGIN = 'USER_DOCKERHUB'\n    &#125;\n    agent none\n    stages &#123;\n        stage(&quot;Desarrollo&quot;) &#123;\n            agent &#123;\n                docker &#123; image &quot;python:3&quot;\n                args '-u root:root'\n                &#125;\n            &#125;\n            stages &#123;\n                stage('Clone') &#123;\n                    steps &#123;\n                        git branch:'main',url:'https://github.com/Evanticks/jenkins-django.git'\n                    &#125;\n                &#125;\n                stage('Install') &#123;\n                    steps &#123;\n                        sh 'pip install -r requirements.txt'\n                    &#125;\n                &#125;\n                stage('Test')\n                &#123;\n                    steps &#123;\n                        sh 'python3 manage.py test'\n                    &#125;\n                &#125;\n\n            &#125;\n        &#125;\n        stage(&quot;Construccion&quot;) &#123;\n            agent any\n            stages &#123;\n                stage('CloneAnfitrion') &#123;\n                    steps &#123;\n                        git branch:'main',url:'https://github.com/Evanticks/docker-django.git'\n                    &#125;\n                &#125;\n                stage('BuildImage') &#123;\n                    steps &#123;\n                        script &#123;\n                            newApp = docker.build &quot;$IMAGEN:latest&quot;\n                        &#125;\n                    &#125;\n                &#125;\n                stage('UploadImage') &#123;\n                    steps &#123;\n                        script &#123;\n                            docker.withRegistry( '', LOGIN ) &#123;\n                                newApp.push()\n                            &#125;\n                        &#125;\n                    &#125;\n                &#125;\n                stage('RemoveImage') &#123;\n                    steps &#123;\n                        sh &quot;docker rmi $IMAGEN:latest&quot;\n                    &#125;\n                &#125;\n                stage ('SSH') &#123;\n                    steps&#123;\n                        sshagent(credentials : ['SSH_ROOT']) &#123;\n                            sh 'ssh -o StrictHostKeyChecking=no shinji@evangelion.entrebytes.org docker rmi -f $IMAGEN:latest'\n                            sh 'ssh -o StrictHostKeyChecking=no shinji@evangelion.entrebytes.org wget https://raw.githubusercontent.com/Evanticks/docker-django/main/docker-compose.yaml -O docker-compose.yaml'\n                            sh 'ssh -o StrictHostKeyChecking=no shinji@evangelion.entrebytes.org docker-compose up -d --force-recreate'\n                        &#125;\n                    &#125;\n                &#125;\n            &#125;\n        &#125;           \n    &#125;\n    post &#123;\n        always &#123;\n            mail to: 'antonio@antonio.gonzalonazareno.org',\n            subject: &quot;Status of pipeline: $&#123;currentBuild.fullDisplayName&#125;&quot;,\n            body: &quot;$&#123;env.BUILD_URL&#125; has result $&#123;currentBuild.result&#125;&quot;\n        &#125;\n    &#125;\n&#125;\n\n</code></pre>\n<p>docker rmi $(docker images --filter “dangling=true” -q --no-trunc)</p>\n<p>El contenido del fichero Jenkinsfile.</p>\n<p>Está arriba.</p>\n<p>Las credenciales que has guardado en Jenkins.</p>\n<p><img src=\"/images/practica-jenkins-5.png\" alt=\"Jenkins\"></p>\n<p>Demuestra al profesor como se realiza la IC/DC completo.</p>\n","site":{"data":{}},"length":3673,"excerpt":"","more":"<p><img src=\"/images/jenkins-logo.png\" alt=\"Jenkins\"></p>\n<h1 id=\"práctica-icdc-con-jenkins\"><a class=\"markdownIt-Anchor\" href=\"#práctica-icdc-con-jenkins\">#</a> Práctica: IC/DC con Jenkins</h1>\n<h2 id=\"ejercicio-1-construcción-de-una-imagen-docker\"><a class=\"markdownIt-Anchor\" href=\"#ejercicio-1-construcción-de-una-imagen-docker\">#</a> Ejercicio 1: Construcción de una imagen docker</h2>\n<pre><code>pipeline &#123;\n    environment &#123;\n        IMAGEN = &quot;evanticks/django_tutorial&quot;\n        LOGIN = 'USER_DOCKERHUB'\n    &#125;\n    agent none\n    stages &#123;\n        stage(&quot;Desarrollo&quot;) &#123;\n            agent &#123;\n                docker &#123; image &quot;python:3&quot;\n                args '-u root:root'\n                &#125;\n            &#125;\n            stages &#123;\n                stage('Clone') &#123;\n                    steps &#123;\n                        git branch:'main',url:'https://github.com/Evanticks/jenkins-django.git'\n                    &#125;\n                &#125;\n                stage('Install') &#123;\n                    steps &#123;\n                        sh 'pip install -r requirements.txt'\n                    &#125;\n                &#125;\n                stage('Test')\n                &#123;\n                    steps &#123;\n                        sh 'python3 manage.py test'\n                    &#125;\n                &#125;\n\n            &#125;\n        &#125;\n        stage(&quot;Construccion&quot;) &#123;\n            agent any\n            stages &#123;\n                stage('CloneAnfitrion') &#123;\n                    steps &#123;\n                        git branch:'main',url:'https://github.com/Evanticks/docker-django.git'\n                    &#125;\n                &#125;\n                stage('BuildImage') &#123;\n                    steps &#123;\n                        script &#123;\n                            newApp = docker.build &quot;$IMAGEN:latest&quot;\n                        &#125;\n                    &#125;\n                &#125;\n                stage('UploadImage') &#123;\n                    steps &#123;\n                        script &#123;\n                            docker.withRegistry( '', LOGIN ) &#123;\n                                newApp.push()\n                            &#125;\n                        &#125;\n                    &#125;\n                &#125;\n                stage('RemoveImage') &#123;\n                    steps &#123;\n                        sh &quot;docker rmi $IMAGEN:latest&quot;\n                    &#125;\n                &#125;\n            &#125;\n        &#125;           \n    &#125;\n    post &#123;\n        always &#123;\n            mail to: 'antonio@gonzalonazareno.org',\n            subject: &quot;Status of pipeline: $&#123;currentBuild.fullDisplayName&#125;&quot;,\n            body: &quot;$&#123;env.BUILD_URL&#125; has result $&#123;currentBuild.result&#125;&quot;\n        &#125;\n    &#125;\n&#125;\n</code></pre>\n<p>Una captura de pantalla donde se vea la salida de un build que se ha ejecutado de manera correcta.</p>\n<p><img src=\"/images/practica-jenkins-1.png\" alt=\"Jenkins\"><br>\n<img src=\"/images/practica-jenkins-3.png\" alt=\"Jenkins\"><br>\nUna captura de pantalla de tu cuenta de Docker Hub donde se vea la imagen subida de último build.</p>\n<p><img src=\"/images/practica-jenkins-1-1.png\" alt=\"Jenkins\"></p>\n<p>Introduce un fallo en el Dockerfile y muestra la salida del build donde se produce el error.</p>\n<p><img src=\"/images/practica-jenkins-2-2.png\" alt=\"Jenkins\"></p>\n<p>Entrega la URL del repositorio para ver el Jenkinsfile.</p>\n<p><a href=\"https://github.com/Evanticks/jenkins-django\">https://github.com/Evanticks/jenkins-django</a></p>\n<p>Pantallazo con el correo que has recibido de la ejecución del pipeline.</p>\n<p><img src=\"/images/practica-jenkins-4.png\" alt=\"Jenkins\"></p>\n<h2 id=\"ejercicio-2-despliegue-de-la-aplicación\"><a class=\"markdownIt-Anchor\" href=\"#ejercicio-2-despliegue-de-la-aplicación\">#</a> Ejercicio 2: Despliegue de la aplicación</h2>\n<pre><code>pipeline &#123;\n    environment &#123;\n        IMAGEN = &quot;evanticks/django_tutorial&quot;\n        LOGIN = 'USER_DOCKERHUB'\n    &#125;\n    agent none\n    stages &#123;\n        stage(&quot;Desarrollo&quot;) &#123;\n            agent &#123;\n                docker &#123; image &quot;python:3&quot;\n                args '-u root:root'\n                &#125;\n            &#125;\n            stages &#123;\n                stage('Clone') &#123;\n                    steps &#123;\n                        git branch:'main',url:'https://github.com/Evanticks/jenkins-django.git'\n                    &#125;\n                &#125;\n                stage('Install') &#123;\n                    steps &#123;\n                        sh 'pip install -r requirements.txt'\n                    &#125;\n                &#125;\n                stage('Test')\n                &#123;\n                    steps &#123;\n                        sh 'python3 manage.py test'\n                    &#125;\n                &#125;\n\n            &#125;\n        &#125;\n        stage(&quot;Construccion&quot;) &#123;\n            agent any\n            stages &#123;\n                stage('CloneAnfitrion') &#123;\n                    steps &#123;\n                        git branch:'main',url:'https://github.com/Evanticks/docker-django.git'\n                    &#125;\n                &#125;\n                stage('BuildImage') &#123;\n                    steps &#123;\n                        script &#123;\n                            newApp = docker.build &quot;$IMAGEN:latest&quot;\n                        &#125;\n                    &#125;\n                &#125;\n                stage('UploadImage') &#123;\n                    steps &#123;\n                        script &#123;\n                            docker.withRegistry( '', LOGIN ) &#123;\n                                newApp.push()\n                            &#125;\n                        &#125;\n                    &#125;\n                &#125;\n                stage('RemoveImage') &#123;\n                    steps &#123;\n                        sh &quot;docker rmi $IMAGEN:latest&quot;\n                    &#125;\n                &#125;\n                stage ('SSH') &#123;\n                    steps&#123;\n                        sshagent(credentials : ['SSH_ROOT']) &#123;\n                            sh 'ssh -o StrictHostKeyChecking=no shinji@evangelion.entrebytes.org docker rmi -f $IMAGEN:latest'\n                            sh 'ssh -o StrictHostKeyChecking=no shinji@evangelion.entrebytes.org wget https://raw.githubusercontent.com/Evanticks/docker-django/main/docker-compose.yaml -O docker-compose.yaml'\n                            sh 'ssh -o StrictHostKeyChecking=no shinji@evangelion.entrebytes.org docker-compose up -d --force-recreate'\n                        &#125;\n                    &#125;\n                &#125;\n            &#125;\n        &#125;           \n    &#125;\n    post &#123;\n        always &#123;\n            mail to: 'antonio@antonio.gonzalonazareno.org',\n            subject: &quot;Status of pipeline: $&#123;currentBuild.fullDisplayName&#125;&quot;,\n            body: &quot;$&#123;env.BUILD_URL&#125; has result $&#123;currentBuild.result&#125;&quot;\n        &#125;\n    &#125;\n&#125;\n\n</code></pre>\n<p>docker rmi $(docker images --filter “dangling=true” -q --no-trunc)</p>\n<p>El contenido del fichero Jenkinsfile.</p>\n<p>Está arriba.</p>\n<p>Las credenciales que has guardado en Jenkins.</p>\n<p><img src=\"/images/practica-jenkins-5.png\" alt=\"Jenkins\"></p>\n<p>Demuestra al profesor como se realiza la IC/DC completo.</p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cldl9ucgc00010yi54vf709rr","category_id":"cldl9ucgh00040yi5edldd0zy","_id":"cldl9ucgn000g0yi5gc3ihjfa"},{"post_id":"cldl9ucgm000e0yi54atb1sxm","category_id":"cldl9ucgh00040yi5edldd0zy","_id":"cldl9ucgp000m0yi52gm83xpp"},{"post_id":"cldl9ucgg00030yi54f2j8x4u","category_id":"cldl9ucgl000b0yi54x783cwm","_id":"cldl9ucgs000q0yi532r3gxtp"},{"post_id":"cldl9ucgm000f0yi5d17u6m4k","category_id":"cldl9ucgh00040yi5edldd0zy","_id":"cldl9ucgt000s0yi58uytasup"},{"post_id":"cldl9ucgo000j0yi56s67411j","category_id":"cldl9ucgl000b0yi54x783cwm","_id":"cldl9ucgu000u0yi583e2fr7g"},{"post_id":"cldl9ucgk00090yi5dce34dzi","category_id":"cldl9ucgn000h0yi5dzea5q6a","_id":"cldl9ucgu000v0yi5gy6r9w01"},{"post_id":"cldl9ucgo000l0yi5cieaakom","category_id":"cldl9ucgn000h0yi5dzea5q6a","_id":"cldl9ucgu000w0yi59iedgg8q"},{"post_id":"cldl9ucgl000a0yi59nosa7ld","category_id":"cldl9ucgl000b0yi54x783cwm","_id":"cldl9ucgu000x0yi506w3bb9v"},{"post_id":"cldl9ucgs000r0yi59e1nf2e8","category_id":"cldl9ucgl000b0yi54x783cwm","_id":"cldl9ucgu000y0yi5g36mc16s"},{"post_id":"cldl9ucgr000p0yi51470589v","category_id":"cldl9ucgu000t0yi559vsbdg5","_id":"cldl9ucgu000z0yi53ocdh7ch"},{"post_id":"cldl9ucgv00100yi59b3p524w","category_id":"cldl9ucgw00120yi58s9r89pz","_id":"cldl9ucgx00170yi54l1g38ik"},{"post_id":"cldl9ucgv00110yi5btc1d0dt","category_id":"cldl9ucgw00120yi58s9r89pz","_id":"cldl9ucgx00190yi5dsav4ygt"},{"post_id":"cldm4xm980000qni5eok90jyo","category_id":"cldm4xm9f0001qni538qo5xbj","_id":"cldm4xm9j0002qni5csmc7yy0"},{"post_id":"cldmvsvq60000m3i517ps0ez0","category_id":"cldmvsvqn0001m3i53fhe1t18","_id":"cldmvsvqu0002m3i53z6ce3rq"},{"post_id":"cldn18mbc00004qi5fptd4r6q","category_id":"cldmvsvqn0001m3i53fhe1t18","_id":"cldn2xts000003ti52tznfvd8"},{"post_id":"cldrq0zqd0000v4i5720cdi7e","category_id":"cldrq0zqq0001v4i565i6dei6","_id":"cldrq0zqx0002v4i53hjzcfoh"}],"PostTag":[{"post_id":"cldl9ucgc00010yi54vf709rr","tag_id":"cldl9ucgi00050yi5bcjoehs3","_id":"cldl9ucgm000d0yi54m1fg1ko"},{"post_id":"cldl9ucgm000e0yi54atb1sxm","tag_id":"cldl9ucgi00050yi5bcjoehs3","_id":"cldl9ucgn000i0yi5dy7fgpqu"},{"post_id":"cldl9ucgg00030yi54f2j8x4u","tag_id":"cldl9ucgl000c0yi51e14560y","_id":"cldl9ucgo000k0yi5ao3r57up"},{"post_id":"cldl9ucgm000f0yi5d17u6m4k","tag_id":"cldl9ucgi00050yi5bcjoehs3","_id":"cldl9ucgq000o0yi53fks7ifi"},{"post_id":"cldl9ucgv00100yi59b3p524w","tag_id":"cldl9ucgw00130yi5ec9efp2y","_id":"cldl9ucgw00160yi5a2uo3ujz"},{"post_id":"cldl9ucgv00110yi5btc1d0dt","tag_id":"cldl9ucgw00130yi5ec9efp2y","_id":"cldl9ucgx00180yi5c0iwcsmc"}],"Tag":[{"name":"Servicios de Red e Internet","_id":"cldl9ucgi00050yi5bcjoehs3"},{"name":"Sistemas Operativos","_id":"cldl9ucgl000c0yi51e14560y"},{"name":"Seguridad","_id":"cldl9ucgw00130yi5ec9efp2y"}]}}